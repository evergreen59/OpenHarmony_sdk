commit ca784e92825462f8ef3065651e4d3784eacd70f2
Author: zhaoxc0502 <zhaoxc0502@thundersoft.com>
Date:   Fri Aug 12 09:44:46 2022 +0800

    0030_linux_drivers_pci_misc_nvmem_of_mtd_mmc
    
    Change-Id: Iec160bd007994d82f416debdccfbc0d9bdb40470

diff --git a/drivers/misc/Kconfig b/drivers/misc/Kconfig
index fafa8b0d8..2063f1930 100644
--- a/drivers/misc/Kconfig
+++ b/drivers/misc/Kconfig
@@ -314,6 +314,26 @@ config ISL29020
 	  This driver can also be built as a module.  If so, the module
 	  will be called isl29020.
 
+config SENSORS_FXOS8700
+	tristate "Freescale FXOS8700 M+G combo sensor"
+	depends on I2C && SYSFS
+	help
+	  If you say yes here you get support for the Freescale FXOS8700
+	  m+g combo  sensor.
+
+	  This driver can also be built as a module.  If so, the module
+	  will be called fxos8700.
+
+config SENSORS_FXAS2100X
+	tristate "Freescale FXAS2100X gyroscope sensor"
+	depends on I2C && SYSFS
+	help
+	  If you say yes here you get support for the Freescale FXAS2100X
+	  gyroscope sensor.
+
+	  This driver can also be built as a module.  If so, the module
+	  will be called fxas2100x.
+
 config SENSORS_TSL2550
 	tristate "Taos TSL2550 ambient light sensor"
 	depends on I2C && SYSFS
diff --git a/drivers/misc/Makefile b/drivers/misc/Makefile
index d23231e73..5e27f80f6 100644
--- a/drivers/misc/Makefile
+++ b/drivers/misc/Makefile
@@ -19,6 +19,8 @@ obj-$(CONFIG_TIFM_7XX1)       	+= tifm_7xx1.o
 obj-$(CONFIG_PHANTOM)		+= phantom.o
 obj-$(CONFIG_QCOM_COINCELL)	+= qcom-coincell.o
 obj-$(CONFIG_QCOM_FASTRPC)	+= fastrpc.o
+obj-$(CONFIG_SENSORS_FXOS8700)  += fxos8700.o
+obj-$(CONFIG_SENSORS_FXAS2100X) += fxas2100x.o
 obj-$(CONFIG_SENSORS_BH1770)	+= bh1770glc.o
 obj-$(CONFIG_SENSORS_APDS990X)	+= apds990x.o
 obj-$(CONFIG_ENCLOSURE_SERVICES) += enclosure.o
diff --git a/drivers/misc/fxas2100x.c b/drivers/misc/fxas2100x.c
new file mode 100644
index 000000000..04541cfb5
--- /dev/null
+++ b/drivers/misc/fxas2100x.c
@@ -0,0 +1,628 @@
+/*
+ * Copyright (C) 2012-2015 Freescale Semiconductor, Inc. All Rights Reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.
+ */
+
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/slab.h>
+#include <linux/i2c.h>
+#include <linux/pm.h>
+#include <linux/mutex.h>
+#include <linux/delay.h>
+#include <linux/interrupt.h>
+#include <linux/irq.h>
+#include <linux/hwmon-sysfs.h>
+#include <linux/err.h>
+#include <linux/hwmon.h>
+#include <linux/input-polldev.h>
+#include <linux/miscdevice.h>
+#include <linux/poll.h>
+
+#define	SENSOR_IOCTL_BASE	'S'
+#define	SENSOR_GET_MODEL_NAME		_IOR(SENSOR_IOCTL_BASE, 0, char *)
+#define	SENSOR_GET_POWER_STATUS		_IOR(SENSOR_IOCTL_BASE, 2, int)
+#define	SENSOR_SET_POWER_STATUS		_IOR(SENSOR_IOCTL_BASE, 3, int)
+#define	SENSOR_GET_DELAY_TIME		_IOR(SENSOR_IOCTL_BASE, 4, int)
+#define	SENSOR_SET_DELAY_TIME		_IOR(SENSOR_IOCTL_BASE, 5, int)
+#define	SENSOR_GET_RAW_DATA		_IOR(SENSOR_IOCTL_BASE, 6, short[3])
+
+#define FXAS2100X_I2C_ADDR	0x20
+#define FXAS21000_CHIP_ID	0xD1
+#define FXAS21002_CHID_ID_1	0xD6
+#define FXAS21002_CHID_ID_2	0xD7
+
+#define FXAS2100X_POSITION_DEFAULT	2
+#define FXAS2100X_DELAY_DEFAULT		200
+
+#define FXAS2100X_STATUS_ZYXDR	0x08
+#define FXAS2100X_BUF_SIZE	6
+
+#define FXAS2100X_POLL_INTERVAL	400
+#define FXAS2100X_POLL_MAX	800
+#define FXAS2100X_POLL_MIN	200
+#define ABSMIN_GYRO_VAL		-32768
+#define ABSMAX_GYRO_VAL		32768
+
+#define FXAS2100X_DRIVER	"fxas2100x"
+
+/* register enum for fxas2100x registers */
+enum {
+	FXAS2100X_STATUS = 0x00,
+	FXAS2100X_OUT_X_MSB,
+	FXAS2100X_OUT_X_LSB,
+	FXAS2100X_OUT_Y_MSB,
+	FXAS2100X_OUT_Y_LSB,
+	FXAS2100X_OUT_Z_MSB,
+	FXAS2100X_OUT_Z_LSB,
+	FXAS2100X_DR_STATUS,
+	FXAS2100X_F_STATUS,
+	FXAS2100X_F_SETUP,
+	FXAS2100X_F_EVENT,
+	FXAS2100X_INT_SRC_FLAG,
+	FXAS2100X_WHO_AM_I,
+	FXAS2100X_CTRL_REG0,
+	FXAS2100X_RT_CFG,
+	FXAS2100X_RT_SRC,
+	FXAS2100X_RT_THS,
+	FXAS2100X_RT_COUNT,
+	FXAS2100X_TEMP,
+	FXAS2100X_CTRL_REG1,
+	FXAS2100X_CTRL_REG2,
+	FXAS2100X_CTRL_REG3, /* fxos21002 special */
+	FXAS2100X_REG_END,
+};
+
+enum {
+	STANDBY = 0,
+	ACTIVED,
+};
+
+struct fxas2100x_data_axis {
+	short x;
+	short y;
+	short z;
+};
+
+struct fxas2100x_data {
+	struct i2c_client *client;
+	struct input_polled_dev *input_polled;
+	atomic_t active;
+	atomic_t active_poll;
+	atomic_t delay;
+	atomic_t position;
+	u8 chip_id;
+};
+
+static struct fxas2100x_data *g_fxas2100x_data;
+
+static int fxas2100x_position_setting[8][3][3] = {
+	{ {0, -1, 0}, {1, 0, 0}, {0, 0, 1} },
+	{ {-1, 0, 0}, {0, -1, 0}, {0, 0, 1} },
+	{ {0, 1, 0}, {-1, 0, 0}, {0, 0, 1} },
+	{ {1, 0, 0}, {0, 1, 0}, {0, 0, 1} },
+	{ {0, -1, 0}, {-1, 0, 0}, {0, 0, -1} },
+	{ {-1, 0, 0}, {0, 1, 0}, {0, 0, -1} },
+	{ {0, 1, 0}, {1, 0, 0}, {0, 0, -1} },
+	{ {1, 0, 0}, {0, -1, 0}, {0, 0, -1} },
+};
+
+static int fxas2100x_data_convert(struct fxas2100x_data *pdata,
+		struct fxas2100x_data_axis *axis_data)
+{
+	short rawdata[3], data[3];
+	int i, j;
+	int position = atomic_read(&pdata->position);
+
+	if (position < 0 || position > 7)
+		position = 0;
+	rawdata[0] = axis_data->x;
+	rawdata[1] = axis_data->y;
+	rawdata[2] = axis_data->z;
+	for (i = 0; i < 3; i++) {
+		data[i] = 0;
+		for (j = 0; j < 3; j++)
+			data[i] += rawdata[j] * fxas2100x_position_setting[position][i][j];
+	}
+	axis_data->x = data[0];
+	axis_data->y = data[1];
+	axis_data->z = data[2];
+	return 0;
+}
+
+static int fxas2100x_device_init(struct i2c_client *client)
+{
+	int result;
+	u8 val;
+	struct device_node *np = client->dev.of_node;
+
+	struct fxas2100x_data *pdata = i2c_get_clientdata(client);
+	if (pdata->chip_id == FXAS21000_CHIP_ID)
+		val = (0x01 << 2); /* fxas21000 dr 200HZ */
+	else
+		val = (0x02 << 2); /* fxas21002 dr 200HZ */
+	result = i2c_smbus_write_byte_data(client, FXAS2100X_CTRL_REG1, val);
+	if (result < 0)
+		goto out;
+
+	/* set interrupt pin as open-drain */
+	if (of_get_property(np, "interrupt-open-drain", NULL)) {
+		result = i2c_smbus_write_byte_data(client, FXAS2100X_CTRL_REG2, 0x01);
+		if (result < 0)
+			goto out;
+	}
+
+	atomic_set(&pdata->active, STANDBY);
+	return 0;
+out:
+	dev_err(&client->dev, "error when init fxas2100x:(%d)", result);
+	return result;
+}
+
+static int fxas2100x_change_mode(struct i2c_client *client, int mode)
+{
+	u8 val;
+	int ret;
+	if (mode == ACTIVED) {
+		val = i2c_smbus_read_byte_data(client, FXAS2100X_CTRL_REG1);
+		val &= ~0x03;
+		val |= 0x02;
+		/* set bit 1 */
+		ret = i2c_smbus_write_byte_data(client, FXAS2100X_CTRL_REG1, val);
+	} else {
+		val = i2c_smbus_read_byte_data(client, FXAS2100X_CTRL_REG1);
+		val &= (~0x03);
+		/* clear bit 0,1 */
+		ret = i2c_smbus_write_byte_data(client, FXAS2100X_CTRL_REG1, val);
+	}
+	return ret;
+}
+
+static int fxas2100x_set_delay(struct i2c_client *client, int delay)
+{
+	return 0;
+}
+
+static int fxas2100x_device_stop(struct i2c_client *client)
+{
+	u8 val;
+	val = i2c_smbus_read_byte_data(client, FXAS2100X_CTRL_REG1);
+	val &= ~0x03;
+	i2c_smbus_write_byte_data(client, FXAS2100X_CTRL_REG1, val);
+	return 0;
+}
+
+static int fxas2100x_read_data(struct fxas2100x_data *pdata,
+		struct fxas2100x_data_axis *data)
+{
+	struct i2c_client * client = pdata->client;
+	int x, y, z;
+	u8 tmp_data[FXAS2100X_BUF_SIZE];
+	int ret;
+
+	ret = i2c_smbus_read_i2c_block_data(client, FXAS2100X_OUT_X_MSB,
+					    FXAS2100X_BUF_SIZE, tmp_data);
+	if (ret < FXAS2100X_BUF_SIZE) {
+		dev_err(&client->dev, "i2c block read failed\n");
+		return -EIO;
+	}
+	data->x = ((tmp_data[0] << 8) & 0xff00) | tmp_data[1];
+	data->y = ((tmp_data[2] << 8) & 0xff00) | tmp_data[3];
+	data->z = ((tmp_data[4] << 8) & 0xff00) | tmp_data[5];
+	if (pdata->chip_id == FXAS21000_CHIP_ID) {
+		x = data->x;
+		y = data->y;
+		z = data->z;
+		x = x * 4 / 5;
+		y = y * 4 / 5;
+		z = z * 4 / 5;
+		data->x = x;
+		data->y = y;
+		data->z = z;
+	}
+
+	return 0;
+}
+
+/* fxas2100x miscdevice */
+static long fxas2100x_ioctl(struct file *file, unsigned int cmd, unsigned long arg)
+{
+	struct fxas2100x_data *pdata = file->private_data;
+	void __user *argp = (void __user *)arg;
+	struct fxas2100x_data_axis data;
+	long ret = 0;
+	short sdata[3];
+	int enable;
+	int delay;
+
+	if (!pdata) {
+		printk(KERN_ERR "FXAS2100X struct datt point is NULL.");
+		return -EFAULT;
+	}
+
+	switch (cmd) {
+	case SENSOR_GET_MODEL_NAME:
+		if (copy_to_user(argp, "FXAS2100X GYRO", strlen("FXAS2100X GYRO") + 1)) {
+			printk(KERN_ERR "SENSOR_GET_MODEL_NAME copy_to_user failed.");
+			ret = -EFAULT;
+		}
+		break;
+	case SENSOR_GET_POWER_STATUS:
+		enable = atomic_read(&pdata->active);
+		if (copy_to_user(argp, &enable, sizeof(int))) {
+			printk(KERN_ERR "SENSOR_SET_POWER_STATUS copy_to_user failed.");
+			ret = -EFAULT;
+		}
+		break;
+	case SENSOR_SET_POWER_STATUS:
+		if (copy_from_user(&enable, argp, sizeof(int))) {
+			printk(KERN_ERR "SENSOR_SET_POWER_STATUS copy_to_user failed.");
+			ret = -EFAULT;
+		}
+		if (pdata->client) {
+			ret = fxas2100x_change_mode(pdata->client, enable ? ACTIVED : STANDBY);
+			if (!ret)
+				atomic_set(&pdata->active, enable);
+		}
+		break;
+	case SENSOR_GET_DELAY_TIME:
+		delay = atomic_read(&pdata->delay);
+		if (copy_to_user(argp, &delay, sizeof(delay))) {
+			printk(KERN_ERR "SENSOR_GET_DELAY_TIME copy_to_user failed.");
+			return -EFAULT;
+		}
+		break;
+	case SENSOR_SET_DELAY_TIME:
+		if (copy_from_user(&delay, argp, sizeof(int))) {
+			printk(KERN_ERR "SENSOR_GET_DELAY_TIME copy_to_user failed.");
+			ret = -EFAULT;
+		}
+		if (pdata->client && delay > 0 && delay <= 500) {
+			ret = fxas2100x_set_delay(pdata->client, delay);
+			if (!ret)
+				atomic_set(&pdata->delay, delay);
+		}
+		break;
+	case SENSOR_GET_RAW_DATA:
+		ret = fxas2100x_read_data(pdata, &data);
+		if (!ret) {
+			fxas2100x_data_convert(pdata, &data);
+			sdata[0] = data.x;
+			sdata[1] = data.y;
+			sdata[2] = data.z;
+			if (copy_to_user(argp, sdata, sizeof(sdata))) {
+				printk(KERN_ERR "SENSOR_GET_RAW_DATA copy_to_user failed.");
+				ret = -EFAULT;
+			}
+		}
+		break;
+	default:
+		ret = -1;
+	}
+
+	return ret;
+}
+
+static int fxas2100x_open(struct inode *inode, struct file *file)
+{
+	file->private_data = g_fxas2100x_data;
+	return nonseekable_open(inode, file);
+}
+
+static int fxas2100x_release(struct inode *inode, struct file *file)
+{
+	/* note: releasing the wdt in NOWAYOUT-mode does not stop it */
+	return 0;
+}
+
+static const struct file_operations fxas2100x_fops = {
+	.owner = THIS_MODULE,
+	.open = fxas2100x_open,
+	.release = fxas2100x_release,
+	.unlocked_ioctl = fxas2100x_ioctl,
+};
+
+static struct miscdevice fxas2100x_device = {
+	.minor = MISC_DYNAMIC_MINOR,
+	.name = "FreescaleGyroscope",
+	.fops = &fxas2100x_fops,
+};
+
+static ssize_t fxas2100x_enable_show(struct device *dev,
+				   struct device_attribute *attr, char *buf)
+{
+	struct fxas2100x_data *pdata = g_fxas2100x_data;
+	int enable = 0;
+	enable = atomic_read(&pdata->active);
+	return sprintf(buf, "%d\n", enable);
+}
+
+static ssize_t fxas2100x_enable_store(struct device *dev,
+				    struct device_attribute *attr,
+				    const char *buf, size_t count)
+{
+	struct fxas2100x_data *pdata = g_fxas2100x_data;
+	struct i2c_client *client = pdata->client;
+	int ret;
+	unsigned long enable;
+
+	if (kstrtoul(buf, 10, &enable) < 0)
+		return -EINVAL;
+
+	enable = (enable > 0) ? 1 : 0;
+	ret = fxas2100x_change_mode(client, (enable > 0 ? ACTIVED : STANDBY));
+	if (!ret) {
+		atomic_set(&pdata->active, enable);
+		atomic_set(&pdata->active_poll, enable);
+		dev_err(dev, "mma enable setting active \n");
+	}
+	return count;
+}
+
+static ssize_t fxas2100x_poll_delay_show(struct device *dev,
+				   struct device_attribute *attr, char *buf)
+{
+	struct fxas2100x_data *pdata = g_fxas2100x_data;
+	int delay = 0;
+
+	delay = atomic_read(&pdata->delay);
+	return sprintf(buf, "%d\n", delay);
+}
+
+static ssize_t fxas2100x_poll_delay_store(struct device *dev,
+				    struct device_attribute *attr,
+				    const char *buf, size_t count)
+{
+	struct fxas2100x_data *pdata = g_fxas2100x_data;
+	struct i2c_client *client = pdata->client;
+	int ret;
+	int delay;
+
+	delay = simple_strtoul(buf, NULL, 10);
+	ret = fxas2100x_set_delay(client, delay);
+	if (!ret)
+		atomic_set(&pdata->delay, delay);
+	return count;
+}
+
+static ssize_t fxas2100x_position_show(struct device *dev,
+				     struct device_attribute *attr, char *buf)
+{
+	struct fxas2100x_data *pdata = g_fxas2100x_data;
+	int position = 0;
+
+	position = atomic_read(&pdata->position);
+	return sprintf(buf, "%d\n", position);
+}
+
+static ssize_t fxas2100x_position_store(struct device *dev,
+				      struct device_attribute *attr,
+				      const char *buf, size_t count)
+{
+	struct fxas2100x_data *pdata = g_fxas2100x_data;
+	int position;
+
+	position = simple_strtoul(buf, NULL, 10);
+	atomic_set(&pdata->position, position);
+	return count;
+}
+
+static DEVICE_ATTR(enable, S_IWUSR | S_IRUGO, fxas2100x_enable_show, fxas2100x_enable_store);
+static DEVICE_ATTR(poll_delay, S_IWUSR | S_IRUGO, fxas2100x_poll_delay_show, fxas2100x_poll_delay_store);
+static DEVICE_ATTR(position, S_IWUSR | S_IRUGO, fxas2100x_position_show, fxas2100x_position_store);
+
+static struct attribute *fxas2100x_attributes[] = {
+	&dev_attr_enable.attr,
+	&dev_attr_poll_delay.attr,
+	&dev_attr_position.attr,
+	NULL
+};
+
+static const struct attribute_group fxas2100x_attr_group = {
+	.attrs	= fxas2100x_attributes,
+};
+
+static void fxas2100x_poll(struct input_polled_dev *dev)
+{
+	struct fxas2100x_data *pdata = g_fxas2100x_data;
+	struct input_dev *idev = pdata->input_polled->input;
+	struct fxas2100x_data_axis data;
+	int ret;
+
+	if (!(atomic_read(&pdata->active_poll)))
+		return;
+
+	ret = fxas2100x_read_data(pdata, &data);
+	if (!ret) {
+		fxas2100x_data_convert(pdata, &data);
+		input_report_abs(idev, ABS_X, data.x);
+		input_report_abs(idev, ABS_Y, data.y);
+		input_report_abs(idev, ABS_Z, data.z);
+		input_sync(idev);
+	}
+}
+
+static int fxas2100x_register_polled_device(struct fxas2100x_data *pdata)
+{
+	struct input_polled_dev *ipoll_dev;
+	struct input_dev *idev;
+	int error;
+
+	ipoll_dev = input_allocate_polled_device();
+	if (!ipoll_dev)
+		return -ENOMEM;
+
+	ipoll_dev->private = pdata;
+	ipoll_dev->poll = fxas2100x_poll;
+	ipoll_dev->poll_interval = FXAS2100X_POLL_INTERVAL;
+	ipoll_dev->poll_interval_min = FXAS2100X_POLL_MIN;
+	ipoll_dev->poll_interval_max = FXAS2100X_POLL_MAX;
+	idev = ipoll_dev->input;
+	idev->name = FXAS2100X_DRIVER;
+	idev->id.bustype = BUS_I2C;
+	idev->dev.parent = &pdata->client->dev;
+
+	idev->evbit[0] = BIT_MASK(EV_ABS);
+	input_set_abs_params(idev, ABS_X, ABSMIN_GYRO_VAL, ABSMAX_GYRO_VAL, 0, 0);
+	input_set_abs_params(idev, ABS_Y, ABSMIN_GYRO_VAL, ABSMAX_GYRO_VAL, 0, 0);
+	input_set_abs_params(idev, ABS_Z, ABSMIN_GYRO_VAL, ABSMAX_GYRO_VAL, 0, 0);
+
+	error = input_register_polled_device(ipoll_dev);
+	if (error) {
+		input_free_polled_device(ipoll_dev);
+		return error;
+	}
+
+	pdata->input_polled = ipoll_dev;
+	return 0;
+}
+
+static int fxas2100x_probe(struct i2c_client *client,
+			   const struct i2c_device_id *id)
+{
+	int result, chip_id;
+	struct fxas2100x_data *pdata;
+	struct i2c_adapter *adapter;
+
+	adapter = to_i2c_adapter(client->dev.parent);
+	result = i2c_check_functionality(adapter,
+					 I2C_FUNC_SMBUS_BYTE |
+					 I2C_FUNC_SMBUS_BYTE_DATA);
+	if (!result)
+		goto err_out;
+
+	chip_id = i2c_smbus_read_byte_data(client, FXAS2100X_WHO_AM_I);
+	if (chip_id != FXAS21000_CHIP_ID && chip_id != FXAS21002_CHID_ID_1 &&
+	    chip_id != FXAS21002_CHID_ID_2) {
+		dev_err(&client->dev,
+			"read chip ID 0x%x is not equal to 0x%x for fxas21000 or 0x%x/0x%x fxas21002!\n",
+			chip_id, FXAS21000_CHIP_ID, FXAS21002_CHID_ID_1, FXAS21002_CHID_ID_2);
+		result = -EINVAL;
+		goto err_out;
+	}
+
+	pdata = kzalloc(sizeof(struct fxas2100x_data), GFP_KERNEL);
+	if (!pdata) {
+		result = -ENOMEM;
+		dev_err(&client->dev, "alloc data memory error!\n");
+		goto err_out;
+	}
+
+	/* Initialize the FXAS2100X chip */
+	g_fxas2100x_data = pdata;
+	pdata->client = client;
+	pdata->chip_id = chip_id;
+	atomic_set(&pdata->delay, FXAS2100X_DELAY_DEFAULT);
+	atomic_set(&pdata->position, FXAS2100X_POSITION_DEFAULT);
+	i2c_set_clientdata(client, pdata);
+	result = misc_register(&fxas2100x_device);
+	if (result != 0) {
+		dev_err(&client->dev, "register acc miscdevice error");
+		goto err_regsiter_misc;
+	}
+
+	/* for debug */
+	if (client->irq <= 0) {
+		result = fxas2100x_register_polled_device(g_fxas2100x_data);
+		if (result)
+			dev_err(&client->dev,
+				"IRQ GPIO conf. error %d, error %d\n",
+				client->irq, result);
+	}
+
+	result = sysfs_create_group(&fxas2100x_device.this_device->kobj,
+				    &fxas2100x_attr_group);
+	if (result) {
+		dev_err(&client->dev, "create device file failed!\n");
+		result = -EINVAL;
+		goto err_create_sysfs;
+	}
+	fxas2100x_device_init(client);
+	dev_info(&client->dev, "fxas2100x device driver probe successfully\n");
+	return 0;
+err_create_sysfs:
+	misc_deregister(&fxas2100x_device);
+err_regsiter_misc:
+	kfree(pdata);
+err_out:
+	return result;
+}
+
+static int fxas2100x_remove(struct i2c_client *client)
+{
+	struct fxas2100x_data *pdata = i2c_get_clientdata(client);
+	fxas2100x_device_stop(client);
+	if (client->irq <= 0) {
+		input_unregister_polled_device(pdata->input_polled);
+		input_free_polled_device(pdata->input_polled);
+	}
+	misc_deregister(&fxas2100x_device);
+	if (pdata != NULL)
+		kfree(pdata);
+	return 0;
+}
+
+#ifdef CONFIG_PM_SLEEP
+static int fxas2100x_suspend(struct device *dev)
+{
+	struct i2c_client *client = to_i2c_client(dev);
+	struct fxas2100x_data *pdata = i2c_get_clientdata(client);
+
+	if (atomic_read(&pdata->active))
+		fxas2100x_device_stop(client);
+	return 0;
+}
+
+static int fxas2100x_resume(struct device *dev)
+{
+	int val = 0;
+	struct i2c_client *client = to_i2c_client(dev);
+	struct fxas2100x_data *pdata = i2c_get_clientdata(client);
+
+	if (atomic_read(&pdata->active)) {
+		val = i2c_smbus_read_byte_data(client, FXAS2100X_CTRL_REG1);
+		val &= ~0x03;
+		val |= 0x02;
+		i2c_smbus_write_byte_data(client, FXAS2100X_CTRL_REG1, val);
+	}
+	return 0;
+
+}
+#endif
+
+static const struct i2c_device_id fxas2100x_id[] = {
+	{ "fxas2100x", 0 },
+	{ /* sentinel */ }
+};
+MODULE_DEVICE_TABLE(i2c, fxas2100x_id);
+
+static SIMPLE_DEV_PM_OPS(fxas2100x_pm_ops, fxas2100x_suspend, fxas2100x_resume);
+static struct i2c_driver fxas2100x_driver = {
+	.driver		= {
+		.name	= FXAS2100X_DRIVER,
+		.owner	= THIS_MODULE,
+		.pm	= &fxas2100x_pm_ops,
+	},
+	.probe		= fxas2100x_probe,
+	.remove		= fxas2100x_remove,
+	.id_table	= fxas2100x_id,
+};
+
+module_i2c_driver(fxas2100x_driver);
+
+MODULE_AUTHOR("Freescale Semiconductor, Inc.");
+MODULE_DESCRIPTION("FXAS2100X 3-Axis Gyrosope Sensor driver");
+MODULE_LICENSE("GPL");
diff --git a/drivers/misc/fxos8700.c b/drivers/misc/fxos8700.c
new file mode 100644
index 000000000..e9a071132
--- /dev/null
+++ b/drivers/misc/fxos8700.c
@@ -0,0 +1,978 @@
+/*
+ *  Copyright (C) 2012-2013 Freescale Semiconductor, Inc. All Rights Reserved.
+ *
+ *  This program is free software; you can redistribute it and/or modify
+ *  it under the terms of the GNU General Public License as published by
+ *  the Free Software Foundation; either version 2 of the License, or
+ *  (at your option) any later version.
+ *
+ *  This program is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *  GNU General Public License for more details.
+ *
+ *  You should have received a copy of the GNU General Public License
+ *  along with this program; if not, write to the Free Software
+ *  Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ */
+
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/slab.h>
+#include <linux/i2c.h>
+#include <linux/pm.h>
+#include <linux/mutex.h>
+#include <linux/delay.h>
+#include <linux/interrupt.h>
+#include <linux/irq.h>
+#include <linux/hwmon-sysfs.h>
+#include <linux/err.h>
+#include <linux/hwmon.h>
+#include <linux/input-polldev.h>
+#include <linux/miscdevice.h>
+#include <linux/poll.h>
+
+/*register define*/
+#define FXOS8700_STATUS 		0x00
+#define FXOS8700_OUT_X_MSB 		0x01
+#define FXOS8700_OUT_X_LSB 		0x02
+#define FXOS8700_OUT_Y_MSB 		0x03
+#define FXOS8700_OUT_Y_LSB 		0x04
+#define FXOS8700_OUT_Z_MSB 		0x05
+#define FXOS8700_OUT_Z_LSB 		0x06
+#define FXOS8700_F_SETUP 		0x09
+#define FXOS8700_TRIG_CFG 		0x0a
+#define FXOS8700_SYSMOD			0x0B
+#define FXOS8700_INT_SOURCE		0x0c
+#define FXOS8700_WHO_AM_I		0x0d
+#define FXOS8700_XYZ_DATA_CFG		0x0e
+#define FXOS8700_HP_FILTER_CUTOFF	0x0f
+#define FXOS8700_PL_STATUS 		0x10
+#define FXOS8700_PL_CFG 		0x11
+#define FXOS8700_PL_COUNT		0x12
+#define FXOS8700_PL_BF_ZCOMP		0x13
+#define FXOS8700_PL_P_L_THS_REG		0x14
+#define FXOS8700_FFMT_CFG		0x15
+#define FXOS8700_FFMT_SRC		0x16
+#define FXOS8700_FFMT_THS		0x17
+#define FXOS8700_FFMT_COUNT		0x18
+#define FXOS8700_TRANSIDENT1_CFG	0x1d
+#define FXOS8700_TRANSIDENT1_SRC	0x1e
+#define FXOS8700_TRANSIDENT1_THS	0x1f
+#define FXOS8700_TRANSIDENT1_COUNT	0x20
+#define FXOS8700_PULSE_CFG		0x21
+#define FXOS8700_PULSE_SRC		0x22
+#define FXOS8700_PULSE_THSX		0x23
+#define FXOS8700_PULSE_THSY		0x24
+#define FXOS8700_PULSE_THSZ		0x25
+#define FXOS8700_PULSE_TMLT		0x26
+#define FXOS8700_PULSE_LTCY		0x27
+#define FXOS8700_PULSE_WIND		0x28
+#define FXOS8700_ATSLP_COUNT		0x29
+#define FXOS8700_CTRL_REG1		0x2a
+#define FXOS8700_CTRL_REG2		0x2b
+#define FXOS8700_CTRL_REG3		0x2c
+#define FXOS8700_CTRL_REG4		0x2d
+#define FXOS8700_CTRL_REG5		0x2e
+#define FXOS8700_OFF_X			0x2f
+#define FXOS8700_OFF_Y			0x30
+#define FXOS8700_OFF_Z			0x31
+#define FXOS8700_M_DR_STATUS		0x32
+#define FXOS8700_M_OUT_X_MSB       	0x33
+#define FXOS8700_M_OUT_X_LSB       	0x34
+#define FXOS8700_M_OUT_Y_MSB       	0x35
+#define FXOS8700_M_OUT_Y_LSB       	0x36
+#define FXOS8700_M_OUT_Z_MSB       	0x37
+#define FXOS8700_M_OUT_Z_LSB       	0x38
+#define FXOS8700_CMP_X_MSB       	0x39
+#define FXOS8700_CMP_X_LSB       	0x3a
+#define FXOS8700_CMP_Y_MSB       	0x3b
+#define FXOS8700_CMP_Y_LSB       	0x3c
+#define FXOS8700_CMP_Z_MSB       	0x3d
+#define FXOS8700_CMP_Z_LSB       	0x3e
+#define FXOS8700_M_OFF_X_MSB       	0x3f
+#define FXOS8700_M_OFF_X_LSB       	0x40
+#define FXOS8700_M_OFF_Y_MSB       	0x41
+#define FXOS8700_M_OFF_Y_LSB       	0x42
+#define FXOS8700_M_OFF_Z_MSB       	0x43
+#define FXOS8700_M_OFF_Z_LSB       	0x44
+#define FXOS8700_MAX_X_MSB       	0x45
+#define FXOS8700_MAX_X_LSB      	0x46
+#define FXOS8700_MAX_Y_MSB       	0x47
+#define FXOS8700_MAX_Y_LSB       	0x48
+#define FXOS8700_MAX_Z_MSB       	0x49
+#define FXOS8700_MAX_Z_LSB       	0x4a
+#define FXOS8700_MIN_X_MSB       	0x4b
+#define FXOS8700_MIN_X_LSB       	0x4c
+#define FXOS8700_MIN_Y_MSB       	0x4d
+#define FXOS8700_MIN_Y_LSB       	0x4e
+#define FXOS8700_MIN_Z_MSB       	0x4f
+#define FXOS8700_MIN_Z_LSB       	0x50
+#define FXOS8700_M_TEMP       		0x51
+#define FXOS8700_MAG_THS_CFG 		0x52
+#define FXOS8700_MAG_THS_SRC 		0x53
+#define FXOS8700_MAG_THS_THS_X1 	0x54
+#define FXOS8700_MAG_THS_THS_X0 	0x55
+#define FXOS8700_MAG_THS_THS_Y1 	0x56
+#define FXOS8700_MAG_THS_THS_Y0 	0x57
+#define FXOS8700_MAG_THS_THS_Z1 	0x58
+#define FXOS8700_MAG_THS_THS_Z0 	0x59
+#define FXOS8700_MAG_THS_CUNT		0x5a
+#define FXOS8700_M_CTRL_REG1		0x5b
+#define FXOS8700_M_CTRL_REG2		0x5c
+#define FXOS8700_M_CTRL_REG3		0x5d
+#define FXOS8700_M_INT_SOURCE		0x5e
+#define FXOS8700_G_VECM_CFG  		0x5f
+#define FXOS8700_G_VECM_THS_MSB  	0x60
+#define FXOS8700_G_VECM_THS_LSB  	0x61
+#define FXOS8700_G_VECM_CNT  		0x62
+#define FXOS8700_G_VECM_INITX_MSB  	0x63
+#define FXOS8700_G_VECM_INITX_LSB  	0x64
+#define FXOS8700_G_VECM_INITY_MSB  	0x65
+#define FXOS8700_G_VECM_INITY_LSB  	0x66
+#define FXOS8700_G_VECM_INITZ_MSB  	0x67
+#define FXOS8700_G_VECM_INITZ_LSB  	0x68
+#define FXOS8700_M_VECM_CFG  		0x69
+#define FXOS8700_M_VECM_THS_MSB 	0x6a
+#define FXOS8700_M_VECM_THS_LSB  	0x6b
+#define FXOS8700_M_VECM_CNT  		0x6d
+#define FXOS8700_M_VECM_INITX_MSB  	0x6d
+#define FXOS8700_M_VECM_INITX_LSB  	0x6e
+#define FXOS8700_M_VECM_INITY_MSB  	0x6f
+#define FXOS8700_M_VECM_INITY_LSB  	0x70
+#define FXOS8700_M_VECM_INITZ_MSB  	0x71
+#define FXOS8700_M_VECM_INITZ_LSB  	0x72
+#define FXOS8700_G_FFMT_THS_X1  	0x73
+#define FXOS8700_G_FFMT_THS_X0 		0x74
+#define FXOS8700_G_FFMT_THS_Y1  	0x75
+#define FXOS8700_G_FFMT_THS_Y0  	0x76
+#define FXOS8700_G_FFMT_THS_Z1  	0x77
+#define FXOS8700_G_FFMT_THS_Z0  	0x78
+#define FXOS8700_G_TRAN_INIT_MSB  	0x79
+#define FXOS8700_G_TRAN_INIT_LSB_X 	0x7a
+#define FXOS8700_G_TRAN_INIT_LSB_Y 	0x7b
+#define FXOS8700_G_TRAN_INIT_LSB_Z 	0x7d
+#define FXOS8700_TM_NVM_LOCK 		0x7e
+#define FXOS8700_NVM_DATA0_35		0x80
+#define FXOS8700_NVM_DATA_BNK3		0xa4
+#define FXOS8700_NVM_DATA_BNK2		0xa5
+#define FXOS8700_NVM_DATA_BNK1		0xa6
+#define FXOS8700_NVM_DATA_BNK0		0xa7
+
+#define	SENSOR_IOCTL_BASE		'S'
+#define	SENSOR_GET_MODEL_NAME		_IOR(SENSOR_IOCTL_BASE, 0, char *)
+#define	SENSOR_GET_POWER_STATUS		_IOR(SENSOR_IOCTL_BASE, 2, int)
+#define	SENSOR_SET_POWER_STATUS		_IOR(SENSOR_IOCTL_BASE, 3, int)
+#define	SENSOR_GET_DELAY_TIME		_IOR(SENSOR_IOCTL_BASE, 4, int)
+#define	SENSOR_SET_DELAY_TIME		_IOR(SENSOR_IOCTL_BASE, 5, int)
+#define	SENSOR_GET_RAW_DATA		_IOR(SENSOR_IOCTL_BASE, 6, short[3])
+
+#define FXOS8700_I2C_ADDR		0x1E
+#define FXOS8700_DEVICE_ID		0xC7
+#define FXOS8700_PRE_DEVICE_ID 		0xC4
+#define FXOS8700_DATA_BUF_SIZE		6
+#define FXOS8700_DELAY_DEFAULT		200 	/* msecs */
+#define FXOS8700_POSITION_DEFAULT	1 	/* msecs */
+
+#define FXOS8700_TYPE_ACC 	0x00
+#define FXOS8700_TYPE_MAG 	0x01
+#define FXOS8700_STANDBY 	0x00
+#define FXOS8700_ACTIVED 	0x01
+
+#define ABS_STATUS		ABS_WHEEL
+#define FXOS8700_DRIVER		"fxos8700"
+
+#define ABSMAX_ACC_VAL          0x01FF
+#define ABSMIN_ACC_VAL          -(ABSMAX_ACC_VAL)
+#define FXOS8700_POLL_INTERVAL	400
+#define FXOS8700_POLL_MAX	800
+#define FXOS8700_POLL_MIN	100
+
+enum { MODE_2G = 0, MODE_4G, MODE_8G,
+};
+
+struct fxos8700_data_axis {
+	short x;
+	short y;
+	short z;
+};
+
+struct fxos8700_data {
+	struct i2c_client *client;
+	struct input_polled_dev *input_polled;
+	struct miscdevice *acc_miscdev;
+	struct miscdevice *mag_miscdev;
+	atomic_t acc_delay;
+	atomic_t mag_delay;
+	atomic_t acc_active;
+	atomic_t acc_active_poll;
+	atomic_t mag_active_poll;
+	atomic_t mag_active;
+	atomic_t position;
+	atomic_t range;
+};
+
+static struct fxos8700_data *g_fxos8700_data;
+static int fxos8700_position_settings[8][3][3] = {
+	{ { 0, -1, 0}, { 1, 0, 0}, {0, 0, 1} },
+	{ {-1, 0, 0}, { 0, -1, 0}, {0, 0, 1} },
+	{ { 0, 1, 0}, {-1, 0, 0}, {0, 0, 1} },
+	{ { 1, 0, 0}, { 0, 1, 0}, {0, 0, 1} },
+	{ { 0, -1, 0}, {-1, 0, 0}, {0, 0, -1} },
+	{ {-1, 0, 0}, { 0, 1, 0}, {0, 0, -1} },
+	{ { 0, 1, 0}, { 1, 0, 0}, {0, 0, -1} },
+	{ { 1, 0, 0}, { 0, -1, 0}, {0, 0, -1} },
+};
+
+static int fxos8700_data_convert(struct fxos8700_data_axis *axis_data, int position)
+{
+	short rawdata[3], data[3];
+	int i, j;
+	if (position < 0 || position > 7)
+		position = 0;
+	rawdata[0] = axis_data->x;
+	rawdata[1] = axis_data->y;
+	rawdata[2] = axis_data->z;
+	for (i = 0; i < 3 ; i++) {
+		data[i] = 0;
+		for (j = 0; j < 3; j++)
+			data[i] += rawdata[j] * fxos8700_position_settings[position][i][j];
+	}
+
+	axis_data->x = data[0];
+	axis_data->y = data[1];
+	axis_data->z = data[2];
+	return 0;
+}
+
+static int fxos8700_change_mode(struct i2c_client *client, int type, int active)
+{
+	u8 data;
+	int acc_act, mag_act;
+	struct fxos8700_data *pdata =  i2c_get_clientdata(client);
+
+	acc_act = atomic_read(&pdata->acc_active);
+	mag_act = atomic_read(&pdata->mag_active);
+	data = i2c_smbus_read_byte_data(client, FXOS8700_CTRL_REG1);
+	if (type == FXOS8700_TYPE_ACC)
+		acc_act = active;
+	else
+		mag_act = active;
+	if (acc_act ==  FXOS8700_ACTIVED || mag_act == FXOS8700_ACTIVED)
+		data |= 0x01;
+	else
+		data &= ~0x01;
+	i2c_smbus_write_byte_data(client, FXOS8700_CTRL_REG1, data);
+
+	return 0;
+}
+
+static int fxos8700_change_range(struct i2c_client *client, int range)
+{
+	int ret;
+
+	ret = i2c_smbus_write_byte_data(client, FXOS8700_XYZ_DATA_CFG, range);
+
+	return ret;
+}
+static int fxos8700_set_odr(struct i2c_client *client, int type, int delay)
+{
+	return 0;
+}
+
+static int fxos8700_device_init(struct i2c_client *client)
+{
+	int result;
+	struct device_node *np = client->dev.of_node;
+	struct fxos8700_data *pdata =  i2c_get_clientdata(client);
+
+	/* set interrupt pin as open-drain */
+	if (of_get_property(np, "interrupt-open-drain", NULL)) {
+		result = i2c_smbus_write_byte_data(client, FXOS8700_CTRL_REG3, 0x01);
+		if (result < 0)
+			goto out;
+	}
+
+	/* standby mode */
+	result = i2c_smbus_write_byte_data(client, FXOS8700_CTRL_REG1, 0x00);
+	if (result < 0)
+		goto out;
+	result = i2c_smbus_write_byte_data(client, FXOS8700_M_CTRL_REG1, 0x1F);
+	if (result < 0)
+		goto out;
+	result = i2c_smbus_write_byte_data(client, FXOS8700_M_CTRL_REG2, 0x5c);
+	if (result < 0)
+		goto out;
+	result = i2c_smbus_write_byte_data(client, FXOS8700_CTRL_REG1, 0x03 << 3);
+	if (result < 0)
+		goto out;
+	result = i2c_smbus_write_byte_data(client, FXOS8700_XYZ_DATA_CFG,
+					   MODE_2G);
+	if (result < 0)
+		goto out;
+
+	atomic_set(&pdata->acc_active, FXOS8700_STANDBY);
+	atomic_set(&pdata->mag_active, FXOS8700_STANDBY);
+	atomic_set(&pdata->position, FXOS8700_POSITION_DEFAULT);
+	atomic_set(&pdata->range, MODE_2G);
+	return 0;
+out:
+	dev_err(&client->dev, "Error when init fxos8700 device:(%d)", result);
+	return result;
+}
+
+static int fxos8700_device_stop(struct i2c_client *client)
+{
+	i2c_smbus_write_byte_data(client, FXOS8700_CTRL_REG1, 0x00);
+	return 0;
+}
+
+static int
+fxos8700_read_data(struct i2c_client *client, struct fxos8700_data_axis *data, int type)
+{
+	u8 tmp_data[FXOS8700_DATA_BUF_SIZE];
+	int ret;
+	u8 reg;
+
+	if (type == FXOS8700_TYPE_ACC)
+		reg = FXOS8700_OUT_X_MSB;
+	else
+		reg = FXOS8700_M_OUT_X_MSB;
+
+	ret = i2c_smbus_read_i2c_block_data(client, reg, FXOS8700_DATA_BUF_SIZE, tmp_data);
+	if (ret < FXOS8700_DATA_BUF_SIZE) {
+		dev_err(&client->dev, "i2c block read %s failed\n",
+			(type == FXOS8700_TYPE_ACC ? "acc" : "mag"));
+		return -EIO;
+	}
+	data->x = ((tmp_data[0] << 8) & 0xff00) | tmp_data[1];
+	data->y = ((tmp_data[2] << 8) & 0xff00) | tmp_data[3];
+	data->z = ((tmp_data[4] << 8) & 0xff00) | tmp_data[5];
+	return 0;
+}
+
+static long fxos8700_acc_ioctl(struct file *file, unsigned int cmd, unsigned long arg)
+{
+	struct fxos8700_data *pdata = file->private_data;
+	void __user *argp = (void __user *)arg;
+	struct fxos8700_data_axis data;
+	long ret = 0;
+	short sdata[3];
+	int enable;
+	int delay;
+	int position;
+
+	if (!pdata) {
+		printk(KERN_ERR "fxos8700 struct datt point is NULL.");
+		return -EFAULT;
+	}
+
+	switch (cmd) {
+	case SENSOR_GET_MODEL_NAME:
+		if (copy_to_user(argp, "FXOS8700 ACC", strlen("FXOS8700 ACC") + 1)) {
+			printk(KERN_ERR "SENSOR_GET_MODEL_NAME copy_to_user failed.");
+			ret = -EFAULT;
+		}
+		break;
+	case SENSOR_GET_POWER_STATUS:
+		enable = atomic_read(&pdata->acc_active);
+		if (copy_to_user(argp, &enable, sizeof(int))) {
+			printk(KERN_ERR "SENSOR_SET_POWER_STATUS copy_to_user failed.");
+			ret = -EFAULT;
+		}
+		break;
+	case SENSOR_SET_POWER_STATUS:
+		if (copy_from_user(&enable, argp, sizeof(int))) {
+			printk(KERN_ERR "SENSOR_SET_POWER_STATUS copy_to_user failed.");
+			ret = -EFAULT;
+		}
+		if (pdata->client) {
+			ret = fxos8700_change_mode(pdata->client, FXOS8700_TYPE_ACC,
+						   enable ? FXOS8700_ACTIVED : FXOS8700_STANDBY);
+			if (!ret)
+				atomic_set(&pdata->acc_active, enable);
+		}
+		break;
+	case SENSOR_GET_DELAY_TIME:
+		delay = atomic_read(&pdata->acc_delay);
+		if (copy_to_user(argp, &delay, sizeof(delay))) {
+			printk(KERN_ERR "SENSOR_GET_DELAY_TIME copy_to_user failed.");
+			return -EFAULT;
+		}
+		break;
+	case SENSOR_SET_DELAY_TIME:
+		if (copy_from_user(&delay, argp, sizeof(int))) {
+			printk(KERN_ERR "SENSOR_SET_DELAY_TIME copy_to_user failed.");
+			ret = -EFAULT;
+		}
+		if (pdata->client && delay > 0 && delay <= 500) {
+			ret = fxos8700_set_odr(pdata->client, FXOS8700_TYPE_ACC, delay);
+			if (!ret)
+				atomic_set(&pdata->acc_delay, delay);
+		}
+		break;
+	case SENSOR_GET_RAW_DATA:
+		position = atomic_read(&pdata->position);
+		ret = fxos8700_read_data(pdata->client, &data, FXOS8700_TYPE_ACC);
+		if (!ret) {
+			fxos8700_data_convert(&data, position);
+			sdata[0] = data.x;
+			sdata[1] = data.y;
+			sdata[2] = data.z;
+			if (copy_to_user(argp, sdata, sizeof(sdata))) {
+				printk(KERN_ERR "SENSOR_GET_RAW_DATA copy_to_user failed.");
+				ret = -EFAULT;
+			}
+		}
+		break;
+	default:
+		ret = -1;
+	}
+	return ret;
+}
+
+static int fxos8700_acc_open(struct inode *inode, struct file *file)
+{
+	file->private_data = g_fxos8700_data;
+	return nonseekable_open(inode, file);
+}
+
+static int fxos8700_acc_release(struct inode *inode, struct file *file)
+{
+	/* note: releasing the wdt in NOWAYOUT-mode does not stop it */
+	return 0;
+}
+
+static const struct file_operations fxos8700_acc_fops = {
+	.owner = THIS_MODULE,
+	.open = fxos8700_acc_open,
+	.release = fxos8700_acc_release,
+	.unlocked_ioctl = fxos8700_acc_ioctl,
+};
+
+/* mag char miscdevice */
+static long fxos8700_mag_ioctl(struct file *file, unsigned int cmd, unsigned long arg)
+{
+	struct fxos8700_data *pdata = file->private_data;
+	void __user *argp = (void __user *)arg;
+	struct fxos8700_data_axis data;
+	long ret = 0;
+	short sdata[3];
+	int enable;
+	int delay;
+	int position;
+
+	if (!pdata) {
+		printk(KERN_ERR "fxos8700 struct datt point is NULL.");
+		return -EFAULT;
+	}
+
+	switch (cmd) {
+	case SENSOR_GET_MODEL_NAME:
+		if (copy_to_user(argp, "FXOS8700 MAG", strlen("FXOS8700 MAG") + 1)) {
+			printk(KERN_ERR "SENSOR_GET_MODEL_NAME copy_to_user failed.");
+			ret = -EFAULT;
+		}
+		break;
+	case SENSOR_GET_POWER_STATUS:
+		enable = atomic_read(&pdata->mag_active);
+		if (copy_to_user(argp, &enable, sizeof(int))) {
+			printk(KERN_ERR "SENSOR_SET_POWER_STATUS copy_to_user failed.");
+			ret = -EFAULT;
+		}
+		break;
+	case SENSOR_SET_POWER_STATUS:
+		if (copy_from_user(&enable, argp, sizeof(int))) {
+			printk(KERN_ERR "SENSOR_SET_POWER_STATUS copy_to_user failed.");
+			ret = -EFAULT;
+		}
+		if (pdata->client) {
+			ret = fxos8700_change_mode(pdata->client, FXOS8700_TYPE_MAG,
+						   enable ? FXOS8700_ACTIVED : FXOS8700_STANDBY);
+			if (!ret)
+				atomic_set(&pdata->mag_active, enable);
+		}
+		break;
+	case SENSOR_GET_DELAY_TIME:
+		delay = atomic_read(&pdata->mag_delay);
+		if (copy_to_user(argp, &delay, sizeof(delay))) {
+			printk(KERN_ERR "SENSOR_GET_DELAY_TIME copy_to_user failed.");
+			return -EFAULT;
+		}
+		break;
+	case SENSOR_SET_DELAY_TIME:
+		if (copy_from_user(&delay, argp, sizeof(int))) {
+			printk(KERN_ERR "SENSOR_SET_DELAY_TIME copy_to_user failed.");
+			ret = -EFAULT;
+		}
+		if (pdata->client && delay > 0 && delay <= 500) {
+			ret = fxos8700_set_odr(pdata->client, FXOS8700_TYPE_MAG, delay);
+			if (!ret)
+				atomic_set(&pdata->mag_delay, delay);
+		}
+		break;
+	case SENSOR_GET_RAW_DATA:
+		position = atomic_read(&pdata->position);
+		ret = fxos8700_read_data(pdata->client, &data, FXOS8700_TYPE_MAG);
+		if (!ret) {
+			fxos8700_data_convert(&data, position);
+			sdata[0] = data.x;
+			sdata[1] = data.y;
+			sdata[2] = data.z;
+			if (copy_to_user(argp, sdata, sizeof(sdata))) {
+				printk(KERN_ERR "SENSOR_GET_RAW_DATA copy_to_user failed.");
+				ret = -EFAULT;
+			}
+		}
+		break;
+	default:
+		ret = -1;
+	}
+	return ret;
+}
+
+static int fxos8700_mag_open(struct inode *inode, struct file *file)
+{
+	file->private_data = g_fxos8700_data;
+	return nonseekable_open(inode, file);
+}
+
+static int fxos8700_mag_release(struct inode *inode, struct file *file)
+{
+	/* note: releasing the wdt in NOWAYOUT-mode does not stop it */
+	return 0;
+}
+
+static const struct file_operations fxos8700_mag_fops = {
+	.owner = THIS_MODULE,
+	.open = fxos8700_mag_open,
+	.release = fxos8700_mag_release,
+	.unlocked_ioctl = fxos8700_mag_ioctl,
+};
+
+static struct miscdevice fxos8700_acc_device = {
+	.minor = MISC_DYNAMIC_MINOR,
+	.name = "FreescaleAccelerometer",
+	.fops = &fxos8700_acc_fops,
+};
+
+static struct miscdevice fxos8700_mag_device = {
+	.minor = MISC_DYNAMIC_MINOR,
+	.name = "FreescaleMagnetometer",
+	.fops = &fxos8700_mag_fops,
+};
+
+static ssize_t fxos8700_enable_show(struct device *dev,
+				   struct device_attribute *attr, char *buf)
+{
+	struct miscdevice *misc_dev = dev_get_drvdata(dev);
+	struct fxos8700_data *pdata = g_fxos8700_data;
+	int enable = 0;
+
+	if (pdata->acc_miscdev == misc_dev)
+		enable = atomic_read(&pdata->acc_active);
+	if (pdata->mag_miscdev == misc_dev)
+		enable = atomic_read(&pdata->mag_active);
+
+	return sprintf(buf, "%d\n", enable);
+}
+
+static ssize_t fxos8700_enable_store(struct device *dev,
+				    struct device_attribute *attr,
+				    const char *buf, size_t count)
+{
+	struct miscdevice *misc_dev = dev_get_drvdata(dev);
+	struct fxos8700_data *pdata = g_fxos8700_data;
+	struct i2c_client *client = pdata->client;
+	unsigned long enable;
+	int type;
+	int ret;
+
+	if (kstrtoul(buf, 10, &enable) < 0)
+		return -EINVAL;
+
+	if (misc_dev == pdata->acc_miscdev)
+		type = FXOS8700_TYPE_ACC;
+	if (misc_dev == pdata->mag_miscdev)
+		type = FXOS8700_TYPE_MAG;
+	enable = (enable > 0 ? FXOS8700_ACTIVED : FXOS8700_STANDBY);
+	ret = fxos8700_change_mode(client, type, enable);
+	if (!ret) {
+		if (type == FXOS8700_TYPE_ACC) {
+			atomic_set(&pdata->acc_active, enable);
+			atomic_set(&pdata->acc_active_poll, enable);
+		} else {
+			atomic_set(&pdata->mag_active, enable);
+			atomic_set(&pdata->mag_active_poll, enable);
+		}
+	}
+	return count;
+}
+
+static ssize_t fxos8700_poll_delay_show(struct device *dev,
+				   struct device_attribute *attr, char *buf)
+{
+	struct miscdevice *misc_dev = dev_get_drvdata(dev);
+	struct fxos8700_data *pdata = g_fxos8700_data;
+	int poll_delay = 0;
+
+	if (pdata->acc_miscdev == misc_dev)
+		poll_delay = atomic_read(&pdata->acc_delay);
+	if (pdata->mag_miscdev == misc_dev)
+		poll_delay = atomic_read(&pdata->mag_delay);
+
+	return sprintf(buf, "%d\n", poll_delay);
+}
+
+
+static ssize_t fxos8700_poll_delay_store(struct device *dev,
+				    struct device_attribute *attr,
+				    const char *buf, size_t count)
+{
+	struct miscdevice *misc_dev = dev_get_drvdata(dev);
+	struct fxos8700_data *pdata = g_fxos8700_data;
+	struct i2c_client *client = pdata->client;
+	unsigned long delay;
+	int type;
+	int ret;
+
+	if (kstrtoul(buf, 10, &delay) < 0)
+		return -EINVAL;
+
+	if (misc_dev == pdata->acc_miscdev)
+		type = FXOS8700_TYPE_ACC;
+	if (misc_dev == pdata->mag_miscdev)
+		type = FXOS8700_TYPE_MAG;
+	ret = fxos8700_set_odr(client, type, delay);
+	if (!ret) {
+		if (type == FXOS8700_TYPE_ACC)
+			atomic_set(&pdata->acc_delay, delay);
+		else
+			atomic_set(&pdata->mag_delay, delay);
+	}
+	return count;
+}
+
+static ssize_t fxos8700_position_show(struct device *dev,
+				   struct device_attribute *attr, char *buf)
+{
+	struct fxos8700_data *pdata = g_fxos8700_data;
+	unsigned long position = atomic_read(&pdata->position);
+
+	return sprintf(buf, "%ld\n", position);
+}
+
+static ssize_t fxos8700_position_store(struct device *dev,
+				    struct device_attribute *attr,
+				    const char *buf, size_t count)
+{
+	unsigned long position;
+	struct fxos8700_data *pdata = g_fxos8700_data;
+
+	if (kstrtoul(buf, 10, &position) < 0)
+		return -EINVAL;
+
+	atomic_set(&pdata->position, position);
+	return count;
+}
+
+static ssize_t fxos8700_range_show(struct device *dev,
+				   struct device_attribute *attr, char *buf)
+{
+	struct fxos8700_data *pdata = g_fxos8700_data;
+	unsigned long range = atomic_read(&pdata->range);
+
+	return sprintf(buf, "%ld\n", range);
+}
+
+static ssize_t fxos8700_range_store(struct device *dev,
+				    struct device_attribute *attr,
+				    const char *buf, size_t count)
+{
+	unsigned long range;
+	struct fxos8700_data *pdata = g_fxos8700_data;
+	struct i2c_client *client = pdata->client;
+	int ret;
+
+	if (kstrtoul(buf, 10, &range) < 0)
+		return -EINVAL;
+
+	if (range == atomic_read(&pdata->range))
+		return count;
+
+	if (atomic_read(&pdata->acc_active) | atomic_read(&pdata->mag_active))
+		printk(KERN_INFO "Pls set the sensor standby and then actived\n");
+	ret = fxos8700_change_range(client, range);
+	if (!ret)
+		atomic_set(&pdata->range, range);
+
+	return count;
+}
+
+static DEVICE_ATTR(enable, S_IWUSR | S_IRUGO, fxos8700_enable_show, fxos8700_enable_store);
+static DEVICE_ATTR(poll_delay, S_IWUSR | S_IRUGO, fxos8700_poll_delay_show, fxos8700_poll_delay_store);
+static DEVICE_ATTR(position, S_IWUSR | S_IRUGO, fxos8700_position_show, fxos8700_position_store);
+static DEVICE_ATTR(range, S_IWUSR | S_IRUGO, fxos8700_range_show, fxos8700_range_store);
+
+static struct attribute *fxos8700_attributes[] = {
+	&dev_attr_enable.attr,
+	&dev_attr_poll_delay.attr,
+	&dev_attr_position.attr,
+	&dev_attr_range.attr,
+	NULL
+};
+
+static const struct attribute_group fxos8700_attr_group = {
+	.attrs = fxos8700_attributes,
+};
+
+static int fxos8700_register_sysfs_device(struct fxos8700_data *pdata)
+{
+	struct miscdevice *misc_dev = NULL;
+	int err = -1;
+
+	/* register sysfs for acc */
+	misc_dev = pdata->acc_miscdev;
+	err = sysfs_create_group(&misc_dev->this_device->kobj, &fxos8700_attr_group);
+	if (err)
+		goto out;
+
+	/* register sysfs for mag */
+	misc_dev = pdata->mag_miscdev;
+	err = sysfs_create_group(&misc_dev->this_device->kobj, &fxos8700_attr_group);
+	if (err)
+		goto err_register_sysfs;
+	return 0;
+err_register_sysfs:
+	misc_dev = pdata->acc_miscdev;
+	sysfs_remove_group(&misc_dev->this_device->kobj, &fxos8700_attr_group);
+	printk("reigster mag sysfs error\n");
+out:
+	printk("reigster acc sysfs error\n");
+	return err;
+}
+
+static int fxos8700_unregister_sysfs_device(struct fxos8700_data *pdata)
+{
+	struct miscdevice *misc_dev;
+	misc_dev =  pdata->acc_miscdev;
+	sysfs_remove_group(&misc_dev->this_device->kobj, &fxos8700_attr_group);
+
+	misc_dev = pdata->mag_miscdev;
+	sysfs_remove_group(&misc_dev->this_device->kobj, &fxos8700_attr_group);
+	return 0;
+}
+
+static void fxos8700_report(struct input_polled_dev *dev, int type)
+{
+	struct fxos8700_data_axis data;
+	struct fxos8700_data *pdata = g_fxos8700_data;
+	struct input_dev *idev = pdata->input_polled->input;
+	int position;
+	int ret;
+
+	position = atomic_read(&pdata->position);
+	ret = fxos8700_read_data(pdata->client, &data, type);
+	if (!ret) {
+		fxos8700_data_convert(&data, position);
+		input_report_abs(idev, ABS_X, data.x);
+		input_report_abs(idev, ABS_Y, data.y);
+		input_report_abs(idev, ABS_Z, data.z);
+		input_sync(idev);
+	}
+}
+
+static void fxos8700_poll(struct input_polled_dev *dev)
+{
+	struct fxos8700_data *pdata = g_fxos8700_data;
+	int type;
+
+	if (!(atomic_read(&pdata->acc_active_poll) ||
+	    atomic_read(&pdata->mag_active_poll)))
+		return;
+
+	if (atomic_read(&pdata->acc_active_poll))
+		type = FXOS8700_TYPE_ACC;
+	if (atomic_read(&pdata->mag_active_poll))
+		type =FXOS8700_TYPE_MAG;
+	fxos8700_report(dev, type);
+}
+
+static int fxo8700_register_polled_device(struct fxos8700_data *pdata)
+{
+	struct input_polled_dev *ipoll_dev;
+	struct input_dev *idev;
+	int error;
+
+	ipoll_dev = input_allocate_polled_device();
+	if (!ipoll_dev)
+		return -ENOMEM;
+
+	ipoll_dev->private = pdata;
+	ipoll_dev->poll = fxos8700_poll;
+	ipoll_dev->poll_interval = FXOS8700_POLL_INTERVAL;
+	ipoll_dev->poll_interval_min = FXOS8700_POLL_MIN;
+	ipoll_dev->poll_interval_max = FXOS8700_POLL_MAX;
+	idev = ipoll_dev->input;
+	idev->name = FXOS8700_DRIVER;
+	idev->id.bustype = BUS_I2C;
+	idev->dev.parent = &pdata->client->dev;
+
+	idev->evbit[0] = BIT_MASK(EV_ABS);
+	input_set_abs_params(idev, ABS_X, ABSMIN_ACC_VAL, ABSMAX_ACC_VAL, 0, 0);
+	input_set_abs_params(idev, ABS_Y, ABSMIN_ACC_VAL, ABSMAX_ACC_VAL, 0, 0);
+	input_set_abs_params(idev, ABS_Z, ABSMIN_ACC_VAL, ABSMAX_ACC_VAL, 0, 0);
+
+	error = input_register_polled_device(ipoll_dev);
+	if (error) {
+		input_free_polled_device(ipoll_dev);
+		return error;
+	}
+
+	pdata->input_polled = ipoll_dev;
+
+	return 0;
+}
+
+static int fxos8700_probe(struct i2c_client *client,
+				   const struct i2c_device_id *id)
+{
+	int result, client_id;
+	struct fxos8700_data *pdata;
+	struct i2c_adapter *adapter;
+
+	adapter = to_i2c_adapter(client->dev.parent);
+	result = i2c_check_functionality(adapter,
+					 I2C_FUNC_SMBUS_BYTE |
+					 I2C_FUNC_SMBUS_BYTE_DATA);
+	if (!result)
+		goto err_out;
+
+	client_id = i2c_smbus_read_byte_data(client, FXOS8700_WHO_AM_I);
+	if (client_id !=  FXOS8700_DEVICE_ID && client_id != FXOS8700_PRE_DEVICE_ID) {
+		dev_err(&client->dev,
+			"read chip ID 0x%x is not equal to 0x%x or 0x%x\n",
+			result, FXOS8700_DEVICE_ID, FXOS8700_PRE_DEVICE_ID);
+		result = -EINVAL;
+		goto err_out;
+	}
+	pdata = kzalloc(sizeof(struct fxos8700_data), GFP_KERNEL);
+	if (!pdata) {
+		result = -ENOMEM;
+		dev_err(&client->dev, "alloc data memory error!\n");
+		goto err_out;
+	}
+	g_fxos8700_data = pdata;
+	pdata->client = client;
+	atomic_set(&pdata->acc_delay, FXOS8700_DELAY_DEFAULT);
+	atomic_set(&pdata->mag_delay, FXOS8700_DELAY_DEFAULT);
+	i2c_set_clientdata(client, pdata);
+
+	result = misc_register(&fxos8700_acc_device);
+	if (result != 0) {
+		printk(KERN_ERR "register acc miscdevice error");
+		goto err_regsiter_acc_misc;
+	}
+	pdata->acc_miscdev = &fxos8700_acc_device;
+
+	result = misc_register(&fxos8700_mag_device);
+	if (result != 0) {
+		printk(KERN_ERR "register acc miscdevice error");
+		goto err_regsiter_mag_misc;
+	}
+	pdata->mag_miscdev = &fxos8700_mag_device;
+
+	/* for debug */
+	if (client->irq <= 0) {
+		result = fxo8700_register_polled_device(g_fxos8700_data);
+		if (result)
+			dev_err(&client->dev,
+				"IRQ GPIO conf. error %d, error %d\n",
+				client->irq, result);
+	}
+
+	result = fxos8700_register_sysfs_device(pdata);
+	if (result) {
+		dev_err(&client->dev, "create device file failed!\n");
+		result = -EINVAL;
+		goto err_register_sys;
+	}
+	fxos8700_device_init(client);
+	printk("fxos8700 device driver probe successfully");
+	return 0;
+err_register_sys:
+	misc_deregister(&fxos8700_mag_device);
+	pdata->mag_miscdev = NULL;
+err_regsiter_mag_misc:
+	misc_deregister(&fxos8700_acc_device);
+	pdata->acc_miscdev = NULL;
+err_regsiter_acc_misc:
+	i2c_set_clientdata(client, NULL);
+	kfree(pdata);
+err_out:
+	return result;
+}
+
+static int fxos8700_remove(struct i2c_client *client)
+{
+	struct fxos8700_data *pdata =  i2c_get_clientdata(client);
+	if (!pdata)
+		return 0;
+	fxos8700_device_stop(client);
+	if (client->irq <= 0) {
+		input_unregister_polled_device(pdata->input_polled);
+		input_free_polled_device(pdata->input_polled);
+	}
+	fxos8700_unregister_sysfs_device(pdata);
+	misc_deregister(&fxos8700_acc_device);
+	misc_deregister(&fxos8700_mag_device);
+	kfree(pdata);
+	return 0;
+}
+
+#ifdef CONFIG_PM_SLEEP
+static int fxos8700_suspend(struct device *dev)
+{
+	struct i2c_client *client = to_i2c_client(dev);
+	struct fxos8700_data *pdata = i2c_get_clientdata(client);
+	if (atomic_read(&pdata->acc_active) || atomic_read(&pdata->mag_active))
+		fxos8700_device_stop(client);
+	return 0;
+}
+
+static int fxos8700_resume(struct device *dev)
+{
+    int ret = 0;
+	struct i2c_client *client = to_i2c_client(dev);
+	struct fxos8700_data *pdata =  i2c_get_clientdata(client);
+	if (atomic_read(&pdata->acc_active))
+		fxos8700_change_mode(client, FXOS8700_TYPE_ACC, FXOS8700_ACTIVED);
+	if (atomic_read(&pdata->mag_active))
+		fxos8700_change_mode(client, FXOS8700_TYPE_MAG, FXOS8700_ACTIVED);
+	return ret;
+}
+#endif
+
+static const struct i2c_device_id fxos8700_id[] = {
+	{"fxos8700", 0},
+	{ /* sentinel */ }
+};
+MODULE_DEVICE_TABLE(i2c, fxos8700_id);
+
+static SIMPLE_DEV_PM_OPS(fxos8700_pm_ops, fxos8700_suspend, fxos8700_resume);
+static struct i2c_driver fxos8700_driver = {
+	.driver = {
+		   .name = FXOS8700_DRIVER,
+		   .owner = THIS_MODULE,
+		   .pm = &fxos8700_pm_ops,
+		   },
+	.probe = fxos8700_probe,
+	.remove = fxos8700_remove,
+	.id_table = fxos8700_id,
+};
+
+module_i2c_driver(fxos8700_driver);
+
+MODULE_AUTHOR("Freescale Semiconductor, Inc.");
+MODULE_DESCRIPTION("FXOS8700 6-Axis Acc and Mag Combo Sensor driver");
+MODULE_LICENSE("GPL");
diff --git a/drivers/mmc/core/block.c b/drivers/mmc/core/block.c
index 99b981a05..1a0f43cdf 100644
--- a/drivers/mmc/core/block.c
+++ b/drivers/mmc/core/block.c
@@ -70,6 +70,7 @@ MODULE_ALIAS("mmc:block");
  * ample.
  */
 #define MMC_BLK_TIMEOUT_MS  (10 * 1000)
+#define MMC_SANITIZE_REQ_TIMEOUT 240000
 #define MMC_EXTRACT_INDEX_FROM_ARG(x) ((x & 0x00FF0000) >> 16)
 #define MMC_EXTRACT_VALUE_FROM_ARG(x) ((x & 0x0000FF00) >> 8)
 
@@ -167,11 +168,6 @@ MODULE_PARM_DESC(perdev_minors, "Minors numbers to allocate per device");
 
 static inline int mmc_blk_part_switch(struct mmc_card *card,
 				      unsigned int part_type);
-static void mmc_blk_rw_rq_prep(struct mmc_queue_req *mqrq,
-			       struct mmc_card *card,
-			       int disable_multi,
-			       struct mmc_queue *mq);
-static void mmc_blk_hsq_req_done(struct mmc_request *mrq);
 
 static struct mmc_blk_data *mmc_blk_get(struct gendisk *disk)
 {
@@ -313,6 +309,7 @@ static int mmc_blk_open(struct block_device *bdev, fmode_t mode)
 	mutex_lock(&block_mutex);
 	if (md) {
 		ret = 0;
+
 		if ((mode & FMODE_WRITE) && md->read_only) {
 			mmc_blk_put(md);
 			ret = -EROFS;
@@ -409,42 +406,66 @@ static int mmc_blk_ioctl_copy_to_user(struct mmc_ioc_cmd __user *ic_ptr,
 	return 0;
 }
 
-static int card_busy_detect(struct mmc_card *card, unsigned int timeout_ms,
-			    u32 *resp_errs)
+static int ioctl_rpmb_card_status_poll(struct mmc_card *card, u32 *status,
+				       u32 retries_max)
 {
-	unsigned long timeout = jiffies + msecs_to_jiffies(timeout_ms);
-	int err = 0;
-	u32 status;
+	int err;
+	u32 retry_count = 0;
+
+	if (!status || !retries_max)
+		return -EINVAL;
 
 	do {
-		bool done = time_after(jiffies, timeout);
+		err = __mmc_send_status(card, status, 5);
+		if (err)
+			break;
 
-		err = __mmc_send_status(card, &status, 5);
-		if (err) {
-			dev_err(mmc_dev(card->host),
-				"error %d requesting status\n", err);
-			return err;
-		}
-
-		/* Accumulate any response error bits seen */
-		if (resp_errs)
-			*resp_errs |= status;
+		if (!R1_STATUS(*status) &&
+				(R1_CURRENT_STATE(*status) != R1_STATE_PRG))
+			break; /* RPMB programming operation complete */
 
 		/*
-		 * Timeout if the device never becomes ready for data and never
-		 * leaves the program state.
+		 * Rechedule to give the MMC device a chance to continue
+		 * processing the previous command without being polled too
+		 * frequently.
 		 */
-		if (done) {
-			dev_err(mmc_dev(card->host),
-				"Card stuck in wrong state! %s status: %#x\n",
-				 __func__, status);
-			return -ETIMEDOUT;
-		}
-	} while (!mmc_ready_for_data(status));
+		usleep_range(1000, 5000);
+	} while (++retry_count < retries_max);
+
+	if (retry_count == retries_max)
+		err = -EPERM;
 
 	return err;
 }
 
+static int ioctl_do_sanitize(struct mmc_card *card)
+{
+	int err;
+
+	if (!mmc_can_sanitize(card)) {
+			pr_warn("%s: %s - SANITIZE is not supported\n",
+				mmc_hostname(card->host), __func__);
+			err = -EOPNOTSUPP;
+			goto out;
+	}
+
+	pr_debug("%s: %s - SANITIZE IN PROGRESS...\n",
+		mmc_hostname(card->host), __func__);
+
+	err = mmc_switch(card, EXT_CSD_CMD_SET_NORMAL,
+					EXT_CSD_SANITIZE_START, 1,
+					MMC_SANITIZE_REQ_TIMEOUT);
+
+	if (err)
+		pr_err("%s: %s - EXT_CSD_SANITIZE_START failed. err=%d\n",
+		       mmc_hostname(card->host), __func__, err);
+
+	pr_debug("%s: %s - SANITIZE COMPLETED\n", mmc_hostname(card->host),
+					     __func__);
+out:
+	return err;
+}
+
 static int __mmc_blk_ioctl_cmd(struct mmc_card *card, struct mmc_blk_data *md,
 			       struct mmc_blk_ioc_data *idata)
 {
@@ -454,6 +475,7 @@ static int __mmc_blk_ioctl_cmd(struct mmc_card *card, struct mmc_blk_data *md,
 	struct scatterlist sg;
 	int err;
 	unsigned int target_part;
+	u32 status = 0;
 
 	if (!card || !md || !idata)
 		return -EINVAL;
@@ -537,11 +559,17 @@ static int __mmc_blk_ioctl_cmd(struct mmc_card *card, struct mmc_blk_data *md,
 	}
 
 	if ((MMC_EXTRACT_INDEX_FROM_ARG(cmd.arg) == EXT_CSD_SANITIZE_START) &&
-	    (cmd.opcode == MMC_SWITCH))
-		return mmc_sanitize(card);
+	    (cmd.opcode == MMC_SWITCH)) {
+		err = ioctl_do_sanitize(card);
+
+		if (err)
+			pr_err("%s: ioctl_do_sanitize() failed. err = %d",
+			       __func__, err);
+
+		return err;
+	}
 
 	mmc_wait_for_req(card->host, &mrq);
-	memcpy(&idata->ic.response, cmd.resp, sizeof(cmd.resp));
 
 	if (cmd.error) {
 		dev_err(mmc_dev(card->host), "%s: cmd error %d\n",
@@ -572,18 +600,6 @@ static int __mmc_blk_ioctl_cmd(struct mmc_card *card, struct mmc_blk_data *md,
 		main_md->part_curr = value & EXT_CSD_PART_CONFIG_ACC_MASK;
 	}
 
-	/*
-	 * Make sure to update CACHE_CTRL in case it was changed. The cache
-	 * will get turned back on if the card is re-initialized, e.g.
-	 * suspend/resume or hw reset in recovery.
-	 */
-	if ((MMC_EXTRACT_INDEX_FROM_ARG(cmd.arg) == EXT_CSD_CACHE_CTRL) &&
-	    (cmd.opcode == MMC_SWITCH)) {
-		u8 value = MMC_EXTRACT_VALUE_FROM_ARG(cmd.arg) & 1;
-
-		card->ext_csd.cache_ctrl = value;
-	}
-
 	/*
 	 * According to the SD specs, some commands require a delay after
 	 * issuing the command.
@@ -591,12 +607,18 @@ static int __mmc_blk_ioctl_cmd(struct mmc_card *card, struct mmc_blk_data *md,
 	if (idata->ic.postsleep_min_us)
 		usleep_range(idata->ic.postsleep_min_us, idata->ic.postsleep_max_us);
 
-	if (idata->rpmb || (cmd.flags & MMC_RSP_R1B) == MMC_RSP_R1B) {
+	memcpy(&(idata->ic.response), cmd.resp, sizeof(cmd.resp));
+
+	if (idata->rpmb) {
 		/*
-		 * Ensure RPMB/R1B command has completed by polling CMD13
+		 * Ensure RPMB command has completed by polling CMD13
 		 * "Send Status".
 		 */
-		err = card_busy_detect(card, MMC_BLK_TIMEOUT_MS, NULL);
+		err = ioctl_rpmb_card_status_poll(card, &status, 5);
+		if (err)
+			dev_err(mmc_dev(card->host),
+					"%s: Card Status=0x%08X, error %d\n",
+					__func__, status, err);
 	}
 
 	return err;
@@ -734,7 +756,7 @@ static int mmc_blk_check_blkdev(struct block_device *bdev)
 	 * whole block device, not on a partition.  This prevents overspray
 	 * between sibling partitions.
 	 */
-	if (!capable(CAP_SYS_RAWIO) || bdev_is_partition(bdev))
+	if ((!capable(CAP_SYS_RAWIO)) || (bdev != bdev->bd_contains))
 		return -EPERM;
 	return 0;
 }
@@ -946,6 +968,58 @@ static unsigned int mmc_blk_data_timeout_ms(struct mmc_host *host,
 	return ms;
 }
 
+static inline bool mmc_blk_in_tran_state(u32 status)
+{
+	/*
+	 * Some cards mishandle the status bits, so make sure to check both the
+	 * busy indication and the card state.
+	 */
+	return status & R1_READY_FOR_DATA &&
+	       (R1_CURRENT_STATE(status) == R1_STATE_TRAN);
+}
+
+static int card_busy_detect(struct mmc_card *card, unsigned int timeout_ms,
+			    struct request *req, u32 *resp_errs)
+{
+	unsigned long timeout = jiffies + msecs_to_jiffies(timeout_ms);
+	int err = 0;
+	u32 status;
+
+	do {
+		bool done = time_after(jiffies, timeout);
+
+		err = __mmc_send_status(card, &status, 5);
+		if (err) {
+			pr_err("%s: error %d requesting status\n",
+			       req->rq_disk->disk_name, err);
+			return err;
+		}
+
+		/* Accumulate any response error bits seen */
+		if (resp_errs)
+			*resp_errs |= status;
+
+		/*
+		 * Timeout if the device never becomes ready for data and never
+		 * leaves the program state.
+		 */
+		if (done) {
+			pr_err("%s: Card stuck in wrong state! %s %s status: %#x\n",
+				mmc_hostname(card->host),
+				req->rq_disk->disk_name, __func__, status);
+			return -ETIMEDOUT;
+		}
+
+		/*
+		 * Some cards mishandle the status bits,
+		 * so make sure to check both the busy
+		 * indication and the card state.
+		 */
+	} while (!mmc_blk_in_tran_state(status));
+
+	return err;
+}
+
 static int mmc_blk_reset(struct mmc_blk_data *md, struct mmc_host *host,
 			 int type)
 {
@@ -1002,12 +1076,6 @@ static void mmc_blk_issue_drv_op(struct mmc_queue *mq, struct request *req)
 
 	switch (mq_rq->drv_op) {
 	case MMC_DRV_OP_IOCTL:
-		if (card->ext_csd.cmdq_en) {
-			ret = mmc_cmdq_disable(card);
-			if (ret)
-				break;
-		}
-		fallthrough;
 	case MMC_DRV_OP_IOCTL_RPMB:
 		idata = mq_rq->drv_op_data;
 		for (i = 0, ret = 0; i < mq_rq->ioc_count; i++) {
@@ -1018,8 +1086,6 @@ static void mmc_blk_issue_drv_op(struct mmc_queue *mq, struct request *req)
 		/* Always switch back to main area after RPMB access */
 		if (rpmb_ioctl)
 			mmc_blk_part_switch(card, 0);
-		else if (card->reenable_cmdq && !card->ext_csd.cmdq_en)
-			mmc_cmdq_enable(card);
 		break;
 	case MMC_DRV_OP_BOOT_WP:
 		ret = mmc_switch(card, EXT_CSD_CMD_SET_NORMAL, EXT_CSD_BOOT_WP,
@@ -1076,7 +1142,7 @@ static void mmc_blk_issue_discard_rq(struct mmc_queue *mq, struct request *req)
 					 card->erase_arg == MMC_TRIM_ARG ?
 					 INAND_CMD38_ARG_TRIM :
 					 INAND_CMD38_ARG_ERASE,
-					 card->ext_csd.generic_cmd6_time);
+					 0);
 		}
 		if (!err)
 			err = mmc_erase(card, from, nr, card->erase_arg);
@@ -1118,7 +1184,7 @@ static void mmc_blk_issue_secdiscard_rq(struct mmc_queue *mq,
 				 arg == MMC_SECURE_TRIM1_ARG ?
 				 INAND_CMD38_ARG_SECTRIM1 :
 				 INAND_CMD38_ARG_SECERASE,
-				 card->ext_csd.generic_cmd6_time);
+				 0);
 		if (err)
 			goto out_retry;
 	}
@@ -1136,7 +1202,7 @@ static void mmc_blk_issue_secdiscard_rq(struct mmc_queue *mq,
 			err = mmc_switch(card, EXT_CSD_CMD_SET_NORMAL,
 					 INAND_CMD38_ARG_EXT_CSD,
 					 INAND_CMD38_ARG_SECTRIM2,
-					 card->ext_csd.generic_cmd6_time);
+					 0);
 			if (err)
 				goto out_retry;
 		}
@@ -1386,7 +1452,6 @@ static void mmc_blk_cqe_complete_rq(struct mmc_queue *mq, struct request *req)
 	struct mmc_request *mrq = &mqrq->brq.mrq;
 	struct request_queue *q = req->q;
 	struct mmc_host *host = mq->card->host;
-	enum mmc_issue_type issue_type = mmc_issue_type(mq, req);
 	unsigned long flags;
 	bool put_card;
 	int err;
@@ -1416,7 +1481,7 @@ static void mmc_blk_cqe_complete_rq(struct mmc_queue *mq, struct request *req)
 
 	spin_lock_irqsave(&mq->lock, flags);
 
-	mq->in_flight[issue_type] -= 1;
+	mq->in_flight[mmc_issue_type(mq, req)] -= 1;
 
 	put_card = (mmc_tot_in_flight(mq) == 0);
 
@@ -1462,7 +1527,7 @@ static void mmc_blk_cqe_req_done(struct mmc_request *mrq)
 	 */
 	if (mq->in_recovery)
 		mmc_blk_cqe_complete_rq(mq, req);
-	else if (likely(!blk_should_fake_timeout(req->q)))
+	else
 		blk_mq_complete_request(req);
 }
 
@@ -1502,30 +1567,9 @@ static int mmc_blk_cqe_issue_flush(struct mmc_queue *mq, struct request *req)
 	return mmc_blk_cqe_start_req(mq->card->host, mrq);
 }
 
-static int mmc_blk_hsq_issue_rw_rq(struct mmc_queue *mq, struct request *req)
-{
-	struct mmc_queue_req *mqrq = req_to_mmc_queue_req(req);
-	struct mmc_host *host = mq->card->host;
-	int err;
-
-	mmc_blk_rw_rq_prep(mqrq, mq->card, 0, mq);
-	mqrq->brq.mrq.done = mmc_blk_hsq_req_done;
-	mmc_pre_req(host, &mqrq->brq.mrq);
-
-	err = mmc_cqe_start_req(host, &mqrq->brq.mrq);
-	if (err)
-		mmc_post_req(host, &mqrq->brq.mrq, err);
-
-	return err;
-}
-
 static int mmc_blk_cqe_issue_rw_rq(struct mmc_queue *mq, struct request *req)
 {
 	struct mmc_queue_req *mqrq = req_to_mmc_queue_req(req);
-	struct mmc_host *host = mq->card->host;
-
-	if (host->hsq_enabled)
-		return mmc_blk_hsq_issue_rw_rq(mq, req);
 
 	mmc_blk_data_prep(mq, mqrq, 0, NULL, NULL);
 
@@ -1625,7 +1669,7 @@ static int mmc_blk_fix_state(struct mmc_card *card, struct request *req)
 
 	mmc_blk_send_stop(card, timeout);
 
-	err = card_busy_detect(card, timeout, NULL);
+	err = card_busy_detect(card, timeout, req, NULL);
 
 	mmc_retune_release(card->host);
 
@@ -1642,31 +1686,31 @@ static void mmc_blk_read_single(struct mmc_queue *mq, struct request *req)
 	struct mmc_card *card = mq->card;
 	struct mmc_host *host = card->host;
 	blk_status_t error = BLK_STS_OK;
+	int retries = 0;
 
 	do {
 		u32 status;
 		int err;
-		int retries = 0;
 
-		while (retries++ <= MMC_READ_SINGLE_RETRIES) {
-			mmc_blk_rw_rq_prep(mqrq, card, 1, mq);
+		mmc_blk_rw_rq_prep(mqrq, card, 1, mq);
 
-			mmc_wait_for_req(host, mrq);
+		mmc_wait_for_req(host, mrq);
 
-			err = mmc_send_status(card, &status);
+		err = mmc_send_status(card, &status);
+		if (err)
+			goto error_exit;
+
+		if (!mmc_host_is_spi(host) &&
+		    !mmc_blk_in_tran_state(status)) {
+			err = mmc_blk_fix_state(card, req);
 			if (err)
 				goto error_exit;
+		}
 
-			if (!mmc_host_is_spi(host) &&
-			    !mmc_ready_for_data(status)) {
-				err = mmc_blk_fix_state(card, req);
-				if (err)
-					goto error_exit;
-			}
+		if (mrq->cmd->error && retries++ < MMC_READ_SINGLE_RETRIES)
+			continue;
 
-			if (!mrq->cmd->error)
-				break;
-		}
+		retries = 0;
 
 		if (mrq->cmd->error ||
 		    mrq->data->error ||
@@ -1717,7 +1761,7 @@ static bool mmc_blk_status_error(struct request *req, u32 status)
 	return brq->cmd.resp[0]  & CMD_ERRORS    ||
 	       brq->stop.resp[0] & stop_err_bits ||
 	       status            & stop_err_bits ||
-	       (rq_data_dir(req) == WRITE && !mmc_ready_for_data(status));
+	       (rq_data_dir(req) == WRITE && !mmc_blk_in_tran_state(status));
 }
 
 static inline bool mmc_blk_cmd_started(struct mmc_blk_request *brq)
@@ -1779,7 +1823,7 @@ static void mmc_blk_mq_rw_recovery(struct mmc_queue *mq, struct request *req)
 
 	/* Try to get back to "tran" state */
 	if (!mmc_host_is_spi(mq->card->host) &&
-	    (err || !mmc_ready_for_data(status)))
+	    (err || !mmc_blk_in_tran_state(status)))
 		err = mmc_blk_fix_state(mq->card, req);
 
 	/*
@@ -1849,7 +1893,7 @@ static int mmc_blk_card_busy(struct mmc_card *card, struct request *req)
 	if (mmc_host_is_spi(card->host) || rq_data_dir(req) == READ)
 		return 0;
 
-	err = card_busy_detect(card, MMC_BLK_TIMEOUT_MS, &status);
+	err = card_busy_detect(card, MMC_BLK_TIMEOUT_MS, req, &status);
 
 	/*
 	 * Do not assume data transferred correctly if there are any error bits
@@ -1911,48 +1955,13 @@ static void mmc_blk_urgent_bkops(struct mmc_queue *mq,
 		mmc_run_bkops(mq->card);
 }
 
-static void mmc_blk_hsq_req_done(struct mmc_request *mrq)
-{
-	struct mmc_queue_req *mqrq =
-		container_of(mrq, struct mmc_queue_req, brq.mrq);
-	struct request *req = mmc_queue_req_to_req(mqrq);
-	struct request_queue *q = req->q;
-	struct mmc_queue *mq = q->queuedata;
-	struct mmc_host *host = mq->card->host;
-	unsigned long flags;
-
-	if (mmc_blk_rq_error(&mqrq->brq) ||
-	    mmc_blk_urgent_bkops_needed(mq, mqrq)) {
-		spin_lock_irqsave(&mq->lock, flags);
-		mq->recovery_needed = true;
-		mq->recovery_req = req;
-		spin_unlock_irqrestore(&mq->lock, flags);
-
-		host->cqe_ops->cqe_recovery_start(host);
-
-		schedule_work(&mq->recovery_work);
-		return;
-	}
-
-	mmc_blk_rw_reset_success(mq, req);
-
-	/*
-	 * Block layer timeouts race with completions which means the normal
-	 * completion path cannot be used during recovery.
-	 */
-	if (mq->in_recovery)
-		mmc_blk_cqe_complete_rq(mq, req);
-	else if (likely(!blk_should_fake_timeout(req->q)))
-		blk_mq_complete_request(req);
-}
-
 void mmc_blk_mq_complete(struct request *req)
 {
 	struct mmc_queue *mq = req->q->queuedata;
 
 	if (mq->use_cqe)
 		mmc_blk_cqe_complete_rq(mq, req);
-	else if (likely(!blk_should_fake_timeout(req->q)))
+	else
 		mmc_blk_mq_complete_rq(mq, req);
 }
 
@@ -2004,7 +2013,7 @@ static void mmc_blk_mq_post_req(struct mmc_queue *mq, struct request *req)
 	 */
 	if (mq->in_recovery)
 		mmc_blk_mq_complete_rq(mq, req);
-	else if (likely(!blk_should_fake_timeout(req->q)))
+	else
 		blk_mq_complete_request(req);
 
 	mmc_blk_mq_dec_in_flight(mq, req);
@@ -2240,10 +2249,6 @@ enum mmc_issued mmc_blk_mq_issue_rq(struct mmc_queue *mq, struct request *req)
 	case MMC_ISSUE_ASYNC:
 		switch (req_op(req)) {
 		case REQ_OP_FLUSH:
-			if (!mmc_cache_enabled(host)) {
-				blk_mq_end_request(req, BLK_STS_OK);
-				return MMC_REQ_FINISHED;
-			}
 			ret = mmc_blk_cqe_issue_flush(mq, req);
 			break;
 		case REQ_OP_READ:
@@ -2504,8 +2509,8 @@ static int mmc_rpmb_chrdev_release(struct inode *inode, struct file *filp)
 	struct mmc_rpmb_data *rpmb = container_of(inode->i_cdev,
 						  struct mmc_rpmb_data, chrdev);
 
-	mmc_blk_put(rpmb->md);
 	put_device(&rpmb->dev);
+	mmc_blk_put(rpmb->md);
 
 	return 0;
 }
diff --git a/drivers/mmc/core/bus.c b/drivers/mmc/core/bus.c
index 4383c262b..74de3f2dd 100644
--- a/drivers/mmc/core/bus.c
+++ b/drivers/mmc/core/bus.c
@@ -68,7 +68,6 @@ mmc_bus_uevent(struct device *dev, struct kobj_uevent_env *env)
 {
 	struct mmc_card *card = mmc_dev_to_card(dev);
 	const char *type;
-	unsigned int i;
 	int retval = 0;
 
 	switch (card->type) {
@@ -94,31 +93,6 @@ mmc_bus_uevent(struct device *dev, struct kobj_uevent_env *env)
 			return retval;
 	}
 
-	if (card->type == MMC_TYPE_SDIO || card->type == MMC_TYPE_SD_COMBO) {
-		retval = add_uevent_var(env, "SDIO_ID=%04X:%04X",
-					card->cis.vendor, card->cis.device);
-		if (retval)
-			return retval;
-
-		retval = add_uevent_var(env, "SDIO_REVISION=%u.%u",
-					card->major_rev, card->minor_rev);
-		if (retval)
-			return retval;
-
-		for (i = 0; i < card->num_info; i++) {
-			retval = add_uevent_var(env, "SDIO_INFO%u=%s", i+1, card->info[i]);
-			if (retval)
-				return retval;
-		}
-	}
-
-	/*
-	 * SDIO (non-combo) cards are not handled by mmc_block driver and do not
-	 * have accessible CID register which used by mmc_card_name() function.
-	 */
-	if (card->type == MMC_TYPE_SDIO)
-		return 0;
-
 	retval = add_uevent_var(env, "MMC_NAME=%s", mmc_card_name(card));
 	if (retval)
 		return retval;
@@ -399,6 +373,11 @@ void mmc_remove_card(struct mmc_card *card)
 	mmc_remove_card_debugfs(card);
 #endif
 
+	if (host->cqe_enabled) {
+		host->cqe_ops->cqe_disable(host);
+		host->cqe_enabled = false;
+	}
+
 	if (mmc_card_present(card)) {
 		if (mmc_host_is_spi(card->host)) {
 			pr_info("%s: SPI card removed\n",
@@ -411,10 +390,6 @@ void mmc_remove_card(struct mmc_card *card)
 		of_node_put(card->dev.of_node);
 	}
 
-	if (host->cqe_enabled) {
-		host->cqe_ops->cqe_disable(host);
-		host->cqe_enabled = false;
-	}
-
 	put_device(&card->dev);
 }
+
diff --git a/drivers/mmc/core/core.c b/drivers/mmc/core/core.c
index eb82f6aac..8009ff847 100644
--- a/drivers/mmc/core/core.c
+++ b/drivers/mmc/core/core.c
@@ -52,6 +52,8 @@
 
 static const unsigned freqs[] = { 400000, 300000, 200000, 100000 };
 
+static int __mmc_max_reserved_idx = -1;
+
 /*
  * Enabling software CRCs on the data blocks can be a significant (30%)
  * performance cost, and for other reasons may not always be desired.
@@ -403,6 +405,23 @@ void mmc_wait_for_req_done(struct mmc_host *host, struct mmc_request *mrq)
 
 		cmd = mrq->cmd;
 
+		/*
+		 * If host has timed out waiting for the sanitize
+		 * to complete, card might be still in programming state
+		 * so let's try to bring the card out of programming
+		 * state.
+		 */
+		if (cmd->sanitize_busy && cmd->error == -ETIMEDOUT) {
+			if (!mmc_interrupt_hpi(host->card)) {
+				pr_warn("%s: %s: Interrupted sanitize\n",
+					mmc_hostname(host), __func__);
+				cmd->error = 0;
+				break;
+			} else {
+				pr_err("%s: %s: Failed to interrupt sanitize\n",
+				       mmc_hostname(host), __func__);
+			}
+		}
 		if (!cmd->error || !cmd->retries ||
 		    mmc_card_removed(host->card))
 			break;
@@ -936,14 +955,11 @@ int mmc_execute_tuning(struct mmc_card *card)
 
 	err = host->ops->execute_tuning(host, opcode);
 
-	if (err) {
+	if (err)
 		pr_err("%s: tuning execution failed: %d\n",
 			mmc_hostname(host), err);
-	} else {
-		host->retune_now = 0;
-		host->need_retune = 0;
+	else
 		mmc_retune_enable(host);
-	}
 
 	return err;
 }
@@ -1207,7 +1223,7 @@ int mmc_set_uhs_voltage(struct mmc_host *host, u32 ocr)
 
 	err = mmc_wait_for_cmd(host, &cmd, 0);
 	if (err)
-		goto power_cycle;
+		return err;
 
 	if (!mmc_host_is_spi(host) && (cmd.resp[0] & R1_ERROR))
 		return -EIO;
@@ -1455,15 +1471,16 @@ void mmc_detach_bus(struct mmc_host *host)
 	mmc_bus_put(host);
 }
 
-void _mmc_detect_change(struct mmc_host *host, unsigned long delay, bool cd_irq)
+static void _mmc_detect_change(struct mmc_host *host, unsigned long delay,
+				bool cd_irq)
 {
 	/*
-	 * Prevent system sleep for 5s to allow user space to consume the
-	 * corresponding uevent. This is especially useful, when CD irq is used
-	 * as a system wakeup, but doesn't hurt in other cases.
+	 * If the device is configured as wakeup, we prevent a new sleep for
+	 * 5 s to give provision for user space to consume the event.
 	 */
-	if (cd_irq && !(host->caps & MMC_CAP_NEEDS_POLL))
-		__pm_wakeup_event(host->ws, 5000);
+	if (cd_irq && !(host->caps & MMC_CAP_NEEDS_POLL) &&
+		device_can_wakeup(mmc_dev(host)))
+		pm_wakeup_event(mmc_dev(host), 5000);
 
 	host->detect_change = 1;
 	mmc_schedule_delayed_work(&host->detect, delay);
@@ -1644,6 +1661,8 @@ static int mmc_do_erase(struct mmc_card *card, unsigned int from,
 	struct mmc_command cmd = {};
 	unsigned int qty = 0, busy_timeout = 0;
 	bool use_r1b_resp = false;
+	unsigned long timeout;
+	int loop_udelay=64, udelay_max=32768;
 	int err;
 
 	mmc_retune_hold(card->host);
@@ -1716,11 +1735,8 @@ static int mmc_do_erase(struct mmc_card *card, unsigned int from,
 	 * the erase operation does not exceed the max_busy_timeout, we should
 	 * use R1B response. Or we need to prevent the host from doing hw busy
 	 * detection, which is done by converting to a R1 response instead.
-	 * Note, some hosts requires R1B, which also means they are on their own
-	 * when it comes to deal with the busy timeout.
 	 */
-	if (!(card->host->caps & MMC_CAP_NEED_RSP_BUSY) &&
-	    card->host->max_busy_timeout &&
+	if (card->host->max_busy_timeout &&
 	    busy_timeout > card->host->max_busy_timeout) {
 		cmd.flags = MMC_RSP_SPI_R1 | MMC_RSP_R1 | MMC_CMD_AC;
 	} else {
@@ -1747,8 +1763,38 @@ static int mmc_do_erase(struct mmc_card *card, unsigned int from,
 	if ((card->host->caps & MMC_CAP_WAIT_WHILE_BUSY) && use_r1b_resp)
 		goto out;
 
-	/* Let's poll to find out when the erase operation completes. */
-	err = mmc_poll_for_busy(card, busy_timeout, MMC_BUSY_ERASE);
+	timeout = jiffies + msecs_to_jiffies(busy_timeout);
+	do {
+		memset(&cmd, 0, sizeof(struct mmc_command));
+		cmd.opcode = MMC_SEND_STATUS;
+		cmd.arg = card->rca << 16;
+		cmd.flags = MMC_RSP_R1 | MMC_CMD_AC;
+		/* Do not retry else we can't see errors */
+		err = mmc_wait_for_cmd(card->host, &cmd, 0);
+		if (err || R1_STATUS(cmd.resp[0])) {
+			pr_err("error %d requesting status %#x\n",
+				err, cmd.resp[0]);
+			err = -EIO;
+			goto out;
+		}
+
+		/* Timeout if the device never becomes ready for data and
+		 * never leaves the program state.
+		 */
+		if (time_after(jiffies, timeout)) {
+			pr_err("%s: Card stuck in programming state! %s\n",
+				mmc_hostname(card->host), __func__);
+			err =  -EIO;
+			goto out;
+		}
+		if ((cmd.resp[0] & R1_READY_FOR_DATA) &&
+		    R1_CURRENT_STATE(cmd.resp[0]) != R1_STATE_PRG)
+			break;
+
+		usleep_range(loop_udelay, loop_udelay*2);
+		if (loop_udelay < udelay_max)
+			loop_udelay *= 2;
+	} while (1);
 
 out:
 	mmc_retune_release(card->host);
@@ -1818,7 +1864,8 @@ int mmc_erase(struct mmc_card *card, unsigned int from, unsigned int nr,
 	unsigned int rem, to = from + nr;
 	int err;
 
-	if (!(card->csd.cmdclass & CCC_ERASE))
+	if (!(card->host->caps & MMC_CAP_ERASE) ||
+	    !(card->csd.cmdclass & CCC_ERASE))
 		return -EOPNOTSUPP;
 
 	if (!card->erase_size)
@@ -1874,7 +1921,8 @@ EXPORT_SYMBOL(mmc_erase);
 
 int mmc_can_erase(struct mmc_card *card)
 {
-	if (card->csd.cmdclass & CCC_ERASE && card->erase_size)
+	if ((card->host->caps & MMC_CAP_ERASE) &&
+	    (card->csd.cmdclass & CCC_ERASE) && card->erase_size)
 		return 1;
 	return 0;
 }
@@ -1909,6 +1957,7 @@ int mmc_can_sanitize(struct mmc_card *card)
 		return 1;
 	return 0;
 }
+EXPORT_SYMBOL(mmc_can_sanitize);
 
 int mmc_can_secure_erase_trim(struct mmc_card *card)
 {
@@ -2066,16 +2115,6 @@ static void mmc_hw_reset_for_init(struct mmc_host *host)
 	host->ops->hw_reset(host);
 }
 
-/**
- * mmc_hw_reset - reset the card in hardware
- * @host: MMC host to which the card is attached
- *
- * Hard reset the card. This function is only for upper layers, like the
- * block layer or card drivers. You cannot use it in host drivers (struct
- * mmc_card might be gone then).
- *
- * Return: 0 on success, -errno on failure
- */
 int mmc_hw_reset(struct mmc_host *host)
 {
 	int ret;
@@ -2092,7 +2131,7 @@ int mmc_hw_reset(struct mmc_host *host)
 	ret = host->bus_ops->hw_reset(host);
 	mmc_bus_put(host);
 
-	if (ret < 0)
+	if (ret)
 		pr_warn("%s: tried to HW reset card, got error %d\n",
 			mmc_hostname(host), ret);
 
@@ -2260,8 +2299,11 @@ void mmc_rescan(struct work_struct *work)
 
 	mmc_bus_get(host);
 
-	/* Verify a registered card to be functional, else remove it. */
-	if (host->bus_ops && !host->bus_dead)
+	/*
+	 * if there is a _removable_ card registered, check whether it is
+	 * still present
+	 */
+	if (host->bus_ops && !host->bus_dead && mmc_card_is_removable(host))
 		host->bus_ops->detect(host);
 
 	host->detect_change = 0;
@@ -2294,13 +2336,7 @@ void mmc_rescan(struct work_struct *work)
 	}
 
 	for (i = 0; i < ARRAY_SIZE(freqs); i++) {
-		unsigned int freq = freqs[i];
-		if (freq > host->f_max) {
-			if (i + 1 < ARRAY_SIZE(freqs))
-				continue;
-			freq = host->f_max;
-		}
-		if (!mmc_rescan_try_freq(host, max(freq, host->f_min)))
+		if (!mmc_rescan_try_freq(host, max(freqs[i], host->f_min)))
 			break;
 		if (freqs[i] <= host->f_min)
 			break;
@@ -2314,8 +2350,9 @@ void mmc_rescan(struct work_struct *work)
 
 void mmc_start_host(struct mmc_host *host)
 {
-	host->f_init = max(min(freqs[0], host->f_max), host->f_min);
+	host->f_init = max(freqs[0], host->f_min);
 	host->rescan_disable = 0;
+	host->ios.power_mode = MMC_POWER_UNDEFINED;
 
 	if (!(host->caps2 & MMC_CAP2_NO_PRESCAN_POWERUP)) {
 		mmc_claim_host(host);
@@ -2363,10 +2400,120 @@ void mmc_stop_host(struct mmc_host *host)
 	mmc_release_host(host);
 }
 
+#ifdef CONFIG_PM_SLEEP
+/* Do the card removal on suspend if card is assumed removeable
+ * Do that in pm notifier while userspace isn't yet frozen, so we will be able
+   to sync the card.
+*/
+static int mmc_pm_notify(struct notifier_block *notify_block,
+			unsigned long mode, void *unused)
+{
+	struct mmc_host *host = container_of(
+		notify_block, struct mmc_host, pm_notify);
+	unsigned long flags;
+	int err = 0;
+
+	switch (mode) {
+	case PM_HIBERNATION_PREPARE:
+	case PM_SUSPEND_PREPARE:
+	case PM_RESTORE_PREPARE:
+		spin_lock_irqsave(&host->lock, flags);
+		host->rescan_disable = 1;
+		spin_unlock_irqrestore(&host->lock, flags);
+		cancel_delayed_work_sync(&host->detect);
+
+		if (!host->bus_ops)
+			break;
+
+		/* Validate prerequisites for suspend */
+		if (host->bus_ops->pre_suspend)
+			err = host->bus_ops->pre_suspend(host);
+		if (!err)
+			break;
+
+		if (!mmc_card_is_removable(host)) {
+			dev_warn(mmc_dev(host),
+				 "pre_suspend failed for non-removable host: "
+				 "%d\n", err);
+			/* Avoid removing non-removable hosts */
+			break;
+		}
+
+		/* Calling bus_ops->remove() with a claimed host can deadlock */
+		host->bus_ops->remove(host);
+		mmc_claim_host(host);
+		mmc_detach_bus(host);
+		mmc_power_off(host);
+		mmc_release_host(host);
+		host->pm_flags = 0;
+		break;
+
+	case PM_POST_SUSPEND:
+	case PM_POST_HIBERNATION:
+	case PM_POST_RESTORE:
+
+		spin_lock_irqsave(&host->lock, flags);
+		host->rescan_disable = 0;
+		spin_unlock_irqrestore(&host->lock, flags);
+		_mmc_detect_change(host, 0, false);
+
+	}
+
+	return 0;
+}
+
+void mmc_register_pm_notifier(struct mmc_host *host)
+{
+	host->pm_notify.notifier_call = mmc_pm_notify;
+	register_pm_notifier(&host->pm_notify);
+}
+
+void mmc_unregister_pm_notifier(struct mmc_host *host)
+{
+	unregister_pm_notifier(&host->pm_notify);
+}
+#endif
+
+/*
+ * mmc_first_nonreserved_index() - get the first index that
+ * is not reserved
+ */
+int mmc_first_nonreserved_index(void)
+{
+	return __mmc_max_reserved_idx + 1;
+}
+EXPORT_SYMBOL(mmc_first_nonreserved_index);
+
+/*
+ * mmc_get_reserved_index() - get the index reserved for this host
+ * Return: The index reserved for this host or negative error value
+ *        if no index is reserved for this host
+ */
+int mmc_get_reserved_index(struct mmc_host *host)
+{
+	return of_alias_get_id(host->parent->of_node, "mmc");
+}
+EXPORT_SYMBOL(mmc_get_reserved_index);
+
+static void mmc_of_reserve_idx(void)
+{
+	int max;
+
+	max = of_alias_get_highest_id("mmc");
+	if (max < 0)
+		return;
+
+	__mmc_max_reserved_idx = max;
+	pr_debug("MMC: reserving %d slots for of aliases\n",
+			__mmc_max_reserved_idx + 1);
+}
+
 static int __init mmc_init(void)
 {
 	int ret;
 
+	mmc_of_reserve_idx();
+
 	ret = mmc_register_bus();
 	if (ret)
 		return ret;
diff --git a/drivers/mmc/core/core.h b/drivers/mmc/core/core.h
index a6c814fdb..de73bea11 100644
--- a/drivers/mmc/core/core.h
+++ b/drivers/mmc/core/core.h
@@ -29,7 +29,6 @@ struct mmc_bus_ops {
 	int (*shutdown)(struct mmc_host *);
 	int (*hw_reset)(struct mmc_host *);
 	int (*sw_reset)(struct mmc_host *);
-	bool (*cache_enabled)(struct mmc_host *);
 };
 
 void mmc_attach_bus(struct mmc_host *host, const struct mmc_bus_ops *ops);
@@ -72,15 +71,14 @@ void mmc_start_host(struct mmc_host *host);
 void __mmc_stop_host(struct mmc_host *host);
 void mmc_stop_host(struct mmc_host *host);
 
-void _mmc_detect_change(struct mmc_host *host, unsigned long delay,
-			bool cd_irq);
 int _mmc_detect_card_removed(struct mmc_host *host);
 int mmc_detect_card_removed(struct mmc_host *host);
 
 int mmc_attach_mmc(struct mmc_host *host);
 int mmc_attach_sd(struct mmc_host *host);
 int mmc_attach_sdio(struct mmc_host *host);
-
+int mmc_first_nonreserved_index(void);
+int mmc_get_reserved_index(struct mmc_host *host);
 /* Module parameters */
 extern bool use_spi_crc;
 
@@ -95,6 +93,14 @@ int mmc_execute_tuning(struct mmc_card *card);
 int mmc_hs200_to_hs400(struct mmc_card *card);
 int mmc_hs400_to_hs200(struct mmc_card *card);
 
+#ifdef CONFIG_PM_SLEEP
+void mmc_register_pm_notifier(struct mmc_host *host);
+void mmc_unregister_pm_notifier(struct mmc_host *host);
+#else
+static inline void mmc_register_pm_notifier(struct mmc_host *host) { }
+static inline void mmc_unregister_pm_notifier(struct mmc_host *host) { }
+#endif
+
 void mmc_wait_for_req_done(struct mmc_host *host, struct mmc_request *mrq);
 bool mmc_is_req_done(struct mmc_host *host, struct mmc_request *mrq);
 
@@ -165,12 +171,4 @@ static inline void mmc_post_req(struct mmc_host *host, struct mmc_request *mrq,
 		host->ops->post_req(host, mrq, err);
 }
 
-static inline bool mmc_cache_enabled(struct mmc_host *host)
-{
-	if (host->bus_ops->cache_enabled)
-		return host->bus_ops->cache_enabled(host);
-
-	return false;
-}
-
 #endif
diff --git a/drivers/mmc/core/debugfs.c b/drivers/mmc/core/debugfs.c
index 9ec84c86c..09e0c7659 100644
--- a/drivers/mmc/core/debugfs.c
+++ b/drivers/mmc/core/debugfs.c
@@ -219,7 +219,7 @@ static int mmc_clock_opt_set(void *data, u64 val)
 	return 0;
 }
 
-DEFINE_DEBUGFS_ATTRIBUTE(mmc_clock_fops, mmc_clock_opt_get, mmc_clock_opt_set,
+DEFINE_SIMPLE_ATTRIBUTE(mmc_clock_fops, mmc_clock_opt_get, mmc_clock_opt_set,
 	"%llu\n");
 
 void mmc_add_host_debugfs(struct mmc_host *host)
@@ -232,8 +232,8 @@ void mmc_add_host_debugfs(struct mmc_host *host)
 	debugfs_create_file("ios", S_IRUSR, root, host, &mmc_ios_fops);
 	debugfs_create_x32("caps", S_IRUSR, root, &host->caps);
 	debugfs_create_x32("caps2", S_IRUSR, root, &host->caps2);
-	debugfs_create_file_unsafe("clock", S_IRUSR | S_IWUSR, root, host,
-				   &mmc_clock_fops);
+	debugfs_create_file("clock", S_IRUSR | S_IWUSR, root, host,
+			    &mmc_clock_fops);
 
 #ifdef CONFIG_FAIL_MMC_REQUEST
 	if (fail_request)
diff --git a/drivers/mmc/core/host.c b/drivers/mmc/core/host.c
index 864c8c205..114926d21 100644
--- a/drivers/mmc/core/host.c
+++ b/drivers/mmc/core/host.c
@@ -15,7 +15,6 @@
 #include <linux/of.h>
 #include <linux/of_gpio.h>
 #include <linux/pagemap.h>
-#include <linux/pm_wakeup.h>
 #include <linux/export.h>
 #include <linux/leds.h>
 #include <linux/slab.h>
@@ -34,64 +33,16 @@
 
 static DEFINE_IDA(mmc_host_ida);
 
-#ifdef CONFIG_PM_SLEEP
-static int mmc_host_class_prepare(struct device *dev)
-{
-	struct mmc_host *host = cls_dev_to_mmc_host(dev);
-
-	/*
-	 * It's safe to access the bus_ops pointer, as both userspace and the
-	 * workqueue for detecting cards are frozen at this point.
-	 */
-	if (!host->bus_ops)
-		return 0;
-
-	/* Validate conditions for system suspend. */
-	if (host->bus_ops->pre_suspend)
-		return host->bus_ops->pre_suspend(host);
-
-	return 0;
-}
-
-static void mmc_host_class_complete(struct device *dev)
-{
-	struct mmc_host *host = cls_dev_to_mmc_host(dev);
-
-	_mmc_detect_change(host, 0, false);
-}
-
-static const struct dev_pm_ops mmc_host_class_dev_pm_ops = {
-	.prepare = mmc_host_class_prepare,
-	.complete = mmc_host_class_complete,
-};
-
-#define MMC_HOST_CLASS_DEV_PM_OPS (&mmc_host_class_dev_pm_ops)
-#else
-#define MMC_HOST_CLASS_DEV_PM_OPS NULL
-#endif
-
 static void mmc_host_classdev_release(struct device *dev)
 {
 	struct mmc_host *host = cls_dev_to_mmc_host(dev);
-	wakeup_source_unregister(host->ws);
-	if (of_alias_get_id(host->parent->of_node, "mmc") < 0)
-		ida_simple_remove(&mmc_host_ida, host->index);
+	ida_simple_remove(&mmc_host_ida, host->index);
 	kfree(host);
 }
 
-static int mmc_host_classdev_shutdown(struct device *dev)
-{
-	struct mmc_host *host = cls_dev_to_mmc_host(dev);
-
-	__mmc_stop_host(host);
-	return 0;
-}
-
 static struct class mmc_host_class = {
 	.name		= "mmc_host",
 	.dev_release	= mmc_host_classdev_release,
-	.shutdown_pre	= mmc_host_classdev_shutdown,
-	.pm		= MMC_HOST_CLASS_DEV_PM_OPS,
 };
 
 int mmc_register_host_class(void)
@@ -224,6 +175,8 @@ int mmc_of_parse(struct mmc_host *host)
 	struct device *dev = host->parent;
 	u32 bus_width, drv_type, cd_debounce_delay_ms;
 	int ret;
+	bool cd_cap_invert, cd_gpio_invert = false;
+	bool ro_cap_invert, ro_gpio_invert = false;
 
 	if (!dev || !dev_fwnode(dev))
 		return 0;
@@ -238,7 +191,7 @@ int mmc_of_parse(struct mmc_host *host)
 	switch (bus_width) {
 	case 8:
 		host->caps |= MMC_CAP_8_BIT_DATA;
-		fallthrough;	/* Hosts capable of 8-bit can also do 4 bits */
+		/* fall through - Hosts capable of 8-bit can also do 4 bits */
 	case 4:
 		host->caps |= MMC_CAP_4_BIT_DATA;
 		break;
@@ -266,12 +219,10 @@ int mmc_of_parse(struct mmc_host *host)
 	 */
 
 	/* Parse Card Detection */
-
 	if (device_property_read_bool(dev, "non-removable")) {
 		host->caps |= MMC_CAP_NONREMOVABLE;
 	} else {
-		if (device_property_read_bool(dev, "cd-inverted"))
-			host->caps2 |= MMC_CAP2_CD_ACTIVE_HIGH;
+		cd_cap_invert = device_property_read_bool(dev, "cd-inverted");
 
 		if (device_property_read_u32(dev, "cd-debounce-delay-ms",
 					     &cd_debounce_delay_ms))
@@ -281,19 +232,32 @@ int mmc_of_parse(struct mmc_host *host)
 			host->caps |= MMC_CAP_NEEDS_POLL;
 
 		ret = mmc_gpiod_request_cd(host, "cd", 0, false,
-					   cd_debounce_delay_ms * 1000);
+					   cd_debounce_delay_ms * 1000,
+					   &cd_gpio_invert);
 		if (!ret)
 			dev_info(host->parent, "Got CD GPIO\n");
 		else if (ret != -ENOENT && ret != -ENOSYS)
 			return ret;
+
+		/*
+		 * There are two ways to flag that the CD line is inverted:
+		 * through the cd-inverted flag and by the GPIO line itself
+		 * being inverted from the GPIO subsystem. This is a leftover
+		 * from the times when the GPIO subsystem did not make it
+		 * possible to flag a line as inverted.
+		 *
+		 * If the capability on the host AND the GPIO line are
+		 * both inverted, the end result is that the CD line is
+		 * not inverted.
+		 */
+		if (cd_cap_invert ^ cd_gpio_invert)
+			host->caps2 |= MMC_CAP2_CD_ACTIVE_HIGH;
 	}
 
 	/* Parse Write Protection */
+	ro_cap_invert = device_property_read_bool(dev, "wp-inverted");
 
-	if (device_property_read_bool(dev, "wp-inverted"))
-		host->caps2 |= MMC_CAP2_RO_ACTIVE_HIGH;
-
-	ret = mmc_gpiod_request_ro(host, "wp", 0, 0);
+	ret = mmc_gpiod_request_ro(host, "wp", 0, 0, &ro_gpio_invert);
 	if (!ret)
 		dev_info(host->parent, "Got WP GPIO\n");
 	else if (ret != -ENOENT && ret != -ENOSYS)
@@ -302,6 +266,10 @@ int mmc_of_parse(struct mmc_host *host)
 	if (device_property_read_bool(dev, "disable-wp"))
 		host->caps2 |= MMC_CAP2_NO_WRITE_PROTECT;
 
+	/* See the comment on CD inversion above */
+	if (ro_cap_invert ^ ro_gpio_invert)
+		host->caps2 |= MMC_CAP2_RO_ACTIVE_HIGH;
+
 	if (device_property_read_bool(dev, "cap-sd-highspeed"))
 		host->caps |= MMC_CAP_SD_HIGHSPEED;
 	if (device_property_read_bool(dev, "cap-mmc-highspeed"))
@@ -324,13 +292,13 @@ int mmc_of_parse(struct mmc_host *host)
 		host->caps |= MMC_CAP_SDIO_IRQ;
 	if (device_property_read_bool(dev, "full-pwr-cycle"))
 		host->caps2 |= MMC_CAP2_FULL_PWR_CYCLE;
-	if (device_property_read_bool(dev, "full-pwr-cycle-in-suspend"))
-		host->caps2 |= MMC_CAP2_FULL_PWR_CYCLE_IN_SUSPEND;
 	if (device_property_read_bool(dev, "keep-power-in-suspend"))
 		host->pm_caps |= MMC_PM_KEEP_POWER;
 	if (device_property_read_bool(dev, "wakeup-source") ||
 	    device_property_read_bool(dev, "enable-sdio-wakeup")) /* legacy */
 		host->pm_caps |= MMC_PM_WAKE_SDIO_IRQ;
+	if (device_property_read_bool(dev, "pm-ignore-notify"))
+		host->pm_caps |= MMC_PM_IGNORE_PM_NOTIFY;
 	if (device_property_read_bool(dev, "mmc-ddr-3_3v"))
 		host->caps |= MMC_CAP_3_3V_DDR;
 	if (device_property_read_bool(dev, "mmc-ddr-1_8v"))
@@ -423,20 +391,6 @@ int mmc_of_parse_voltage(struct device_node *np, u32 *mask)
 }
 EXPORT_SYMBOL(mmc_of_parse_voltage);
 
-/**
- * mmc_first_nonreserved_index() - get the first index that is not reserved
- */
-static int mmc_first_nonreserved_index(void)
-{
-	int max;
-
-	max = of_alias_get_highest_id("mmc");
-	if (max < 0)
-		return 0;
-
-	return max + 1;
-}
-
 /**
  *	mmc_alloc_host - initialise the per-host structure.
  *	@extra: sizeof private data structure
@@ -446,9 +400,9 @@ static int mmc_first_nonreserved_index(void)
  */
 struct mmc_host *mmc_alloc_host(int extra, struct device *dev)
 {
-	int index;
+	int err;
+	int alias_id;
 	struct mmc_host *host;
-	int alias_id, min_idx, max_idx;
 
 	host = kzalloc(sizeof(struct mmc_host) + extra, GFP_KERNEL);
 	if (!host)
@@ -456,27 +410,25 @@ struct mmc_host *mmc_alloc_host(int extra, struct device *dev)
 
 	/* scanning will be enabled when we're ready */
 	host->rescan_disable = 1;
+	host->parent = dev;
 
-	alias_id = of_alias_get_id(dev->of_node, "mmc");
-	if (alias_id >= 0) {
-		index = alias_id;
-	} else {
-		min_idx = mmc_first_nonreserved_index();
-		max_idx = 0;
-
-		index = ida_simple_get(&mmc_host_ida, min_idx, max_idx, GFP_KERNEL);
-		if (index < 0) {
-			kfree(host);
-			return NULL;
-		}
+	alias_id = mmc_get_reserved_index(host);
+	if (alias_id >= 0)
+		err = ida_simple_get(&mmc_host_ida, alias_id,
+				alias_id + 1, GFP_KERNEL);
+	else
+		err = ida_simple_get(&mmc_host_ida,
+					mmc_first_nonreserved_index(),
+					0, GFP_KERNEL);
+	if (err < 0) {
+		kfree(host);
+		return NULL;
 	}
 
-	host->index = index;
+	host->index = err;
 
 	dev_set_name(&host->class_dev, "mmc%d", host->index);
-	host->ws = wakeup_source_register(NULL, dev_name(&host->class_dev));
 
-	host->parent = dev;
 	host->class_dev.parent = dev;
 	host->class_dev.class = &mmc_host_class;
 	device_initialize(&host->class_dev);
@@ -506,7 +458,6 @@ struct mmc_host *mmc_alloc_host(int extra, struct device *dev)
 
 	host->fixed_drv_type = -EINVAL;
 	host->ios.power_delay_ms = 10;
-	host->ios.power_mode = MMC_POWER_UNDEFINED;
 
 	return host;
 }
@@ -539,6 +490,9 @@ int mmc_add_host(struct mmc_host *host)
 #endif
 
 	mmc_start_host(host);
+	if (!(host->pm_caps& MMC_PM_IGNORE_PM_NOTIFY))
+		mmc_register_pm_notifier(host);
+
 	return 0;
 }
 
@@ -554,6 +508,8 @@ EXPORT_SYMBOL(mmc_add_host);
  */
 void mmc_remove_host(struct mmc_host *host)
 {
+	if (!(host->pm_caps& MMC_PM_IGNORE_PM_NOTIFY))
+		mmc_unregister_pm_notifier(host);
 	mmc_stop_host(host);
 
 #ifdef CONFIG_DEBUG_FS
diff --git a/drivers/mmc/core/mmc.c b/drivers/mmc/core/mmc.c
index 7494d5950..c88048955 100644
--- a/drivers/mmc/core/mmc.c
+++ b/drivers/mmc/core/mmc.c
@@ -297,7 +297,7 @@ static void mmc_manage_enhanced_area(struct mmc_card *card, u8 *ext_csd)
 	}
 }
 
-static void mmc_part_add(struct mmc_card *card, u64 size,
+static void mmc_part_add(struct mmc_card *card, unsigned int size,
 			 unsigned int part_cfg, char *name, int idx, bool ro,
 			 int area_type)
 {
@@ -313,7 +313,7 @@ static void mmc_manage_gp_partitions(struct mmc_card *card, u8 *ext_csd)
 {
 	int idx;
 	u8 hc_erase_grp_sz, hc_wp_grp_sz;
-	u64 part_size;
+	unsigned int part_size;
 
 	/*
 	 * General purpose partition feature support --
@@ -343,7 +343,8 @@ static void mmc_manage_gp_partitions(struct mmc_card *card, u8 *ext_csd)
 				(ext_csd[EXT_CSD_GP_SIZE_MULT + idx * 3 + 1]
 				<< 8) +
 				ext_csd[EXT_CSD_GP_SIZE_MULT + idx * 3];
-			part_size *= (hc_erase_grp_sz * hc_wp_grp_sz);
+			part_size *= (size_t)(hc_erase_grp_sz *
+				hc_wp_grp_sz);
 			mmc_part_add(card, part_size << 19,
 				EXT_CSD_PART_CONFIG_ACC_GP0 + idx,
 				"gp%d", idx, false,
@@ -361,7 +362,7 @@ static void mmc_manage_gp_partitions(struct mmc_card *card, u8 *ext_csd)
 static int mmc_decode_ext_csd(struct mmc_card *card, u8 *ext_csd)
 {
 	int err = 0, idx;
-	u64 part_size;
+	unsigned int part_size;
 	struct device_node *np;
 	bool broken_hpi = false;
 
@@ -423,6 +424,10 @@ static int mmc_decode_ext_csd(struct mmc_card *card, u8 *ext_csd)
 
 		/* EXT_CSD value is in units of 10ms, but we store in ms */
 		card->ext_csd.part_time = 10 * ext_csd[EXT_CSD_PART_SWITCH_TIME];
+		/* Some eMMC set the value too low so set a minimum */
+		if (card->ext_csd.part_time &&
+		    card->ext_csd.part_time < MMC_MIN_PART_SWITCH_TIME)
+			card->ext_csd.part_time = MMC_MIN_PART_SWITCH_TIME;
 
 		/* Sleep / awake timeout in 100ns units */
 		if (sa_shift > 0 && sa_shift <= 0x17)
@@ -612,17 +617,6 @@ static int mmc_decode_ext_csd(struct mmc_card *card, u8 *ext_csd)
 		card->ext_csd.data_sector_size = 512;
 	}
 
-	/*
-	 * GENERIC_CMD6_TIME is to be used "unless a specific timeout is defined
-	 * when accessing a specific field", so use it here if there is no
-	 * PARTITION_SWITCH_TIME.
-	 */
-	if (!card->ext_csd.part_time)
-		card->ext_csd.part_time = card->ext_csd.generic_cmd6_time;
-	/* Some eMMC set the value too low so set a minimum */
-	if (card->ext_csd.part_time < MMC_MIN_PART_SWITCH_TIME)
-		card->ext_csd.part_time = MMC_MIN_PART_SWITCH_TIME;
-
 	/* eMMC v5 or later */
 	if (card->ext_csd.rev >= 7) {
 		memcpy(card->ext_csd.fwrev, &ext_csd[EXT_CSD_FIRMWARE_VERSION],
@@ -654,9 +648,6 @@ static int mmc_decode_ext_csd(struct mmc_card *card, u8 *ext_csd)
 				 mmc_hostname(card->host),
 				 card->ext_csd.cmdq_depth);
 		}
-		card->ext_csd.enhanced_rpmb_supported =
-					(card->ext_csd.rel_param &
-					 EXT_CSD_WR_REL_PARAM_EN_RPMB_REL_WR);
 	}
 out:
 	return err;
@@ -796,8 +787,6 @@ MMC_DEV_ATTR(enhanced_area_offset, "%llu\n",
 		card->ext_csd.enhanced_area_offset);
 MMC_DEV_ATTR(enhanced_area_size, "%u\n", card->ext_csd.enhanced_area_size);
 MMC_DEV_ATTR(raw_rpmb_size_mult, "%#x\n", card->ext_csd.raw_rpmb_size_mult);
-MMC_DEV_ATTR(enhanced_rpmb_supported, "%#x\n",
-	card->ext_csd.enhanced_rpmb_supported);
 MMC_DEV_ATTR(rel_sectors, "%#x\n", card->ext_csd.rel_sectors);
 MMC_DEV_ATTR(ocr, "0x%08x\n", card->ocr);
 MMC_DEV_ATTR(rca, "0x%04x\n", card->rca);
@@ -855,7 +844,6 @@ static struct attribute *mmc_std_attrs[] = {
 	&dev_attr_enhanced_area_offset.attr,
 	&dev_attr_enhanced_area_size.attr,
 	&dev_attr_raw_rpmb_size_mult.attr,
-	&dev_attr_enhanced_rpmb_supported.attr,
 	&dev_attr_rel_sectors.attr,
 	&dev_attr_ocr.attr,
 	&dev_attr_rca.attr,
@@ -1068,7 +1056,7 @@ static int mmc_select_hs(struct mmc_card *card)
 	err = __mmc_switch(card, EXT_CSD_CMD_SET_NORMAL,
 			   EXT_CSD_HS_TIMING, EXT_CSD_TIMING_HS,
 			   card->ext_csd.generic_cmd6_time, MMC_TIMING_MMC_HS,
-			   true, true);
+			   true, true, true);
 	if (err)
 		pr_warn("%s: switch to high-speed failed, err:%d\n",
 			mmc_hostname(card->host), err);
@@ -1100,7 +1088,7 @@ static int mmc_select_hs_ddr(struct mmc_card *card)
 			   ext_csd_bits,
 			   card->ext_csd.generic_cmd6_time,
 			   MMC_TIMING_MMC_DDR52,
-			   true, true);
+			   true, true, true);
 	if (err) {
 		pr_err("%s: switch to bus width %d ddr failed\n",
 			mmc_hostname(host), 1 << bus_width);
@@ -1168,25 +1156,25 @@ static int mmc_select_hs400(struct mmc_card *card)
 	err = __mmc_switch(card, EXT_CSD_CMD_SET_NORMAL,
 			   EXT_CSD_HS_TIMING, val,
 			   card->ext_csd.generic_cmd6_time, 0,
-			   false, true);
+			   true, false, true);
 	if (err) {
 		pr_err("%s: switch to high-speed from hs200 failed, err:%d\n",
 			mmc_hostname(host), err);
 		return err;
 	}
 
+	/* Set host controller to HS timing */
+	mmc_set_timing(card->host, MMC_TIMING_MMC_HS);
+
 	/* Prepare host to downgrade to HS timing */
 	if (host->ops->hs400_downgrade)
 		host->ops->hs400_downgrade(host);
 
-	/* Set host controller to HS timing */
-	mmc_set_timing(host, MMC_TIMING_MMC_HS);
-
 	/* Reduce frequency to HS frequency */
 	max_dtr = card->ext_csd.hs_max_dtr;
 	mmc_set_clock(host, max_dtr);
 
-	err = mmc_switch_status(card, true);
+	err = mmc_switch_status(card);
 	if (err)
 		goto out_err;
 
@@ -1210,7 +1198,7 @@ static int mmc_select_hs400(struct mmc_card *card)
 	err = __mmc_switch(card, EXT_CSD_CMD_SET_NORMAL,
 			   EXT_CSD_HS_TIMING, val,
 			   card->ext_csd.generic_cmd6_time, 0,
-			   false, true);
+			   true, false, true);
 	if (err) {
 		pr_err("%s: switch to hs400 failed, err:%d\n",
 			 mmc_hostname(host), err);
@@ -1224,7 +1212,7 @@ static int mmc_select_hs400(struct mmc_card *card)
 	if (host->ops->hs400_complete)
 		host->ops->hs400_complete(host);
 
-	err = mmc_switch_status(card, true);
+	err = mmc_switch_status(card);
 	if (err)
 		goto out_err;
 
@@ -1256,29 +1244,29 @@ int mmc_hs400_to_hs200(struct mmc_card *card)
 	val = EXT_CSD_TIMING_HS;
 	err = __mmc_switch(card, EXT_CSD_CMD_SET_NORMAL, EXT_CSD_HS_TIMING,
 			   val, card->ext_csd.generic_cmd6_time, 0,
-			   false, true);
+			   true, false, true);
 	if (err)
 		goto out_err;
 
-	if (host->ops->hs400_downgrade)
-		host->ops->hs400_downgrade(host);
-
 	mmc_set_timing(host, MMC_TIMING_MMC_DDR52);
 
-	err = mmc_switch_status(card, true);
+	err = mmc_switch_status(card);
 	if (err)
 		goto out_err;
 
 	/* Switch HS DDR to HS */
 	err = __mmc_switch(card, EXT_CSD_CMD_SET_NORMAL, EXT_CSD_BUS_WIDTH,
 			   EXT_CSD_BUS_WIDTH_8, card->ext_csd.generic_cmd6_time,
-			   0, false, true);
+			   0, true, false, true);
 	if (err)
 		goto out_err;
 
 	mmc_set_timing(host, MMC_TIMING_MMC_HS);
 
-	err = mmc_switch_status(card, true);
+	if (host->ops->hs400_downgrade)
+		host->ops->hs400_downgrade(host);
+
+	err = mmc_switch_status(card);
 	if (err)
 		goto out_err;
 
@@ -1287,7 +1275,7 @@ int mmc_hs400_to_hs200(struct mmc_card *card)
 	      card->drive_strength << EXT_CSD_DRV_STR_SHIFT;
 	err = __mmc_switch(card, EXT_CSD_CMD_SET_NORMAL, EXT_CSD_HS_TIMING,
 			   val, card->ext_csd.generic_cmd6_time, 0,
-			   false, true);
+			   true, false, true);
 	if (err)
 		goto out_err;
 
@@ -1298,7 +1286,7 @@ int mmc_hs400_to_hs200(struct mmc_card *card)
 	 * failed. If there really is a problem, we would expect tuning will
 	 * fail and the result ends up the same.
 	 */
-	err = mmc_switch_status(card, false);
+	err = __mmc_switch_status(card, false);
 	if (err)
 		goto out_err;
 
@@ -1371,7 +1359,7 @@ static int mmc_select_hs400es(struct mmc_card *card)
 	err = __mmc_switch(card, EXT_CSD_CMD_SET_NORMAL,
 			   EXT_CSD_HS_TIMING, EXT_CSD_TIMING_HS,
 			   card->ext_csd.generic_cmd6_time, 0,
-			   false, true);
+			   true, false, true);
 	if (err) {
 		pr_err("%s: switch to hs for hs400es failed, err:%d\n",
 			mmc_hostname(host), err);
@@ -1379,7 +1367,7 @@ static int mmc_select_hs400es(struct mmc_card *card)
 	}
 
 	mmc_set_timing(host, MMC_TIMING_MMC_HS);
-	err = mmc_switch_status(card, true);
+	err = mmc_switch_status(card);
 	if (err)
 		goto out_err;
 
@@ -1405,7 +1393,7 @@ static int mmc_select_hs400es(struct mmc_card *card)
 	err = __mmc_switch(card, EXT_CSD_CMD_SET_NORMAL,
 			   EXT_CSD_HS_TIMING, val,
 			   card->ext_csd.generic_cmd6_time, 0,
-			   false, true);
+			   true, false, true);
 	if (err) {
 		pr_err("%s: switch to hs400es failed, err:%d\n",
 			mmc_hostname(host), err);
@@ -1420,7 +1408,7 @@ static int mmc_select_hs400es(struct mmc_card *card)
 	if (host->ops->hs400_enhanced_strobe)
 		host->ops->hs400_enhanced_strobe(host, &host->ios);
 
-	err = mmc_switch_status(card, true);
+	err = mmc_switch_status(card);
 	if (err)
 		goto out_err;
 
@@ -1470,7 +1458,7 @@ static int mmc_select_hs200(struct mmc_card *card)
 		err = __mmc_switch(card, EXT_CSD_CMD_SET_NORMAL,
 				   EXT_CSD_HS_TIMING, val,
 				   card->ext_csd.generic_cmd6_time, 0,
-				   false, true);
+				   true, false, true);
 		if (err)
 			goto err;
 		old_timing = host->ios.timing;
@@ -1481,7 +1469,7 @@ static int mmc_select_hs200(struct mmc_card *card)
 		 * switch failed. If there really is a problem, we would expect
 		 * tuning will fail and the result ends up the same.
 		 */
-		err = mmc_switch_status(card, false);
+		err = __mmc_switch_status(card, false);
 
 		/*
 		 * mmc_select_timing() assumes timing has not changed if
@@ -1770,17 +1758,13 @@ static int mmc_init_card(struct mmc_host *host, u32 ocr,
 		goto free_card;
 
 	if (mmc_card_hs200(card)) {
-		host->doing_init_tune = 1;
-
 		err = mmc_hs200_tuning(card);
-		if (!err)
-			err = mmc_select_hs400(card);
-
-		host->doing_init_tune = 0;
-
 		if (err)
 			goto free_card;
 
+		err = mmc_select_hs400(card);
+		if (err)
+			goto free_card;
 	} else if (!mmc_card_hs400es(card)) {
 		/* Select the desired bus width optionally */
 		err = mmc_select_bus_width(card);
@@ -1868,19 +1852,15 @@ static int mmc_init_card(struct mmc_host *host, u32 ocr,
 	 */
 	card->reenable_cmdq = card->ext_csd.cmdq_en;
 
-	if (host->cqe_ops && !host->cqe_enabled) {
+	if (card->ext_csd.cmdq_en && !host->cqe_enabled) {
 		err = host->cqe_ops->cqe_enable(host, card);
-		if (!err) {
+		if (err) {
+			pr_err("%s: Failed to enable CQE, error %d\n",
+				mmc_hostname(host), err);
+		} else {
 			host->cqe_enabled = true;
-
-			if (card->ext_csd.cmdq_en) {
-				pr_info("%s: Command Queue Engine enabled\n",
-					mmc_hostname(host));
-			} else {
-				host->hsq_enabled = true;
-				pr_info("%s: Host Software Queue enabled\n",
-					mmc_hostname(host));
-			}
+			pr_info("%s: Command Queue Engine enabled\n",
+				mmc_hostname(host));
 		}
 	}
 
@@ -1931,12 +1911,9 @@ static int mmc_sleep(struct mmc_host *host)
 	 * If the max_busy_timeout of the host is specified, validate it against
 	 * the sleep cmd timeout. A failure means we need to prevent the host
 	 * from doing hw busy detection, which is done by converting to a R1
-	 * response instead of a R1B. Note, some hosts requires R1B, which also
-	 * means they are on their own when it comes to deal with the busy
-	 * timeout.
+	 * response instead of a R1B.
 	 */
-	if (!(host->caps & MMC_CAP_NEED_RSP_BUSY) && host->max_busy_timeout &&
-	    (timeout_ms > host->max_busy_timeout)) {
+	if (host->max_busy_timeout && (timeout_ms > host->max_busy_timeout)) {
 		cmd.flags = MMC_RSP_R1 | MMC_CMD_AC;
 	} else {
 		cmd.flags = MMC_RSP_R1B | MMC_CMD_AC;
@@ -1979,7 +1956,7 @@ static int mmc_poweroff_notify(struct mmc_card *card, unsigned int notify_type)
 
 	err = __mmc_switch(card, EXT_CSD_CMD_SET_NORMAL,
 			EXT_CSD_POWER_OFF_NOTIFICATION,
-			notify_type, timeout, 0, false, false);
+			notify_type, timeout, 0, true, false, false);
 	if (err)
 		pr_err("%s: Power Off Notification timed out, %u\n",
 		       mmc_hostname(card->host), timeout);
@@ -2033,12 +2010,6 @@ static void mmc_detect(struct mmc_host *host)
 	}
 }
 
-static bool _mmc_cache_enabled(struct mmc_host *host)
-{
-	return host->card->ext_csd.cache_size > 0 &&
-	       host->card->ext_csd.cache_ctrl & 1;
-}
-
 static int _mmc_suspend(struct mmc_host *host, bool is_suspend)
 {
 	int err = 0;
@@ -2055,8 +2026,7 @@ static int _mmc_suspend(struct mmc_host *host, bool is_suspend)
 		goto out;
 
 	if (mmc_can_poweroff_notify(host->card) &&
-	    ((host->caps2 & MMC_CAP2_FULL_PWR_CYCLE) || !is_suspend ||
-	     (host->caps2 & MMC_CAP2_FULL_PWR_CYCLE_IN_SUSPEND)))
+		((host->caps2 & MMC_CAP2_FULL_PWR_CYCLE) || !is_suspend))
 		err = mmc_poweroff_notify(host->card, notify_type);
 	else if (mmc_can_sleep(host->card))
 		err = mmc_sleep(host);
@@ -2218,7 +2188,6 @@ static const struct mmc_bus_ops mmc_ops = {
 	.alive = mmc_alive,
 	.shutdown = mmc_shutdown,
 	.hw_reset = _mmc_hw_reset,
-	.cache_enabled = _mmc_cache_enabled,
 };
 
 /*
diff --git a/drivers/mmc/core/mmc_ops.c b/drivers/mmc/core/mmc_ops.c
index ebad70e44..80bab66c6 100644
--- a/drivers/mmc/core/mmc_ops.c
+++ b/drivers/mmc/core/mmc_ops.c
@@ -19,9 +19,7 @@
 #include "host.h"
 #include "mmc_ops.h"
 
-#define MMC_BKOPS_TIMEOUT_MS		(120 * 1000) /* 120s */
-#define MMC_CACHE_FLUSH_TIMEOUT_MS	(30 * 1000) /* 30s */
-#define MMC_SANITIZE_TIMEOUT_MS		(240 * 1000) /* 240s */
+#define MMC_OPS_TIMEOUT_MS	(10 * 60 * 1000) /* 10 minute timeout */
 
 static const u8 tuning_blk_pattern_4bit[] = {
 	0xff, 0x0f, 0xff, 0x00, 0xff, 0xcc, 0xc3, 0xcc,
@@ -431,7 +429,7 @@ static int mmc_switch_status_error(struct mmc_host *host, u32 status)
 }
 
 /* Caller must hold re-tuning */
-int mmc_switch_status(struct mmc_card *card, bool crc_err_fatal)
+int __mmc_switch_status(struct mmc_card *card, bool crc_err_fatal)
 {
 	u32 status;
 	int err;
@@ -445,57 +443,25 @@ int mmc_switch_status(struct mmc_card *card, bool crc_err_fatal)
 	return mmc_switch_status_error(card->host, status);
 }
 
-static int mmc_busy_status(struct mmc_card *card, bool retry_crc_err,
-			   enum mmc_busy_cmd busy_cmd, bool *busy)
+int mmc_switch_status(struct mmc_card *card)
 {
-	struct mmc_host *host = card->host;
-	u32 status = 0;
-	int err;
-
-	if (host->ops->card_busy) {
-		*busy = host->ops->card_busy(host);
-		return 0;
-	}
-
-	err = mmc_send_status(card, &status);
-	if (retry_crc_err && err == -EILSEQ) {
-		*busy = true;
-		return 0;
-	}
-	if (err)
-		return err;
-
-	switch (busy_cmd) {
-	case MMC_BUSY_CMD6:
-		err = mmc_switch_status_error(card->host, status);
-		break;
-	case MMC_BUSY_ERASE:
-		err = R1_STATUS(status) ? -EIO : 0;
-		break;
-	case MMC_BUSY_HPI:
-		break;
-	default:
-		err = -EINVAL;
-	}
-
-	if (err)
-		return err;
-
-	*busy = !mmc_ready_for_data(status);
-	return 0;
+	return __mmc_switch_status(card, true);
 }
 
-static int __mmc_poll_for_busy(struct mmc_card *card, unsigned int timeout_ms,
-			       bool send_status, bool retry_crc_err,
-			       enum mmc_busy_cmd busy_cmd)
+static int mmc_poll_for_busy(struct mmc_card *card, unsigned int timeout_ms,
+			bool send_status, bool retry_crc_err)
 {
 	struct mmc_host *host = card->host;
 	int err;
 	unsigned long timeout;
-	unsigned int udelay = 32, udelay_max = 32768;
+	u32 status = 0;
 	bool expired = false;
 	bool busy = false;
 
+	/* We have an unspecified cmd timeout, use the fallback value. */
+	if (!timeout_ms)
+		timeout_ms = MMC_OPS_TIMEOUT_MS;
+
 	/*
 	 * In cases when not allowed to poll by using CMD13 or because we aren't
 	 * capable of polling by using ->card_busy(), then rely on waiting the
@@ -514,9 +480,21 @@ static int __mmc_poll_for_busy(struct mmc_card *card, unsigned int timeout_ms,
 		 */
 		expired = time_after(jiffies, timeout);
 
-		err = mmc_busy_status(card, retry_crc_err, busy_cmd, &busy);
-		if (err)
-			return err;
+		if (host->ops->card_busy) {
+			busy = host->ops->card_busy(host);
+		} else {
+			err = mmc_send_status(card, &status);
+			if (retry_crc_err && err == -EILSEQ) {
+				busy = true;
+			} else if (err) {
+				return err;
+			} else {
+				err = mmc_switch_status_error(host, status);
+				if (err)
+					return err;
+				busy = R1_CURRENT_STATE(status) == R1_STATE_PRG;
+			}
+		}
 
 		/* Timeout if the device still remains busy. */
 		if (expired && busy) {
@@ -524,24 +502,11 @@ static int __mmc_poll_for_busy(struct mmc_card *card, unsigned int timeout_ms,
 				mmc_hostname(host), __func__);
 			return -ETIMEDOUT;
 		}
-
-		/* Throttle the polling rate to avoid hogging the CPU. */
-		if (busy) {
-			usleep_range(udelay, udelay * 2);
-			if (udelay < udelay_max)
-				udelay *= 2;
-		}
 	} while (busy);
 
 	return 0;
 }
 
-int mmc_poll_for_busy(struct mmc_card *card, unsigned int timeout_ms,
-		      enum mmc_busy_cmd busy_cmd)
-{
-	return __mmc_poll_for_busy(card, timeout_ms, true, false, busy_cmd);
-}
-
 /**
  *	__mmc_switch - modify EXT_CSD register
  *	@card: the MMC card associated with the data transfer
@@ -551,6 +516,7 @@ int mmc_poll_for_busy(struct mmc_card *card, unsigned int timeout_ms,
  *	@timeout_ms: timeout (ms) for operation performed by register write,
  *                   timeout of zero implies maximum possible timeout
  *	@timing: new timing to change to
+ *	@use_busy_signal: use the busy signal as response type
  *	@send_status: send status cmd to poll for busy
  *	@retry_crc_err: retry when CRC errors when polling with CMD13 for busy
  *
@@ -558,31 +524,24 @@ int mmc_poll_for_busy(struct mmc_card *card, unsigned int timeout_ms,
  */
 int __mmc_switch(struct mmc_card *card, u8 set, u8 index, u8 value,
 		unsigned int timeout_ms, unsigned char timing,
-		bool send_status, bool retry_crc_err)
+		bool use_busy_signal, bool send_status,	bool retry_crc_err)
 {
 	struct mmc_host *host = card->host;
 	int err;
 	struct mmc_command cmd = {};
-	bool use_r1b_resp = true;
+	bool use_r1b_resp = use_busy_signal;
 	unsigned char old_timing = host->ios.timing;
 
 	mmc_retune_hold(host);
 
-	if (!timeout_ms) {
-		pr_warn("%s: unspecified timeout for CMD6 - use generic\n",
-			mmc_hostname(host));
-		timeout_ms = card->ext_csd.generic_cmd6_time;
-	}
-
 	/*
-	 * If the max_busy_timeout of the host is specified, make sure it's
-	 * enough to fit the used timeout_ms. In case it's not, let's instruct
-	 * the host to avoid HW busy detection, by converting to a R1 response
-	 * instead of a R1B. Note, some hosts requires R1B, which also means
-	 * they are on their own when it comes to deal with the busy timeout.
+	 * If the cmd timeout and the max_busy_timeout of the host are both
+	 * specified, let's validate them. A failure means we need to prevent
+	 * the host from doing hw busy detection, which is done by converting
+	 * to a R1 response instead of a R1B.
 	 */
-	if (!(host->caps & MMC_CAP_NEED_RSP_BUSY) && host->max_busy_timeout &&
-	    (timeout_ms > host->max_busy_timeout))
+	if (timeout_ms && host->max_busy_timeout &&
+		(timeout_ms > host->max_busy_timeout))
 		use_r1b_resp = false;
 
 	cmd.opcode = MMC_SWITCH;
@@ -593,23 +552,33 @@ int __mmc_switch(struct mmc_card *card, u8 set, u8 index, u8 value,
 	cmd.flags = MMC_CMD_AC;
 	if (use_r1b_resp) {
 		cmd.flags |= MMC_RSP_SPI_R1B | MMC_RSP_R1B;
+		/*
+		 * A busy_timeout of zero means the host can decide to use
+		 * whatever value it finds suitable.
+		 */
 		cmd.busy_timeout = timeout_ms;
 	} else {
 		cmd.flags |= MMC_RSP_SPI_R1 | MMC_RSP_R1;
 	}
 
+	if (index == EXT_CSD_SANITIZE_START)
+		cmd.sanitize_busy = true;
+
 	err = mmc_wait_for_cmd(host, &cmd, MMC_CMD_RETRIES);
 	if (err)
 		goto out;
 
+	/* No need to check card status in case of unblocking command */
+	if (!use_busy_signal)
+		goto out;
+
 	/*If SPI or used HW busy detection above, then we don't need to poll. */
 	if (((host->caps & MMC_CAP_WAIT_WHILE_BUSY) && use_r1b_resp) ||
 		mmc_host_is_spi(host))
 		goto out_tim;
 
 	/* Let's try to poll to find out when the command is completed. */
-	err = __mmc_poll_for_busy(card, timeout_ms, send_status, retry_crc_err,
-				  MMC_BUSY_CMD6);
+	err = mmc_poll_for_busy(card, timeout_ms, send_status, retry_crc_err);
 	if (err)
 		goto out;
 
@@ -618,8 +587,14 @@ int __mmc_switch(struct mmc_card *card, u8 set, u8 index, u8 value,
 	if (timing)
 		mmc_set_timing(host, timing);
 
+	/*
+	 * WORKAROUND: for Sandisk eMMC cards, it might need certain delay
+	 * before sending CMD13 after CMD6
+	 */
+	mdelay(1);
+
 	if (send_status) {
-		err = mmc_switch_status(card, true);
+		err = mmc_switch_status(card);
 		if (err && timing)
 			mmc_set_timing(host, old_timing);
 	}
@@ -633,7 +608,7 @@ int mmc_switch(struct mmc_card *card, u8 set, u8 index, u8 value,
 		unsigned int timeout_ms)
 {
 	return __mmc_switch(card, set, index, value, timeout_ms, 0,
-			    true, false);
+			true, true, false);
 }
 EXPORT_SYMBOL_GPL(mmc_switch);
 
@@ -829,46 +804,32 @@ int mmc_bus_test(struct mmc_card *card, u8 bus_width)
 	return mmc_send_bus_test(card, card->host, MMC_BUS_TEST_R, width);
 }
 
-static int mmc_send_hpi_cmd(struct mmc_card *card)
+static int mmc_send_hpi_cmd(struct mmc_card *card, u32 *status)
 {
-	unsigned int busy_timeout_ms = card->ext_csd.out_of_int_time;
-	struct mmc_host *host = card->host;
-	bool use_r1b_resp = true;
 	struct mmc_command cmd = {};
+	unsigned int opcode;
 	int err;
 
-	cmd.opcode = card->ext_csd.hpi_cmd;
-	cmd.arg = card->rca << 16 | 1;
-
-	/*
-	 * Make sure the host's max_busy_timeout fit the needed timeout for HPI.
-	 * In case it doesn't, let's instruct the host to avoid HW busy
-	 * detection, by using a R1 response instead of R1B.
-	 */
-	if (host->max_busy_timeout && busy_timeout_ms > host->max_busy_timeout)
-		use_r1b_resp = false;
-
-	if (cmd.opcode == MMC_STOP_TRANSMISSION && use_r1b_resp) {
+	opcode = card->ext_csd.hpi_cmd;
+	if (opcode == MMC_STOP_TRANSMISSION)
 		cmd.flags = MMC_RSP_R1B | MMC_CMD_AC;
-		cmd.busy_timeout = busy_timeout_ms;
-	} else {
+	else if (opcode == MMC_SEND_STATUS)
 		cmd.flags = MMC_RSP_R1 | MMC_CMD_AC;
-		use_r1b_resp = false;
-	}
 
-	err = mmc_wait_for_cmd(host, &cmd, 0);
+	cmd.opcode = opcode;
+	cmd.arg = card->rca << 16 | 1;
+
+	err = mmc_wait_for_cmd(card->host, &cmd, 0);
 	if (err) {
-		pr_warn("%s: HPI error %d. Command response %#x\n",
-			mmc_hostname(host), err, cmd.resp[0]);
+		pr_warn("%s: error %d interrupting operation. "
+			"HPI command response %#x\n", mmc_hostname(card->host),
+			err, cmd.resp[0]);
 		return err;
 	}
+	if (status)
+		*status = cmd.resp[0];
 
-	/* No need to poll when using HW busy detection. */
-	if (host->caps & MMC_CAP_WAIT_WHILE_BUSY && use_r1b_resp)
-		return 0;
-
-	/* Let's poll to find out when the HPI request completes. */
-	return mmc_poll_for_busy(card, busy_timeout_ms, MMC_BUSY_HPI);
+	return 0;
 }
 
 /**
@@ -878,10 +839,11 @@ static int mmc_send_hpi_cmd(struct mmc_card *card)
  *	Issued High Priority Interrupt, and check for card status
  *	until out-of prg-state.
  */
-static int mmc_interrupt_hpi(struct mmc_card *card)
+int mmc_interrupt_hpi(struct mmc_card *card)
 {
 	int err;
 	u32 status;
+	unsigned long prg_wait;
 
 	if (!card->ext_csd.hpi_en) {
 		pr_info("%s: HPI enable bit unset\n", mmc_hostname(card->host));
@@ -914,7 +876,20 @@ static int mmc_interrupt_hpi(struct mmc_card *card)
 		goto out;
 	}
 
-	err = mmc_send_hpi_cmd(card);
+	err = mmc_send_hpi_cmd(card, &status);
+	if (err)
+		goto out;
+
+	prg_wait = jiffies + msecs_to_jiffies(card->ext_csd.out_of_int_time);
+	do {
+		err = mmc_send_status(card, &status);
+
+		if (!err && R1_CURRENT_STATE(status) == R1_STATE_TRAN)
+			break;
+		if (time_after(jiffies, prg_wait))
+			err = -ETIMEDOUT;
+	} while (!err);
+
 out:
 	return err;
 }
@@ -972,7 +947,7 @@ void mmc_run_bkops(struct mmc_card *card)
 	 * urgent levels by using an asynchronous background task, when idle.
 	 */
 	err = mmc_switch(card, EXT_CSD_CMD_SET_NORMAL,
-			 EXT_CSD_BKOPS_START, 1, MMC_BKOPS_TIMEOUT_MS);
+			EXT_CSD_BKOPS_START, 1, MMC_OPS_TIMEOUT_MS);
 	if (err)
 		pr_warn("%s: Error %d starting bkops\n",
 			mmc_hostname(card->host), err);
@@ -988,10 +963,11 @@ int mmc_flush_cache(struct mmc_card *card)
 {
 	int err = 0;
 
-	if (mmc_cache_enabled(card->host)) {
+	if (mmc_card_mmc(card) &&
+			(card->ext_csd.cache_size > 0) &&
+			(card->ext_csd.cache_ctrl & 1)) {
 		err = mmc_switch(card, EXT_CSD_CMD_SET_NORMAL,
-				 EXT_CSD_FLUSH_CACHE, 1,
-				 MMC_CACHE_FLUSH_TIMEOUT_MS);
+				EXT_CSD_FLUSH_CACHE, 1, 0);
 		if (err)
 			pr_err("%s: cache flush error %d\n",
 					mmc_hostname(card->host), err);
@@ -1028,37 +1004,3 @@ int mmc_cmdq_disable(struct mmc_card *card)
 	return mmc_cmdq_switch(card, false);
 }
 EXPORT_SYMBOL_GPL(mmc_cmdq_disable);
-
-int mmc_sanitize(struct mmc_card *card)
-{
-	struct mmc_host *host = card->host;
-	int err;
-
-	if (!mmc_can_sanitize(card)) {
-		pr_warn("%s: Sanitize not supported\n", mmc_hostname(host));
-		return -EOPNOTSUPP;
-	}
-
-	pr_debug("%s: Sanitize in progress...\n", mmc_hostname(host));
-
-	mmc_retune_hold(host);
-
-	err = mmc_switch(card, EXT_CSD_CMD_SET_NORMAL, EXT_CSD_SANITIZE_START,
-			 1, MMC_SANITIZE_TIMEOUT_MS);
-	if (err)
-		pr_err("%s: Sanitize failed err=%d\n", mmc_hostname(host), err);
-
-	/*
-	 * If the sanitize operation timed out, the card is probably still busy
-	 * in the R1_STATE_PRG. Rather than continue to wait, let's try to abort
-	 * it with a HPI command to get back into R1_STATE_TRAN.
-	 */
-	if (err == -ETIMEDOUT && !mmc_interrupt_hpi(card))
-		pr_warn("%s: Sanitize aborted\n", mmc_hostname(host));
-
-	mmc_retune_release(host);
-
-	pr_debug("%s: Sanitize completed\n", mmc_hostname(host));
-	return err;
-}
-EXPORT_SYMBOL_GPL(mmc_sanitize);
diff --git a/drivers/mmc/core/mmc_ops.h b/drivers/mmc/core/mmc_ops.h
index 632009260..8f2f94757 100644
--- a/drivers/mmc/core/mmc_ops.h
+++ b/drivers/mmc/core/mmc_ops.h
@@ -10,12 +10,6 @@
 
 #include <linux/types.h>
 
-enum mmc_busy_cmd {
-	MMC_BUSY_CMD6,
-	MMC_BUSY_ERASE,
-	MMC_BUSY_HPI,
-};
-
 struct mmc_host;
 struct mmc_card;
 
@@ -32,21 +26,20 @@ int mmc_send_cid(struct mmc_host *host, u32 *cid);
 int mmc_spi_read_ocr(struct mmc_host *host, int highcap, u32 *ocrp);
 int mmc_spi_set_crc(struct mmc_host *host, int use_crc);
 int mmc_bus_test(struct mmc_card *card, u8 bus_width);
+int mmc_interrupt_hpi(struct mmc_card *card);
 int mmc_can_ext_csd(struct mmc_card *card);
 int mmc_get_ext_csd(struct mmc_card *card, u8 **new_ext_csd);
-int mmc_switch_status(struct mmc_card *card, bool crc_err_fatal);
-int mmc_poll_for_busy(struct mmc_card *card, unsigned int timeout_ms,
-		      enum mmc_busy_cmd busy_cmd);
+int mmc_switch_status(struct mmc_card *card);
+int __mmc_switch_status(struct mmc_card *card, bool crc_err_fatal);
 int __mmc_switch(struct mmc_card *card, u8 set, u8 index, u8 value,
 		unsigned int timeout_ms, unsigned char timing,
-		bool send_status, bool retry_crc_err);
+		bool use_busy_signal, bool send_status,	bool retry_crc_err);
 int mmc_switch(struct mmc_card *card, u8 set, u8 index, u8 value,
 		unsigned int timeout_ms);
 void mmc_run_bkops(struct mmc_card *card);
 int mmc_flush_cache(struct mmc_card *card);
 int mmc_cmdq_enable(struct mmc_card *card);
 int mmc_cmdq_disable(struct mmc_card *card);
-int mmc_sanitize(struct mmc_card *card);
 
 #endif
 
diff --git a/drivers/mmc/core/queue.c b/drivers/mmc/core/queue.c
index 002426e3c..9edc08685 100644
--- a/drivers/mmc/core/queue.c
+++ b/drivers/mmc/core/queue.c
@@ -62,7 +62,7 @@ enum mmc_issue_type mmc_issue_type(struct mmc_queue *mq, struct request *req)
 {
 	struct mmc_host *host = mq->card->host;
 
-	if (mq->use_cqe && !host->hsq_enabled)
+	if (mq->use_cqe)
 		return mmc_cqe_issue_type(host, req);
 
 	if (req_op(req) == REQ_OP_READ || req_op(req) == REQ_OP_WRITE)
@@ -107,10 +107,11 @@ static enum blk_eh_timer_return mmc_cqe_timed_out(struct request *req)
 	case MMC_ISSUE_DCMD:
 		if (host->cqe_ops->cqe_timeout(host, mrq, &recovery_needed)) {
 			if (recovery_needed)
-				mmc_cqe_recovery_notifier(mrq);
+				__mmc_cqe_recovery_notifier(mq);
 			return BLK_EH_RESET_TIMER;
 		}
-		/* The request has gone already */
+		/* No timeout (XXX: huh? comment doesn't make much sense) */
+		blk_mq_complete_request(req);
 		return BLK_EH_DONE;
 	default:
 		/* Timeout is handled by mmc core */
@@ -123,16 +124,19 @@ static enum blk_eh_timer_return mmc_mq_timed_out(struct request *req,
 {
 	struct request_queue *q = req->q;
 	struct mmc_queue *mq = q->queuedata;
-	struct mmc_card *card = mq->card;
-	struct mmc_host *host = card->host;
 	unsigned long flags;
-	bool ignore_tout;
+	int ret;
 
 	spin_lock_irqsave(&mq->lock, flags);
-	ignore_tout = mq->recovery_needed || !mq->use_cqe || host->hsq_enabled;
+
+	if (mq->recovery_needed || !mq->use_cqe)
+		ret = BLK_EH_RESET_TIMER;
+	else
+		ret = mmc_cqe_timed_out(req);
+
 	spin_unlock_irqrestore(&mq->lock, flags);
 
-	return ignore_tout ? BLK_EH_RESET_TIMER : mmc_cqe_timed_out(req);
+	return ret;
 }
 
 static void mmc_mq_recovery_handler(struct work_struct *work)
@@ -140,13 +144,12 @@ static void mmc_mq_recovery_handler(struct work_struct *work)
 	struct mmc_queue *mq = container_of(work, struct mmc_queue,
 					    recovery_work);
 	struct request_queue *q = mq->queue;
-	struct mmc_host *host = mq->card->host;
 
 	mmc_get_card(mq->card, &mq->ctx);
 
 	mq->in_recovery = true;
 
-	if (mq->use_cqe && !host->hsq_enabled)
+	if (mq->use_cqe)
 		mmc_blk_cqe_recovery(mq);
 	else
 		mmc_blk_mq_recovery(mq);
@@ -157,9 +160,6 @@ static void mmc_mq_recovery_handler(struct work_struct *work)
 	mq->recovery_needed = false;
 	spin_unlock_irq(&mq->lock);
 
-	if (host->hsq_enabled)
-		host->cqe_ops->cqe_recovery_finish(host);
-
 	mmc_put_card(mq->card, &mq->ctx);
 
 	blk_mq_run_hw_queues(q, true);
@@ -190,7 +190,7 @@ static void mmc_queue_setup_discard(struct request_queue *q,
 	q->limits.discard_granularity = card->pref_erase << 9;
 	/* granularity must not be greater than max. discard */
 	if (card->pref_erase > max_discard)
-		q->limits.discard_granularity = SECTOR_SIZE;
+		q->limits.discard_granularity = 0;
 	if (mmc_can_secure_erase_trim(card))
 		blk_queue_flag_set(QUEUE_FLAG_SECERASE, q);
 }
@@ -203,7 +203,7 @@ static unsigned int mmc_get_max_segments(struct mmc_host *host)
 
 /**
  * mmc_init_request() - initialize the MMC-specific per-request data
- * @mq: the request queue
+ * @q: the request queue
  * @req: the request
  * @gfp: memory allocation policy
  */
@@ -279,14 +279,6 @@ static blk_status_t mmc_mq_queue_rq(struct blk_mq_hw_ctx *hctx,
 		}
 		break;
 	case MMC_ISSUE_ASYNC:
-		/*
-		 * For MMC host software queue, we only allow 2 requests in
-		 * flight to avoid a long latency.
-		 */
-		if (host->hsq_enabled && mq->in_flight[issue_type] > 2) {
-			spin_unlock_irq(&mq->lock);
-			return BLK_STS_RESOURCE;
-		}
 		break;
 	default:
 		/*
@@ -384,10 +376,8 @@ static void mmc_setup_queue(struct mmc_queue *mq, struct mmc_card *card)
 		     "merging was advertised but not possible");
 	blk_queue_max_segments(mq->queue, mmc_get_max_segments(host));
 
-	if (mmc_card_mmc(card) && card->ext_csd.data_sector_size) {
+	if (mmc_card_mmc(card))
 		block_size = card->ext_csd.data_sector_size;
-		WARN_ON(block_size != 512 && block_size != 4096);
-	}
 
 	blk_queue_logical_block_size(mq->queue, block_size);
 	/*
@@ -440,7 +430,7 @@ int mmc_init_queue(struct mmc_queue *mq, struct mmc_card *card)
 	 * The queue depth for CQE must match the hardware because the request
 	 * tag is used to index the hardware queue.
 	 */
-	if (mq->use_cqe && !host->hsq_enabled)
+	if (mq->use_cqe)
 		mq->tag_set.queue_depth =
 			min_t(int, card->ext_csd.cmdq_depth, host->cqe_qdepth);
 	else
@@ -474,7 +464,8 @@ int mmc_init_queue(struct mmc_queue *mq, struct mmc_card *card)
 	}
 
 	if (mmc_host_is_spi(host) && host->use_spi_crc)
-		blk_queue_flag_set(QUEUE_FLAG_STABLE_WRITES, mq->queue);
+		mq->queue->backing_dev_info->capabilities |=
+			BDI_CAP_STABLE_WRITES;
 
 	mq->queue->queuedata = mq;
 	blk_queue_rq_timeout(mq->queue, 60 * HZ);
diff --git a/drivers/mmc/core/quirks.h b/drivers/mmc/core/quirks.h
index d68e6e513..2d2d9ea8b 100644
--- a/drivers/mmc/core/quirks.h
+++ b/drivers/mmc/core/quirks.h
@@ -14,7 +14,7 @@
 
 #include "card.h"
 
-static const struct mmc_fixup __maybe_unused mmc_blk_fixups[] = {
+static const struct mmc_fixup mmc_blk_fixups[] = {
 #define INAND_CMD38_ARG_EXT_CSD  113
 #define INAND_CMD38_ARG_ERASE    0x00
 #define INAND_CMD38_ARG_TRIM     0x01
@@ -102,7 +102,7 @@ static const struct mmc_fixup __maybe_unused mmc_blk_fixups[] = {
 	END_FIXUP
 };
 
-static const struct mmc_fixup __maybe_unused mmc_ext_csd_fixups[] = {
+static const struct mmc_fixup mmc_ext_csd_fixups[] = {
 	/*
 	 * Certain Hynix eMMC 4.41 cards might get broken when HPI feature
 	 * is used so disable the HPI feature for such buggy cards.
@@ -119,14 +119,7 @@ static const struct mmc_fixup __maybe_unused mmc_ext_csd_fixups[] = {
 	END_FIXUP
 };
 
-
-static const struct mmc_fixup __maybe_unused sdio_fixup_methods[] = {
-	SDIO_FIXUP(SDIO_VENDOR_ID_TI_WL1251, SDIO_DEVICE_ID_TI_WL1251,
-		   add_quirk, MMC_QUIRK_NONSTD_FUNC_IF),
-
-	SDIO_FIXUP(SDIO_VENDOR_ID_TI_WL1251, SDIO_DEVICE_ID_TI_WL1251,
-		   add_quirk, MMC_QUIRK_DISABLE_CD),
-
+static const struct mmc_fixup sdio_fixup_methods[] = {
 	SDIO_FIXUP(SDIO_VENDOR_ID_TI, SDIO_DEVICE_ID_TI_WL1271,
 		   add_quirk, MMC_QUIRK_NONSTD_FUNC_IF),
 
@@ -139,7 +132,7 @@ static const struct mmc_fixup __maybe_unused sdio_fixup_methods[] = {
 	SDIO_FIXUP(SDIO_VENDOR_ID_MARVELL, SDIO_DEVICE_ID_MARVELL_8797_F0,
 		   add_quirk, MMC_QUIRK_BROKEN_IRQ_POLLING),
 
-	SDIO_FIXUP(SDIO_VENDOR_ID_MARVELL, SDIO_DEVICE_ID_MARVELL_8887_F0,
+	SDIO_FIXUP(SDIO_VENDOR_ID_MARVELL, SDIO_DEVICE_ID_MARVELL_8887WLAN,
 		   add_limit_rate_quirk, 150000000),
 
 	END_FIXUP
diff --git a/drivers/mmc/core/regulator.c b/drivers/mmc/core/regulator.c
index 609201a46..b6febbcf8 100644
--- a/drivers/mmc/core/regulator.c
+++ b/drivers/mmc/core/regulator.c
@@ -136,8 +136,6 @@ static int mmc_regulator_set_voltage_if_supported(struct regulator *regulator,
 						  int min_uV, int target_uV,
 						  int max_uV)
 {
-	int current_uV;
-
 	/*
 	 * Check if supported first to avoid errors since we may try several
 	 * signal levels during power up and don't want to show errors.
@@ -145,22 +143,12 @@ static int mmc_regulator_set_voltage_if_supported(struct regulator *regulator,
 	if (!regulator_is_supported_voltage(regulator, min_uV, max_uV))
 		return -EINVAL;
 
-	/*
-	 * The voltage is already set, no need to switch.
-	 * Return 1 to indicate that no switch happened.
-	 */
-	current_uV = regulator_get_voltage(regulator);
-	if (current_uV == target_uV)
-		return 1;
-
 	return regulator_set_voltage_triplet(regulator, min_uV, target_uV,
 					     max_uV);
 }
 
 /**
  * mmc_regulator_set_vqmmc - Set VQMMC as per the ios
- * @mmc: the host to regulate
- * @ios: io bus settings
  *
  * For 3.3V signaling, we try to match VQMMC to VMMC as closely as possible.
  * That will match the behavior of old boards where VQMMC and VMMC were supplied
@@ -210,10 +198,9 @@ int mmc_regulator_set_vqmmc(struct mmc_host *mmc, struct mmc_ios *ios)
 		 * voltage in two steps and try to stay close to vmmc
 		 * with a 0.3V tolerance at first.
 		 */
-		ret = mmc_regulator_set_voltage_if_supported(mmc->supply.vqmmc,
-							min_uV, volt, max_uV);
-		if (ret >= 0)
-			return ret;
+		if (!mmc_regulator_set_voltage_if_supported(mmc->supply.vqmmc,
+						min_uV, volt, max_uV))
+			return 0;
 
 		return mmc_regulator_set_voltage_if_supported(mmc->supply.vqmmc,
 						2700000, volt, 3600000);
diff --git a/drivers/mmc/core/sd.c b/drivers/mmc/core/sd.c
index bac343a8d..6a5982310 100644
--- a/drivers/mmc/core/sd.c
+++ b/drivers/mmc/core/sd.c
@@ -135,9 +135,6 @@ static int mmc_decode_csd(struct mmc_card *card)
 			csd->erase_size = UNSTUFF_BITS(resp, 39, 7) + 1;
 			csd->erase_size <<= csd->write_blkbits - 9;
 		}
-
-		if (UNSTUFF_BITS(resp, 13, 1))
-			mmc_card_set_readonly(card);
 		break;
 	case 1:
 		/*
@@ -172,9 +169,6 @@ static int mmc_decode_csd(struct mmc_card *card)
 		csd->write_blkbits = 9;
 		csd->write_partial = 0;
 		csd->erase_size = 1;
-
-		if (UNSTUFF_BITS(resp, 13, 1))
-			mmc_card_set_readonly(card);
 		break;
 	default:
 		pr_err("%s: unrecognised CSD structure version %d\n",
@@ -382,11 +376,11 @@ int mmc_sd_switch_hs(struct mmc_card *card)
 	if (!status)
 		return -ENOMEM;
 
-	err = mmc_sd_switch(card, 1, 0, HIGH_SPEED_BUS_SPEED, status);
+	err = mmc_sd_switch(card, 1, 0, 1, status);
 	if (err)
 		goto out;
 
-	if ((status[16] & 0xF) != HIGH_SPEED_BUS_SPEED) {
+	if ((status[16] & 0xF) != 1) {
 		pr_warn("%s: Problem switching card into high-speed mode!\n",
 			mmc_hostname(card->host));
 		err = 0;
@@ -504,6 +498,12 @@ static int sd_set_bus_speed_mode(struct mmc_card *card, u8 *status)
 	else {
 		mmc_set_timing(card->host, timing);
 		mmc_set_clock(card->host, card->sw_caps.uhs_max_dtr);
+		/*
+		 * FIXME: Sandisk SD3.0 cards DDR50 mode requires such
+		 * delay to get stable, without this delay we may encounter
+		 * CRC errors after switch to DDR50 mode
+		 */
+		mmc_delay(100);
 	}
 
 	return 0;
@@ -713,36 +713,7 @@ static ssize_t mmc_dsr_show(struct device *dev,
 
 static DEVICE_ATTR(dsr, S_IRUGO, mmc_dsr_show, NULL);
 
-MMC_DEV_ATTR(vendor, "0x%04x\n", card->cis.vendor);
-MMC_DEV_ATTR(device, "0x%04x\n", card->cis.device);
-MMC_DEV_ATTR(revision, "%u.%u\n", card->major_rev, card->minor_rev);
-
-#define sdio_info_attr(num)									\
-static ssize_t info##num##_show(struct device *dev, struct device_attribute *attr, char *buf)	\
-{												\
-	struct mmc_card *card = mmc_dev_to_card(dev);						\
-												\
-	if (num > card->num_info)								\
-		return -ENODATA;								\
-	if (!card->info[num-1][0])								\
-		return 0;									\
-	return sprintf(buf, "%s\n", card->info[num-1]);						\
-}												\
-static DEVICE_ATTR_RO(info##num)
-
-sdio_info_attr(1);
-sdio_info_attr(2);
-sdio_info_attr(3);
-sdio_info_attr(4);
-
 static struct attribute *sd_std_attrs[] = {
-	&dev_attr_vendor.attr,
-	&dev_attr_device.attr,
-	&dev_attr_revision.attr,
-	&dev_attr_info1.attr,
-	&dev_attr_info2.attr,
-	&dev_attr_info3.attr,
-	&dev_attr_info4.attr,
 	&dev_attr_cid.attr,
 	&dev_attr_csd.attr,
 	&dev_attr_scr.attr,
@@ -761,32 +732,7 @@ static struct attribute *sd_std_attrs[] = {
 	&dev_attr_dsr.attr,
 	NULL,
 };
-
-static umode_t sd_std_is_visible(struct kobject *kobj, struct attribute *attr,
-				 int index)
-{
-	struct device *dev = kobj_to_dev(kobj);
-	struct mmc_card *card = mmc_dev_to_card(dev);
-
-	/* CIS vendor and device ids, revision and info string are available only for Combo cards */
-	if ((attr == &dev_attr_vendor.attr ||
-	     attr == &dev_attr_device.attr ||
-	     attr == &dev_attr_revision.attr ||
-	     attr == &dev_attr_info1.attr ||
-	     attr == &dev_attr_info2.attr ||
-	     attr == &dev_attr_info3.attr ||
-	     attr == &dev_attr_info4.attr
-	    ) && card->type != MMC_TYPE_SD_COMBO)
-		return 0;
-
-	return attr->mode;
-}
-
-static const struct attribute_group sd_std_group = {
-	.attrs = sd_std_attrs,
-	.is_visible = sd_std_is_visible,
-};
-__ATTRIBUTE_GROUPS(sd_std);
+ATTRIBUTE_GROUPS(sd_std);
 
 struct device_type sd_type = {
 	.groups = sd_std_groups,
@@ -847,13 +793,11 @@ int mmc_sd_get_cid(struct mmc_host *host, u32 ocr, u32 *cid, u32 *rocr)
 		return err;
 
 	/*
-	 * In case the S18A bit is set in the response, let's start the signal
-	 * voltage switch procedure. SPI mode doesn't support CMD11.
-	 * Note that, according to the spec, the S18A bit is not valid unless
-	 * the CCS bit is set as well. We deliberately deviate from the spec in
-	 * regards to this, which allows UHS-I to be supported for SDSC cards.
+	 * In case CCS and S18A in the response is set, start Signal Voltage
+	 * Switch procedure. SPI mode doesn't support CMD11.
 	 */
-	if (!mmc_host_is_spi(host) && rocr && (*rocr & 0x01000000)) {
+	if (!mmc_host_is_spi(host) && rocr &&
+	   ((*rocr & 0x41000000) == 0x41000000)) {
 		err = mmc_set_uhs_voltage(host, pocr);
 		if (err == -EAGAIN) {
 			retries--;
@@ -1144,16 +1088,6 @@ static int mmc_sd_init_card(struct mmc_host *host, u32 ocr,
 		}
 	}
 
-	if (host->cqe_ops && !host->cqe_enabled) {
-		err = host->cqe_ops->cqe_enable(host, card);
-		if (!err) {
-			host->cqe_enabled = true;
-			host->hsq_enabled = true;
-			pr_info("%s: Host Software Queue enabled\n",
-				mmc_hostname(host));
-		}
-	}
-
 	if (host->caps2 & MMC_CAP2_AVOID_3_3V &&
 	    host->ios.signal_voltage == MMC_SIGNAL_VOLTAGE_330) {
 		pr_err("%s: Host failed to negotiate down from 3.3V\n",
diff --git a/drivers/mmc/core/sdio.c b/drivers/mmc/core/sdio.c
old mode 100644
new mode 100755
index 1b0853a82..5c54d6eeb
--- a/drivers/mmc/core/sdio.c
+++ b/drivers/mmc/core/sdio.c
@@ -27,48 +27,6 @@
 #include "sdio_ops.h"
 #include "sdio_cis.h"
 
-MMC_DEV_ATTR(vendor, "0x%04x\n", card->cis.vendor);
-MMC_DEV_ATTR(device, "0x%04x\n", card->cis.device);
-MMC_DEV_ATTR(revision, "%u.%u\n", card->major_rev, card->minor_rev);
-MMC_DEV_ATTR(ocr, "0x%08x\n", card->ocr);
-MMC_DEV_ATTR(rca, "0x%04x\n", card->rca);
-
-#define sdio_info_attr(num)									\
-static ssize_t info##num##_show(struct device *dev, struct device_attribute *attr, char *buf)	\
-{												\
-	struct mmc_card *card = mmc_dev_to_card(dev);						\
-												\
-	if (num > card->num_info)								\
-		return -ENODATA;								\
-	if (!card->info[num-1][0])								\
-		return 0;									\
-	return sprintf(buf, "%s\n", card->info[num-1]);						\
-}												\
-static DEVICE_ATTR_RO(info##num)
-
-sdio_info_attr(1);
-sdio_info_attr(2);
-sdio_info_attr(3);
-sdio_info_attr(4);
-
-static struct attribute *sdio_std_attrs[] = {
-	&dev_attr_vendor.attr,
-	&dev_attr_device.attr,
-	&dev_attr_revision.attr,
-	&dev_attr_info1.attr,
-	&dev_attr_info2.attr,
-	&dev_attr_info3.attr,
-	&dev_attr_info4.attr,
-	&dev_attr_ocr.attr,
-	&dev_attr_rca.attr,
-	NULL,
-};
-ATTRIBUTE_GROUPS(sdio_std);
-
-static struct device_type sdio_type = {
-	.groups = sdio_std_groups,
-};
-
 static int sdio_read_fbr(struct sdio_func *func)
 {
 	int ret;
@@ -200,18 +158,15 @@ static int sdio_read_cccr(struct mmc_card *card, u32 ocr)
 			if (mmc_host_uhs(card->host)) {
 				if (data & SDIO_UHS_DDR50)
 					card->sw_caps.sd3_bus_mode
-						|= SD_MODE_UHS_DDR50 | SD_MODE_UHS_SDR50
-							| SD_MODE_UHS_SDR25 | SD_MODE_UHS_SDR12;
+						|= SD_MODE_UHS_DDR50;
 
 				if (data & SDIO_UHS_SDR50)
 					card->sw_caps.sd3_bus_mode
-						|= SD_MODE_UHS_SDR50 | SD_MODE_UHS_SDR25
-							| SD_MODE_UHS_SDR12;
+						|= SD_MODE_UHS_SDR50;
 
 				if (data & SDIO_UHS_SDR104)
 					card->sw_caps.sd3_bus_mode
-						|= SD_MODE_UHS_SDR104 | SD_MODE_UHS_SDR50
-							| SD_MODE_UHS_SDR25 | SD_MODE_UHS_SDR12;
+						|= SD_MODE_UHS_SDR104;
 			}
 
 			ret = mmc_io_rw_direct(card, 0, 0,
@@ -330,49 +285,30 @@ static int sdio_disable_wide(struct mmc_card *card)
 	return 0;
 }
 
-static int sdio_disable_4bit_bus(struct mmc_card *card)
-{
-	int err;
-
-	if (card->type == MMC_TYPE_SDIO)
-		goto out;
-
-	if (!(card->host->caps & MMC_CAP_4_BIT_DATA))
-		return 0;
-
-	if (!(card->scr.bus_widths & SD_SCR_BUS_WIDTH_4))
-		return 0;
-
-	err = mmc_app_set_bus_width(card, MMC_BUS_WIDTH_1);
-	if (err)
-		return err;
-
-out:
-	return sdio_disable_wide(card);
-}
-
 
 static int sdio_enable_4bit_bus(struct mmc_card *card)
 {
 	int err;
 
-	err = sdio_enable_wide(card);
-	if (err <= 0)
-		return err;
 	if (card->type == MMC_TYPE_SDIO)
-		goto out;
-
-	if (card->scr.bus_widths & SD_SCR_BUS_WIDTH_4) {
+		err = sdio_enable_wide(card);
+	else if ((card->host->caps & MMC_CAP_4_BIT_DATA) &&
+		 (card->scr.bus_widths & SD_SCR_BUS_WIDTH_4)) {
 		err = mmc_app_set_bus_width(card, MMC_BUS_WIDTH_4);
-		if (err) {
-			sdio_disable_wide(card);
+		if (err)
 			return err;
-		}
+		err = sdio_enable_wide(card);
+		if (err <= 0)
+			mmc_app_set_bus_width(card, MMC_BUS_WIDTH_1);
+	} else
+		return 0;
+
+	if (err > 0) {
+		mmc_set_bus_width(card->host, MMC_BUS_WIDTH_4);
+		err = 0;
 	}
-out:
-	mmc_set_bus_width(card->host, MMC_BUS_WIDTH_4);
 
-	return 0;
+	return err;
 }
 
 
@@ -564,8 +500,10 @@ static int sdio_set_bus_speed_mode(struct mmc_card *card)
 	max_rate = min_not_zero(card->quirk_max_rate,
 				card->sw_caps.uhs_max_dtr);
 
-	mmc_set_timing(card->host, timing);
-	mmc_set_clock(card->host, max_rate);
+	if (bus_speed) {
+		mmc_set_timing(card->host, timing);
+		mmc_set_clock(card->host, max_rate);
+	}
 
 	return 0;
 }
@@ -605,33 +543,13 @@ static int mmc_sdio_init_uhs_card(struct mmc_card *card)
 	return err;
 }
 
-static int mmc_sdio_pre_init(struct mmc_host *host, u32 ocr,
-			     struct mmc_card *card)
+static void mmc_sdio_resend_if_cond(struct mmc_host *host,
+				    struct mmc_card *card)
 {
-	if (card)
-		mmc_remove_card(card);
-
-	/*
-	 * Reset the card by performing the same steps that are taken by
-	 * mmc_rescan_try_freq() and mmc_attach_sdio() during a "normal" probe.
-	 *
-	 * sdio_reset() is technically not needed. Having just powered up the
-	 * hardware, it should already be in reset state. However, some
-	 * platforms (such as SD8686 on OLPC) do not instantly cut power,
-	 * meaning that a reset is required when restoring power soon after
-	 * powering off. It is harmless in other cases.
-	 *
-	 * The CMD5 reset (mmc_send_io_op_cond()), according to the SDIO spec,
-	 * is not necessary for non-removable cards. However, it is required
-	 * for OLPC SD8686 (which expects a [CMD5,5,3,7] init sequence), and
-	 * harmless in other situations.
-	 *
-	 */
-
 	sdio_reset(host);
 	mmc_go_idle(host);
-	mmc_send_if_cond(host, ocr);
-	return mmc_send_io_op_cond(host, 0, NULL);
+	mmc_send_if_cond(host, host->ocr_avail);
+	mmc_remove_card(card);
 }
 
 /*
@@ -666,7 +584,7 @@ static int mmc_sdio_init_card(struct mmc_host *host, u32 ocr,
 	 */
 	err = mmc_send_io_op_cond(host, ocr, &rocr);
 	if (err)
-		return err;
+		goto err;
 
 	/*
 	 * For SPI, enable CRC as appropriate.
@@ -674,15 +592,17 @@ static int mmc_sdio_init_card(struct mmc_host *host, u32 ocr,
 	if (mmc_host_is_spi(host)) {
 		err = mmc_spi_set_crc(host, use_spi_crc);
 		if (err)
-			return err;
+			goto err;
 	}
 
 	/*
 	 * Allocate card structure.
 	 */
-	card = mmc_alloc_card(host, &sdio_type);
-	if (IS_ERR(card))
-		return PTR_ERR(card);
+	card = mmc_alloc_card(host, NULL);
+	if (IS_ERR(card)) {
+		err = PTR_ERR(card);
+		goto err;
+	}
 
 	if ((rocr & R4_MEMORY_PRESENT) &&
 	    mmc_sd_get_cid(host, ocr & rocr, card->raw_cid, NULL) == 0) {
@@ -690,15 +610,19 @@ static int mmc_sdio_init_card(struct mmc_host *host, u32 ocr,
 
 		if (oldcard && (oldcard->type != MMC_TYPE_SD_COMBO ||
 		    memcmp(card->raw_cid, oldcard->raw_cid, sizeof(card->raw_cid)) != 0)) {
-			err = -ENOENT;
-			goto mismatch;
+			mmc_remove_card(card);
+			pr_debug("%s: Perhaps the card was replaced\n",
+				mmc_hostname(host));
+			return -ENOENT;
 		}
 	} else {
 		card->type = MMC_TYPE_SDIO;
 
 		if (oldcard && oldcard->type != MMC_TYPE_SDIO) {
-			err = -ENOENT;
-			goto mismatch;
+			mmc_remove_card(card);
+			pr_debug("%s: Perhaps the card was replaced\n",
+				mmc_hostname(host));
+			return -ENOENT;
 		}
 	}
 
@@ -722,7 +646,7 @@ static int mmc_sdio_init_card(struct mmc_host *host, u32 ocr,
 	if (rocr & ocr & R4_18V_PRESENT) {
 		err = mmc_set_uhs_voltage(host, ocr_card);
 		if (err == -EAGAIN) {
-			mmc_sdio_pre_init(host, ocr_card, card);
+			mmc_sdio_resend_if_cond(host, card);
 			retries--;
 			goto try_again;
 		} else if (err) {
@@ -753,7 +677,7 @@ static int mmc_sdio_init_card(struct mmc_host *host, u32 ocr,
 	if (!oldcard && card->type == MMC_TYPE_SD_COMBO) {
 		err = mmc_sd_get_csd(host, card);
 		if (err)
-			goto remove;
+			return err;
 
 		mmc_decode_cid(card);
 	}
@@ -780,12 +704,7 @@ static int mmc_sdio_init_card(struct mmc_host *host, u32 ocr,
 			mmc_set_timing(card->host, MMC_TIMING_SD_HS);
 		}
 
-		if (oldcard)
-			mmc_remove_card(card);
-		else
-			host->card = card;
-
-		return 0;
+		goto finish;
 	}
 
 	/*
@@ -794,13 +713,14 @@ static int mmc_sdio_init_card(struct mmc_host *host, u32 ocr,
 	 */
 	err = sdio_read_cccr(card, ocr);
 	if (err) {
-		mmc_sdio_pre_init(host, ocr_card, card);
+		mmc_sdio_resend_if_cond(host, card);
 		if (ocr & R4_18V_PRESENT) {
 			/* Retry init sequence, but without R4_18V_PRESENT. */
 			retries = 0;
 			goto try_again;
+		} else {
+			goto remove;
 		}
-		return err;
 	}
 
 	/*
@@ -811,14 +731,16 @@ static int mmc_sdio_init_card(struct mmc_host *host, u32 ocr,
 		goto remove;
 
 	if (oldcard) {
-		if (card->cis.vendor == oldcard->cis.vendor &&
-		    card->cis.device == oldcard->cis.device) {
-			mmc_remove_card(card);
-			card = oldcard;
-		} else {
-			err = -ENOENT;
-			goto mismatch;
+		int same = (card->cis.vendor == oldcard->cis.vendor &&
+			    card->cis.device == oldcard->cis.device);
+		mmc_remove_card(card);
+		if (!same) {
+			pr_debug("%s: Perhaps the card was replaced\n",
+				mmc_hostname(host));
+			return -ENOENT;
 		}
+
+		card = oldcard;
 	}
 	card->ocr = ocr_card;
 	mmc_fixup_device(card, sdio_fixup_methods);
@@ -879,15 +801,16 @@ static int mmc_sdio_init_card(struct mmc_host *host, u32 ocr,
 		err = -EINVAL;
 		goto remove;
 	}
-
-	host->card = card;
+finish:
+	if (!oldcard)
+		host->card = card;
 	return 0;
 
-mismatch:
-	pr_debug("%s: Perhaps the card was replaced\n", mmc_hostname(host));
 remove:
-	if (oldcard != card)
+	if (!oldcard)
 		mmc_remove_card(card);
+
+err:
 	return err;
 }
 
@@ -895,13 +818,68 @@ static int mmc_sdio_reinit_card(struct mmc_host *host)
 {
 	int ret;
 
-	ret = mmc_sdio_pre_init(host, host->card->ocr, NULL);
+	/*
+	 * Reset the card by performing the same steps that are taken by
+	 * mmc_rescan_try_freq() and mmc_attach_sdio() during a "normal" probe.
+	 *
+	 * sdio_reset() is technically not needed. Having just powered up the
+	 * hardware, it should already be in reset state. However, some
+	 * platforms (such as SD8686 on OLPC) do not instantly cut power,
+	 * meaning that a reset is required when restoring power soon after
+	 * powering off. It is harmless in other cases.
+	 *
+	 * The CMD5 reset (mmc_send_io_op_cond()), according to the SDIO spec,
+	 * is not necessary for non-removable cards. However, it is required
+	 * for OLPC SD8686 (which expects a [CMD5,5,3,7] init sequence), and
+	 * harmless in other situations.
+	 *
+	 */
+
+	sdio_reset(host);
+	mmc_go_idle(host);
+	mmc_send_if_cond(host, host->card->ocr);
+
+	ret = mmc_send_io_op_cond(host, 0, NULL);
 	if (ret)
 		return ret;
 
 	return mmc_sdio_init_card(host, host->card->ocr, host->card);
 }
 
+
+
+int sdio_reset_comm(struct mmc_card *card)
+{
+	struct mmc_host *host = card->host;
+	u32 ocr;
+	u32 rocr;
+	int err;
+
+	mmc_claim_host(host);
+	mmc_go_idle(host);
+	mmc_set_clock(host, host->f_min);
+	err = mmc_send_io_op_cond(host, 0, &ocr);
+	if (err)
+		goto err;
+	rocr = mmc_select_voltage(host, ocr);
+	if (!rocr) {
+		err = -EINVAL;
+		goto err;
+	}
+	err = mmc_sdio_init_card(host, rocr, card);
+	if (err)
+		goto err;
+	mmc_release_host(host);
+	return 0;
+err:
+	pr_err("%s: Error resetting SDIO communications (%d)\n",
+		mmc_hostname(host), err);
+	mmc_release_host(host);
+	return err;
+}
+EXPORT_SYMBOL(sdio_reset_comm);
+
+
 /*
  * Host is being removed. Free up the current card.
  */
@@ -919,6 +897,16 @@ static void mmc_sdio_remove(struct mmc_host *host)
 	mmc_remove_card(host->card);
 	host->card = NULL;
 }
+void mmc_sdio_force_remove(struct mmc_host *host)
+{
+	mmc_sdio_remove(host);
+
+	mmc_claim_host(host);
+	mmc_detach_bus(host);
+	mmc_power_off(host);
+	mmc_release_host(host);
+}
+EXPORT_SYMBOL_GPL(mmc_sdio_force_remove);
 
 /*
  * Card detection - card is alive.
@@ -985,37 +973,21 @@ static void mmc_sdio_detect(struct mmc_host *host)
  */
 static int mmc_sdio_pre_suspend(struct mmc_host *host)
 {
-	int i;
+	int i, err = 0;
 
 	for (i = 0; i < host->card->sdio_funcs; i++) {
 		struct sdio_func *func = host->card->sdio_func[i];
 		if (func && sdio_func_present(func) && func->dev.driver) {
 			const struct dev_pm_ops *pmops = func->dev.driver->pm;
-			if (!pmops || !pmops->suspend || !pmops->resume)
+			if (!pmops || !pmops->suspend || !pmops->resume) {
 				/* force removal of entire card in that case */
-				goto remove;
+				err = -ENOSYS;
+				break;
+			}
 		}
 	}
 
-	return 0;
-
-remove:
-	if (!mmc_card_is_removable(host)) {
-		dev_warn(mmc_dev(host),
-			 "missing suspend/resume ops for non-removable SDIO card\n");
-		/* Don't remove a non-removable card - we can't re-detect it. */
-		return 0;
-	}
-
-	/* Remove the SDIO card and let it be re-detected later on. */
-	mmc_sdio_remove(host);
-	mmc_claim_host(host);
-	mmc_detach_bus(host);
-	mmc_power_off(host);
-	mmc_release_host(host);
-	host->pm_flags = 0;
-
-	return 0;
+	return err;
 }
 
 /*
@@ -1032,7 +1004,7 @@ static int mmc_sdio_suspend(struct mmc_host *host)
 	mmc_claim_host(host);
 
 	if (mmc_card_keep_power(host) && mmc_card_wake_sdio_irq(host))
-		sdio_disable_4bit_bus(host->card);
+		sdio_disable_wide(host->card);
 
 	if (!mmc_card_keep_power(host)) {
 		mmc_power_off(host);
@@ -1120,35 +1092,9 @@ static int mmc_sdio_runtime_resume(struct mmc_host *host)
 	return ret;
 }
 
-/*
- * SDIO HW reset
- *
- * Returns 0 if the HW reset was executed synchronously, returns 1 if the HW
- * reset was asynchronously scheduled, else a negative error code.
- */
 static int mmc_sdio_hw_reset(struct mmc_host *host)
 {
-	struct mmc_card *card = host->card;
-
-	/*
-	 * In case the card is shared among multiple func drivers, reset the
-	 * card through a rescan work. In this way it will be removed and
-	 * re-detected, thus all func drivers becomes informed about it.
-	 */
-	if (atomic_read(&card->sdio_funcs_probed) > 1) {
-		if (mmc_card_removed(card))
-			return 1;
-		host->rescan_entered = 0;
-		mmc_card_set_removed(card);
-		_mmc_detect_change(host, 0, false);
-		return 1;
-	}
-
-	/*
-	 * A single func driver has been probed, then let's skip the heavy
-	 * hotplug dance above and execute the reset immediately.
-	 */
-	mmc_power_cycle(host, card->ocr);
+	mmc_power_cycle(host, host->card->ocr);
 	return mmc_sdio_reinit_card(host);
 }
 
diff --git a/drivers/mmc/core/sdio_bus.c b/drivers/mmc/core/sdio_bus.c
index 3d709029e..2963e6542 100644
--- a/drivers/mmc/core/sdio_bus.c
+++ b/drivers/mmc/core/sdio_bus.c
@@ -28,50 +28,34 @@
 #define to_sdio_driver(d)	container_of(d, struct sdio_driver, drv)
 
 /* show configuration fields */
-#define sdio_config_attr(field, format_string, args...)			\
+#define sdio_config_attr(field, format_string)				\
 static ssize_t								\
 field##_show(struct device *dev, struct device_attribute *attr, char *buf)				\
 {									\
 	struct sdio_func *func;						\
 									\
 	func = dev_to_sdio_func (dev);					\
-	return sprintf(buf, format_string, args);			\
+	return sprintf (buf, format_string, func->field);		\
 }									\
 static DEVICE_ATTR_RO(field)
 
-sdio_config_attr(class, "0x%02x\n", func->class);
-sdio_config_attr(vendor, "0x%04x\n", func->vendor);
-sdio_config_attr(device, "0x%04x\n", func->device);
-sdio_config_attr(revision, "%u.%u\n", func->major_rev, func->minor_rev);
-sdio_config_attr(modalias, "sdio:c%02Xv%04Xd%04X\n", func->class, func->vendor, func->device);
-
-#define sdio_info_attr(num)									\
-static ssize_t info##num##_show(struct device *dev, struct device_attribute *attr, char *buf)	\
-{												\
-	struct sdio_func *func = dev_to_sdio_func(dev);						\
-												\
-	if (num > func->num_info)								\
-		return -ENODATA;								\
-	if (!func->info[num-1][0])								\
-		return 0;									\
-	return sprintf(buf, "%s\n", func->info[num-1]);						\
-}												\
-static DEVICE_ATTR_RO(info##num)
-
-sdio_info_attr(1);
-sdio_info_attr(2);
-sdio_info_attr(3);
-sdio_info_attr(4);
+sdio_config_attr(class, "0x%02x\n");
+sdio_config_attr(vendor, "0x%04x\n");
+sdio_config_attr(device, "0x%04x\n");
+
+static ssize_t modalias_show(struct device *dev, struct device_attribute *attr, char *buf)
+{
+	struct sdio_func *func = dev_to_sdio_func (dev);
+
+	return sprintf(buf, "sdio:c%02Xv%04Xd%04X\n",
+			func->class, func->vendor, func->device);
+}
+static DEVICE_ATTR_RO(modalias);
 
 static struct attribute *sdio_dev_attrs[] = {
 	&dev_attr_class.attr,
 	&dev_attr_vendor.attr,
 	&dev_attr_device.attr,
-	&dev_attr_revision.attr,
-	&dev_attr_info1.attr,
-	&dev_attr_info2.attr,
-	&dev_attr_info3.attr,
-	&dev_attr_info4.attr,
 	&dev_attr_modalias.attr,
 	NULL,
 };
@@ -122,7 +106,6 @@ static int
 sdio_bus_uevent(struct device *dev, struct kobj_uevent_env *env)
 {
 	struct sdio_func *func = dev_to_sdio_func(dev);
-	unsigned int i;
 
 	if (add_uevent_var(env,
 			"SDIO_CLASS=%02X", func->class))
@@ -132,15 +115,6 @@ sdio_bus_uevent(struct device *dev, struct kobj_uevent_env *env)
 			"SDIO_ID=%04X:%04X", func->vendor, func->device))
 		return -ENOMEM;
 
-	if (add_uevent_var(env,
-			"SDIO_REVISION=%u.%u", func->major_rev, func->minor_rev))
-		return -ENOMEM;
-
-	for (i = 0; i < func->num_info; i++) {
-		if (add_uevent_var(env, "SDIO_INFO%u=%s", i+1, func->info[i]))
-			return -ENOMEM;
-	}
-
 	if (add_uevent_var(env,
 			"MODALIAS=sdio:c%02Xv%04Xd%04X",
 			func->class, func->vendor, func->device))
@@ -164,8 +138,6 @@ static int sdio_bus_probe(struct device *dev)
 	if (ret)
 		return ret;
 
-	atomic_inc(&func->card->sdio_funcs_probed);
-
 	/* Unbound SDIO functions are always suspended.
 	 * During probe, the function is set active and the usage count
 	 * is incremented.  If the driver supports runtime PM,
@@ -181,10 +153,7 @@ static int sdio_bus_probe(struct device *dev)
 	/* Set the default block size so the driver is sure it's something
 	 * sensible. */
 	sdio_claim_host(func);
-	if (mmc_card_removed(func->card))
-		ret = -ENOMEDIUM;
-	else
-		ret = sdio_set_block_size(func, 0);
+	ret = sdio_set_block_size(func, 0);
 	sdio_release_host(func);
 	if (ret)
 		goto disable_runtimepm;
@@ -196,7 +165,6 @@ static int sdio_bus_probe(struct device *dev)
 	return 0;
 
 disable_runtimepm:
-	atomic_dec(&func->card->sdio_funcs_probed);
 	if (func->card->host->caps & MMC_CAP_POWER_OFF_CARD)
 		pm_runtime_put_noidle(dev);
 	dev_pm_domain_detach(dev, false);
@@ -213,7 +181,6 @@ static int sdio_bus_remove(struct device *dev)
 		pm_runtime_get_sync(dev);
 
 	drv->remove(func);
-	atomic_dec(&func->card->sdio_funcs_probed);
 
 	if (func->irq_handler) {
 		pr_warn("WARNING: driver %s did not remove its interrupt handler!\n",
diff --git a/drivers/mmc/core/sdio_cis.c b/drivers/mmc/core/sdio_cis.c
index b23773583..e0655278c 100644
--- a/drivers/mmc/core/sdio_cis.c
+++ b/drivers/mmc/core/sdio_cis.c
@@ -20,21 +20,12 @@
 #include "sdio_cis.h"
 #include "sdio_ops.h"
 
-#define SDIO_READ_CIS_TIMEOUT_MS  (10 * 1000) /* 10s */
-
 static int cistpl_vers_1(struct mmc_card *card, struct sdio_func *func,
 			 const unsigned char *buf, unsigned size)
 {
-	u8 major_rev, minor_rev;
 	unsigned i, nr_strings;
 	char **buffer, *string;
 
-	if (size < 2)
-		return 0;
-
-	major_rev = buf[0];
-	minor_rev = buf[1];
-
 	/* Find all null-terminated (including zero length) strings in
 	   the TPLLV1_INFO field. Trailing garbage is ignored. */
 	buf += 2;
@@ -66,13 +57,9 @@ static int cistpl_vers_1(struct mmc_card *card, struct sdio_func *func,
 	}
 
 	if (func) {
-		func->major_rev = major_rev;
-		func->minor_rev = minor_rev;
 		func->num_info = nr_strings;
 		func->info = (const char**)buffer;
 	} else {
-		card->major_rev = major_rev;
-		card->minor_rev = minor_rev;
 		card->num_info = nr_strings;
 		card->info = (const char**)buffer;
 	}
@@ -276,8 +263,6 @@ static int sdio_read_cis(struct mmc_card *card, struct sdio_func *func)
 
 	do {
 		unsigned char tpl_code, tpl_link;
-		unsigned long timeout = jiffies +
-			msecs_to_jiffies(SDIO_READ_CIS_TIMEOUT_MS);
 
 		ret = mmc_io_rw_direct(card, 0, 0, ptr++, 0, &tpl_code);
 		if (ret)
@@ -330,8 +315,6 @@ static int sdio_read_cis(struct mmc_card *card, struct sdio_func *func)
 			prev = &this->next;
 
 			if (ret == -ENOENT) {
-				if (time_after(jiffies, timeout))
-					break;
 				/* warn about unknown tuples */
 				pr_warn_ratelimited("%s: queuing unknown"
 				       " CIS tuple 0x%02x (%u bytes)\n",
diff --git a/drivers/mmc/core/sdio_io.c b/drivers/mmc/core/sdio_io.c
index 79dbf9021..2ba00acf6 100644
--- a/drivers/mmc/core/sdio_io.c
+++ b/drivers/mmc/core/sdio_io.c
@@ -133,7 +133,7 @@ int sdio_disable_func(struct sdio_func *func)
 
 err:
 	pr_debug("SDIO: Failed to disable device %s\n", sdio_func_id(func));
-	return ret;
+	return -EIO;
 }
 EXPORT_SYMBOL_GPL(sdio_disable_func);
 
@@ -709,7 +709,6 @@ EXPORT_SYMBOL_GPL(sdio_get_host_pm_caps);
 /**
  *	sdio_set_host_pm_flags - set wanted host power management capabilities
  *	@func: SDIO function attached to host
- *	@flags: Power Management flags to set
  *
  *	Set a capability bitmask corresponding to wanted host controller
  *	power management features for the upcoming suspend state.
diff --git a/drivers/mmc/core/sdio_irq.c b/drivers/mmc/core/sdio_irq.c
index 4b1f7c966..900871073 100644
--- a/drivers/mmc/core/sdio_irq.c
+++ b/drivers/mmc/core/sdio_irq.c
@@ -139,10 +139,11 @@ EXPORT_SYMBOL_GPL(sdio_signal_irq);
 static int sdio_irq_thread(void *_host)
 {
 	struct mmc_host *host = _host;
+	struct sched_param param = { .sched_priority = 1 };
 	unsigned long period, idle_period;
 	int ret;
 
-	sched_set_fifo_low(current);
+	sched_setscheduler(current, SCHED_FIFO, &param);
 
 	/*
 	 * We want to allow for SDIO cards to work even on non SDIO
@@ -275,15 +276,14 @@ static void sdio_single_irq_set(struct mmc_card *card)
 
 	card->sdio_single_irq = NULL;
 	if ((card->host->caps & MMC_CAP_SDIO_IRQ) &&
-	    card->host->sdio_irqs == 1) {
+	    card->host->sdio_irqs == 1)
 		for (i = 0; i < card->sdio_funcs; i++) {
-			func = card->sdio_func[i];
-			if (func && func->irq_handler) {
-				card->sdio_single_irq = func;
-				break;
-			}
-		}
-	}
+		       func = card->sdio_func[i];
+		       if (func && func->irq_handler) {
+			       card->sdio_single_irq = func;
+			       break;
+		       }
+	       }
 }
 
 /**
diff --git a/drivers/mmc/core/sdio_ops.c b/drivers/mmc/core/sdio_ops.c
index 4c229dd2b..93d346c01 100644
--- a/drivers/mmc/core/sdio_ops.c
+++ b/drivers/mmc/core/sdio_ops.c
@@ -121,7 +121,6 @@ int mmc_io_rw_extended(struct mmc_card *card, int write, unsigned fn,
 	struct sg_table sgtable;
 	unsigned int nents, left_size, i;
 	unsigned int seg_size = card->host->max_seg_size;
-	int err;
 
 	WARN_ON(blksz == 0);
 
@@ -171,32 +170,28 @@ int mmc_io_rw_extended(struct mmc_card *card, int write, unsigned fn,
 
 	mmc_set_data_timeout(&data, card);
 
-	mmc_pre_req(card->host, &mrq);
-
 	mmc_wait_for_req(card->host, &mrq);
 
-	if (cmd.error)
-		err = cmd.error;
-	else if (data.error)
-		err = data.error;
-	else if (mmc_host_is_spi(card->host))
-		/* host driver already reported errors */
-		err = 0;
-	else if (cmd.resp[0] & R5_ERROR)
-		err = -EIO;
-	else if (cmd.resp[0] & R5_FUNCTION_NUMBER)
-		err = -EINVAL;
-	else if (cmd.resp[0] & R5_OUT_OF_RANGE)
-		err = -ERANGE;
-	else
-		err = 0;
-
-	mmc_post_req(card->host, &mrq, err);
-
 	if (nents > 1)
 		sg_free_table(&sgtable);
 
-	return err;
+	if (cmd.error)
+		return cmd.error;
+	if (data.error)
+		return data.error;
+
+	if (mmc_host_is_spi(card->host)) {
+		/* host driver already reported errors */
+	} else {
+		if (cmd.resp[0] & R5_ERROR)
+			return -EIO;
+		if (cmd.resp[0] & R5_FUNCTION_NUMBER)
+			return -EINVAL;
+		if (cmd.resp[0] & R5_OUT_OF_RANGE)
+			return -ERANGE;
+	}
+
+	return 0;
 }
 
 int sdio_reset(struct mmc_host *host)
diff --git a/drivers/mmc/core/slot-gpio.c b/drivers/mmc/core/slot-gpio.c
index 05e907451..da2596c5f 100644
--- a/drivers/mmc/core/slot-gpio.c
+++ b/drivers/mmc/core/slot-gpio.c
@@ -19,6 +19,7 @@
 struct mmc_gpio {
 	struct gpio_desc *ro_gpio;
 	struct gpio_desc *cd_gpio;
+	bool override_cd_active_level;
 	irqreturn_t (*cd_gpio_isr)(int irq, void *dev_id);
 	char *ro_label;
 	char *cd_label;
@@ -79,6 +80,13 @@ int mmc_gpio_get_cd(struct mmc_host *host)
 		return -ENOSYS;
 
 	cansleep = gpiod_cansleep(ctx->cd_gpio);
+	if (ctx->override_cd_active_level) {
+		int value = cansleep ?
+				gpiod_get_raw_value_cansleep(ctx->cd_gpio) :
+				gpiod_get_raw_value(ctx->cd_gpio);
+		return !value ^ !!(host->caps2 & MMC_CAP2_CD_ACTIVE_HIGH);
+	}
+
 	return cansleep ?
 		gpiod_get_value_cansleep(ctx->cd_gpio) :
 		gpiod_get_value(ctx->cd_gpio);
@@ -160,6 +168,8 @@ EXPORT_SYMBOL(mmc_gpio_set_cd_isr);
  * @idx: index of the GPIO to obtain in the consumer
  * @override_active_level: ignore %GPIO_ACTIVE_LOW flag
  * @debounce: debounce time in microseconds
+ * @gpio_invert: will return whether the GPIO line is inverted or not, set
+ * to NULL to ignore
  *
  * Note that this must be called prior to mmc_add_host()
  * otherwise the caller must also call mmc_gpiod_request_cd_irq().
@@ -168,7 +178,7 @@ EXPORT_SYMBOL(mmc_gpio_set_cd_isr);
  */
 int mmc_gpiod_request_cd(struct mmc_host *host, const char *con_id,
 			 unsigned int idx, bool override_active_level,
-			 unsigned int debounce)
+			 unsigned int debounce, bool *gpio_invert)
 {
 	struct mmc_gpio *ctx = host->slot.handler_priv;
 	struct gpio_desc *desc;
@@ -184,14 +194,10 @@ int mmc_gpiod_request_cd(struct mmc_host *host, const char *con_id,
 			ctx->cd_debounce_delay_ms = debounce / 1000;
 	}
 
-	/* override forces default (active-low) polarity ... */
-	if (override_active_level && !gpiod_is_active_low(desc))
-		gpiod_toggle_active_low(desc);
-
-	/* ... or active-high */
-	if (host->caps2 & MMC_CAP2_CD_ACTIVE_HIGH)
-		gpiod_toggle_active_low(desc);
+	if (gpio_invert)
+		*gpio_invert = !gpiod_is_active_low(desc);
 
+	ctx->override_cd_active_level = override_active_level;
 	ctx->cd_gpio = desc;
 
 	return 0;
@@ -212,11 +218,14 @@ EXPORT_SYMBOL(mmc_can_gpio_cd);
  * @con_id: function within the GPIO consumer
  * @idx: index of the GPIO to obtain in the consumer
  * @debounce: debounce time in microseconds
+ * @gpio_invert: will return whether the GPIO line is inverted or not,
+ * set to NULL to ignore
  *
  * Returns zero on success, else an error.
  */
 int mmc_gpiod_request_ro(struct mmc_host *host, const char *con_id,
-			 unsigned int idx, unsigned int debounce)
+			 unsigned int idx,
+			 unsigned int debounce, bool *gpio_invert)
 {
 	struct mmc_gpio *ctx = host->slot.handler_priv;
 	struct gpio_desc *desc;
@@ -232,8 +241,8 @@ int mmc_gpiod_request_ro(struct mmc_host *host, const char *con_id,
 			return ret;
 	}
 
-	if (host->caps2 & MMC_CAP2_RO_ACTIVE_HIGH)
-		gpiod_toggle_active_low(desc);
+	if (gpio_invert)
+		*gpio_invert = !gpiod_is_active_low(desc);
 
 	ctx->ro_gpio = desc;
 
diff --git a/drivers/mmc/host/bcm2835.c b/drivers/mmc/host/bcm2835.c
index 8c2361e66..148414d7f 100644
--- a/drivers/mmc/host/bcm2835.c
+++ b/drivers/mmc/host/bcm2835.c
@@ -1280,7 +1280,8 @@ static int bcm2835_add_host(struct bcm2835_host *host)
 
 	/* host controller capabilities */
 	mmc->caps |= MMC_CAP_SD_HIGHSPEED | MMC_CAP_MMC_HIGHSPEED |
-		     MMC_CAP_NEEDS_POLL | MMC_CAP_HW_RESET | MMC_CAP_CMD23;
+		     MMC_CAP_NEEDS_POLL | MMC_CAP_HW_RESET | MMC_CAP_ERASE |
+		     MMC_CAP_CMD23;
 
 	spin_lock_init(&host->lock);
 	mutex_init(&host->mutex);
@@ -1356,6 +1357,7 @@ static int bcm2835_probe(struct platform_device *pdev)
 {
 	struct device *dev = &pdev->dev;
 	struct clk *clk;
+	struct resource *iomem;
 	struct bcm2835_host *host;
 	struct mmc_host *mmc;
 	const __be32 *regaddr_p;
@@ -1371,7 +1373,8 @@ static int bcm2835_probe(struct platform_device *pdev)
 	host->pdev = pdev;
 	spin_lock_init(&host->lock);
 
-	host->ioaddr = devm_platform_ioremap_resource(pdev, 0);
+	iomem = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	host->ioaddr = devm_ioremap_resource(dev, iomem);
 	if (IS_ERR(host->ioaddr)) {
 		ret = PTR_ERR(host->ioaddr);
 		goto err;
@@ -1392,21 +1395,13 @@ static int bcm2835_probe(struct platform_device *pdev)
 	host->dma_chan = NULL;
 	host->dma_desc = NULL;
 
-	host->dma_chan_rxtx = dma_request_chan(dev, "rx-tx");
-	if (IS_ERR(host->dma_chan_rxtx)) {
-		ret = PTR_ERR(host->dma_chan_rxtx);
-		host->dma_chan_rxtx = NULL;
-
-		if (ret == -EPROBE_DEFER)
-			goto err;
-
-		/* Ignore errors to fall back to PIO mode */
-	}
-
+	host->dma_chan_rxtx = dma_request_slave_channel(dev, "rx-tx");
 
 	clk = devm_clk_get(dev, NULL);
 	if (IS_ERR(clk)) {
-		ret = dev_err_probe(dev, PTR_ERR(clk), "could not get clk\n");
+		ret = PTR_ERR(clk);
+		if (ret != -EPROBE_DEFER)
+			dev_err(dev, "could not get clk: %d\n", ret);
 		goto err;
 	}
 
@@ -1474,7 +1469,6 @@ static struct platform_driver bcm2835_driver = {
 	.remove     = bcm2835_remove,
 	.driver     = {
 		.name		= "sdhost-bcm2835",
-		.probe_type	= PROBE_PREFER_ASYNCHRONOUS,
 		.of_match_table	= bcm2835_match,
 	},
 };
diff --git a/drivers/mmc/host/cqhci.c b/drivers/mmc/host/cqhci.c
index 7ba4f7141..80a281d44 100644
--- a/drivers/mmc/host/cqhci.c
+++ b/drivers/mmc/host/cqhci.c
@@ -5,7 +5,6 @@
 #include <linux/delay.h>
 #include <linux/highmem.h>
 #include <linux/io.h>
-#include <linux/iopoll.h>
 #include <linux/module.h>
 #include <linux/dma-mapping.h>
 #include <linux/slab.h>
@@ -144,7 +143,7 @@ static void cqhci_dumpregs(struct cqhci_host *cq_host)
 		CQHCI_DUMP(": ===========================================\n");
 }
 
-/*
+/**
  * The allocated descriptor table for task, link & transfer descritors
  * looks like:
  * |----------|
@@ -302,16 +301,16 @@ static void __cqhci_disable(struct cqhci_host *cq_host)
 	cq_host->activated = false;
 }
 
-int cqhci_deactivate(struct mmc_host *mmc)
+int cqhci_suspend(struct mmc_host *mmc)
 {
 	struct cqhci_host *cq_host = mmc->cqe_private;
 
-	if (cq_host->enabled && cq_host->activated)
+	if (cq_host->enabled)
 		__cqhci_disable(cq_host);
 
 	return 0;
 }
-EXPORT_SYMBOL(cqhci_deactivate);
+EXPORT_SYMBOL(cqhci_suspend);
 
 int cqhci_resume(struct mmc_host *mmc)
 {
@@ -325,20 +324,14 @@ static int cqhci_enable(struct mmc_host *mmc, struct mmc_card *card)
 	struct cqhci_host *cq_host = mmc->cqe_private;
 	int err;
 
-	if (!card->ext_csd.cmdq_en)
-		return -EINVAL;
-
 	if (cq_host->enabled)
 		return 0;
 
 	cq_host->rca = card->rca;
 
 	err = cqhci_host_alloc_tdl(cq_host);
-	if (err) {
-		pr_err("%s: Failed to enable CQE, error %d\n",
-		       mmc_hostname(mmc), err);
+	if (err)
 		return err;
-	}
 
 	__cqhci_enable(cq_host);
 
@@ -353,16 +346,12 @@ static int cqhci_enable(struct mmc_host *mmc, struct mmc_card *card)
 /* CQHCI is idle and should halt immediately, so set a small timeout */
 #define CQHCI_OFF_TIMEOUT 100
 
-static u32 cqhci_read_ctl(struct cqhci_host *cq_host)
-{
-	return cqhci_readl(cq_host, CQHCI_CTL);
-}
-
 static void cqhci_off(struct mmc_host *mmc)
 {
 	struct cqhci_host *cq_host = mmc->cqe_private;
+	ktime_t timeout;
+	bool timed_out;
 	u32 reg;
-	int err;
 
 	if (!cq_host->enabled || !mmc->cqe_on || cq_host->recovery_halt)
 		return;
@@ -372,16 +361,19 @@ static void cqhci_off(struct mmc_host *mmc)
 
 	cqhci_writel(cq_host, CQHCI_HALT, CQHCI_CTL);
 
-	err = readx_poll_timeout(cqhci_read_ctl, cq_host, reg,
-				 reg & CQHCI_HALT, 0, CQHCI_OFF_TIMEOUT);
-	if (err < 0)
+	timeout = ktime_add_us(ktime_get(), CQHCI_OFF_TIMEOUT);
+	while (1) {
+		timed_out = ktime_compare(ktime_get(), timeout) > 0;
+		reg = cqhci_readl(cq_host, CQHCI_CTL);
+		if ((reg & CQHCI_HALT) || timed_out)
+			break;
+	}
+
+	if (timed_out)
 		pr_err("%s: cqhci: CQE stuck on\n", mmc_hostname(mmc));
 	else
 		pr_debug("%s: cqhci: CQE off\n", mmc_hostname(mmc));
 
-	if (cq_host->ops->post_disable)
-		cq_host->ops->post_disable(mmc);
-
 	mmc->cqe_on = false;
 }
 
@@ -428,7 +420,7 @@ static void cqhci_prep_task_desc(struct mmc_request *mrq,
 		CQHCI_BLK_COUNT(mrq->data->blocks) |
 		CQHCI_BLK_ADDR((u64)mrq->data->blk_addr);
 
-	pr_debug("%s: cqhci: tag %d task descriptor 0x%016llx\n",
+	pr_debug("%s: cqhci: tag %d task descriptor 0x016%llx\n",
 		 mmc_hostname(mrq->host), mrq->tag, (unsigned long long)*data);
 }
 
@@ -586,9 +578,6 @@ static int cqhci_request(struct mmc_host *mmc, struct mmc_request *mrq)
 		__cqhci_enable(cq_host);
 
 	if (!mmc->cqe_on) {
-		if (cq_host->ops->pre_enable)
-			cq_host->ops->pre_enable(mmc);
-
 		cqhci_writel(cq_host, 0, CQHCI_CTL);
 		mmc->cqe_on = true;
 		pr_debug("%s: cqhci: CQE on\n", mmc_hostname(mmc));
@@ -1085,7 +1074,7 @@ struct cqhci_host *cqhci_pltfm_init(struct platform_device *pdev)
 
 	/* check and setup CMDQ interface */
 	cqhci_memres = platform_get_resource_byname(pdev, IORESOURCE_MEM,
-						   "cqhci");
+						   "cqhci_mem");
 	if (!cqhci_memres) {
 		dev_dbg(&pdev->dev, "CMDQ not supported\n");
 		return ERR_PTR(-EINVAL);
diff --git a/drivers/mmc/host/cqhci.h b/drivers/mmc/host/cqhci.h
index 89bf6adbc..def76e9b5 100644
--- a/drivers/mmc/host/cqhci.h
+++ b/drivers/mmc/host/cqhci.h
@@ -206,8 +206,6 @@ struct cqhci_host_ops {
 	void (*disable)(struct mmc_host *mmc, bool recovery);
 	void (*update_dcmd_desc)(struct mmc_host *mmc, struct mmc_request *mrq,
 				 u64 *data);
-	void (*pre_enable)(struct mmc_host *mmc);
-	void (*post_disable)(struct mmc_host *mmc);
 };
 
 static inline void cqhci_writel(struct cqhci_host *host, u32 val, int reg)
@@ -232,11 +230,7 @@ irqreturn_t cqhci_irq(struct mmc_host *mmc, u32 intmask, int cmd_error,
 		      int data_error);
 int cqhci_init(struct cqhci_host *cq_host, struct mmc_host *mmc, bool dma64);
 struct cqhci_host *cqhci_pltfm_init(struct platform_device *pdev);
-int cqhci_deactivate(struct mmc_host *mmc);
-static inline int cqhci_suspend(struct mmc_host *mmc)
-{
-	return cqhci_deactivate(mmc);
-}
+int cqhci_suspend(struct mmc_host *mmc);
 int cqhci_resume(struct mmc_host *mmc);
 
 #endif
diff --git a/drivers/mmc/host/dw_mmc-exynos.c b/drivers/mmc/host/dw_mmc-exynos.c
index 1f8a3c0dd..ae2c74186 100644
--- a/drivers/mmc/host/dw_mmc-exynos.c
+++ b/drivers/mmc/host/dw_mmc-exynos.c
@@ -176,7 +176,6 @@ static int dw_mci_exynos_runtime_resume(struct device *dev)
 #ifdef CONFIG_PM_SLEEP
 /**
  * dw_mci_exynos_suspend_noirq - Exynos-specific suspend code
- * @dev: Device to suspend (this device)
  *
  * This ensures that device will be in runtime active state in
  * dw_mci_exynos_resume_noirq after calling pm_runtime_force_resume()
@@ -189,7 +188,6 @@ static int dw_mci_exynos_suspend_noirq(struct device *dev)
 
 /**
  * dw_mci_exynos_resume_noirq - Exynos-specific resume code
- * @dev: Device to resume (this device)
  *
  * On exynos5420 there is a silicon errata that will sometimes leave the
  * WAKEUP_INT bit in the CLKSEL register asserted.  This bit is 1 to indicate
@@ -486,7 +484,7 @@ static int dw_mci_exynos_execute_tuning(struct dw_mci_slot *slot, u32 opcode)
 	struct dw_mci_exynos_priv_data *priv = host->priv;
 	struct mmc_host *mmc = slot->mmc;
 	u8 start_smpl, smpl, candiates = 0;
-	s8 found;
+	s8 found = -1;
 	int ret = 0;
 
 	start_smpl = dw_mci_exynos_get_clksmpl(host);
@@ -606,7 +604,6 @@ static struct platform_driver dw_mci_exynos_pltfm_driver = {
 	.remove		= dw_mci_exynos_remove,
 	.driver		= {
 		.name		= "dwmmc_exynos",
-		.probe_type	= PROBE_PREFER_ASYNCHRONOUS,
 		.of_match_table	= dw_mci_exynos_match,
 		.pm		= &dw_mci_exynos_pmops,
 	},
diff --git a/drivers/mmc/host/dw_mmc-hi3798cv200.c b/drivers/mmc/host/dw_mmc-hi3798cv200.c
index 39794f938..83e1bad0a 100644
--- a/drivers/mmc/host/dw_mmc-hi3798cv200.c
+++ b/drivers/mmc/host/dw_mmc-hi3798cv200.c
@@ -200,7 +200,6 @@ static struct platform_driver dw_mci_hi3798cv200_driver = {
 	.remove = dw_mci_hi3798cv200_remove,
 	.driver = {
 		.name = "dwmmc_hi3798cv200",
-		.probe_type = PROBE_PREFER_ASYNCHRONOUS,
 		.of_match_table = dw_mci_hi3798cv200_match,
 	},
 };
diff --git a/drivers/mmc/host/dw_mmc-k3.c b/drivers/mmc/host/dw_mmc-k3.c
index 29d2494eb..23b6f65b3 100644
--- a/drivers/mmc/host/dw_mmc-k3.c
+++ b/drivers/mmc/host/dw_mmc-k3.c
@@ -238,7 +238,7 @@ static void dw_mci_hs_set_timing(struct dw_mci *host, int timing,
 		if (smpl_phase >= USE_DLY_MIN_SMPL &&
 				smpl_phase <= USE_DLY_MAX_SMPL)
 			use_smpl_dly = 1;
-		fallthrough;
+			/* fallthrough */
 	case MMC_TIMING_UHS_SDR50:
 		if (smpl_phase >= ENABLE_SHIFT_MIN_SMPL &&
 				smpl_phase <= ENABLE_SHIFT_MAX_SMPL)
@@ -424,7 +424,7 @@ static int dw_mci_hi3660_switch_voltage(struct mmc_host *mmc,
 
 	if (!IS_ERR(mmc->supply.vqmmc)) {
 		ret = mmc_regulator_set_vqmmc(mmc, ios);
-		if (ret < 0) {
+		if (ret) {
 			dev_err(host->dev, "Regulator set error %d\n", ret);
 			return ret;
 		}
@@ -473,7 +473,6 @@ static struct platform_driver dw_mci_k3_pltfm_driver = {
 	.remove		= dw_mci_pltfm_remove,
 	.driver		= {
 		.name		= "dwmmc_k3",
-		.probe_type	= PROBE_PREFER_ASYNCHRONOUS,
 		.of_match_table	= dw_mci_k3_match,
 		.pm		= &dw_mci_k3_dev_pm_ops,
 	},
diff --git a/drivers/mmc/host/dw_mmc-pltfm.c b/drivers/mmc/host/dw_mmc-pltfm.c
index 73731cd3b..7de37f524 100644
--- a/drivers/mmc/host/dw_mmc-pltfm.c
+++ b/drivers/mmc/host/dw_mmc-pltfm.c
@@ -98,7 +98,6 @@ static struct platform_driver dw_mci_pltfm_driver = {
 	.remove		= dw_mci_pltfm_remove,
 	.driver		= {
 		.name		= "dw_mmc",
-		.probe_type	= PROBE_PREFER_ASYNCHRONOUS,
 		.of_match_table	= dw_mci_pltfm_match,
 		.pm		= &dw_mci_pltfm_pmops,
 	},
diff --git a/drivers/mmc/host/dw_mmc.c b/drivers/mmc/host/dw_mmc.c
index a6170f80b..4fd2cfa40 100644
--- a/drivers/mmc/host/dw_mmc.c
+++ b/drivers/mmc/host/dw_mmc.c
@@ -176,11 +176,11 @@ static void dw_mci_init_debugfs(struct dw_mci_slot *slot)
 
 	debugfs_create_file("regs", S_IRUSR, root, host, &dw_mci_regs_fops);
 	debugfs_create_file("req", S_IRUSR, root, slot, &dw_mci_req_fops);
-	debugfs_create_u32("state", S_IRUSR, root, &host->state);
-	debugfs_create_xul("pending_events", S_IRUSR, root,
-			   &host->pending_events);
-	debugfs_create_xul("completed_events", S_IRUSR, root,
-			   &host->completed_events);
+	debugfs_create_u32("state", S_IRUSR, root, (u32 *)&host->state);
+	debugfs_create_x32("pending_events", S_IRUSR, root,
+			   (u32 *)&host->pending_events);
+	debugfs_create_x32("completed_events", S_IRUSR, root,
+			   (u32 *)&host->completed_events);
 }
 #endif /* defined(CONFIG_DEBUG_FS) */
 
@@ -782,7 +782,6 @@ static int dw_mci_edmac_start_dma(struct dw_mci *host,
 	int ret = 0;
 
 	/* Set external dma config: burst size, burst width */
-	memset(&cfg, 0, sizeof(cfg));
 	cfg.dst_addr = host->phy_regs + fifo_offset;
 	cfg.src_addr = cfg.dst_addr;
 	cfg.dst_addr_width = DMA_SLAVE_BUSWIDTH_4_BYTES;
@@ -834,14 +833,12 @@ static int dw_mci_edmac_init(struct dw_mci *host)
 	if (!host->dms)
 		return -ENOMEM;
 
-	host->dms->ch = dma_request_chan(host->dev, "rx-tx");
-	if (IS_ERR(host->dms->ch)) {
-		int ret = PTR_ERR(host->dms->ch);
-
+	host->dms->ch = dma_request_slave_channel(host->dev, "rx-tx");
+	if (!host->dms->ch) {
 		dev_err(host->dev, "Failed to get external DMA channel.\n");
 		kfree(host->dms);
 		host->dms = NULL;
-		return ret;
+		return -ENXIO;
 	}
 
 	return 0;
@@ -1547,7 +1544,8 @@ static int dw_mci_switch_voltage(struct mmc_host *mmc, struct mmc_ios *ios)
 
 	if (!IS_ERR(mmc->supply.vqmmc)) {
 		ret = mmc_regulator_set_vqmmc(mmc, ios);
-		if (ret < 0) {
+
+		if (ret) {
 			dev_dbg(&mmc->class_dev,
 					 "Regulator set error %d - %s V\n",
 					 ret, uhs & v18 ? "1.8" : "3.3");
@@ -2020,8 +2018,8 @@ static void dw_mci_tasklet_func(unsigned long priv)
 					continue;
 				}
 
-				send_stop_abort(host, data);
 				dw_mci_stop_dma(host);
+				send_stop_abort(host, data);
 				state = STATE_SENDING_STOP;
 				break;
 			}
@@ -2032,7 +2030,7 @@ static void dw_mci_tasklet_func(unsigned long priv)
 			}
 
 			prev_state = state = STATE_SENDING_DATA;
-			fallthrough;
+			/* fall through */
 
 		case STATE_SENDING_DATA:
 			/*
@@ -2045,10 +2043,10 @@ static void dw_mci_tasklet_func(unsigned long priv)
 			 */
 			if (test_and_clear_bit(EVENT_DATA_ERROR,
 					       &host->pending_events)) {
+				dw_mci_stop_dma(host);
 				if (!(host->data_status & (SDMMC_INT_DRTO |
 							   SDMMC_INT_EBE)))
 					send_stop_abort(host, data);
-				dw_mci_stop_dma(host);
 				state = STATE_DATA_ERROR;
 				break;
 			}
@@ -2081,16 +2079,16 @@ static void dw_mci_tasklet_func(unsigned long priv)
 			 */
 			if (test_and_clear_bit(EVENT_DATA_ERROR,
 					       &host->pending_events)) {
+				dw_mci_stop_dma(host);
 				if (!(host->data_status & (SDMMC_INT_DRTO |
 							   SDMMC_INT_EBE)))
 					send_stop_abort(host, data);
-				dw_mci_stop_dma(host);
 				state = STATE_DATA_ERROR;
 				break;
 			}
 			prev_state = state = STATE_DATA_BUSY;
 
-			fallthrough;
+			/* fall through */
 
 		case STATE_DATA_BUSY:
 			if (!dw_mci_clear_pending_data_complete(host)) {
@@ -2143,7 +2141,7 @@ static void dw_mci_tasklet_func(unsigned long priv)
 			 */
 			prev_state = state = STATE_SENDING_STOP;
 
-			fallthrough;
+			/* fall through */
 
 		case STATE_SENDING_STOP:
 			if (!dw_mci_clear_pending_cmd_complete(host))
@@ -2753,6 +2751,12 @@ static int dw_mci_init_slot_caps(struct dw_mci_slot *slot)
 	if (host->pdata->caps)
 		mmc->caps = host->pdata->caps;
 
+	/*
+	 * Support MMC_CAP_ERASE by default.
+	 * It needs to use trim/discard/erase commands.
+	 */
+	mmc->caps |= MMC_CAP_ERASE;
+
 	if (host->pdata->pm_caps)
 		mmc->pm_caps = host->pdata->pm_caps;
 
@@ -3163,9 +3167,12 @@ int dw_mci_probe(struct dw_mci *host)
 
 	if (!host->pdata) {
 		host->pdata = dw_mci_parse_dt(host);
-		if (IS_ERR(host->pdata))
-			return dev_err_probe(host->dev, PTR_ERR(host->pdata),
-					     "platform data not available\n");
+		if (PTR_ERR(host->pdata) == -EPROBE_DEFER) {
+			return -EPROBE_DEFER;
+		} else if (IS_ERR(host->pdata)) {
+			dev_err(host->dev, "platform data not available\n");
+			return -EINVAL;
+		}
 	}
 
 	host->biu_clk = devm_clk_get(host->dev, "biu");
@@ -3435,8 +3442,8 @@ int dw_mci_runtime_resume(struct device *dev)
 	 * Restore the initial value at FIFOTH register
 	 * And Invalidate the prev_blksz with zero
 	 */
-	mci_writel(host, FIFOTH, host->fifoth_val);
-	host->prev_blksz = 0;
+	 mci_writel(host, FIFOTH, host->fifoth_val);
+	 host->prev_blksz = 0;
 
 	/* Put in max timeout */
 	mci_writel(host, TMOUT, 0xFFFFFFFF);
diff --git a/drivers/mmc/host/meson-gx-mmc.c b/drivers/mmc/host/meson-gx-mmc.c
index b274083a6..e712315c7 100644
--- a/drivers/mmc/host/meson-gx-mmc.c
+++ b/drivers/mmc/host/meson-gx-mmc.c
@@ -161,11 +161,11 @@ struct meson_host {
 	bool dram_access_quirk;
 
 	struct pinctrl *pinctrl;
+	struct pinctrl_state *pins_default;
 	struct pinctrl_state *pins_clk_gate;
 
 	unsigned int bounce_buf_size;
 	void *bounce_buf;
-	void __iomem *bounce_iomem_buf;
 	dma_addr_t bounce_dma_addr;
 	struct sd_emmc_desc *descs;
 	dma_addr_t descs_dma_addr;
@@ -327,7 +327,7 @@ static void meson_mmc_clk_ungate(struct meson_host *host)
 	u32 cfg;
 
 	if (host->pins_clk_gate)
-		pinctrl_select_default_state(host->dev);
+		pinctrl_select_state(host->pinctrl, host->pins_default);
 
 	/* Make sure the clock is not stopped in the controller */
 	cfg = readl(host->regs + SD_EMMC_CFG);
@@ -427,9 +427,11 @@ static int meson_mmc_clk_init(struct meson_host *host)
 
 		snprintf(name, sizeof(name), "clkin%d", i);
 		clk = devm_clk_get(host->dev, name);
-		if (IS_ERR(clk))
-			return dev_err_probe(host->dev, PTR_ERR(clk),
-					     "Missing clock %s\n", name);
+		if (IS_ERR(clk)) {
+			if (clk != ERR_PTR(-EPROBE_DEFER))
+				dev_err(host->dev, "Missing clock %s\n", name);
+			return PTR_ERR(clk);
+		}
 
 		mux_parent_names[i] = __clk_get_name(clk);
 	}
@@ -520,7 +522,7 @@ static int meson_mmc_resampling_tuning(struct mmc_host *mmc, u32 opcode)
 	val |= ADJUST_ADJ_EN;
 	writel(val, host->regs + host->data->adjust);
 
-	if (mmc_doing_retune(mmc))
+	if (mmc->doing_retune)
 		dly = FIELD_GET(ADJUST_ADJ_DELAY_MASK, val) + 1;
 	else
 		dly = 0;
@@ -735,53 +737,6 @@ static void meson_mmc_desc_chain_transfer(struct mmc_host *mmc, u32 cmd_cfg)
 	writel(start, host->regs + SD_EMMC_START);
 }
 
-/* local sg copy for dram_access_quirk */
-static void meson_mmc_copy_buffer(struct meson_host *host, struct mmc_data *data,
-				  size_t buflen, bool to_buffer)
-{
-	unsigned int sg_flags = SG_MITER_ATOMIC;
-	struct scatterlist *sgl = data->sg;
-	unsigned int nents = data->sg_len;
-	struct sg_mapping_iter miter;
-	unsigned int offset = 0;
-
-	if (to_buffer)
-		sg_flags |= SG_MITER_FROM_SG;
-	else
-		sg_flags |= SG_MITER_TO_SG;
-
-	sg_miter_start(&miter, sgl, nents, sg_flags);
-
-	while ((offset < buflen) && sg_miter_next(&miter)) {
-		unsigned int buf_offset = 0;
-		unsigned int len, left;
-		u32 *buf = miter.addr;
-
-		len = min(miter.length, buflen - offset);
-		left = len;
-
-		if (to_buffer) {
-			do {
-				writel(*buf++, host->bounce_iomem_buf + offset + buf_offset);
-
-				buf_offset += 4;
-				left -= 4;
-			} while (left);
-		} else {
-			do {
-				*buf++ = readl(host->bounce_iomem_buf + offset + buf_offset);
-
-				buf_offset += 4;
-				left -= 4;
-			} while (left);
-		}
-
-		offset += len;
-	}
-
-	sg_miter_stop(&miter);
-}
-
 static void meson_mmc_start_cmd(struct mmc_host *mmc, struct mmc_command *cmd)
 {
 	struct meson_host *host = mmc_priv(mmc);
@@ -825,11 +780,8 @@ static void meson_mmc_start_cmd(struct mmc_host *mmc, struct mmc_command *cmd)
 		if (data->flags & MMC_DATA_WRITE) {
 			cmd_cfg |= CMD_CFG_DATA_WR;
 			WARN_ON(xfer_bytes > host->bounce_buf_size);
-			if (host->dram_access_quirk)
-				meson_mmc_copy_buffer(host, data, xfer_bytes, true);
-			else
-				sg_copy_to_buffer(data->sg, data->sg_len,
-						  host->bounce_buf, xfer_bytes);
+			sg_copy_to_buffer(data->sg, data->sg_len,
+					  host->bounce_buf, xfer_bytes);
 			dma_wmb();
 		}
 
@@ -848,43 +800,12 @@ static void meson_mmc_start_cmd(struct mmc_host *mmc, struct mmc_command *cmd)
 	writel(cmd->arg, host->regs + SD_EMMC_CMD_ARG);
 }
 
-static int meson_mmc_validate_dram_access(struct mmc_host *mmc, struct mmc_data *data)
-{
-	struct scatterlist *sg;
-	int i;
-
-	/* Reject request if any element offset or size is not 32bit aligned */
-	for_each_sg(data->sg, sg, data->sg_len, i) {
-		if (!IS_ALIGNED(sg->offset, sizeof(u32)) ||
-		    !IS_ALIGNED(sg->length, sizeof(u32))) {
-			dev_err(mmc_dev(mmc), "unaligned sg offset %u len %u\n",
-				data->sg->offset, data->sg->length);
-			return -EINVAL;
-		}
-	}
-
-	return 0;
-}
-
 static void meson_mmc_request(struct mmc_host *mmc, struct mmc_request *mrq)
 {
 	struct meson_host *host = mmc_priv(mmc);
 	bool needs_pre_post_req = mrq->data &&
 			!(mrq->data->host_cookie & SD_EMMC_PRE_REQ_DONE);
 
-	/*
-	 * The memory at the end of the controller used as bounce buffer for
-	 * the dram_access_quirk only accepts 32bit read/write access,
-	 * check the aligment and length of the data before starting the request.
-	 */
-	if (host->dram_access_quirk && mrq->data) {
-		mrq->cmd->error = meson_mmc_validate_dram_access(mmc, mrq->data);
-		if (mrq->cmd->error) {
-			mmc_request_done(mmc, mrq);
-			return;
-		}
-	}
-
 	if (needs_pre_post_req) {
 		meson_mmc_get_transfer_mode(mmc, mrq);
 		if (!meson_mmc_desc_chain_mode(mrq->data))
@@ -1029,11 +950,8 @@ static irqreturn_t meson_mmc_irq_thread(int irq, void *dev_id)
 	if (meson_mmc_bounce_buf_read(data)) {
 		xfer_bytes = data->blksz * data->blocks;
 		WARN_ON(xfer_bytes > host->bounce_buf_size);
-		if (host->dram_access_quirk)
-			meson_mmc_copy_buffer(host, data, xfer_bytes, false);
-		else
-			sg_copy_from_buffer(data->sg, data->sg_len,
-					    host->bounce_buf, xfer_bytes);
+		sg_copy_from_buffer(data->sg, data->sg_len,
+				    host->bounce_buf, xfer_bytes);
 	}
 
 	next_cmd = meson_mmc_get_next_command(cmd);
@@ -1087,8 +1005,6 @@ static int meson_mmc_card_busy(struct mmc_host *mmc)
 
 static int meson_mmc_voltage_switch(struct mmc_host *mmc, struct mmc_ios *ios)
 {
-	int ret;
-
 	/* vqmmc regulator is available */
 	if (!IS_ERR(mmc->supply.vqmmc)) {
 		/*
@@ -1098,8 +1014,7 @@ static int meson_mmc_voltage_switch(struct mmc_host *mmc, struct mmc_ios *ios)
 		 * to 1.8v. Please make sure the regulator framework is aware
 		 * of your own regulator constraints
 		 */
-		ret = mmc_regulator_set_vqmmc(mmc, ios);
-		return ret < 0 ? ret : 0;
+		return mmc_regulator_set_vqmmc(mmc, ios);
 	}
 
 	/* no vqmmc regulator, assume fixed regulator at 3/3.3V */
@@ -1160,8 +1075,12 @@ static int meson_mmc_probe(struct platform_device *pdev)
 	}
 
 	ret = device_reset_optional(&pdev->dev);
-	if (ret)
-		return dev_err_probe(&pdev->dev, ret, "device reset failed\n");
+	if (ret) {
+		if (ret != -EPROBE_DEFER)
+			dev_err(&pdev->dev, "device reset failed: %d\n", ret);
+
+		return ret;
+	}
 
 	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
 	host->regs = devm_ioremap_resource(&pdev->dev, res);
@@ -1182,6 +1101,13 @@ static int meson_mmc_probe(struct platform_device *pdev)
 		goto free_host;
 	}
 
+	host->pins_default = pinctrl_lookup_state(host->pinctrl,
+						  PINCTRL_STATE_DEFAULT);
+	if (IS_ERR(host->pins_default)) {
+		ret = PTR_ERR(host->pins_default);
+		goto free_host;
+	}
+
 	host->pins_clk_gate = pinctrl_lookup_state(host->pinctrl,
 						   "clk-gate");
 	if (IS_ERR(host->pins_clk_gate)) {
@@ -1225,11 +1151,9 @@ static int meson_mmc_probe(struct platform_device *pdev)
 
 	mmc->caps |= MMC_CAP_CMD23;
 	if (host->dram_access_quirk) {
-		/* Limit segments to 1 due to low available sram memory */
-		mmc->max_segs = 1;
 		/* Limit to the available sram memory */
-		mmc->max_blk_count = SD_EMMC_SRAM_DATA_BUF_LEN /
-				     mmc->max_blk_size;
+		mmc->max_segs = SD_EMMC_SRAM_DATA_BUF_LEN / mmc->max_blk_size;
+		mmc->max_blk_count = mmc->max_segs;
 	} else {
 		mmc->max_blk_count = CMD_CFG_LENGTH_MASK;
 		mmc->max_segs = SD_EMMC_DESC_BUF_LEN /
@@ -1253,7 +1177,7 @@ static int meson_mmc_probe(struct platform_device *pdev)
 		 * instead of the DDR memory
 		 */
 		host->bounce_buf_size = SD_EMMC_SRAM_DATA_BUF_LEN;
-		host->bounce_iomem_buf = host->regs + SD_EMMC_SRAM_DATA_BUF_OFF;
+		host->bounce_buf = host->regs + SD_EMMC_SRAM_DATA_BUF_OFF;
 		host->bounce_dma_addr = res->start + SD_EMMC_SRAM_DATA_BUF_OFF;
 	} else {
 		/* data bounce buffer */
@@ -1349,7 +1273,6 @@ static struct platform_driver meson_mmc_driver = {
 	.remove		= meson_mmc_remove,
 	.driver		= {
 		.name = DRIVER_NAME,
-		.probe_type = PROBE_PREFER_ASYNCHRONOUS,
 		.of_match_table = of_match_ptr(meson_mmc_of_match),
 	},
 };
diff --git a/drivers/mmc/host/mmc_spi.c b/drivers/mmc/host/mmc_spi.c
index 02f4fd26e..66e354d51 100644
--- a/drivers/mmc/host/mmc_spi.c
+++ b/drivers/mmc/host/mmc_spi.c
@@ -77,8 +77,14 @@
 
 #define MMC_SPI_BLOCKSIZE	512
 
-#define MMC_SPI_R1B_TIMEOUT_MS	3000
-#define MMC_SPI_INIT_TIMEOUT_MS	3000
+
+/* These fixed timeouts come from the latest SD specs, which say to ignore
+ * the CSD values.  The R1B value is for card erase (e.g. the "I forgot the
+ * card's password" scenario); it's mostly applied to STOP_TRANSMISSION after
+ * reads which takes nowhere near that long.  Older cards may be able to use
+ * shorter timeouts ... but why bother?
+ */
+#define r1b_timeout		(HZ * 3)
 
 /* One of the critical speed parameters is the amount of data which may
  * be transferred in one command. If this value is too low, the SD card
@@ -242,7 +248,6 @@ static char *maptype(struct mmc_command *cmd)
 static int mmc_spi_response_get(struct mmc_spi_host *host,
 		struct mmc_command *cmd, int cs_on)
 {
-	unsigned long timeout_ms;
 	u8	*cp = host->data->status;
 	u8	*end = cp + host->t.len;
 	int	value = 0;
@@ -341,11 +346,8 @@ static int mmc_spi_response_get(struct mmc_spi_host *host,
 		/* maybe we read all the busy tokens already */
 		while (cp < end && *cp == 0)
 			cp++;
-		if (cp == end) {
-			timeout_ms = cmd->busy_timeout ? cmd->busy_timeout :
-				MMC_SPI_R1B_TIMEOUT_MS;
-			mmc_spi_wait_unbusy(host, msecs_to_jiffies(timeout_ms));
-		}
+		if (cp == end)
+			mmc_spi_wait_unbusy(host, r1b_timeout);
 		break;
 
 	/* SPI R2 == R1 + second status byte; SEND_STATUS
@@ -882,9 +884,9 @@ mmc_spi_data_do(struct mmc_spi_host *host, struct mmc_command *cmd,
 	else
 		clock_rate = spi->max_speed_hz;
 
-	timeout = data->timeout_ns / 1000 +
+	timeout = data->timeout_ns +
 		  data->timeout_clks * 1000000 / clock_rate;
-	timeout = usecs_to_jiffies((unsigned int)timeout) + 1;
+	timeout = usecs_to_jiffies((unsigned int)(timeout / 1000)) + 1;
 
 	/* Handle scatterlist segments one at a time, with synch for
 	 * each 512-byte block
@@ -1116,7 +1118,7 @@ static void mmc_spi_initsequence(struct mmc_spi_host *host)
 	/* Try to be very sure any previous command has completed;
 	 * wait till not-busy, skip debris from any old commands.
 	 */
-	mmc_spi_wait_unbusy(host, msecs_to_jiffies(MMC_SPI_INIT_TIMEOUT_MS));
+	mmc_spi_wait_unbusy(host, r1b_timeout);
 	mmc_spi_readbytes(host, 10);
 
 	/*
@@ -1132,22 +1134,17 @@ static void mmc_spi_initsequence(struct mmc_spi_host *host)
 	 * SPI protocol.  Another is that when chipselect is released while
 	 * the card returns BUSY status, the clock must issue several cycles
 	 * with chipselect high before the card will stop driving its output.
-	 *
-	 * SPI_CS_HIGH means "asserted" here. In some cases like when using
-	 * GPIOs for chip select, SPI_CS_HIGH is set but this will be logically
-	 * inverted by gpiolib, so if we want to ascertain to drive it high
-	 * we should toggle the default with an XOR as we do here.
 	 */
-	host->spi->mode ^= SPI_CS_HIGH;
+	host->spi->mode |= SPI_CS_HIGH;
 	if (spi_setup(host->spi) != 0) {
 		/* Just warn; most cards work without it. */
 		dev_warn(&host->spi->dev,
 				"can't change chip-select polarity\n");
-		host->spi->mode ^= SPI_CS_HIGH;
+		host->spi->mode &= ~SPI_CS_HIGH;
 	} else {
 		mmc_spi_readbytes(host, 18);
 
-		host->spi->mode ^= SPI_CS_HIGH;
+		host->spi->mode &= ~SPI_CS_HIGH;
 		if (spi_setup(host->spi) != 0) {
 			/* Wot, we can't get the same setup we had before? */
 			dev_err(&host->spi->dev,
@@ -1278,52 +1275,6 @@ mmc_spi_detect_irq(int irq, void *mmc)
 	return IRQ_HANDLED;
 }
 
-#ifdef CONFIG_HAS_DMA
-static int mmc_spi_dma_alloc(struct mmc_spi_host *host)
-{
-	struct spi_device *spi = host->spi;
-	struct device *dev;
-
-	if (!spi->master->dev.parent->dma_mask)
-		return 0;
-
-	dev = spi->master->dev.parent;
-
-	host->ones_dma = dma_map_single(dev, host->ones, MMC_SPI_BLOCKSIZE,
-					DMA_TO_DEVICE);
-	if (dma_mapping_error(dev, host->ones_dma))
-		return -ENOMEM;
-
-	host->data_dma = dma_map_single(dev, host->data, sizeof(*host->data),
-					DMA_BIDIRECTIONAL);
-	if (dma_mapping_error(dev, host->data_dma)) {
-		dma_unmap_single(dev, host->ones_dma, MMC_SPI_BLOCKSIZE,
-				 DMA_TO_DEVICE);
-		return -ENOMEM;
-	}
-
-	dma_sync_single_for_cpu(dev, host->data_dma, sizeof(*host->data),
-				DMA_BIDIRECTIONAL);
-
-	host->dma_dev = dev;
-	return 0;
-}
-
-static void mmc_spi_dma_free(struct mmc_spi_host *host)
-{
-	if (!host->dma_dev)
-		return;
-
-	dma_unmap_single(host->dma_dev, host->ones_dma, MMC_SPI_BLOCKSIZE,
-			 DMA_TO_DEVICE);
-	dma_unmap_single(host->dma_dev, host->data_dma,	sizeof(*host->data),
-			 DMA_BIDIRECTIONAL);
-}
-#else
-static inline int mmc_spi_dma_alloc(struct mmc_spi_host *host) { return 0; }
-static inline void mmc_spi_dma_free(struct mmc_spi_host *host) {}
-#endif
-
 static int mmc_spi_probe(struct spi_device *spi)
 {
 	void			*ones;
@@ -1420,9 +1371,23 @@ static int mmc_spi_probe(struct spi_device *spi)
 	if (!host->data)
 		goto fail_nobuf1;
 
-	status = mmc_spi_dma_alloc(host);
-	if (status)
-		goto fail_dma;
+	if (spi->master->dev.parent->dma_mask) {
+		struct device	*dev = spi->master->dev.parent;
+
+		host->dma_dev = dev;
+		host->ones_dma = dma_map_single(dev, ones,
+				MMC_SPI_BLOCKSIZE, DMA_TO_DEVICE);
+		if (dma_mapping_error(dev, host->ones_dma))
+			goto fail_ones_dma;
+		host->data_dma = dma_map_single(dev, host->data,
+				sizeof(*host->data), DMA_BIDIRECTIONAL);
+		if (dma_mapping_error(dev, host->data_dma))
+			goto fail_data_dma;
+
+		dma_sync_single_for_cpu(host->dma_dev,
+				host->data_dma, sizeof(*host->data),
+				DMA_BIDIRECTIONAL);
+	}
 
 	/* setup message for status/busy readback */
 	spi_message_init(&host->readback);
@@ -1456,7 +1421,7 @@ static int mmc_spi_probe(struct spi_device *spi)
 	 * Index 0 is card detect
 	 * Old boardfiles were specifying 1 ms as debounce
 	 */
-	status = mmc_gpiod_request_cd(mmc, NULL, 0, false, 1000);
+	status = mmc_gpiod_request_cd(mmc, NULL, 0, false, 1, NULL);
 	if (status == -EPROBE_DEFER)
 		goto fail_add_host;
 	if (!status) {
@@ -1471,7 +1436,7 @@ static int mmc_spi_probe(struct spi_device *spi)
 	mmc_detect_change(mmc, 0);
 
 	/* Index 1 is write protect/read only */
-	status = mmc_gpiod_request_ro(mmc, NULL, 1, 0);
+	status = mmc_gpiod_request_ro(mmc, NULL, 1, 0, NULL);
 	if (status == -EPROBE_DEFER)
 		goto fail_add_host;
 	if (!status)
@@ -1490,12 +1455,20 @@ static int mmc_spi_probe(struct spi_device *spi)
 fail_add_host:
 	mmc_remove_host(mmc);
 fail_glue_init:
-	mmc_spi_dma_free(host);
-fail_dma:
+	if (host->dma_dev)
+		dma_unmap_single(host->dma_dev, host->data_dma,
+				sizeof(*host->data), DMA_BIDIRECTIONAL);
+fail_data_dma:
+	if (host->dma_dev)
+		dma_unmap_single(host->dma_dev, host->ones_dma,
+				MMC_SPI_BLOCKSIZE, DMA_TO_DEVICE);
+fail_ones_dma:
 	kfree(host->data);
+
 fail_nobuf1:
 	mmc_free_host(mmc);
 	mmc_spi_put_pdata(spi);
+
 nomem:
 	kfree(ones);
 	return status;
@@ -1513,7 +1486,13 @@ static int mmc_spi_remove(struct spi_device *spi)
 
 	mmc_remove_host(mmc);
 
-	mmc_spi_dma_free(host);
+	if (host->dma_dev) {
+		dma_unmap_single(host->dma_dev, host->ones_dma,
+			MMC_SPI_BLOCKSIZE, DMA_TO_DEVICE);
+		dma_unmap_single(host->dma_dev, host->data_dma,
+			sizeof(*host->data), DMA_BIDIRECTIONAL);
+	}
+
 	kfree(host->data);
 	kfree(host->ones);
 
diff --git a/drivers/mmc/host/mmci.c b/drivers/mmc/host/mmci.c
index 9bde0def1..c37e70dbe 100644
--- a/drivers/mmc/host/mmci.c
+++ b/drivers/mmc/host/mmci.c
@@ -22,7 +22,6 @@
 #include <linux/mmc/pm.h>
 #include <linux/mmc/host.h>
 #include <linux/mmc/card.h>
-#include <linux/mmc/sd.h>
 #include <linux/mmc/slot-gpio.h>
 #include <linux/amba/bus.h>
 #include <linux/clk.h>
@@ -45,7 +44,6 @@
 #define DRIVER_NAME "mmci-pl18x"
 
 static void mmci_variant_init(struct mmci_host *host);
-static void ux500_variant_init(struct mmci_host *host);
 static void ux500v2_variant_init(struct mmci_host *host);
 
 static unsigned int fmax = 515633;
@@ -170,8 +168,6 @@ static struct variant_data variant_ux500 = {
 	.cmdreg_srsp		= MCI_CPSM_RESPONSE,
 	.datalength_bits	= 24,
 	.datactrl_blocksz	= 11,
-	.datactrl_any_blocksz	= true,
-	.dma_power_of_2		= true,
 	.datactrl_mask_sdio	= MCI_DPSM_ST_SDIOEN,
 	.st_sdio		= true,
 	.st_clkdiv		= true,
@@ -188,7 +184,7 @@ static struct variant_data variant_ux500 = {
 	.irq_pio_mask		= MCI_IRQ_PIO_MASK,
 	.start_err		= MCI_STARTBITERR,
 	.opendrain		= MCI_OD,
-	.init			= ux500_variant_init,
+	.init			= mmci_variant_init,
 };
 
 static struct variant_data variant_ux500v2 = {
@@ -205,8 +201,6 @@ static struct variant_data variant_ux500v2 = {
 	.datactrl_mask_ddrmode	= MCI_DPSM_ST_DDRMODE,
 	.datalength_bits	= 24,
 	.datactrl_blocksz	= 11,
-	.datactrl_any_blocksz	= true,
-	.dma_power_of_2		= true,
 	.datactrl_mask_sdio	= MCI_DPSM_ST_SDIOEN,
 	.st_sdio		= true,
 	.st_clkdiv		= true,
@@ -266,40 +260,7 @@ static struct variant_data variant_stm32_sdmmc = {
 	.datacnt_useless	= true,
 	.datalength_bits	= 25,
 	.datactrl_blocksz	= 14,
-	.datactrl_any_blocksz	= true,
-	.datactrl_mask_sdio	= MCI_DPSM_ST_SDIOEN,
 	.stm32_idmabsize_mask	= GENMASK(12, 5),
-	.busy_timeout		= true,
-	.busy_detect		= true,
-	.busy_detect_flag	= MCI_STM32_BUSYD0,
-	.busy_detect_mask	= MCI_STM32_BUSYD0ENDMASK,
-	.init			= sdmmc_variant_init,
-};
-
-static struct variant_data variant_stm32_sdmmcv2 = {
-	.fifosize		= 16 * 4,
-	.fifohalfsize		= 8 * 4,
-	.f_max			= 208000000,
-	.stm32_clkdiv		= true,
-	.cmdreg_cpsm_enable	= MCI_CPSM_STM32_ENABLE,
-	.cmdreg_lrsp_crc	= MCI_CPSM_STM32_LRSP_CRC,
-	.cmdreg_srsp_crc	= MCI_CPSM_STM32_SRSP_CRC,
-	.cmdreg_srsp		= MCI_CPSM_STM32_SRSP,
-	.cmdreg_stop		= MCI_CPSM_STM32_CMDSTOP,
-	.data_cmd_enable	= MCI_CPSM_STM32_CMDTRANS,
-	.irq_pio_mask		= MCI_IRQ_PIO_STM32_MASK,
-	.datactrl_first		= true,
-	.datacnt_useless	= true,
-	.datalength_bits	= 25,
-	.datactrl_blocksz	= 14,
-	.datactrl_any_blocksz	= true,
-	.datactrl_mask_sdio	= MCI_DPSM_ST_SDIOEN,
-	.stm32_idmabsize_mask	= GENMASK(16, 5),
-	.dma_lli		= true,
-	.busy_timeout		= true,
-	.busy_detect		= true,
-	.busy_detect_flag	= MCI_STM32_BUSYD0,
-	.busy_detect_mask	= MCI_STM32_BUSYD0ENDMASK,
 	.init			= sdmmc_variant_init,
 };
 
@@ -318,7 +279,6 @@ static struct variant_data variant_qcom = {
 	.data_cmd_enable	= MCI_CPSM_QCOM_DATCMD,
 	.datalength_bits	= 24,
 	.datactrl_blocksz	= 11,
-	.datactrl_any_blocksz	= true,
 	.pwrreg_powerup		= MCI_PWR_UP,
 	.f_max			= 208000000,
 	.explicit_mclk_control	= true,
@@ -459,7 +419,7 @@ static void mmci_set_clkreg(struct mmci_host *host, unsigned int desired)
 	mmci_write_clkreg(host, clk);
 }
 
-static void mmci_dma_release(struct mmci_host *host)
+void mmci_dma_release(struct mmci_host *host)
 {
 	if (host->ops && host->ops->dma_release)
 		host->ops->dma_release(host);
@@ -467,7 +427,7 @@ static void mmci_dma_release(struct mmci_host *host)
 	host->use_dma = false;
 }
 
-static void mmci_dma_setup(struct mmci_host *host)
+void mmci_dma_setup(struct mmci_host *host)
 {
 	if (!host->ops || !host->ops->dma_setup)
 		return;
@@ -487,11 +447,10 @@ static void mmci_dma_setup(struct mmci_host *host)
 static int mmci_validate_data(struct mmci_host *host,
 			      struct mmc_data *data)
 {
-	struct variant_data *variant = host->variant;
-
 	if (!data)
 		return 0;
-	if (!is_power_of_2(data->blksz) && !variant->datactrl_any_blocksz) {
+
+	if (!is_power_of_2(data->blksz)) {
 		dev_err(mmc_dev(host->mmc),
 			"unsupported block size (%d bytes)\n", data->blksz);
 		return -EINVAL;
@@ -503,7 +462,7 @@ static int mmci_validate_data(struct mmci_host *host,
 	return 0;
 }
 
-static int mmci_prep_data(struct mmci_host *host, struct mmc_data *data, bool next)
+int mmci_prep_data(struct mmci_host *host, struct mmc_data *data, bool next)
 {
 	int err;
 
@@ -519,7 +478,7 @@ static int mmci_prep_data(struct mmci_host *host, struct mmc_data *data, bool ne
 	return err;
 }
 
-static void mmci_unprep_data(struct mmci_host *host, struct mmc_data *data,
+void mmci_unprep_data(struct mmci_host *host, struct mmc_data *data,
 		      int err)
 {
 	if (host->ops && host->ops->unprep_data)
@@ -528,7 +487,7 @@ static void mmci_unprep_data(struct mmci_host *host, struct mmc_data *data,
 	data->host_cookie = 0;
 }
 
-static void mmci_get_next_data(struct mmci_host *host, struct mmc_data *data)
+void mmci_get_next_data(struct mmci_host *host, struct mmc_data *data)
 {
 	WARN_ON(data->host_cookie && data->host_cookie != host->next_cookie);
 
@@ -536,7 +495,7 @@ static void mmci_get_next_data(struct mmci_host *host, struct mmc_data *data)
 		host->ops->get_next_data(host, data);
 }
 
-static int mmci_dma_start(struct mmci_host *host, unsigned int datactrl)
+int mmci_dma_start(struct mmci_host *host, unsigned int datactrl)
 {
 	struct mmc_data *data = host->data;
 	int ret;
@@ -556,9 +515,7 @@ static int mmci_dma_start(struct mmci_host *host, unsigned int datactrl)
 		 "Submit MMCI DMA job, sglen %d blksz %04x blks %04x flags %08x\n",
 		 data->sg_len, data->blksz, data->blocks, data->flags);
 
-	ret = host->ops->dma_start(host, &datactrl);
-	if (ret)
-		return ret;
+	host->ops->dma_start(host, &datactrl);
 
 	/* Trigger the DMA transfer */
 	mmci_write_datactrlreg(host, datactrl);
@@ -573,7 +530,7 @@ static int mmci_dma_start(struct mmci_host *host, unsigned int datactrl)
 	return 0;
 }
 
-static void mmci_dma_finalize(struct mmci_host *host, struct mmc_data *data)
+void mmci_dma_finalize(struct mmci_host *host, struct mmc_data *data)
 {
 	if (!host->use_dma)
 		return;
@@ -582,7 +539,7 @@ static void mmci_dma_finalize(struct mmci_host *host, struct mmc_data *data)
 		host->ops->dma_finalize(host, data);
 }
 
-static void mmci_dma_error(struct mmci_host *host)
+void mmci_dma_error(struct mmci_host *host)
 {
 	if (!host->use_dma)
 		return;
@@ -653,67 +610,6 @@ static u32 ux500v2_get_dctrl_cfg(struct mmci_host *host)
 	return MCI_DPSM_ENABLE | (host->data->blksz << 16);
 }
 
-static bool ux500_busy_complete(struct mmci_host *host, u32 status, u32 err_msk)
-{
-	void __iomem *base = host->base;
-
-	/*
-	 * Before unmasking for the busy end IRQ, confirm that the
-	 * command was sent successfully. To keep track of having a
-	 * command in-progress, waiting for busy signaling to end,
-	 * store the status in host->busy_status.
-	 *
-	 * Note that, the card may need a couple of clock cycles before
-	 * it starts signaling busy on DAT0, hence re-read the
-	 * MMCISTATUS register here, to allow the busy bit to be set.
-	 * Potentially we may even need to poll the register for a
-	 * while, to allow it to be set, but tests indicates that it
-	 * isn't needed.
-	 */
-	if (!host->busy_status && !(status & err_msk) &&
-	    (readl(base + MMCISTATUS) & host->variant->busy_detect_flag)) {
-		writel(readl(base + MMCIMASK0) |
-		       host->variant->busy_detect_mask,
-		       base + MMCIMASK0);
-
-		host->busy_status = status & (MCI_CMDSENT | MCI_CMDRESPEND);
-		return false;
-	}
-
-	/*
-	 * If there is a command in-progress that has been successfully
-	 * sent, then bail out if busy status is set and wait for the
-	 * busy end IRQ.
-	 *
-	 * Note that, the HW triggers an IRQ on both edges while
-	 * monitoring DAT0 for busy completion, but there is only one
-	 * status bit in MMCISTATUS for the busy state. Therefore
-	 * both the start and the end interrupts needs to be cleared,
-	 * one after the other. So, clear the busy start IRQ here.
-	 */
-	if (host->busy_status &&
-	    (status & host->variant->busy_detect_flag)) {
-		writel(host->variant->busy_detect_mask, base + MMCICLEAR);
-		return false;
-	}
-
-	/*
-	 * If there is a command in-progress that has been successfully
-	 * sent and the busy bit isn't set, it means we have received
-	 * the busy end IRQ. Clear and mask the IRQ, then continue to
-	 * process the command.
-	 */
-	if (host->busy_status) {
-		writel(host->variant->busy_detect_mask, base + MMCICLEAR);
-
-		writel(readl(base + MMCIMASK0) &
-		       ~host->variant->busy_detect_mask, base + MMCIMASK0);
-		host->busy_status = 0;
-	}
-
-	return true;
-}
-
 /*
  * All the DMA operation mode stuff goes inside this ifdef.
  * This assumes that you have a generic DMA device interface,
@@ -744,20 +640,10 @@ int mmci_dmae_setup(struct mmci_host *host)
 
 	host->dma_priv = dmae;
 
-	dmae->rx_channel = dma_request_chan(mmc_dev(host->mmc), "rx");
-	if (IS_ERR(dmae->rx_channel)) {
-		int ret = PTR_ERR(dmae->rx_channel);
-		dmae->rx_channel = NULL;
-		return ret;
-	}
-
-	dmae->tx_channel = dma_request_chan(mmc_dev(host->mmc), "tx");
-	if (IS_ERR(dmae->tx_channel)) {
-		if (PTR_ERR(dmae->tx_channel) == -EPROBE_DEFER)
-			dev_warn(mmc_dev(host->mmc),
-				 "Deferred probe for TX channel ignored\n");
-		dmae->tx_channel = NULL;
-	}
+	dmae->rx_channel = dma_request_slave_channel(mmc_dev(host->mmc),
+						     "rx");
+	dmae->tx_channel = dma_request_slave_channel(mmc_dev(host->mmc),
+						     "tx");
 
 	/*
 	 * If only an RX channel is specified, the driver will
@@ -936,18 +822,6 @@ static int _mmci_dmae_prep_data(struct mmci_host *host, struct mmc_data *data,
 	if (data->blksz * data->blocks <= variant->fifosize)
 		return -EINVAL;
 
-	/*
-	 * This is necessary to get SDIO working on the Ux500. We do not yet
-	 * know if this is a bug in:
-	 * - The Ux500 DMA controller (DMA40)
-	 * - The MMCI DMA interface on the Ux500
-	 * some power of two blocks (such as 64 bytes) are sent regularly
-	 * during SDIO traffic and those work fine so for these we enable DMA
-	 * transfers.
-	 */
-	if (host->variant->dma_power_of_2 && !is_power_of_2(data->blksz))
-		return -EINVAL;
-
 	device = chan->device;
 	nr_sg = dma_map_sg(device->dev, data->sg, data->sg_len,
 			   mmc_get_dma_dir(data));
@@ -998,14 +872,9 @@ int mmci_dmae_prep_data(struct mmci_host *host,
 int mmci_dmae_start(struct mmci_host *host, unsigned int *datactrl)
 {
 	struct mmci_dmae_priv *dmae = host->dma_priv;
-	int ret;
 
 	host->dma_in_progress = true;
-	ret = dma_submit_error(dmaengine_submit(dmae->desc_current));
-	if (ret < 0) {
-		host->dma_in_progress = false;
-		return ret;
-	}
+	dmaengine_submit(dmae->desc_current);
 	dma_async_issue_pending(dmae->cur);
 
 	*datactrl |= MCI_DPSM_DMAENABLE;
@@ -1079,21 +948,14 @@ static struct mmci_host_ops mmci_variant_ops = {
 };
 #endif
 
-static void mmci_variant_init(struct mmci_host *host)
+void mmci_variant_init(struct mmci_host *host)
 {
 	host->ops = &mmci_variant_ops;
 }
 
-static void ux500_variant_init(struct mmci_host *host)
+void ux500v2_variant_init(struct mmci_host *host)
 {
 	host->ops = &mmci_variant_ops;
-	host->ops->busy_complete = ux500_busy_complete;
-}
-
-static void ux500v2_variant_init(struct mmci_host *host)
-{
-	host->ops = &mmci_variant_ops;
-	host->ops->busy_complete = ux500_busy_complete;
 	host->ops->get_datactrl_cfg = ux500v2_get_dctrl_cfg;
 }
 
@@ -1213,7 +1075,6 @@ static void
 mmci_start_command(struct mmci_host *host, struct mmc_command *cmd, u32 c)
 {
 	void __iomem *base = host->base;
-	unsigned long long clks;
 
 	dev_dbg(mmc_dev(host->mmc), "op %02x arg %08x flags %08x\n",
 	    cmd->opcode, cmd->arg, cmd->flags);
@@ -1236,23 +1097,6 @@ mmci_start_command(struct mmci_host *host, struct mmc_command *cmd, u32 c)
 		else
 			c |= host->variant->cmdreg_srsp;
 	}
-
-	if (host->variant->busy_timeout && cmd->flags & MMC_RSP_BUSY) {
-		if (!cmd->busy_timeout)
-			cmd->busy_timeout = 10 * MSEC_PER_SEC;
-
-		if (cmd->busy_timeout > host->mmc->max_busy_timeout)
-			clks = (unsigned long long)host->mmc->max_busy_timeout * host->cclk;
-		else
-			clks = (unsigned long long)cmd->busy_timeout * host->cclk;
-
-		do_div(clks, MSEC_PER_SEC);
-		writel_relaxed(clks, host->base + MMCIDATATIMER);
-	}
-
-	if (host->ops->pre_sig_volt_switch && cmd->opcode == SD_SWITCH_VOLTAGE)
-		host->ops->pre_sig_volt_switch(host);
-
 	if (/*interrupt*/0)
 		c |= MCI_CPSM_INTERRUPT;
 
@@ -1357,7 +1201,6 @@ static void
 mmci_cmd_irq(struct mmci_host *host, struct mmc_command *cmd,
 	     unsigned int status)
 {
-	u32 err_msk = MCI_CMDCRCFAIL | MCI_CMDTIMEOUT;
 	void __iomem *base = host->base;
 	bool sbc, busy_resp;
 
@@ -1372,17 +1215,74 @@ mmci_cmd_irq(struct mmci_host *host, struct mmc_command *cmd,
 	 * handling. Note that we tag on any latent IRQs postponed
 	 * due to waiting for busy status.
 	 */
-	if (host->variant->busy_timeout && busy_resp)
-		err_msk |= MCI_DATATIMEOUT;
-
-	if (!((status | host->busy_status) &
-	      (err_msk | MCI_CMDSENT | MCI_CMDRESPEND)))
+	if (!((status|host->busy_status) &
+	      (MCI_CMDCRCFAIL|MCI_CMDTIMEOUT|MCI_CMDSENT|MCI_CMDRESPEND)))
 		return;
 
 	/* Handle busy detection on DAT0 if the variant supports it. */
-	if (busy_resp && host->variant->busy_detect)
-		if (!host->ops->busy_complete(host, status, err_msk))
+	if (busy_resp && host->variant->busy_detect) {
+
+		/*
+		 * Before unmasking for the busy end IRQ, confirm that the
+		 * command was sent successfully. To keep track of having a
+		 * command in-progress, waiting for busy signaling to end,
+		 * store the status in host->busy_status.
+		 *
+		 * Note that, the card may need a couple of clock cycles before
+		 * it starts signaling busy on DAT0, hence re-read the
+		 * MMCISTATUS register here, to allow the busy bit to be set.
+		 * Potentially we may even need to poll the register for a
+		 * while, to allow it to be set, but tests indicates that it
+		 * isn't needed.
+		 */
+		if (!host->busy_status &&
+		    !(status & (MCI_CMDCRCFAIL|MCI_CMDTIMEOUT)) &&
+		    (readl(base + MMCISTATUS) & host->variant->busy_detect_flag)) {
+
+			writel(readl(base + MMCIMASK0) |
+			       host->variant->busy_detect_mask,
+			       base + MMCIMASK0);
+
+			host->busy_status =
+				status & (MCI_CMDSENT|MCI_CMDRESPEND);
+			return;
+		}
+
+		/*
+		 * If there is a command in-progress that has been successfully
+		 * sent, then bail out if busy status is set and wait for the
+		 * busy end IRQ.
+		 *
+		 * Note that, the HW triggers an IRQ on both edges while
+		 * monitoring DAT0 for busy completion, but there is only one
+		 * status bit in MMCISTATUS for the busy state. Therefore
+		 * both the start and the end interrupts needs to be cleared,
+		 * one after the other. So, clear the busy start IRQ here.
+		 */
+		if (host->busy_status &&
+		    (status & host->variant->busy_detect_flag)) {
+			writel(host->variant->busy_detect_mask,
+			       host->base + MMCICLEAR);
 			return;
+		}
+
+		/*
+		 * If there is a command in-progress that has been successfully
+		 * sent and the busy bit isn't set, it means we have received
+		 * the busy end IRQ. Clear and mask the IRQ, then continue to
+		 * process the command.
+		 */
+		if (host->busy_status) {
+
+			writel(host->variant->busy_detect_mask,
+			       host->base + MMCICLEAR);
+
+			writel(readl(base + MMCIMASK0) &
+			       ~host->variant->busy_detect_mask,
+			       base + MMCIMASK0);
+			host->busy_status = 0;
+		}
+	}
 
 	host->cmd = NULL;
 
@@ -1390,10 +1290,6 @@ mmci_cmd_irq(struct mmci_host *host, struct mmc_command *cmd,
 		cmd->error = -ETIMEDOUT;
 	} else if (status & MCI_CMDCRCFAIL && cmd->flags & MMC_RSP_CRC) {
 		cmd->error = -EILSEQ;
-	} else if (host->variant->busy_timeout && busy_resp &&
-		   status & MCI_DATATIMEOUT) {
-		cmd->error = -ETIMEDOUT;
-		host->irq_action = IRQ_WAKE_THREAD;
 	} else {
 		cmd->resp[0] = readl(base + MMCIRESPONSE0);
 		cmd->resp[1] = readl(base + MMCIRESPONSE1);
@@ -1412,10 +1308,7 @@ mmci_cmd_irq(struct mmci_host *host, struct mmc_command *cmd,
 				return;
 			}
 		}
-
-		if (host->irq_action != IRQ_WAKE_THREAD)
-			mmci_request_end(host, host->mrq);
-
+		mmci_request_end(host, host->mrq);
 	} else if (sbc) {
 		mmci_start_command(host, host->mrq->cmd, 0);
 	} else if (!host->variant->datactrl_first &&
@@ -1608,9 +1501,9 @@ static irqreturn_t mmci_irq(int irq, void *dev_id)
 {
 	struct mmci_host *host = dev_id;
 	u32 status;
+	int ret = 0;
 
 	spin_lock(&host->lock);
-	host->irq_action = IRQ_HANDLED;
 
 	do {
 		status = readl(host->base + MMCISTATUS);
@@ -1650,41 +1543,12 @@ static irqreturn_t mmci_irq(int irq, void *dev_id)
 		if (host->variant->busy_detect_flag)
 			status &= ~host->variant->busy_detect_flag;
 
+		ret = 1;
 	} while (status);
 
 	spin_unlock(&host->lock);
 
-	return host->irq_action;
-}
-
-/*
- * mmci_irq_thread() - A threaded IRQ handler that manages a reset of the HW.
- *
- * A reset is needed for some variants, where a datatimeout for a R1B request
- * causes the DPSM to stay busy (non-functional).
- */
-static irqreturn_t mmci_irq_thread(int irq, void *dev_id)
-{
-	struct mmci_host *host = dev_id;
-	unsigned long flags;
-
-	if (host->rst) {
-		reset_control_assert(host->rst);
-		udelay(2);
-		reset_control_deassert(host->rst);
-	}
-
-	spin_lock_irqsave(&host->lock, flags);
-	writel(host->clk_reg, host->base + MMCICLOCK);
-	writel(host->pwr_reg, host->base + MMCIPOWER);
-	writel(MCI_IRQENABLE | host->variant->start_err,
-	       host->base + MMCIMASK0);
-
-	host->irq_action = IRQ_HANDLED;
-	mmci_request_end(host, host->mrq);
-	spin_unlock_irqrestore(&host->lock, flags);
-
-	return host->irq_action;
+	return IRQ_RETVAL(ret);
 }
 
 static void mmci_request(struct mmc_host *mmc, struct mmc_request *mrq)
@@ -1719,20 +1583,6 @@ static void mmci_request(struct mmc_host *mmc, struct mmc_request *mrq)
 	spin_unlock_irqrestore(&host->lock, flags);
 }
 
-static void mmci_set_max_busy_timeout(struct mmc_host *mmc)
-{
-	struct mmci_host *host = mmc_priv(mmc);
-	u32 max_busy_timeout = 0;
-
-	if (!host->variant->busy_detect)
-		return;
-
-	if (host->variant->busy_timeout && mmc->actual_clock)
-		max_busy_timeout = ~0UL / (mmc->actual_clock / MSEC_PER_SEC);
-
-	mmc->max_busy_timeout = max_busy_timeout;
-}
-
 static void mmci_set_ios(struct mmc_host *mmc, struct mmc_ios *ios)
 {
 	struct mmci_host *host = mmc_priv(mmc);
@@ -1809,7 +1659,7 @@ static void mmci_set_ios(struct mmc_host *mmc, struct mmc_ios *ios)
 		if (ios->bus_mode == MMC_BUSMODE_OPENDRAIN)
 			pinctrl_select_state(host->pinctrl, host->pins_opendrain);
 		else
-			pinctrl_select_default_state(mmc_dev(mmc));
+			pinctrl_select_state(host->pinctrl, host->pins_default);
 	}
 
 	/*
@@ -1837,8 +1687,6 @@ static void mmci_set_ios(struct mmc_host *mmc, struct mmc_ios *ios)
 	else
 		mmci_set_clkreg(host, ios->clock);
 
-	mmci_set_max_busy_timeout(mmc);
-
 	if (host->ops && host->ops->set_pwrreg)
 		host->ops->set_pwrreg(host, pwr);
 	else
@@ -1866,18 +1714,28 @@ static int mmci_get_cd(struct mmc_host *mmc)
 
 static int mmci_sig_volt_switch(struct mmc_host *mmc, struct mmc_ios *ios)
 {
-	struct mmci_host *host = mmc_priv(mmc);
-	int ret;
+	int ret = 0;
 
-	ret = mmc_regulator_set_vqmmc(mmc, ios);
+	if (!IS_ERR(mmc->supply.vqmmc)) {
 
-	if (!ret && host->ops && host->ops->post_sig_volt_switch)
-		ret = host->ops->post_sig_volt_switch(host, ios);
-	else if (ret)
-		ret = 0;
+		switch (ios->signal_voltage) {
+		case MMC_SIGNAL_VOLTAGE_330:
+			ret = regulator_set_voltage(mmc->supply.vqmmc,
+						2700000, 3600000);
+			break;
+		case MMC_SIGNAL_VOLTAGE_180:
+			ret = regulator_set_voltage(mmc->supply.vqmmc,
+						1700000, 1950000);
+			break;
+		case MMC_SIGNAL_VOLTAGE_120:
+			ret = regulator_set_voltage(mmc->supply.vqmmc,
+						1100000, 1300000);
+			break;
+		}
 
-	if (ret < 0)
-		dev_warn(mmc_dev(mmc), "Voltage switch failed\n");
+		if (ret)
+			dev_warn(mmc_dev(mmc), "Voltage switch failed\n");
+	}
 
 	return ret;
 }
@@ -1959,8 +1817,6 @@ static int mmci_probe(struct amba_device *dev,
 
 	host = mmc_priv(mmc);
 	host->mmc = mmc;
-	host->mmc_ops = &mmci_ops;
-	mmc->ops = &mmci_ops;
 
 	/*
 	 * Some variant (STM32) doesn't have opendrain bit, nevertheless
@@ -1974,6 +1830,14 @@ static int mmci_probe(struct amba_device *dev,
 			goto host_free;
 		}
 
+		host->pins_default = pinctrl_lookup_state(host->pinctrl,
+							  PINCTRL_STATE_DEFAULT);
+		if (IS_ERR(host->pins_default)) {
+			dev_err(mmc_dev(mmc), "Can't select default pins\n");
+			ret = PTR_ERR(host->pins_default);
+			goto host_free;
+		}
+
 		host->pins_opendrain = pinctrl_lookup_state(host->pinctrl,
 							    MMCI_PINCTRL_STATE_OPENDRAIN);
 		if (IS_ERR(host->pins_opendrain)) {
@@ -2093,17 +1957,16 @@ static int mmci_probe(struct amba_device *dev,
 			mmci_write_datactrlreg(host,
 					       host->variant->busy_dpsm_flag);
 		mmc->caps |= MMC_CAP_WAIT_WHILE_BUSY;
+		mmc->max_busy_timeout = 0;
 	}
 
-	/* Variants with mandatory busy timeout in HW needs R1B responses. */
-	if (variant->busy_timeout)
-		mmc->caps |= MMC_CAP_NEED_RSP_BUSY;
-
 	/* Prepare a CMD12 - needed to clear the DPSM on some variants. */
 	host->stop_abort.opcode = MMC_STOP_TRANSMISSION;
 	host->stop_abort.arg = 0;
 	host->stop_abort.flags = MMC_RSP_R1B | MMC_CMD_AC;
 
+	mmc->ops = &mmci_ops;
+
 	/* We support these PM capabilities. */
 	mmc->pm_caps |= MMC_PM_KEEP_POWER;
 
@@ -2153,18 +2016,17 @@ static int mmci_probe(struct amba_device *dev,
 	 * silently of these do not exist
 	 */
 	if (!np) {
-		ret = mmc_gpiod_request_cd(mmc, "cd", 0, false, 0);
+		ret = mmc_gpiod_request_cd(mmc, "cd", 0, false, 0, NULL);
 		if (ret == -EPROBE_DEFER)
 			goto clk_disable;
 
-		ret = mmc_gpiod_request_ro(mmc, "wp", 0, 0);
+		ret = mmc_gpiod_request_ro(mmc, "wp", 0, 0, NULL);
 		if (ret == -EPROBE_DEFER)
 			goto clk_disable;
 	}
 
-	ret = devm_request_threaded_irq(&dev->dev, dev->irq[0], mmci_irq,
-					mmci_irq_thread, IRQF_SHARED,
-					DRIVER_NAME " (cmd)", host);
+	ret = devm_request_irq(&dev->dev, dev->irq[0], mmci_irq, IRQF_SHARED,
+			DRIVER_NAME " (cmd)", host);
 	if (ret)
 		goto clk_disable;
 
@@ -2295,7 +2157,7 @@ static int mmci_runtime_resume(struct device *dev)
 		struct mmci_host *host = mmc_priv(mmc);
 		clk_prepare_enable(host->clk);
 		mmci_restore(host);
-		pinctrl_select_default_state(dev);
+		pinctrl_pm_select_default_state(dev);
 	}
 
 	return 0;
@@ -2365,11 +2227,6 @@ static const struct amba_id mmci_ids[] = {
 		.mask	= 0xf0ffffff,
 		.data	= &variant_stm32_sdmmc,
 	},
-	{
-		.id     = 0x00253180,
-		.mask	= 0xf0ffffff,
-		.data	= &variant_stm32_sdmmcv2,
-	},
 	/* Qualcomm variants */
 	{
 		.id     = 0x00051180,
diff --git a/drivers/mmc/host/mmci.h b/drivers/mmc/host/mmci.h
index e1a9b96a3..833236ecb 100644
--- a/drivers/mmc/host/mmci.h
+++ b/drivers/mmc/host/mmci.h
@@ -164,8 +164,6 @@
 #define MCI_ST_CARDBUSY		(1 << 24)
 /* Extended status bits for the STM32 variants */
 #define MCI_STM32_BUSYD0	BIT(20)
-#define MCI_STM32_BUSYD0END	BIT(21)
-#define MCI_STM32_VSWEND	BIT(25)
 
 #define MMCICLEAR		0x038
 #define MCI_CMDCRCFAILCLR	(1 << 0)
@@ -183,9 +181,6 @@
 #define MCI_ST_SDIOITC		(1 << 22)
 #define MCI_ST_CEATAENDC	(1 << 23)
 #define MCI_ST_BUSYENDC		(1 << 24)
-/* Extended clear bits for the STM32 variants */
-#define MCI_STM32_VSWENDC	BIT(25)
-#define MCI_STM32_CKSTOPC	BIT(26)
 
 #define MMCIMASK0		0x03c
 #define MCI_CMDCRCFAILMASK	(1 << 0)
@@ -283,11 +278,7 @@ struct mmci_host;
  * @stm32_clkdiv: true if using a STM32-specific clock divider algorithm
  * @datactrl_mask_ddrmode: ddr mode mask in datactrl register.
  * @datactrl_mask_sdio: SDIO enable mask in datactrl register
- * @datactrl_blocksz: block size in power of two
- * @datactrl_any_blocksz: true if block any block sizes are accepted by
- *		  hardware, such as with some SDIO traffic that send
- *		  odd packets.
- * @dma_power_of_2: DMA only works with blocks that are a power of 2.
+ * @datactrl_blksz: block size in power of two
  * @datactrl_first: true if data must be setup before send command
  * @datacnt_useless: true if you could not use datacnt register to read
  *		     remaining data
@@ -296,8 +287,6 @@ struct mmci_host;
  * @signal_direction: input/out direction of bus signals can be indicated
  * @pwrreg_clkgate: MMCIPOWER register must be used to gate the clock
  * @busy_detect: true if the variant supports busy detection on DAT0.
- * @busy_timeout: true if the variant starts data timer when the DPSM
- *		  enter in Wait_R or Busy state.
  * @busy_dpsm_flag: bitmask enabling busy detection in the DPSM
  * @busy_detect_flag: bitmask identifying the bit in the MMCISTATUS register
  *		      indicating that the card is busy
@@ -334,8 +323,6 @@ struct variant_data {
 	unsigned int		datactrl_mask_ddrmode;
 	unsigned int		datactrl_mask_sdio;
 	unsigned int		datactrl_blocksz;
-	u8			datactrl_any_blocksz:1;
-	u8			dma_power_of_2:1;
 	u8			datactrl_first:1;
 	u8			datacnt_useless:1;
 	u8			st_sdio:1;
@@ -346,7 +333,6 @@ struct variant_data {
 	u8			signal_direction:1;
 	u8			pwrreg_clkgate:1;
 	u8			busy_detect:1;
-	u8			busy_timeout:1;
 	u32			busy_dpsm_flag;
 	u32			busy_detect_flag;
 	u32			busy_detect_mask;
@@ -380,9 +366,6 @@ struct mmci_host_ops {
 	void (*dma_error)(struct mmci_host *host);
 	void (*set_clkreg)(struct mmci_host *host, unsigned int desired);
 	void (*set_pwrreg)(struct mmci_host *host, unsigned int pwr);
-	bool (*busy_complete)(struct mmci_host *host, u32 status, u32 err_msk);
-	void (*pre_sig_volt_switch)(struct mmci_host *host);
-	int (*post_sig_volt_switch)(struct mmci_host *host, struct mmc_ios *ios);
 };
 
 struct mmci_host {
@@ -413,11 +396,10 @@ struct mmci_host {
 	u32			mask1_reg;
 	u8			vqmmc_enabled:1;
 	struct mmci_platform_data *plat;
-	struct mmc_host_ops	*mmc_ops;
 	struct mmci_host_ops	*ops;
 	struct variant_data	*variant;
-	void			*variant_priv;
 	struct pinctrl		*pinctrl;
+	struct pinctrl_state	*pins_default;
 	struct pinctrl_state	*pins_opendrain;
 
 	u8			hw_designer;
@@ -425,7 +407,6 @@ struct mmci_host {
 
 	struct timer_list	timer;
 	unsigned int		oldstat;
-	u32			irq_action;
 
 	/* pio stuff */
 	struct sg_mapping_iter	sg_miter;
diff --git a/drivers/mmc/host/mmci_stm32_sdmmc.c b/drivers/mmc/host/mmci_stm32_sdmmc.c
index a75d3dd34..8e83ae692 100644
--- a/drivers/mmc/host/mmci_stm32_sdmmc.c
+++ b/drivers/mmc/host/mmci_stm32_sdmmc.c
@@ -3,13 +3,10 @@
  * Copyright (C) STMicroelectronics 2018 - All Rights Reserved
  * Author: Ludovic.barre@st.com for STMicroelectronics.
  */
-#include <linux/bitfield.h>
 #include <linux/delay.h>
 #include <linux/dma-mapping.h>
-#include <linux/iopoll.h>
 #include <linux/mmc/host.h>
 #include <linux/mmc/card.h>
-#include <linux/of_address.h>
 #include <linux/reset.h>
 #include <linux/scatterlist.h>
 #include "mmci.h"
@@ -17,42 +14,19 @@
 #define SDMMC_LLI_BUF_LEN	PAGE_SIZE
 #define SDMMC_IDMA_BURST	BIT(MMCI_STM32_IDMABNDT_SHIFT)
 
-#define DLYB_CR			0x0
-#define DLYB_CR_DEN		BIT(0)
-#define DLYB_CR_SEN		BIT(1)
-
-#define DLYB_CFGR		0x4
-#define DLYB_CFGR_SEL_MASK	GENMASK(3, 0)
-#define DLYB_CFGR_UNIT_MASK	GENMASK(14, 8)
-#define DLYB_CFGR_LNG_MASK	GENMASK(27, 16)
-#define DLYB_CFGR_LNGF		BIT(31)
-
-#define DLYB_NB_DELAY		11
-#define DLYB_CFGR_SEL_MAX	(DLYB_NB_DELAY + 1)
-#define DLYB_CFGR_UNIT_MAX	127
-
-#define DLYB_LNG_TIMEOUT_US	1000
-#define SDMMC_VSWEND_TIMEOUT_US 10000
-
 struct sdmmc_lli_desc {
 	u32 idmalar;
 	u32 idmabase;
 	u32 idmasize;
 };
 
-struct sdmmc_idma {
+struct sdmmc_priv {
 	dma_addr_t sg_dma;
 	void *sg_cpu;
 };
 
-struct sdmmc_dlyb {
-	void __iomem *base;
-	u32 unit;
-	u32 max;
-};
-
-static int sdmmc_idma_validate_data(struct mmci_host *host,
-				    struct mmc_data *data)
+int sdmmc_idma_validate_data(struct mmci_host *host,
+			     struct mmc_data *data)
 {
 	struct scatterlist *sg;
 	int i;
@@ -62,8 +36,8 @@ static int sdmmc_idma_validate_data(struct mmci_host *host,
 	 * excepted the last element which has no constraint on idmasize
 	 */
 	for_each_sg(data->sg, sg, data->sg_len - 1, i) {
-		if (!IS_ALIGNED(data->sg->offset, sizeof(u32)) ||
-		    !IS_ALIGNED(data->sg->length, SDMMC_IDMA_BURST)) {
+		if (!IS_ALIGNED(sg_dma_address(data->sg), sizeof(u32)) ||
+		    !IS_ALIGNED(sg_dma_len(data->sg), SDMMC_IDMA_BURST)) {
 			dev_err(mmc_dev(host->mmc),
 				"unaligned scatterlist: ofst:%x length:%d\n",
 				data->sg->offset, data->sg->length);
@@ -71,7 +45,7 @@ static int sdmmc_idma_validate_data(struct mmci_host *host,
 		}
 	}
 
-	if (!IS_ALIGNED(data->sg->offset, sizeof(u32))) {
+	if (!IS_ALIGNED(sg_dma_address(data->sg), sizeof(u32))) {
 		dev_err(mmc_dev(host->mmc),
 			"unaligned last scatterlist: ofst:%x length:%d\n",
 			data->sg->offset, data->sg->length);
@@ -118,20 +92,21 @@ static void sdmmc_idma_unprep_data(struct mmci_host *host,
 
 static int sdmmc_idma_setup(struct mmci_host *host)
 {
-	struct sdmmc_idma *idma;
-	struct device *dev = mmc_dev(host->mmc);
+	struct sdmmc_priv *idma;
 
-	idma = devm_kzalloc(dev, sizeof(*idma), GFP_KERNEL);
+	idma = devm_kzalloc(mmc_dev(host->mmc), sizeof(*idma), GFP_KERNEL);
 	if (!idma)
 		return -ENOMEM;
 
 	host->dma_priv = idma;
 
 	if (host->variant->dma_lli) {
-		idma->sg_cpu = dmam_alloc_coherent(dev, SDMMC_LLI_BUF_LEN,
+		idma->sg_cpu = dmam_alloc_coherent(mmc_dev(host->mmc),
+						   SDMMC_LLI_BUF_LEN,
 						   &idma->sg_dma, GFP_KERNEL);
 		if (!idma->sg_cpu) {
-			dev_err(dev, "Failed to alloc IDMA descriptor\n");
+			dev_err(mmc_dev(host->mmc),
+				"Failed to alloc IDMA descriptor\n");
 			return -ENOMEM;
 		}
 		host->mmc->max_segs = SDMMC_LLI_BUF_LEN /
@@ -142,13 +117,13 @@ static int sdmmc_idma_setup(struct mmci_host *host)
 		host->mmc->max_seg_size = host->mmc->max_req_size;
 	}
 
-	return dma_set_max_seg_size(dev, host->mmc->max_seg_size);
+	return 0;
 }
 
 static int sdmmc_idma_start(struct mmci_host *host, unsigned int *datactrl)
 
 {
-	struct sdmmc_idma *idma = host->dma_priv;
+	struct sdmmc_priv *idma = host->dma_priv;
 	struct sdmmc_lli_desc *desc = (struct sdmmc_lli_desc *)idma->sg_cpu;
 	struct mmc_data *data = host->data;
 	struct scatterlist *sg;
@@ -187,9 +162,6 @@ static int sdmmc_idma_start(struct mmci_host *host, unsigned int *datactrl)
 static void sdmmc_idma_finalize(struct mmci_host *host, struct mmc_data *data)
 {
 	writel_relaxed(0, host->base + MMCI_STM32_IDMACTRLR);
-
-	if (!data->host_cookie)
-		sdmmc_idma_unprep_data(host, data, 0);
 }
 
 static void mmci_sdmmc_set_clkreg(struct mmci_host *host, unsigned int desired)
@@ -254,25 +226,12 @@ static void mmci_sdmmc_set_clkreg(struct mmci_host *host, unsigned int desired)
 	mmci_write_clkreg(host, clk);
 }
 
-static void sdmmc_dlyb_input_ck(struct sdmmc_dlyb *dlyb)
-{
-	if (!dlyb || !dlyb->base)
-		return;
-
-	/* Output clock = Input clock */
-	writel_relaxed(0, dlyb->base + DLYB_CR);
-}
-
 static void mmci_sdmmc_set_pwrreg(struct mmci_host *host, unsigned int pwr)
 {
 	struct mmc_ios ios = host->mmc->ios;
-	struct sdmmc_dlyb *dlyb = host->variant_priv;
 
-	/* adds OF options */
 	pwr = host->pwr_reg_add;
 
-	sdmmc_dlyb_input_ck(dlyb);
-
 	if (ios.power_mode == MMC_POWER_OFF) {
 		/* Only a reset could power-off sdmmc */
 		reset_control_assert(host->rst);
@@ -295,10 +254,6 @@ static void mmci_sdmmc_set_pwrreg(struct mmci_host *host, unsigned int pwr)
 		writel(MCI_IRQENABLE | host->variant->start_err,
 		       host->base + MMCIMASK0);
 
-		/* preserves voltage switch bits */
-		pwr |= host->pwr_reg & (MCI_STM32_VSWITCHEN |
-					MCI_STM32_VSWITCH);
-
 		/*
 		 * After a power-cycle state, we must set the SDMMC in
 		 * Power-off. The SDMMC_D[7:0], SDMMC_CMD and SDMMC_CK are
@@ -327,183 +282,6 @@ static u32 sdmmc_get_dctrl_cfg(struct mmci_host *host)
 	return datactrl;
 }
 
-static bool sdmmc_busy_complete(struct mmci_host *host, u32 status, u32 err_msk)
-{
-	void __iomem *base = host->base;
-	u32 busy_d0, busy_d0end, mask, sdmmc_status;
-
-	mask = readl_relaxed(base + MMCIMASK0);
-	sdmmc_status = readl_relaxed(base + MMCISTATUS);
-	busy_d0end = sdmmc_status & MCI_STM32_BUSYD0END;
-	busy_d0 = sdmmc_status & MCI_STM32_BUSYD0;
-
-	/* complete if there is an error or busy_d0end */
-	if ((status & err_msk) || busy_d0end)
-		goto complete;
-
-	/*
-	 * On response the busy signaling is reflected in the BUSYD0 flag.
-	 * if busy_d0 is in-progress we must activate busyd0end interrupt
-	 * to wait this completion. Else this request has no busy step.
-	 */
-	if (busy_d0) {
-		if (!host->busy_status) {
-			writel_relaxed(mask | host->variant->busy_detect_mask,
-				       base + MMCIMASK0);
-			host->busy_status = status &
-				(MCI_CMDSENT | MCI_CMDRESPEND);
-		}
-		return false;
-	}
-
-complete:
-	if (host->busy_status) {
-		writel_relaxed(mask & ~host->variant->busy_detect_mask,
-			       base + MMCIMASK0);
-		host->busy_status = 0;
-	}
-
-	writel_relaxed(host->variant->busy_detect_mask, base + MMCICLEAR);
-
-	return true;
-}
-
-static void sdmmc_dlyb_set_cfgr(struct sdmmc_dlyb *dlyb,
-				int unit, int phase, bool sampler)
-{
-	u32 cfgr;
-
-	writel_relaxed(DLYB_CR_SEN | DLYB_CR_DEN, dlyb->base + DLYB_CR);
-
-	cfgr = FIELD_PREP(DLYB_CFGR_UNIT_MASK, unit) |
-	       FIELD_PREP(DLYB_CFGR_SEL_MASK, phase);
-	writel_relaxed(cfgr, dlyb->base + DLYB_CFGR);
-
-	if (!sampler)
-		writel_relaxed(DLYB_CR_DEN, dlyb->base + DLYB_CR);
-}
-
-static int sdmmc_dlyb_lng_tuning(struct mmci_host *host)
-{
-	struct sdmmc_dlyb *dlyb = host->variant_priv;
-	u32 cfgr;
-	int i, lng, ret;
-
-	for (i = 0; i <= DLYB_CFGR_UNIT_MAX; i++) {
-		sdmmc_dlyb_set_cfgr(dlyb, i, DLYB_CFGR_SEL_MAX, true);
-
-		ret = readl_relaxed_poll_timeout(dlyb->base + DLYB_CFGR, cfgr,
-						 (cfgr & DLYB_CFGR_LNGF),
-						 1, DLYB_LNG_TIMEOUT_US);
-		if (ret) {
-			dev_warn(mmc_dev(host->mmc),
-				 "delay line cfg timeout unit:%d cfgr:%d\n",
-				 i, cfgr);
-			continue;
-		}
-
-		lng = FIELD_GET(DLYB_CFGR_LNG_MASK, cfgr);
-		if (lng < BIT(DLYB_NB_DELAY) && lng > 0)
-			break;
-	}
-
-	if (i > DLYB_CFGR_UNIT_MAX)
-		return -EINVAL;
-
-	dlyb->unit = i;
-	dlyb->max = __fls(lng);
-
-	return 0;
-}
-
-static int sdmmc_dlyb_phase_tuning(struct mmci_host *host, u32 opcode)
-{
-	struct sdmmc_dlyb *dlyb = host->variant_priv;
-	int cur_len = 0, max_len = 0, end_of_len = 0;
-	int phase;
-
-	for (phase = 0; phase <= dlyb->max; phase++) {
-		sdmmc_dlyb_set_cfgr(dlyb, dlyb->unit, phase, false);
-
-		if (mmc_send_tuning(host->mmc, opcode, NULL)) {
-			cur_len = 0;
-		} else {
-			cur_len++;
-			if (cur_len > max_len) {
-				max_len = cur_len;
-				end_of_len = phase;
-			}
-		}
-	}
-
-	if (!max_len) {
-		dev_err(mmc_dev(host->mmc), "no tuning point found\n");
-		return -EINVAL;
-	}
-
-	writel_relaxed(0, dlyb->base + DLYB_CR);
-
-	phase = end_of_len - max_len / 2;
-	sdmmc_dlyb_set_cfgr(dlyb, dlyb->unit, phase, false);
-
-	dev_dbg(mmc_dev(host->mmc), "unit:%d max_dly:%d phase:%d\n",
-		dlyb->unit, dlyb->max, phase);
-
-	return 0;
-}
-
-static int sdmmc_execute_tuning(struct mmc_host *mmc, u32 opcode)
-{
-	struct mmci_host *host = mmc_priv(mmc);
-	struct sdmmc_dlyb *dlyb = host->variant_priv;
-
-	if (!dlyb || !dlyb->base)
-		return -EINVAL;
-
-	if (sdmmc_dlyb_lng_tuning(host))
-		return -EINVAL;
-
-	return sdmmc_dlyb_phase_tuning(host, opcode);
-}
-
-static void sdmmc_pre_sig_volt_vswitch(struct mmci_host *host)
-{
-	/* clear the voltage switch completion flag */
-	writel_relaxed(MCI_STM32_VSWENDC, host->base + MMCICLEAR);
-	/* enable Voltage switch procedure */
-	mmci_write_pwrreg(host, host->pwr_reg | MCI_STM32_VSWITCHEN);
-}
-
-static int sdmmc_post_sig_volt_switch(struct mmci_host *host,
-				      struct mmc_ios *ios)
-{
-	unsigned long flags;
-	u32 status;
-	int ret = 0;
-
-	spin_lock_irqsave(&host->lock, flags);
-	if (ios->signal_voltage == MMC_SIGNAL_VOLTAGE_180 &&
-	    host->pwr_reg & MCI_STM32_VSWITCHEN) {
-		mmci_write_pwrreg(host, host->pwr_reg | MCI_STM32_VSWITCH);
-		spin_unlock_irqrestore(&host->lock, flags);
-
-		/* wait voltage switch completion while 10ms */
-		ret = readl_relaxed_poll_timeout(host->base + MMCISTATUS,
-						 status,
-						 (status & MCI_STM32_VSWEND),
-						 10, SDMMC_VSWEND_TIMEOUT_US);
-
-		writel_relaxed(MCI_STM32_VSWENDC | MCI_STM32_CKSTOPC,
-			       host->base + MMCICLEAR);
-		spin_lock_irqsave(&host->lock, flags);
-		mmci_write_pwrreg(host, host->pwr_reg &
-				  ~(MCI_STM32_VSWITCHEN | MCI_STM32_VSWITCH));
-	}
-	spin_unlock_irqrestore(&host->lock, flags);
-
-	return ret;
-}
-
 static struct mmci_host_ops sdmmc_variant_ops = {
 	.validate_data = sdmmc_idma_validate_data,
 	.prep_data = sdmmc_idma_prep_data,
@@ -514,29 +292,9 @@ static struct mmci_host_ops sdmmc_variant_ops = {
 	.dma_finalize = sdmmc_idma_finalize,
 	.set_clkreg = mmci_sdmmc_set_clkreg,
 	.set_pwrreg = mmci_sdmmc_set_pwrreg,
-	.busy_complete = sdmmc_busy_complete,
-	.pre_sig_volt_switch = sdmmc_pre_sig_volt_vswitch,
-	.post_sig_volt_switch = sdmmc_post_sig_volt_switch,
 };
 
 void sdmmc_variant_init(struct mmci_host *host)
 {
-	struct device_node *np = host->mmc->parent->of_node;
-	void __iomem *base_dlyb;
-	struct sdmmc_dlyb *dlyb;
-
 	host->ops = &sdmmc_variant_ops;
-	host->pwr_reg = readl_relaxed(host->base + MMCIPOWER);
-
-	base_dlyb = devm_of_iomap(mmc_dev(host->mmc), np, 1, NULL);
-	if (IS_ERR(base_dlyb))
-		return;
-
-	dlyb = devm_kzalloc(mmc_dev(host->mmc), sizeof(*dlyb), GFP_KERNEL);
-	if (!dlyb)
-		return;
-
-	dlyb->base = base_dlyb;
-	host->variant_priv = dlyb;
-	host->mmc_ops->execute_tuning = sdmmc_execute_tuning;
 }
diff --git a/drivers/mmc/host/renesas_sdhi.h b/drivers/mmc/host/renesas_sdhi.h
index cb962c788..c0504aa90 100644
--- a/drivers/mmc/host/renesas_sdhi.h
+++ b/drivers/mmc/host/renesas_sdhi.h
@@ -14,8 +14,8 @@
 
 struct renesas_sdhi_scc {
 	unsigned long clk_rate;	/* clock rate for SDR104 */
-	u32 tap;		/* sampling clock position for SDR104/HS400 (8 TAP) */
-	u32 tap_hs400_4tap;	/* sampling clock position for HS400 (4 TAP) */
+	u32 tap;		/* sampling clock position for SDR104 */
+	u32 tap_hs400;		/* sampling clock position for HS400 */
 };
 
 struct renesas_sdhi_of_data {
@@ -33,15 +33,6 @@ struct renesas_sdhi_of_data {
 	unsigned short max_segs;
 };
 
-#define SDHI_CALIB_TABLE_MAX 32
-
-struct renesas_sdhi_quirks {
-	bool hs400_disabled;
-	bool hs400_4taps;
-	u32 hs400_bad_taps;
-	const u8 (*hs400_calib_table)[SDHI_CALIB_TABLE_MAX];
-};
-
 struct tmio_mmc_dma {
 	enum dma_slave_buswidth dma_buswidth;
 	bool (*filter)(struct dma_chan *chan, void *arg);
@@ -55,21 +46,11 @@ struct renesas_sdhi {
 	struct clk *clk_cd;
 	struct tmio_mmc_data mmc_data;
 	struct tmio_mmc_dma dma_priv;
-	const struct renesas_sdhi_quirks *quirks;
 	struct pinctrl *pinctrl;
 	struct pinctrl_state *pins_default, *pins_uhs;
 	void __iomem *scc_ctl;
 	u32 scc_tappos;
 	u32 scc_tappos_hs400;
-	const u8 *adjust_hs400_calib_table;
-	bool needs_adjust_hs400;
-
-	/* Tuning values: 1 for success, 0 for failure */
-	DECLARE_BITMAP(taps, BITS_PER_LONG);
-	/* Sampling data comparison: 1 for match, 0 for mismatch */
-	DECLARE_BITMAP(smpcmp, BITS_PER_LONG);
-	unsigned int tap_num;
-	unsigned int tap_set;
 };
 
 #define host_to_priv(host) \
diff --git a/drivers/mmc/host/renesas_sdhi_core.c b/drivers/mmc/host/renesas_sdhi_core.c
index 782879d46..234551a68 100644
--- a/drivers/mmc/host/renesas_sdhi_core.c
+++ b/drivers/mmc/host/renesas_sdhi_core.c
@@ -24,9 +24,7 @@
 #include <linux/module.h>
 #include <linux/of_device.h>
 #include <linux/platform_device.h>
-#include <linux/pm_domain.h>
 #include <linux/mmc/host.h>
-#include <linux/mmc/mmc.h>
 #include <linux/mmc/slot-gpio.h>
 #include <linux/mfd/tmio.h>
 #include <linux/sh_dma.h>
@@ -48,7 +46,10 @@
 #define SDHI_VER_GEN3_SD	0xcc10
 #define SDHI_VER_GEN3_SDMMC	0xcd10
 
-#define SDHI_GEN3_MMC0_ADDR	0xee140000
+struct renesas_sdhi_quirks {
+	bool hs400_disabled;
+	bool hs400_4taps;
+};
 
 static void renesas_sdhi_sdbuf_width(struct tmio_mmc_host *host, int width)
 {
@@ -86,12 +87,17 @@ static int renesas_sdhi_clk_enable(struct tmio_mmc_host *host)
 {
 	struct mmc_host *mmc = host->mmc;
 	struct renesas_sdhi *priv = host_to_priv(host);
-	int ret;
+	int ret = clk_prepare_enable(priv->clk);
 
-	ret = clk_prepare_enable(priv->clk_cd);
 	if (ret < 0)
 		return ret;
 
+	ret = clk_prepare_enable(priv->clk_cd);
+	if (ret < 0) {
+		clk_disable_unprepare(priv->clk);
+		return ret;
+	}
+
 	/*
 	 * The clock driver may not know what maximum frequency
 	 * actually works, so it should be set with the max-frequency
@@ -120,12 +126,8 @@ static unsigned int renesas_sdhi_clk_update(struct tmio_mmc_host *host,
 	unsigned int freq, diff, best_freq = 0, diff_min = ~0;
 	int i;
 
-	/*
-	 * We simply return the current rate if a) we are not on a R-Car Gen2+
-	 * SoC (may work for others, but untested) or b) if the SCC needs its
-	 * clock during tuning, so we don't change the external clock setup.
-	 */
-	if (!(host->pdata->flags & TMIO_MMC_MIN_RCAR2) || mmc_doing_tune(host->mmc))
+	/* tested only on R-Car Gen2+ currently; may work for others */
+	if (!(host->pdata->flags & TMIO_MMC_MIN_RCAR2))
 		return clk_get_rate(priv->clk);
 
 	/*
@@ -200,6 +202,7 @@ static void renesas_sdhi_clk_disable(struct tmio_mmc_host *host)
 {
 	struct renesas_sdhi *priv = host_to_priv(host);
 
+	clk_disable_unprepare(priv->clk);
 	clk_disable_unprepare(priv->clk_cd);
 }
 
@@ -239,7 +242,7 @@ static int renesas_sdhi_start_signal_voltage_switch(struct mmc_host *mmc,
 			MMC_SIGNAL_VOLTAGE_330 ? 0 : -EINVAL;
 
 	ret = mmc_regulator_set_vqmmc(host->mmc, ios);
-	if (ret < 0)
+	if (ret)
 		return ret;
 
 	return pinctrl_select_state(priv->pinctrl, pin_state);
@@ -252,67 +255,23 @@ static int renesas_sdhi_start_signal_voltage_switch(struct mmc_host *mmc,
 #define SH_MOBILE_SDHI_SCC_CKSEL	0x006
 #define SH_MOBILE_SDHI_SCC_RVSCNTL	0x008
 #define SH_MOBILE_SDHI_SCC_RVSREQ	0x00A
-#define SH_MOBILE_SDHI_SCC_SMPCMP       0x00C
 #define SH_MOBILE_SDHI_SCC_TMPPORT2	0x00E
-#define SH_MOBILE_SDHI_SCC_TMPPORT3	0x014
-#define SH_MOBILE_SDHI_SCC_TMPPORT4	0x016
-#define SH_MOBILE_SDHI_SCC_TMPPORT5	0x018
-#define SH_MOBILE_SDHI_SCC_TMPPORT6	0x01A
-#define SH_MOBILE_SDHI_SCC_TMPPORT7	0x01C
 
+/* Definitions for values the SH_MOBILE_SDHI_SCC_DTCNTL register */
 #define SH_MOBILE_SDHI_SCC_DTCNTL_TAPEN		BIT(0)
 #define SH_MOBILE_SDHI_SCC_DTCNTL_TAPNUM_SHIFT	16
 #define SH_MOBILE_SDHI_SCC_DTCNTL_TAPNUM_MASK	0xff
 
+/* Definitions for values the SH_MOBILE_SDHI_SCC_CKSEL register */
 #define SH_MOBILE_SDHI_SCC_CKSEL_DTSEL		BIT(0)
-
+/* Definitions for values the SH_MOBILE_SDHI_SCC_RVSCNTL register */
 #define SH_MOBILE_SDHI_SCC_RVSCNTL_RVSEN	BIT(0)
-
-#define SH_MOBILE_SDHI_SCC_RVSREQ_REQTAPDOWN	BIT(0)
-#define SH_MOBILE_SDHI_SCC_RVSREQ_REQTAPUP	BIT(1)
+/* Definitions for values the SH_MOBILE_SDHI_SCC_RVSREQ register */
 #define SH_MOBILE_SDHI_SCC_RVSREQ_RVSERR	BIT(2)
-
-#define SH_MOBILE_SDHI_SCC_SMPCMP_CMD_REQDOWN	BIT(8)
-#define SH_MOBILE_SDHI_SCC_SMPCMP_CMD_REQUP	BIT(24)
-#define SH_MOBILE_SDHI_SCC_SMPCMP_CMD_ERR	(BIT(8) | BIT(24))
-
+/* Definitions for values the SH_MOBILE_SDHI_SCC_TMPPORT2 register */
 #define SH_MOBILE_SDHI_SCC_TMPPORT2_HS400OSEL	BIT(4)
 #define SH_MOBILE_SDHI_SCC_TMPPORT2_HS400EN	BIT(31)
 
-/* Definitions for values the SH_MOBILE_SDHI_SCC_TMPPORT4 register */
-#define SH_MOBILE_SDHI_SCC_TMPPORT4_DLL_ACC_START	BIT(0)
-
-/* Definitions for values the SH_MOBILE_SDHI_SCC_TMPPORT5 register */
-#define SH_MOBILE_SDHI_SCC_TMPPORT5_DLL_RW_SEL_R	BIT(8)
-#define SH_MOBILE_SDHI_SCC_TMPPORT5_DLL_RW_SEL_W	(0 << 8)
-#define SH_MOBILE_SDHI_SCC_TMPPORT5_DLL_ADR_MASK	0x3F
-
-/* Definitions for values the SH_MOBILE_SDHI_SCC register */
-#define SH_MOBILE_SDHI_SCC_TMPPORT_DISABLE_WP_CODE	0xa5000000
-#define SH_MOBILE_SDHI_SCC_TMPPORT_CALIB_CODE_MASK	0x1f
-#define SH_MOBILE_SDHI_SCC_TMPPORT_MANUAL_MODE		BIT(7)
-
-static const u8 r8a7796_es13_calib_table[2][SDHI_CALIB_TABLE_MAX] = {
-	{ 3,  3,  3,  3,  3,  3,  3,  4,  4,  5,  6,  7,  8,  9, 10, 15,
-	 16, 16, 16, 16, 16, 16, 17, 18, 18, 19, 20, 21, 22, 23, 24, 25 },
-	{ 5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  6,  7,  8, 11,
-	 12, 17, 18, 18, 18, 18, 18, 18, 18, 19, 20, 21, 22, 23, 25, 25 }
-};
-
-static const u8 r8a77965_calib_table[2][SDHI_CALIB_TABLE_MAX] = {
-	{ 1,  2,  6,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 15, 15, 16,
-	 17, 18, 19, 20, 21, 22, 23, 24, 25, 25, 26, 27, 28, 29, 30, 31 },
-	{ 2,  3,  4,  4,  5,  6,  7,  9, 10, 11, 12, 13, 14, 15, 16, 17,
-	 17, 17, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 31, 31, 31 }
-};
-
-static const u8 r8a77990_calib_table[2][SDHI_CALIB_TABLE_MAX] = {
-	{ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
-	  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0 },
-	{ 0,  0,  0,  1,  2,  3,  3,  4,  4,  4,  5,  5,  6,  8,  9, 10,
-	 11, 12, 13, 15, 16, 17, 17, 18, 18, 19, 20, 22, 24, 25, 26, 26 }
-};
-
 static inline u32 sd_scc_read32(struct tmio_mmc_host *host,
 				struct renesas_sdhi *priv, int addr)
 {
@@ -362,12 +321,18 @@ static unsigned int renesas_sdhi_init_tuning(struct tmio_mmc_host *host)
 		SH_MOBILE_SDHI_SCC_DTCNTL_TAPNUM_MASK;
 }
 
-static void renesas_sdhi_hs400_complete(struct mmc_host *mmc)
+static void renesas_sdhi_prepare_tuning(struct tmio_mmc_host *host,
+					unsigned long tap)
+{
+	struct renesas_sdhi *priv = host_to_priv(host);
+
+	/* Set sampling clock position */
+	sd_scc_write32(host, priv, SH_MOBILE_SDHI_SCC_TAPSET, tap);
+}
+
+static void renesas_sdhi_hs400_complete(struct tmio_mmc_host *host)
 {
-	struct tmio_mmc_host *host = mmc_priv(mmc);
 	struct renesas_sdhi *priv = host_to_priv(host);
-	u32 bad_taps = priv->quirks ? priv->quirks->hs400_bad_taps : 0;
-	bool use_4tap = priv->quirks && priv->quirks->hs400_4taps;
 
 	sd_ctrl_write16(host, CTL_SD_CARD_CLK_CTL, ~CLK_CTL_SCLKEN &
 		sd_ctrl_read16(host, CTL_SD_CARD_CLK_CTL));
@@ -379,12 +344,6 @@ static void renesas_sdhi_hs400_complete(struct mmc_host *mmc)
 	sd_scc_write32(host, priv, SH_MOBILE_SDHI_SCC_DT2FF,
 		       priv->scc_tappos_hs400);
 
-	/* Gen3 can't do automatic tap correction with HS400, so disable it */
-	if (sd_ctrl_read16(host, CTL_VERSION) == SDHI_VER_GEN3_SDMMC)
-		sd_scc_write32(host, priv, SH_MOBILE_SDHI_SCC_RVSCNTL,
-			       ~SH_MOBILE_SDHI_SCC_RVSCNTL_RVSEN &
-			       sd_scc_read32(host, priv, SH_MOBILE_SDHI_SCC_RVSCNTL));
-
 	sd_scc_write32(host, priv, SH_MOBILE_SDHI_SCC_TMPPORT2,
 		       (SH_MOBILE_SDHI_SCC_TMPPORT2_HS400EN |
 			SH_MOBILE_SDHI_SCC_TMPPORT2_HS400OSEL) |
@@ -395,23 +354,10 @@ static void renesas_sdhi_hs400_complete(struct mmc_host *mmc)
 		       SH_MOBILE_SDHI_SCC_DTCNTL_TAPEN |
 		       0x4 << SH_MOBILE_SDHI_SCC_DTCNTL_TAPNUM_SHIFT);
 
-	/* Avoid bad TAP */
-	if (bad_taps & BIT(priv->tap_set)) {
-		u32 new_tap = (priv->tap_set + 1) % priv->tap_num;
-
-		if (bad_taps & BIT(new_tap))
-			new_tap = (priv->tap_set - 1) % priv->tap_num;
-
-		if (bad_taps & BIT(new_tap)) {
-			new_tap = priv->tap_set;
-			dev_dbg(&host->pdev->dev, "Can't handle three bad tap in a row\n");
-		}
-
-		priv->tap_set = new_tap;
-	}
 
-	sd_scc_write32(host, priv, SH_MOBILE_SDHI_SCC_TAPSET,
-		       priv->tap_set / (use_4tap ? 2 : 1));
+	if (host->pdata->flags & TMIO_MMC_HAVE_4TAP_HS400)
+		sd_scc_write32(host, priv, SH_MOBILE_SDHI_SCC_TAPSET,
+			       host->tap_set / 2);
 
 	sd_scc_write32(host, priv, SH_MOBILE_SDHI_SCC_CKSEL,
 		       SH_MOBILE_SDHI_SCC_CKSEL_DTSEL |
@@ -419,9 +365,6 @@ static void renesas_sdhi_hs400_complete(struct mmc_host *mmc)
 
 	sd_ctrl_write16(host, CTL_SD_CARD_CLK_CTL, CLK_CTL_SCLKEN |
 			sd_ctrl_read16(host, CTL_SD_CARD_CLK_CTL));
-
-	if (priv->adjust_hs400_calib_table)
-		priv->needs_adjust_hs400 = true;
 }
 
 static void renesas_sdhi_reset_scc(struct tmio_mmc_host *host,
@@ -436,9 +379,8 @@ static void renesas_sdhi_reset_scc(struct tmio_mmc_host *host,
 				     SH_MOBILE_SDHI_SCC_CKSEL));
 }
 
-static void renesas_sdhi_disable_scc(struct mmc_host *mmc)
+static void renesas_sdhi_disable_scc(struct tmio_mmc_host *host)
 {
-	struct tmio_mmc_host *host = mmc_priv(mmc);
 	struct renesas_sdhi *priv = host_to_priv(host);
 
 	renesas_sdhi_reset_scc(host, priv);
@@ -452,74 +394,6 @@ static void renesas_sdhi_disable_scc(struct mmc_host *mmc)
 			sd_ctrl_read16(host, CTL_SD_CARD_CLK_CTL));
 }
 
-static u32 sd_scc_tmpport_read32(struct tmio_mmc_host *host,
-				 struct renesas_sdhi *priv, u32 addr)
-{
-	/* read mode */
-	sd_scc_write32(host, priv, SH_MOBILE_SDHI_SCC_TMPPORT5,
-		       SH_MOBILE_SDHI_SCC_TMPPORT5_DLL_RW_SEL_R |
-		       (SH_MOBILE_SDHI_SCC_TMPPORT5_DLL_ADR_MASK & addr));
-
-	/* access start and stop */
-	sd_scc_write32(host, priv, SH_MOBILE_SDHI_SCC_TMPPORT4,
-		       SH_MOBILE_SDHI_SCC_TMPPORT4_DLL_ACC_START);
-	sd_scc_write32(host, priv, SH_MOBILE_SDHI_SCC_TMPPORT4, 0);
-
-	return sd_scc_read32(host, priv, SH_MOBILE_SDHI_SCC_TMPPORT7);
-}
-
-static void sd_scc_tmpport_write32(struct tmio_mmc_host *host,
-				   struct renesas_sdhi *priv, u32 addr, u32 val)
-{
-	/* write mode */
-	sd_scc_write32(host, priv, SH_MOBILE_SDHI_SCC_TMPPORT5,
-		       SH_MOBILE_SDHI_SCC_TMPPORT5_DLL_RW_SEL_W |
-		       (SH_MOBILE_SDHI_SCC_TMPPORT5_DLL_ADR_MASK & addr));
-
-	sd_scc_write32(host, priv, SH_MOBILE_SDHI_SCC_TMPPORT6, val);
-
-	/* access start and stop */
-	sd_scc_write32(host, priv, SH_MOBILE_SDHI_SCC_TMPPORT4,
-		       SH_MOBILE_SDHI_SCC_TMPPORT4_DLL_ACC_START);
-	sd_scc_write32(host, priv, SH_MOBILE_SDHI_SCC_TMPPORT4, 0);
-}
-
-static void renesas_sdhi_adjust_hs400_mode_enable(struct tmio_mmc_host *host)
-{
-	struct renesas_sdhi *priv = host_to_priv(host);
-	u32 calib_code;
-
-	/* disable write protect */
-	sd_scc_tmpport_write32(host, priv, 0x00,
-			       SH_MOBILE_SDHI_SCC_TMPPORT_DISABLE_WP_CODE);
-	/* read calibration code and adjust */
-	calib_code = sd_scc_tmpport_read32(host, priv, 0x26);
-	calib_code &= SH_MOBILE_SDHI_SCC_TMPPORT_CALIB_CODE_MASK;
-
-	sd_scc_tmpport_write32(host, priv, 0x22,
-			       SH_MOBILE_SDHI_SCC_TMPPORT_MANUAL_MODE |
-			       priv->adjust_hs400_calib_table[calib_code]);
-
-	/* set offset value to TMPPORT3, hardcoded to OFFSET0 (= 0x3) for now */
-	sd_scc_write32(host, priv, SH_MOBILE_SDHI_SCC_TMPPORT3, 0x3);
-
-	/* adjustment done, clear flag */
-	priv->needs_adjust_hs400 = false;
-}
-
-static void renesas_sdhi_adjust_hs400_mode_disable(struct tmio_mmc_host *host)
-{
-	struct renesas_sdhi *priv = host_to_priv(host);
-
-	/* disable write protect */
-	sd_scc_tmpport_write32(host, priv, 0x00,
-			       SH_MOBILE_SDHI_SCC_TMPPORT_DISABLE_WP_CODE);
-	/* disable manual calibration */
-	sd_scc_tmpport_write32(host, priv, 0x22, 0);
-	/* clear offset value of TMPPORT3 */
-	sd_scc_write32(host, priv, SH_MOBILE_SDHI_SCC_TMPPORT3, 0);
-}
-
 static void renesas_sdhi_reset_hs400_mode(struct tmio_mmc_host *host,
 					  struct renesas_sdhi *priv)
 {
@@ -537,50 +411,27 @@ static void renesas_sdhi_reset_hs400_mode(struct tmio_mmc_host *host,
 			 SH_MOBILE_SDHI_SCC_TMPPORT2_HS400OSEL) &
 			sd_scc_read32(host, priv, SH_MOBILE_SDHI_SCC_TMPPORT2));
 
-	if (priv->adjust_hs400_calib_table)
-		renesas_sdhi_adjust_hs400_mode_disable(host);
-
 	sd_ctrl_write16(host, CTL_SD_CARD_CLK_CTL, CLK_CTL_SCLKEN |
 			sd_ctrl_read16(host, CTL_SD_CARD_CLK_CTL));
 }
 
-static int renesas_sdhi_prepare_hs400_tuning(struct mmc_host *mmc, struct mmc_ios *ios)
+static void renesas_sdhi_prepare_hs400_tuning(struct tmio_mmc_host *host)
 {
-	struct tmio_mmc_host *host = mmc_priv(mmc);
-
 	renesas_sdhi_reset_hs400_mode(host, host_to_priv(host));
-	return 0;
 }
 
-static void renesas_sdhi_reset(struct tmio_mmc_host *host)
-{
-	struct renesas_sdhi *priv = host_to_priv(host);
-
-	renesas_sdhi_reset_scc(host, priv);
-	renesas_sdhi_reset_hs400_mode(host, priv);
-	priv->needs_adjust_hs400 = false;
-
-	sd_ctrl_write16(host, CTL_SD_CARD_CLK_CTL, CLK_CTL_SCLKEN |
-			sd_ctrl_read16(host, CTL_SD_CARD_CLK_CTL));
-
-	sd_scc_write32(host, priv, SH_MOBILE_SDHI_SCC_RVSCNTL,
-		       ~SH_MOBILE_SDHI_SCC_RVSCNTL_RVSEN &
-		       sd_scc_read32(host, priv, SH_MOBILE_SDHI_SCC_RVSCNTL));
-
-	if (host->pdata->flags & TMIO_MMC_MIN_RCAR2)
-		sd_ctrl_write32_as_16_and_16(host, CTL_IRQ_MASK,
-					     TMIO_MASK_INIT_RCAR2);
-}
-
-#define SH_MOBILE_SDHI_MIN_TAP_ROW 3
+#define SH_MOBILE_SDHI_MAX_TAP 3
 
 static int renesas_sdhi_select_tuning(struct tmio_mmc_host *host)
 {
 	struct renesas_sdhi *priv = host_to_priv(host);
-	unsigned int tap_start = 0, tap_end = 0, tap_cnt = 0, rs, re, i;
-	unsigned int taps_size = priv->tap_num * 2, min_tap_row;
-	unsigned long *bitmap;
+	unsigned long tap_cnt;  /* counter of tuning success */
+	unsigned long tap_start;/* start position of tuning success */
+	unsigned long tap_end;  /* end position of tuning success */
+	unsigned long ntap;     /* temporary counter of tuning success */
+	unsigned long i;
 
+	/* Clear SCC_RVSREQ */
 	sd_scc_write32(host, priv, SH_MOBILE_SDHI_SCC_RVSREQ, 0);
 
 	/*
@@ -588,48 +439,48 @@ static int renesas_sdhi_select_tuning(struct tmio_mmc_host *host)
 	 * result requiring the tap to be good in both runs before
 	 * considering it for tuning selection.
 	 */
-	for (i = 0; i < taps_size; i++) {
-		int offset = priv->tap_num * (i < priv->tap_num ? 1 : -1);
+	for (i = 0; i < host->tap_num * 2; i++) {
+		int offset = host->tap_num * (i < host->tap_num ? 1 : -1);
 
-		if (!test_bit(i, priv->taps))
-			clear_bit(i + offset, priv->taps);
-
-		if (!test_bit(i, priv->smpcmp))
-			clear_bit(i + offset, priv->smpcmp);
+		if (!test_bit(i, host->taps))
+			clear_bit(i + offset, host->taps);
 	}
 
 	/*
-	 * If all TAP are OK, the sampling clock position is selected by
-	 * identifying the change point of data.
+	 * Find the longest consecutive run of successful probes.  If that
+	 * is more than SH_MOBILE_SDHI_MAX_TAP probes long then use the
+	 * center index as the tap.
 	 */
-	if (bitmap_full(priv->taps, taps_size)) {
-		bitmap = priv->smpcmp;
-		min_tap_row = 1;
-	} else {
-		bitmap = priv->taps;
-		min_tap_row = SH_MOBILE_SDHI_MIN_TAP_ROW;
+	tap_cnt = 0;
+	ntap = 0;
+	tap_start = 0;
+	tap_end = 0;
+	for (i = 0; i < host->tap_num * 2; i++) {
+		if (test_bit(i, host->taps)) {
+			ntap++;
+		} else {
+			if (ntap > tap_cnt) {
+				tap_start = i - ntap;
+				tap_end = i - 1;
+				tap_cnt = ntap;
+			}
+			ntap = 0;
+		}
 	}
 
-	/*
-	 * Find the longest consecutive run of successful probes. If that
-	 * is at least SH_MOBILE_SDHI_MIN_TAP_ROW probes long then use the
-	 * center index as the tap, otherwise bail out.
-	 */
-	bitmap_for_each_set_region(bitmap, rs, re, 0, taps_size) {
-		if (re - rs > tap_cnt) {
-			tap_end = re;
-			tap_start = rs;
-			tap_cnt = tap_end - tap_start;
-		}
+	if (ntap > tap_cnt) {
+		tap_start = i - ntap;
+		tap_end = i - 1;
+		tap_cnt = ntap;
 	}
 
-	if (tap_cnt >= min_tap_row)
-		priv->tap_set = (tap_start + tap_end) / 2 % priv->tap_num;
+	if (tap_cnt >= SH_MOBILE_SDHI_MAX_TAP)
+		host->tap_set = (tap_start + tap_end) / 2 % host->tap_num;
 	else
 		return -EIO;
 
 	/* Set SCC */
-	sd_scc_write32(host, priv, SH_MOBILE_SDHI_SCC_TAPSET, priv->tap_set);
+	sd_scc_write32(host, priv, SH_MOBILE_SDHI_SCC_TAPSET, host->tap_set);
 
 	/* Enable auto re-tuning */
 	sd_scc_write32(host, priv, SH_MOBILE_SDHI_SCC_RVSCNTL,
@@ -639,114 +490,29 @@ static int renesas_sdhi_select_tuning(struct tmio_mmc_host *host)
 	return 0;
 }
 
-static int renesas_sdhi_execute_tuning(struct mmc_host *mmc, u32 opcode)
-{
-	struct tmio_mmc_host *host = mmc_priv(mmc);
-	struct renesas_sdhi *priv = host_to_priv(host);
-	int i, ret;
-
-	priv->tap_num = renesas_sdhi_init_tuning(host);
-	if (!priv->tap_num)
-		return 0; /* Tuning is not supported */
-
-	if (priv->tap_num * 2 >= sizeof(priv->taps) * BITS_PER_BYTE) {
-		dev_err(&host->pdev->dev,
-			"Too many taps, please update 'taps' in tmio_mmc_host!\n");
-		return -EINVAL;
-	}
-
-	bitmap_zero(priv->taps, priv->tap_num * 2);
-	bitmap_zero(priv->smpcmp, priv->tap_num * 2);
-
-	/* Issue CMD19 twice for each tap */
-	for (i = 0; i < 2 * priv->tap_num; i++) {
-		int cmd_error = 0;
-
-		/* Set sampling clock position */
-		sd_scc_write32(host, priv, SH_MOBILE_SDHI_SCC_TAPSET, i % priv->tap_num);
-
-		if (mmc_send_tuning(mmc, opcode, &cmd_error) == 0)
-			set_bit(i, priv->taps);
-
-		if (sd_scc_read32(host, priv, SH_MOBILE_SDHI_SCC_SMPCMP) == 0)
-			set_bit(i, priv->smpcmp);
-
-		if (cmd_error)
-			mmc_abort_tuning(mmc, opcode);
-	}
-
-	ret = renesas_sdhi_select_tuning(host);
-	if (ret < 0)
-		renesas_sdhi_reset(host);
-	return ret;
-}
-
-static bool renesas_sdhi_manual_correction(struct tmio_mmc_host *host, bool use_4tap)
+static bool renesas_sdhi_check_scc_error(struct tmio_mmc_host *host)
 {
 	struct renesas_sdhi *priv = host_to_priv(host);
-	unsigned int new_tap = priv->tap_set, error_tap = priv->tap_set;
-	u32 val;
+	bool use_4tap = host->pdata->flags & TMIO_MMC_HAVE_4TAP_HS400;
 
-	val = sd_scc_read32(host, priv, SH_MOBILE_SDHI_SCC_RVSREQ);
-	if (!val)
+	/*
+	 * Skip checking SCC errors when running on 4 taps in HS400 mode as
+	 * any retuning would still result in the same 4 taps being used.
+	 */
+	if (!(host->mmc->ios.timing == MMC_TIMING_UHS_SDR104) &&
+	    !(host->mmc->ios.timing == MMC_TIMING_MMC_HS200) &&
+	    !(host->mmc->ios.timing == MMC_TIMING_MMC_HS400 && !use_4tap))
 		return false;
 
-	sd_scc_write32(host, priv, SH_MOBILE_SDHI_SCC_RVSREQ, 0);
-
-	/* Change TAP position according to correction status */
-	if (sd_ctrl_read16(host, CTL_VERSION) == SDHI_VER_GEN3_SDMMC &&
-	    host->mmc->ios.timing == MMC_TIMING_MMC_HS400) {
-		u32 bad_taps = priv->quirks ? priv->quirks->hs400_bad_taps : 0;
-		/*
-		 * With HS400, the DAT signal is based on DS, not CLK.
-		 * Therefore, use only CMD status.
-		 */
-		u32 smpcmp = sd_scc_read32(host, priv, SH_MOBILE_SDHI_SCC_SMPCMP) &
-					   SH_MOBILE_SDHI_SCC_SMPCMP_CMD_ERR;
-		if (!smpcmp) {
-			return false;	/* no error in CMD signal */
-		} else if (smpcmp == SH_MOBILE_SDHI_SCC_SMPCMP_CMD_REQUP) {
-			new_tap++;
-			error_tap--;
-		} else if (smpcmp == SH_MOBILE_SDHI_SCC_SMPCMP_CMD_REQDOWN) {
-			new_tap--;
-			error_tap++;
-		} else {
-			return true;	/* need retune */
-		}
-
-		/*
-		 * When new_tap is a bad tap, we cannot change. Then, we compare
-		 * with the HS200 tuning result. When smpcmp[error_tap] is OK,
-		 * we can at least retune.
-		 */
-		if (bad_taps & BIT(new_tap % priv->tap_num))
-			return test_bit(error_tap % priv->tap_num, priv->smpcmp);
-	} else {
-		if (val & SH_MOBILE_SDHI_SCC_RVSREQ_RVSERR)
-			return true;    /* need retune */
-		else if (val & SH_MOBILE_SDHI_SCC_RVSREQ_REQTAPUP)
-			new_tap++;
-		else if (val & SH_MOBILE_SDHI_SCC_RVSREQ_REQTAPDOWN)
-			new_tap--;
-		else
-			return false;
-	}
-
-	priv->tap_set = (new_tap % priv->tap_num);
-	sd_scc_write32(host, priv, SH_MOBILE_SDHI_SCC_TAPSET,
-		       priv->tap_set / (use_4tap ? 2 : 1));
-
-	return false;
-}
-
-static bool renesas_sdhi_auto_correction(struct tmio_mmc_host *host)
-{
-	struct renesas_sdhi *priv = host_to_priv(host);
+	if (mmc_doing_retune(host->mmc))
+		return false;
 
 	/* Check SCC error */
-	if (sd_scc_read32(host, priv, SH_MOBILE_SDHI_SCC_RVSREQ) &
+	if (sd_scc_read32(host, priv, SH_MOBILE_SDHI_SCC_RVSCNTL) &
+	    SH_MOBILE_SDHI_SCC_RVSCNTL_RVSEN &&
+	    sd_scc_read32(host, priv, SH_MOBILE_SDHI_SCC_RVSREQ) &
 	    SH_MOBILE_SDHI_SCC_RVSREQ_RVSERR) {
+		/* Clear SCC error */
 		sd_scc_write32(host, priv, SH_MOBILE_SDHI_SCC_RVSREQ, 0);
 		return true;
 	}
@@ -754,28 +520,29 @@ static bool renesas_sdhi_auto_correction(struct tmio_mmc_host *host)
 	return false;
 }
 
-static bool renesas_sdhi_check_scc_error(struct tmio_mmc_host *host)
+static void renesas_sdhi_hw_reset(struct tmio_mmc_host *host)
 {
-	struct renesas_sdhi *priv = host_to_priv(host);
-	bool use_4tap = priv->quirks && priv->quirks->hs400_4taps;
+	struct renesas_sdhi *priv;
 
-	/*
-	 * Skip checking SCC errors when running on 4 taps in HS400 mode as
-	 * any retuning would still result in the same 4 taps being used.
-	 */
-	if (!(host->mmc->ios.timing == MMC_TIMING_UHS_SDR104) &&
-	    !(host->mmc->ios.timing == MMC_TIMING_MMC_HS200) &&
-	    !(host->mmc->ios.timing == MMC_TIMING_MMC_HS400 && !use_4tap))
-		return false;
+	priv = host_to_priv(host);
 
-	if (mmc_doing_tune(host->mmc))
-		return false;
+	renesas_sdhi_reset_scc(host, priv);
+	renesas_sdhi_reset_hs400_mode(host, priv);
 
-	if (sd_scc_read32(host, priv, SH_MOBILE_SDHI_SCC_RVSCNTL) &
-	    SH_MOBILE_SDHI_SCC_RVSCNTL_RVSEN)
-		return renesas_sdhi_auto_correction(host);
+	sd_ctrl_write16(host, CTL_SD_CARD_CLK_CTL, CLK_CTL_SCLKEN |
+			sd_ctrl_read16(host, CTL_SD_CARD_CLK_CTL));
+
+	sd_scc_write32(host, priv, SH_MOBILE_SDHI_SCC_RVSCNTL,
+		       ~SH_MOBILE_SDHI_SCC_RVSCNTL_RVSEN &
+		       sd_scc_read32(host, priv, SH_MOBILE_SDHI_SCC_RVSCNTL));
+
+	sd_scc_write32(host, priv, SH_MOBILE_SDHI_SCC_RVSCNTL,
+		       ~SH_MOBILE_SDHI_SCC_RVSCNTL_RVSEN &
+		       sd_scc_read32(host, priv, SH_MOBILE_SDHI_SCC_RVSCNTL));
 
-	return renesas_sdhi_manual_correction(host, use_4tap);
+	if (host->pdata->flags & TMIO_MMC_MIN_RCAR2)
+		sd_ctrl_write32_as_16_and_16(host, CTL_IRQ_MASK,
+					     TMIO_MASK_INIT_RCAR2);
 }
 
 static int renesas_sdhi_wait_idle(struct tmio_mmc_host *host, u32 bit)
@@ -811,7 +578,7 @@ static int renesas_sdhi_write16_hook(struct tmio_mmc_host *host, int addr)
 	case HOST_MODE:
 		if (host->pdata->flags & TMIO_MMC_HAVE_CBSY)
 			bit = TMIO_STAT_CMD_BUSY;
-		fallthrough;
+		/* fallthrough */
 	case CTL_SD_CARD_CLK_CTL:
 		return renesas_sdhi_wait_idle(host, bit);
 	}
@@ -837,13 +604,6 @@ static int renesas_sdhi_multi_io_quirk(struct mmc_card *card,
 	return blk_size;
 }
 
-static void renesas_sdhi_fixup_request(struct tmio_mmc_host *host, struct mmc_request *mrq)
-{
-	struct renesas_sdhi *priv = host_to_priv(host);
-
-	if (priv->needs_adjust_hs400 && mrq->cmd->opcode == MMC_SEND_STATUS)
-		renesas_sdhi_adjust_hs400_mode_enable(host);
-}
 static void renesas_sdhi_enable_dma(struct tmio_mmc_host *host, bool enable)
 {
 	/* Iff regs are 8 byte apart, sdbuf is 64 bit. Otherwise always 32. */
@@ -860,52 +620,18 @@ static const struct renesas_sdhi_quirks sdhi_quirks_4tap_nohs400 = {
 
 static const struct renesas_sdhi_quirks sdhi_quirks_4tap = {
 	.hs400_4taps = true,
-	.hs400_bad_taps = BIT(2) | BIT(3) | BIT(6) | BIT(7),
 };
 
 static const struct renesas_sdhi_quirks sdhi_quirks_nohs400 = {
 	.hs400_disabled = true,
 };
 
-static const struct renesas_sdhi_quirks sdhi_quirks_bad_taps1357 = {
-	.hs400_bad_taps = BIT(1) | BIT(3) | BIT(5) | BIT(7),
-};
-
-static const struct renesas_sdhi_quirks sdhi_quirks_bad_taps2367 = {
-	.hs400_bad_taps = BIT(2) | BIT(3) | BIT(6) | BIT(7),
-};
-
-static const struct renesas_sdhi_quirks sdhi_quirks_r8a7796_es13 = {
-	.hs400_4taps = true,
-	.hs400_bad_taps = BIT(2) | BIT(3) | BIT(6) | BIT(7),
-	.hs400_calib_table = r8a7796_es13_calib_table,
-};
-
-static const struct renesas_sdhi_quirks sdhi_quirks_r8a77965 = {
-	.hs400_bad_taps = BIT(2) | BIT(3) | BIT(6) | BIT(7),
-	.hs400_calib_table = r8a77965_calib_table,
-};
-
-static const struct renesas_sdhi_quirks sdhi_quirks_r8a77990 = {
-	.hs400_calib_table = r8a77990_calib_table,
-};
-
-/*
- * Note for r8a7796 / r8a774a1: we can't distinguish ES1.1 and 1.2 as of now.
- * So, we want to treat them equally and only have a match for ES1.2 to enforce
- * this if there ever will be a way to distinguish ES1.2.
- */
 static const struct soc_device_attribute sdhi_quirks_match[]  = {
-	{ .soc_id = "r8a774a1", .revision = "ES1.[012]", .data = &sdhi_quirks_4tap_nohs400 },
 	{ .soc_id = "r8a7795", .revision = "ES1.*", .data = &sdhi_quirks_4tap_nohs400 },
 	{ .soc_id = "r8a7795", .revision = "ES2.0", .data = &sdhi_quirks_4tap },
-	{ .soc_id = "r8a7795", .revision = "ES3.*", .data = &sdhi_quirks_bad_taps2367 },
 	{ .soc_id = "r8a7796", .revision = "ES1.[012]", .data = &sdhi_quirks_4tap_nohs400 },
-	{ .soc_id = "r8a7796", .revision = "ES1.*", .data = &sdhi_quirks_r8a7796_es13 },
-	{ .soc_id = "r8a77961", .data = &sdhi_quirks_bad_taps1357 },
-	{ .soc_id = "r8a77965", .data = &sdhi_quirks_r8a77965 },
+	{ .soc_id = "r8a774a1", .revision = "ES1.[012]", .data = &sdhi_quirks_4tap_nohs400 },
 	{ .soc_id = "r8a77980", .data = &sdhi_quirks_nohs400 },
-	{ .soc_id = "r8a77990", .data = &sdhi_quirks_r8a77990 },
 	{ /* Sentinel. */ },
 };
 
@@ -939,7 +665,6 @@ int renesas_sdhi_probe(struct platform_device *pdev,
 	if (!priv)
 		return -ENOMEM;
 
-	priv->quirks = quirks;
 	mmc_data = &priv->mmc_data;
 	dma_priv = &priv->dma_priv;
 
@@ -999,6 +724,9 @@ int renesas_sdhi_probe(struct platform_device *pdev,
 	if (quirks && quirks->hs400_disabled)
 		host->mmc->caps2 &= ~(MMC_CAP2_HS400 | MMC_CAP2_HS400_ES);
 
+	if (quirks && quirks->hs400_4taps)
+		mmc_data->flags |= TMIO_MMC_HAVE_4TAP_HS400;
+
 	/* For some SoC, we disable internal WP. GPIO may override this */
 	if (mmc_can_gpio_ro(host->mmc))
 		mmc_data->capabilities2 &= ~MMC_CAP2_NO_WRITE_PROTECT;
@@ -1011,9 +739,11 @@ int renesas_sdhi_probe(struct platform_device *pdev,
 			renesas_sdhi_start_signal_voltage_switch;
 		host->sdcard_irq_setbit_mask = TMIO_STAT_ALWAYS_SET_27;
 
+		/* SDR and HS200/400 registers requires HW reset */
 		if (of_data && of_data->scc_offset) {
 			priv->scc_ctl = host->ctl + of_data->scc_offset;
-			host->reset = renesas_sdhi_reset;
+			host->mmc->caps |= MMC_CAP_HW_RESET;
+			host->hw_reset = renesas_sdhi_hw_reset;
 		}
 	}
 
@@ -1047,8 +777,6 @@ int renesas_sdhi_probe(struct platform_device *pdev,
 	/* All SDHI have SDIO status bits which must be 1 */
 	mmc_data->flags |= TMIO_MMC_SDIO_STATUS_SETBITS;
 
-	dev_pm_domain_start(&pdev->dev);
-
 	ret = renesas_sdhi_clk_enable(host);
 	if (ret)
 		goto efree;
@@ -1062,14 +790,6 @@ int renesas_sdhi_probe(struct platform_device *pdev,
 	if (ver == SDHI_VER_GEN2_SDR50)
 		mmc_data->flags &= ~TMIO_MMC_HAVE_CBSY;
 
-	if (ver == SDHI_VER_GEN3_SDMMC && quirks && quirks->hs400_calib_table) {
-		host->fixup_request = renesas_sdhi_fixup_request;
-		priv->adjust_hs400_calib_table = *(
-			res->start == SDHI_GEN3_MMC0_ADDR ?
-			quirks->hs400_calib_table :
-			quirks->hs400_calib_table + 1);
-	}
-
 	ret = tmio_mmc_host_probe(host);
 	if (ret < 0)
 		goto edisclk;
@@ -1080,29 +800,29 @@ int renesas_sdhi_probe(struct platform_device *pdev,
 	     host->mmc->caps2 & (MMC_CAP2_HS200_1_8V_SDR |
 				 MMC_CAP2_HS400_1_8V))) {
 		const struct renesas_sdhi_scc *taps = of_data->taps;
-		bool use_4tap = priv->quirks && priv->quirks->hs400_4taps;
 		bool hit = false;
 
 		for (i = 0; i < of_data->taps_num; i++) {
 			if (taps[i].clk_rate == 0 ||
 			    taps[i].clk_rate == host->mmc->f_max) {
 				priv->scc_tappos = taps->tap;
-				priv->scc_tappos_hs400 = use_4tap ?
-							 taps->tap_hs400_4tap :
-							 taps->tap;
+				priv->scc_tappos_hs400 = taps->tap_hs400;
 				hit = true;
 				break;
 			}
 		}
 
 		if (!hit)
-			dev_warn(&host->pdev->dev, "Unknown clock rate for tuning\n");
-
-		host->check_retune = renesas_sdhi_check_scc_error;
-		host->ops.execute_tuning = renesas_sdhi_execute_tuning;
-		host->ops.prepare_hs400_tuning = renesas_sdhi_prepare_hs400_tuning;
-		host->ops.hs400_downgrade = renesas_sdhi_disable_scc;
-		host->ops.hs400_complete = renesas_sdhi_hs400_complete;
+			dev_warn(&host->pdev->dev, "Unknown clock rate for SDR104\n");
+
+		host->init_tuning = renesas_sdhi_init_tuning;
+		host->prepare_tuning = renesas_sdhi_prepare_tuning;
+		host->select_tuning = renesas_sdhi_select_tuning;
+		host->check_scc_error = renesas_sdhi_check_scc_error;
+		host->prepare_hs400_tuning =
+			renesas_sdhi_prepare_hs400_tuning;
+		host->hs400_downgrade = renesas_sdhi_disable_scc;
+		host->hs400_complete = renesas_sdhi_hs400_complete;
 	}
 
 	num_irqs = platform_irq_count(pdev);
@@ -1130,8 +850,10 @@ int renesas_sdhi_probe(struct platform_device *pdev,
 			goto eirq;
 	}
 
-	dev_info(&pdev->dev, "%s base at %pa, max clock rate %u MHz\n",
-		 mmc_hostname(host->mmc), &res->start, host->mmc->f_max / 1000000);
+	dev_info(&pdev->dev, "%s base at 0x%08lx max clock rate %u MHz\n",
+		 mmc_hostname(host->mmc), (unsigned long)
+		 (platform_get_resource(pdev, IORESOURCE_MEM, 0)->start),
+		 host->mmc->f_max / 1000000);
 
 	return ret;
 
@@ -1152,7 +874,6 @@ int renesas_sdhi_remove(struct platform_device *pdev)
 
 	tmio_mmc_host_remove(host);
 	renesas_sdhi_clk_disable(host);
-	tmio_mmc_host_free(host);
 
 	return 0;
 }
diff --git a/drivers/mmc/host/renesas_sdhi_internal_dmac.c b/drivers/mmc/host/renesas_sdhi_internal_dmac.c
index f3e76d6b3..a66f8d6d6 100644
--- a/drivers/mmc/host/renesas_sdhi_internal_dmac.c
+++ b/drivers/mmc/host/renesas_sdhi_internal_dmac.c
@@ -82,7 +82,7 @@ static struct renesas_sdhi_scc rcar_gen3_scc_taps[] = {
 	{
 		.clk_rate = 0,
 		.tap = 0x00000300,
-		.tap_hs400_4tap = 0x00000100,
+		.tap_hs400 = 0x00000704,
 	},
 };
 
@@ -186,8 +186,8 @@ renesas_sdhi_internal_dmac_start_dma(struct tmio_mmc_host *host,
 			mmc_get_dma_dir(data)))
 		goto force_pio;
 
-	/* This DMAC cannot handle if buffer is not 128-bytes alignment */
-	if (!IS_ALIGNED(sg_dma_address(sg), 128))
+	/* This DMAC cannot handle if buffer is not 8-bytes alignment */
+	if (!IS_ALIGNED(sg_dma_address(sg), 8))
 		goto force_pio_with_unmap;
 
 	if (data->flags & MMC_DATA_READ) {
@@ -229,15 +229,15 @@ static void renesas_sdhi_internal_dmac_issue_tasklet_fn(unsigned long arg)
 					    DTRAN_CTRL_DM_START);
 }
 
-static bool renesas_sdhi_internal_dmac_complete(struct tmio_mmc_host *host)
+static void renesas_sdhi_internal_dmac_complete_tasklet_fn(unsigned long arg)
 {
+	struct tmio_mmc_host *host = (struct tmio_mmc_host *)arg;
 	enum dma_data_direction dir;
 
-	if (!host->dma_on)
-		return false;
+	spin_lock_irq(&host->lock);
 
 	if (!host->data)
-		return false;
+		goto out;
 
 	if (host->data->flags & MMC_DATA_READ)
 		dir = DMA_FROM_DEVICE;
@@ -250,30 +250,11 @@ static bool renesas_sdhi_internal_dmac_complete(struct tmio_mmc_host *host)
 	if (dir == DMA_FROM_DEVICE)
 		clear_bit(SDHI_INTERNAL_DMAC_RX_IN_USE, &global_flags);
 
-	host->dma_on = false;
-
-	return true;
-}
-
-static void renesas_sdhi_internal_dmac_complete_tasklet_fn(unsigned long arg)
-{
-	struct tmio_mmc_host *host = (struct tmio_mmc_host *)arg;
-
-	spin_lock_irq(&host->lock);
-	if (!renesas_sdhi_internal_dmac_complete(host))
-		goto out;
-
 	tmio_mmc_do_data_irq(host);
 out:
 	spin_unlock_irq(&host->lock);
 }
 
-static void renesas_sdhi_internal_dmac_end_dma(struct tmio_mmc_host *host)
-{
-	if (host->data)
-		renesas_sdhi_internal_dmac_complete(host);
-}
-
 static void
 renesas_sdhi_internal_dmac_request_dma(struct tmio_mmc_host *host,
 				       struct tmio_mmc_data *pdata)
@@ -311,30 +292,47 @@ static const struct tmio_mmc_dma_ops renesas_sdhi_internal_dmac_dma_ops = {
 	.release = renesas_sdhi_internal_dmac_release_dma,
 	.abort = renesas_sdhi_internal_dmac_abort_dma,
 	.dataend = renesas_sdhi_internal_dmac_dataend_dma,
-	.end = renesas_sdhi_internal_dmac_end_dma,
 };
 
 /*
  * Whitelist of specific R-Car Gen3 SoC ES versions to use this DMAC
  * implementation as others may use a different implementation.
  */
-static const struct soc_device_attribute soc_dma_quirks[] = {
+static const struct soc_device_attribute soc_whitelist[] = {
+	/* specific ones */
 	{ .soc_id = "r7s9210",
 	  .data = (void *)BIT(SDHI_INTERNAL_DMAC_ADDR_MODE_FIXED_ONLY) },
 	{ .soc_id = "r8a7795", .revision = "ES1.*",
 	  .data = (void *)BIT(SDHI_INTERNAL_DMAC_ONE_RX_ONLY) },
 	{ .soc_id = "r8a7796", .revision = "ES1.0",
 	  .data = (void *)BIT(SDHI_INTERNAL_DMAC_ONE_RX_ONLY) },
+	/* generic ones */
+	{ .soc_id = "r8a774a1" },
+	{ .soc_id = "r8a774c0" },
+	{ .soc_id = "r8a77470" },
+	{ .soc_id = "r8a7795" },
+	{ .soc_id = "r8a7796" },
+	{ .soc_id = "r8a77965" },
+	{ .soc_id = "r8a77970" },
+	{ .soc_id = "r8a77980" },
+	{ .soc_id = "r8a77990" },
+	{ .soc_id = "r8a77995" },
 	{ /* sentinel */ }
 };
 
 static int renesas_sdhi_internal_dmac_probe(struct platform_device *pdev)
 {
-	const struct soc_device_attribute *soc = soc_device_match(soc_dma_quirks);
+	const struct soc_device_attribute *soc = soc_device_match(soc_whitelist);
 	struct device *dev = &pdev->dev;
 
-	if (soc)
-		global_flags |= (unsigned long)soc->data;
+	if (!soc)
+		return -ENODEV;
+
+	global_flags |= (unsigned long)soc->data;
+
+	dev->dma_parms = devm_kzalloc(dev, sizeof(*dev->dma_parms), GFP_KERNEL);
+	if (!dev->dma_parms)
+		return -ENOMEM;
 
 	/* value is max of SD_SECCNT. Confirmed by HW engineers */
 	dma_set_max_seg_size(dev, 0xffffffff);
@@ -353,7 +351,6 @@ static const struct dev_pm_ops renesas_sdhi_internal_dmac_dev_pm_ops = {
 static struct platform_driver renesas_internal_dmac_sdhi_driver = {
 	.driver		= {
 		.name	= "renesas_sdhi_internal_dmac",
-		.probe_type = PROBE_PREFER_ASYNCHRONOUS,
 		.pm	= &renesas_sdhi_internal_dmac_dev_pm_ops,
 		.of_match_table = renesas_sdhi_internal_dmac_of_match,
 	},
diff --git a/drivers/mmc/host/sdhci-acpi.c b/drivers/mmc/host/sdhci-acpi.c
index a2cdb37fc..36ea523b6 100644
--- a/drivers/mmc/host/sdhci-acpi.c
+++ b/drivers/mmc/host/sdhci-acpi.c
@@ -23,7 +23,6 @@
 #include <linux/pm.h>
 #include <linux/pm_runtime.h>
 #include <linux/delay.h>
-#include <linux/dmi.h>
 
 #include <linux/mmc/host.h>
 #include <linux/mmc/pm.h>
@@ -62,7 +61,7 @@ struct sdhci_acpi_slot {
 	mmc_pm_flag_t	pm_caps;
 	unsigned int	flags;
 	size_t		priv_size;
-	int (*probe_slot)(struct platform_device *, struct acpi_device *);
+	int (*probe_slot)(struct platform_device *, const char *, const char *);
 	int (*remove_slot)(struct platform_device *);
 	int (*free_slot)(struct platform_device *pdev);
 	int (*setup_host)(struct platform_device *pdev);
@@ -73,14 +72,7 @@ struct sdhci_acpi_host {
 	const struct sdhci_acpi_slot	*slot;
 	struct platform_device		*pdev;
 	bool				use_runtime_pm;
-	bool				is_intel;
-	bool				reset_signal_volt_on_suspend;
-	unsigned long			private[] ____cacheline_aligned;
-};
-
-enum {
-	DMI_QUIRK_RESET_SD_SIGNAL_VOLT_ON_SUSP			= BIT(0),
-	DMI_QUIRK_SD_NO_WRITE_PROTECT				= BIT(1),
+	unsigned long			private[0] ____cacheline_aligned;
 };
 
 static inline void *sdhci_acpi_priv(struct sdhci_acpi_host *c)
@@ -242,7 +234,7 @@ static const struct sdhci_acpi_chip sdhci_acpi_chip_int = {
 static bool sdhci_acpi_byt(void)
 {
 	static const struct x86_cpu_id byt[] = {
-		X86_MATCH_INTEL_FAM6_MODEL(ATOM_SILVERMONT, NULL),
+		{ X86_VENDOR_INTEL, 6, INTEL_FAM6_ATOM_SILVERMONT },
 		{}
 	};
 
@@ -252,7 +244,7 @@ static bool sdhci_acpi_byt(void)
 static bool sdhci_acpi_cht(void)
 {
 	static const struct x86_cpu_id cht[] = {
-		X86_MATCH_INTEL_FAM6_MODEL(ATOM_AIRMONT, NULL),
+		{ X86_VENDOR_INTEL, 6, INTEL_FAM6_ATOM_AIRMONT },
 		{}
 	};
 
@@ -333,10 +325,12 @@ static bool sdhci_acpi_cht_pci_wifi(unsigned int vendor, unsigned int device,
  * wifi card in the expected slot with an ACPI companion node, is used to
  * indicate that acpi_device_fix_up_power() should be avoided.
  */
-static inline bool sdhci_acpi_no_fixup_child_power(struct acpi_device *adev)
+static inline bool sdhci_acpi_no_fixup_child_power(const char *hid,
+						   const char *uid)
 {
 	return sdhci_acpi_cht() &&
-	       acpi_dev_hid_uid_match(adev, "80860F14", "2") &&
+	       !strcmp(hid, "80860F14") &&
+	       !strcmp(uid, "2") &&
 	       sdhci_acpi_cht_pci_wifi(0x14e4, 0x43ec, 0, 28);
 }
 
@@ -351,7 +345,8 @@ static inline bool sdhci_acpi_byt_defer(struct device *dev)
 	return false;
 }
 
-static inline bool sdhci_acpi_no_fixup_child_power(struct acpi_device *adev)
+static inline bool sdhci_acpi_no_fixup_child_power(const char *hid,
+						   const char *uid)
 {
 	return false;
 }
@@ -380,18 +375,19 @@ static int bxt_get_cd(struct mmc_host *mmc)
 	return ret;
 }
 
-static int intel_probe_slot(struct platform_device *pdev, struct acpi_device *adev)
+static int intel_probe_slot(struct platform_device *pdev, const char *hid,
+			    const char *uid)
 {
 	struct sdhci_acpi_host *c = platform_get_drvdata(pdev);
 	struct intel_host *intel_host = sdhci_acpi_priv(c);
 	struct sdhci_host *host = c->host;
 
-	if (acpi_dev_hid_uid_match(adev, "80860F14", "1") &&
+	if (hid && uid && !strcmp(hid, "80860F14") && !strcmp(uid, "1") &&
 	    sdhci_readl(host, SDHCI_CAPABILITIES) == 0x446cc8b2 &&
 	    sdhci_readl(host, SDHCI_CAPABILITIES_1) == 0x00000807)
 		host->timeout_clk = 1000; /* 1000 kHz i.e. 1 MHz */
 
-	if (acpi_dev_hid_uid_match(adev, "80865ACA", NULL))
+	if (hid && !strcmp(hid, "80865ACA"))
 		host->mmc_host_ops.get_cd = bxt_get_cd;
 
 	intel_dsm_init(intel_host, &pdev->dev, host->mmc);
@@ -399,8 +395,6 @@ static int intel_probe_slot(struct platform_device *pdev, struct acpi_device *ad
 	host->mmc_host_ops.start_signal_voltage_switch =
 					intel_start_signal_voltage_switch;
 
-	c->is_intel = true;
-
 	return 0;
 }
 
@@ -479,7 +473,8 @@ static irqreturn_t sdhci_acpi_qcom_handler(int irq, void *ptr)
 	return IRQ_HANDLED;
 }
 
-static int qcom_probe_slot(struct platform_device *pdev, struct acpi_device *adev)
+static int qcom_probe_slot(struct platform_device *pdev, const char *hid,
+			   const char *uid)
 {
 	struct sdhci_acpi_host *c = platform_get_drvdata(pdev);
 	struct sdhci_host *host = c->host;
@@ -487,7 +482,7 @@ static int qcom_probe_slot(struct platform_device *pdev, struct acpi_device *ade
 
 	*irq = -EINVAL;
 
-	if (!acpi_dev_hid_uid_match(adev, "QCOM8051", NULL))
+	if (strcmp(hid, "QCOM8051"))
 		return 0;
 
 	*irq = platform_get_irq(pdev, 1);
@@ -506,12 +501,14 @@ static int qcom_free_slot(struct platform_device *pdev)
 	struct sdhci_host *host = c->host;
 	struct acpi_device *adev;
 	int *irq = sdhci_acpi_priv(c);
+	const char *hid;
 
 	adev = ACPI_COMPANION(dev);
 	if (!adev)
 		return -ENODEV;
 
-	if (!acpi_dev_hid_uid_match(adev, "QCOM8051", NULL))
+	hid = acpi_device_hid(adev);
+	if (strcmp(hid, "QCOM8051"))
 		return 0;
 
 	if (*irq < 0)
@@ -535,11 +532,6 @@ static const struct sdhci_acpi_slot sdhci_acpi_slot_qcom_sd = {
 	.caps    = MMC_CAP_NONREMOVABLE,
 };
 
-struct amd_sdhci_host {
-	bool	tuned_clock;
-	bool	dll_enabled;
-};
-
 /* AMD sdhci reset dll register. */
 #define SDHCI_AMD_RESET_DLL_REGISTER    0x908
 
@@ -547,100 +539,42 @@ static int amd_select_drive_strength(struct mmc_card *card,
 				     unsigned int max_dtr, int host_drv,
 				     int card_drv, int *drv_type)
 {
-	*drv_type = MMC_SET_DRIVER_TYPE_A;
 	return MMC_SET_DRIVER_TYPE_A;
 }
 
-static void sdhci_acpi_amd_hs400_dll(struct sdhci_host *host, bool enable)
+static void sdhci_acpi_amd_hs400_dll(struct sdhci_host *host)
 {
-	struct sdhci_acpi_host *acpi_host = sdhci_priv(host);
-	struct amd_sdhci_host *amd_host = sdhci_acpi_priv(acpi_host);
-
 	/* AMD Platform requires dll setting */
 	sdhci_writel(host, 0x40003210, SDHCI_AMD_RESET_DLL_REGISTER);
 	usleep_range(10, 20);
-	if (enable)
-		sdhci_writel(host, 0x40033210, SDHCI_AMD_RESET_DLL_REGISTER);
-
-	amd_host->dll_enabled = enable;
+	sdhci_writel(host, 0x40033210, SDHCI_AMD_RESET_DLL_REGISTER);
 }
 
 /*
- * The initialization sequence for HS400 is:
- *     HS->HS200->Perform Tuning->HS->HS400
- *
- * The re-tuning sequence is:
- *     HS400->DDR52->HS->HS200->Perform Tuning->HS->HS400
- *
- * The AMD eMMC Controller can only use the tuned clock while in HS200 and HS400
- * mode. If we switch to a different mode, we need to disable the tuned clock.
- * If we have previously performed tuning and switch back to HS200 or
- * HS400, we can re-enable the tuned clock.
- *
+ * For AMD Platform it is required to disable the tuning
+ * bit first controller to bring to HS Mode from HS200
+ * mode, later enable to tune to HS400 mode.
  */
 static void amd_set_ios(struct mmc_host *mmc, struct mmc_ios *ios)
 {
 	struct sdhci_host *host = mmc_priv(mmc);
-	struct sdhci_acpi_host *acpi_host = sdhci_priv(host);
-	struct amd_sdhci_host *amd_host = sdhci_acpi_priv(acpi_host);
 	unsigned int old_timing = host->timing;
-	u16 val;
 
 	sdhci_set_ios(mmc, ios);
-
-	if (old_timing != host->timing && amd_host->tuned_clock) {
-		if (host->timing == MMC_TIMING_MMC_HS400 ||
-		    host->timing == MMC_TIMING_MMC_HS200) {
-			val = sdhci_readw(host, SDHCI_HOST_CONTROL2);
-			val |= SDHCI_CTRL_TUNED_CLK;
-			sdhci_writew(host, val, SDHCI_HOST_CONTROL2);
-		} else {
-			val = sdhci_readw(host, SDHCI_HOST_CONTROL2);
-			val &= ~SDHCI_CTRL_TUNED_CLK;
-			sdhci_writew(host, val, SDHCI_HOST_CONTROL2);
-		}
-
-		/* DLL is only required for HS400 */
-		if (host->timing == MMC_TIMING_MMC_HS400 &&
-		    !amd_host->dll_enabled)
-			sdhci_acpi_amd_hs400_dll(host, true);
-	}
-}
-
-static int amd_sdhci_execute_tuning(struct mmc_host *mmc, u32 opcode)
-{
-	int err;
-	struct sdhci_host *host = mmc_priv(mmc);
-	struct sdhci_acpi_host *acpi_host = sdhci_priv(host);
-	struct amd_sdhci_host *amd_host = sdhci_acpi_priv(acpi_host);
-
-	amd_host->tuned_clock = false;
-
-	err = sdhci_execute_tuning(mmc, opcode);
-
-	if (!err && !host->tuning_err)
-		amd_host->tuned_clock = true;
-
-	return err;
-}
-
-static void amd_sdhci_reset(struct sdhci_host *host, u8 mask)
-{
-	struct sdhci_acpi_host *acpi_host = sdhci_priv(host);
-	struct amd_sdhci_host *amd_host = sdhci_acpi_priv(acpi_host);
-
-	if (mask & SDHCI_RESET_ALL) {
-		amd_host->tuned_clock = false;
-		sdhci_acpi_amd_hs400_dll(host, false);
+	if (old_timing == MMC_TIMING_MMC_HS200 &&
+	    ios->timing == MMC_TIMING_MMC_HS)
+		sdhci_writew(host, 0x9, SDHCI_HOST_CONTROL2);
+	if (old_timing != MMC_TIMING_MMC_HS400 &&
+	    ios->timing == MMC_TIMING_MMC_HS400) {
+		sdhci_writew(host, 0x80, SDHCI_HOST_CONTROL2);
+		sdhci_acpi_amd_hs400_dll(host);
 	}
-
-	sdhci_reset(host, mask);
 }
 
 static const struct sdhci_ops sdhci_acpi_ops_amd = {
 	.set_clock	= sdhci_set_clock,
 	.set_bus_width	= sdhci_set_bus_width,
-	.reset		= amd_sdhci_reset,
+	.reset		= sdhci_reset,
 	.set_uhs_signaling = sdhci_set_uhs_signaling,
 };
 
@@ -649,7 +583,7 @@ static const struct sdhci_acpi_chip sdhci_acpi_chip_amd = {
 };
 
 static int sdhci_acpi_emmc_amd_probe_slot(struct platform_device *pdev,
-					  struct acpi_device *adev)
+					  const char *hid, const char *uid)
 {
 	struct sdhci_acpi_host *c = platform_get_drvdata(pdev);
 	struct sdhci_host *host   = c->host;
@@ -662,58 +596,17 @@ static int sdhci_acpi_emmc_amd_probe_slot(struct platform_device *pdev,
 	    (host->mmc->caps & MMC_CAP_1_8V_DDR))
 		host->mmc->caps2 = MMC_CAP2_HS400_1_8V;
 
-	/*
-	 * There are two types of presets out in the wild:
-	 * 1) Default/broken presets.
-	 *    These presets have two sets of problems:
-	 *    a) The clock divisor for SDR12, SDR25, and SDR50 is too small.
-	 *       This results in clock frequencies that are 2x higher than
-	 *       acceptable. i.e., SDR12 = 25 MHz, SDR25 = 50 MHz, SDR50 =
-	 *       100 MHz.x
-	 *    b) The HS200 and HS400 driver strengths don't match.
-	 *       By default, the SDR104 preset register has a driver strength of
-	 *       A, but the (internal) HS400 preset register has a driver
-	 *       strength of B. As part of initializing HS400, HS200 tuning
-	 *       needs to be performed. Having different driver strengths
-	 *       between tuning and operation is wrong. It results in different
-	 *       rise/fall times that lead to incorrect sampling.
-	 * 2) Firmware with properly initialized presets.
-	 *    These presets have proper clock divisors. i.e., SDR12 => 12MHz,
-	 *    SDR25 => 25 MHz, SDR50 => 50 MHz. Additionally the HS200 and
-	 *    HS400 preset driver strengths match.
-	 *
-	 *    Enabling presets for HS400 doesn't work for the following reasons:
-	 *    1) sdhci_set_ios has a hard coded list of timings that are used
-	 *       to determine if presets should be enabled.
-	 *    2) sdhci_get_preset_value is using a non-standard register to
-	 *       read out HS400 presets. The AMD controller doesn't support this
-	 *       non-standard register. In fact, it doesn't expose the HS400
-	 *       preset register anywhere in the SDHCI memory map. This results
-	 *       in reading a garbage value and using the wrong presets.
-	 *
-	 *       Since HS400 and HS200 presets must be identical, we could
-	 *       instead use the the SDR104 preset register.
-	 *
-	 *    If the above issues are resolved we could remove this quirk for
-	 *    firmware that that has valid presets (i.e., SDR12 <= 12 MHz).
-	 */
-	host->quirks2 |= SDHCI_QUIRK2_PRESET_VALUE_BROKEN;
-
 	host->mmc_host_ops.select_drive_strength = amd_select_drive_strength;
 	host->mmc_host_ops.set_ios = amd_set_ios;
-	host->mmc_host_ops.execute_tuning = amd_sdhci_execute_tuning;
 	return 0;
 }
 
 static const struct sdhci_acpi_slot sdhci_acpi_slot_amd_emmc = {
-	.chip		= &sdhci_acpi_chip_amd,
-	.caps		= MMC_CAP_8_BIT_DATA | MMC_CAP_NONREMOVABLE,
-	.quirks		= SDHCI_QUIRK_32BIT_DMA_ADDR |
-			  SDHCI_QUIRK_32BIT_DMA_SIZE |
-			  SDHCI_QUIRK_32BIT_ADMA_SIZE,
-	.quirks2	= SDHCI_QUIRK2_BROKEN_64_BIT_DMA,
+	.chip   = &sdhci_acpi_chip_amd,
+	.caps   = MMC_CAP_8_BIT_DATA | MMC_CAP_NONREMOVABLE,
+	.quirks = SDHCI_QUIRK_32BIT_DMA_ADDR | SDHCI_QUIRK_32BIT_DMA_SIZE |
+			SDHCI_QUIRK_32BIT_ADMA_SIZE,
 	.probe_slot     = sdhci_acpi_emmc_amd_probe_slot,
-	.priv_size	= sizeof(struct amd_sdhci_host),
 };
 
 struct sdhci_acpi_uid_slot {
@@ -761,53 +654,17 @@ static const struct acpi_device_id sdhci_acpi_ids[] = {
 };
 MODULE_DEVICE_TABLE(acpi, sdhci_acpi_ids);
 
-static const struct dmi_system_id sdhci_acpi_quirks[] = {
-	{
-		/*
-		 * The Lenovo Miix 320-10ICR has a bug in the _PS0 method of
-		 * the SHC1 ACPI device, this bug causes it to reprogram the
-		 * wrong LDO (DLDO3) to 1.8V if 1.8V modes are used and the
-		 * card is (runtime) suspended + resumed. DLDO3 is used for
-		 * the LCD and setting it to 1.8V causes the LCD to go black.
-		 */
-		.matches = {
-			DMI_MATCH(DMI_SYS_VENDOR, "LENOVO"),
-			DMI_MATCH(DMI_PRODUCT_VERSION, "Lenovo MIIX 320-10ICR"),
-		},
-		.driver_data = (void *)DMI_QUIRK_RESET_SD_SIGNAL_VOLT_ON_SUSP,
-	},
-	{
-		/*
-		 * The Acer Aspire Switch 10 (SW5-012) microSD slot always
-		 * reports the card being write-protected even though microSD
-		 * cards do not have a write-protect switch at all.
-		 */
-		.matches = {
-			DMI_MATCH(DMI_SYS_VENDOR, "Acer"),
-			DMI_MATCH(DMI_PRODUCT_NAME, "Aspire SW5-012"),
-		},
-		.driver_data = (void *)DMI_QUIRK_SD_NO_WRITE_PROTECT,
-	},
-	{
-		/*
-		 * The Toshiba WT8-B's microSD slot always reports the card being
-		 * write-protected.
-		 */
-		.matches = {
-			DMI_MATCH(DMI_SYS_VENDOR, "TOSHIBA"),
-			DMI_MATCH(DMI_PRODUCT_NAME, "TOSHIBA ENCORE 2 WT8-B"),
-		},
-		.driver_data = (void *)DMI_QUIRK_SD_NO_WRITE_PROTECT,
-	},
-	{} /* Terminating entry */
-};
-
-static const struct sdhci_acpi_slot *sdhci_acpi_get_slot(struct acpi_device *adev)
+static const struct sdhci_acpi_slot *sdhci_acpi_get_slot(const char *hid,
+							 const char *uid)
 {
 	const struct sdhci_acpi_uid_slot *u;
 
 	for (u = sdhci_acpi_uids; u->hid; u++) {
-		if (acpi_dev_hid_uid_match(adev, u->hid, u->uid))
+		if (strcmp(u->hid, hid))
+			continue;
+		if (!u->uid)
+			return u->slot;
+		if (uid && !strcmp(u->uid, uid))
 			return u->slot;
 	}
 	return NULL;
@@ -818,28 +675,27 @@ static int sdhci_acpi_probe(struct platform_device *pdev)
 	struct device *dev = &pdev->dev;
 	const struct sdhci_acpi_slot *slot;
 	struct acpi_device *device, *child;
-	const struct dmi_system_id *id;
 	struct sdhci_acpi_host *c;
 	struct sdhci_host *host;
 	struct resource *iomem;
 	resource_size_t len;
 	size_t priv_size;
-	int quirks = 0;
+	const char *hid;
+	const char *uid;
 	int err;
 
 	device = ACPI_COMPANION(dev);
 	if (!device)
 		return -ENODEV;
 
-	id = dmi_first_match(sdhci_acpi_quirks);
-	if (id)
-		quirks = (long)id->driver_data;
+	hid = acpi_device_hid(device);
+	uid = acpi_device_uid(device);
 
-	slot = sdhci_acpi_get_slot(device);
+	slot = sdhci_acpi_get_slot(hid, uid);
 
 	/* Power on the SDHCI controller and its children */
 	acpi_device_fix_up_power(device);
-	if (!sdhci_acpi_no_fixup_child_power(device)) {
+	if (!sdhci_acpi_no_fixup_child_power(hid, uid)) {
 		list_for_each_entry(child, &device->children, node)
 			if (child->status.present && child->status.enabled)
 				acpi_device_fix_up_power(child);
@@ -889,7 +745,7 @@ static int sdhci_acpi_probe(struct platform_device *pdev)
 
 	if (c->slot) {
 		if (c->slot->probe_slot) {
-			err = c->slot->probe_slot(pdev, device);
+			err = c->slot->probe_slot(pdev, hid, uid);
 			if (err)
 				goto err_free;
 		}
@@ -913,19 +769,13 @@ static int sdhci_acpi_probe(struct platform_device *pdev)
 	if (sdhci_acpi_flag(c, SDHCI_ACPI_SD_CD)) {
 		bool v = sdhci_acpi_flag(c, SDHCI_ACPI_SD_CD_OVERRIDE_LEVEL);
 
-		err = mmc_gpiod_request_cd(host->mmc, NULL, 0, v, 0);
+		err = mmc_gpiod_request_cd(host->mmc, NULL, 0, v, 0, NULL);
 		if (err) {
 			if (err == -EPROBE_DEFER)
 				goto err_free;
 			dev_warn(dev, "failed to setup card detect gpio\n");
 			c->use_runtime_pm = false;
 		}
-
-		if (quirks & DMI_QUIRK_RESET_SD_SIGNAL_VOLT_ON_SUSP)
-			c->reset_signal_volt_on_suspend = true;
-
-		if (quirks & DMI_QUIRK_SD_NO_WRITE_PROTECT)
-			host->mmc->caps2 |= MMC_CAP2_NO_WRITE_PROTECT;
 	}
 
 	err = sdhci_setup_host(host);
@@ -990,39 +840,17 @@ static int sdhci_acpi_remove(struct platform_device *pdev)
 	return 0;
 }
 
-static void __maybe_unused sdhci_acpi_reset_signal_voltage_if_needed(
-	struct device *dev)
-{
-	struct sdhci_acpi_host *c = dev_get_drvdata(dev);
-	struct sdhci_host *host = c->host;
-
-	if (c->is_intel && c->reset_signal_volt_on_suspend &&
-	    host->mmc->ios.signal_voltage != MMC_SIGNAL_VOLTAGE_330) {
-		struct intel_host *intel_host = sdhci_acpi_priv(c);
-		unsigned int fn = INTEL_DSM_V33_SWITCH;
-		u32 result = 0;
-
-		intel_dsm(intel_host, dev, fn, &result);
-	}
-}
-
 #ifdef CONFIG_PM_SLEEP
 
 static int sdhci_acpi_suspend(struct device *dev)
 {
 	struct sdhci_acpi_host *c = dev_get_drvdata(dev);
 	struct sdhci_host *host = c->host;
-	int ret;
 
 	if (host->tuning_mode != SDHCI_TUNING_MODE_3)
 		mmc_retune_needed(host->mmc);
 
-	ret = sdhci_suspend_host(host);
-	if (ret)
-		return ret;
-
-	sdhci_acpi_reset_signal_voltage_if_needed(dev);
-	return 0;
+	return sdhci_suspend_host(host);
 }
 
 static int sdhci_acpi_resume(struct device *dev)
@@ -1042,17 +870,11 @@ static int sdhci_acpi_runtime_suspend(struct device *dev)
 {
 	struct sdhci_acpi_host *c = dev_get_drvdata(dev);
 	struct sdhci_host *host = c->host;
-	int ret;
 
 	if (host->tuning_mode != SDHCI_TUNING_MODE_3)
 		mmc_retune_needed(host->mmc);
 
-	ret = sdhci_runtime_suspend_host(host);
-	if (ret)
-		return ret;
-
-	sdhci_acpi_reset_signal_voltage_if_needed(dev);
-	return 0;
+	return sdhci_runtime_suspend_host(host);
 }
 
 static int sdhci_acpi_runtime_resume(struct device *dev)
@@ -1075,7 +897,6 @@ static const struct dev_pm_ops sdhci_acpi_pm_ops = {
 static struct platform_driver sdhci_acpi_driver = {
 	.driver = {
 		.name			= "sdhci-acpi",
-		.probe_type		= PROBE_PREFER_ASYNCHRONOUS,
 		.acpi_match_table	= sdhci_acpi_ids,
 		.pm			= &sdhci_acpi_pm_ops,
 	},
diff --git a/drivers/mmc/host/sdhci-brcmstb.c b/drivers/mmc/host/sdhci-brcmstb.c
index f24623aac..73bb440aa 100644
--- a/drivers/mmc/host/sdhci-brcmstb.c
+++ b/drivers/mmc/host/sdhci-brcmstb.c
@@ -9,298 +9,66 @@
 #include <linux/mmc/host.h>
 #include <linux/module.h>
 #include <linux/of.h>
-#include <linux/bitops.h>
-#include <linux/delay.h>
 
 #include "sdhci-pltfm.h"
-#include "cqhci.h"
 
-#define SDHCI_VENDOR 0x78
-#define  SDHCI_VENDOR_ENHANCED_STRB 0x1
-
-#define BRCMSTB_PRIV_FLAGS_NO_64BIT		BIT(0)
-#define BRCMSTB_PRIV_FLAGS_BROKEN_TIMEOUT	BIT(1)
-
-#define SDHCI_ARASAN_CQE_BASE_ADDR		0x200
-
-struct sdhci_brcmstb_priv {
-	void __iomem *cfg_regs;
-	bool has_cqe;
-};
-
-struct brcmstb_match_priv {
-	void (*hs400es)(struct mmc_host *mmc, struct mmc_ios *ios);
-	struct sdhci_ops *ops;
-	unsigned int flags;
-};
-
-static void sdhci_brcmstb_hs400es(struct mmc_host *mmc, struct mmc_ios *ios)
-{
-	struct sdhci_host *host = mmc_priv(mmc);
-
-	u32 reg;
-
-	dev_dbg(mmc_dev(mmc), "%s(): Setting HS400-Enhanced-Strobe mode\n",
-		__func__);
-	reg = readl(host->ioaddr + SDHCI_VENDOR);
-	if (ios->enhanced_strobe)
-		reg |= SDHCI_VENDOR_ENHANCED_STRB;
-	else
-		reg &= ~SDHCI_VENDOR_ENHANCED_STRB;
-	writel(reg, host->ioaddr + SDHCI_VENDOR);
-}
-
-static void sdhci_brcmstb_set_clock(struct sdhci_host *host, unsigned int clock)
-{
-	u16 clk;
-
-	host->mmc->actual_clock = 0;
-
-	clk = sdhci_calc_clk(host, clock, &host->mmc->actual_clock);
-	sdhci_writew(host, clk, SDHCI_CLOCK_CONTROL);
-
-	if (clock == 0)
-		return;
-
-	sdhci_enable_clk(host, clk);
-}
-
-static void sdhci_brcmstb_set_uhs_signaling(struct sdhci_host *host,
-					    unsigned int timing)
-{
-	u16 ctrl_2;
-
-	dev_dbg(mmc_dev(host->mmc), "%s: Setting UHS signaling for %d timing\n",
-		__func__, timing);
-	ctrl_2 = sdhci_readw(host, SDHCI_HOST_CONTROL2);
-	/* Select Bus Speed Mode for host */
-	ctrl_2 &= ~SDHCI_CTRL_UHS_MASK;
-	if ((timing == MMC_TIMING_MMC_HS200) ||
-	    (timing == MMC_TIMING_UHS_SDR104))
-		ctrl_2 |= SDHCI_CTRL_UHS_SDR104;
-	else if (timing == MMC_TIMING_UHS_SDR12)
-		ctrl_2 |= SDHCI_CTRL_UHS_SDR12;
-	else if (timing == MMC_TIMING_SD_HS ||
-		 timing == MMC_TIMING_MMC_HS ||
-		 timing == MMC_TIMING_UHS_SDR25)
-		ctrl_2 |= SDHCI_CTRL_UHS_SDR25;
-	else if (timing == MMC_TIMING_UHS_SDR50)
-		ctrl_2 |= SDHCI_CTRL_UHS_SDR50;
-	else if ((timing == MMC_TIMING_UHS_DDR50) ||
-		 (timing == MMC_TIMING_MMC_DDR52))
-		ctrl_2 |= SDHCI_CTRL_UHS_DDR50;
-	else if (timing == MMC_TIMING_MMC_HS400)
-		ctrl_2 |= SDHCI_CTRL_HS400; /* Non-standard */
-	sdhci_writew(host, ctrl_2, SDHCI_HOST_CONTROL2);
-}
-
-static void sdhci_brcmstb_dumpregs(struct mmc_host *mmc)
-{
-	sdhci_dumpregs(mmc_priv(mmc));
-}
-
-static void sdhci_brcmstb_cqe_enable(struct mmc_host *mmc)
-{
-	struct sdhci_host *host = mmc_priv(mmc);
-	u32 reg;
-
-	reg = sdhci_readl(host, SDHCI_PRESENT_STATE);
-	while (reg & SDHCI_DATA_AVAILABLE) {
-		sdhci_readl(host, SDHCI_BUFFER);
-		reg = sdhci_readl(host, SDHCI_PRESENT_STATE);
-	}
-
-	sdhci_cqe_enable(mmc);
-}
-
-static const struct cqhci_host_ops sdhci_brcmstb_cqhci_ops = {
-	.enable         = sdhci_brcmstb_cqe_enable,
-	.disable        = sdhci_cqe_disable,
-	.dumpregs       = sdhci_brcmstb_dumpregs,
-};
-
-static struct sdhci_ops sdhci_brcmstb_ops = {
+static const struct sdhci_ops sdhci_brcmstb_ops = {
 	.set_clock = sdhci_set_clock,
 	.set_bus_width = sdhci_set_bus_width,
 	.reset = sdhci_reset,
 	.set_uhs_signaling = sdhci_set_uhs_signaling,
 };
 
-static struct sdhci_ops sdhci_brcmstb_ops_7216 = {
-	.set_clock = sdhci_brcmstb_set_clock,
-	.set_bus_width = sdhci_set_bus_width,
-	.reset = sdhci_reset,
-	.set_uhs_signaling = sdhci_brcmstb_set_uhs_signaling,
-};
-
-static struct brcmstb_match_priv match_priv_7425 = {
-	.flags = BRCMSTB_PRIV_FLAGS_NO_64BIT |
-	BRCMSTB_PRIV_FLAGS_BROKEN_TIMEOUT,
+static const struct sdhci_pltfm_data sdhci_brcmstb_pdata = {
 	.ops = &sdhci_brcmstb_ops,
 };
 
-static struct brcmstb_match_priv match_priv_7445 = {
-	.flags = BRCMSTB_PRIV_FLAGS_BROKEN_TIMEOUT,
-	.ops = &sdhci_brcmstb_ops,
-};
-
-static const struct brcmstb_match_priv match_priv_7216 = {
-	.hs400es = sdhci_brcmstb_hs400es,
-	.ops = &sdhci_brcmstb_ops_7216,
-};
-
-static const struct of_device_id sdhci_brcm_of_match[] = {
-	{ .compatible = "brcm,bcm7425-sdhci", .data = &match_priv_7425 },
-	{ .compatible = "brcm,bcm7445-sdhci", .data = &match_priv_7445 },
-	{ .compatible = "brcm,bcm7216-sdhci", .data = &match_priv_7216 },
-	{},
-};
-
-static u32 sdhci_brcmstb_cqhci_irq(struct sdhci_host *host, u32 intmask)
-{
-	int cmd_error = 0;
-	int data_error = 0;
-
-	if (!sdhci_cqe_irq(host, intmask, &cmd_error, &data_error))
-		return intmask;
-
-	cqhci_irq(host->mmc, intmask, cmd_error, data_error);
-
-	return 0;
-}
-
-static int sdhci_brcmstb_add_host(struct sdhci_host *host,
-				  struct sdhci_brcmstb_priv *priv)
-{
-	struct cqhci_host *cq_host;
-	bool dma64;
-	int ret;
-
-	if (!priv->has_cqe)
-		return sdhci_add_host(host);
-
-	dev_dbg(mmc_dev(host->mmc), "CQE is enabled\n");
-	host->mmc->caps2 |= MMC_CAP2_CQE | MMC_CAP2_CQE_DCMD;
-	ret = sdhci_setup_host(host);
-	if (ret)
-		return ret;
-
-	cq_host = devm_kzalloc(mmc_dev(host->mmc),
-			       sizeof(*cq_host), GFP_KERNEL);
-	if (!cq_host) {
-		ret = -ENOMEM;
-		goto cleanup;
-	}
-
-	cq_host->mmio = host->ioaddr + SDHCI_ARASAN_CQE_BASE_ADDR;
-	cq_host->ops = &sdhci_brcmstb_cqhci_ops;
-
-	dma64 = host->flags & SDHCI_USE_64_BIT_DMA;
-	if (dma64) {
-		dev_dbg(mmc_dev(host->mmc), "Using 64 bit DMA\n");
-		cq_host->caps |= CQHCI_TASK_DESC_SZ_128;
-	}
-
-	ret = cqhci_init(cq_host, host->mmc, dma64);
-	if (ret)
-		goto cleanup;
-
-	ret = __sdhci_add_host(host);
-	if (ret)
-		goto cleanup;
-
-	return 0;
-
-cleanup:
-	sdhci_cleanup_host(host);
-	return ret;
-}
-
 static int sdhci_brcmstb_probe(struct platform_device *pdev)
 {
-	const struct brcmstb_match_priv *match_priv;
-	struct sdhci_pltfm_data brcmstb_pdata;
-	struct sdhci_pltfm_host *pltfm_host;
-	const struct of_device_id *match;
-	struct sdhci_brcmstb_priv *priv;
 	struct sdhci_host *host;
-	struct resource *iomem;
-	bool has_cqe = false;
+	struct sdhci_pltfm_host *pltfm_host;
 	struct clk *clk;
 	int res;
 
-	match = of_match_node(sdhci_brcm_of_match, pdev->dev.of_node);
-	match_priv = match->data;
-
-	dev_dbg(&pdev->dev, "Probe found match for %s\n",  match->compatible);
-
-	clk = devm_clk_get_optional(&pdev->dev, NULL);
-	if (IS_ERR(clk))
-		return dev_err_probe(&pdev->dev, PTR_ERR(clk),
-				     "Failed to get clock from Device Tree\n");
-
+	clk = devm_clk_get(&pdev->dev, NULL);
+	if (IS_ERR(clk)) {
+		dev_err(&pdev->dev, "Clock not found in Device Tree\n");
+		clk = NULL;
+	}
 	res = clk_prepare_enable(clk);
 	if (res)
 		return res;
 
-	memset(&brcmstb_pdata, 0, sizeof(brcmstb_pdata));
-	if (device_property_read_bool(&pdev->dev, "supports-cqe")) {
-		has_cqe = true;
-		match_priv->ops->irq = sdhci_brcmstb_cqhci_irq;
-	}
-	brcmstb_pdata.ops = match_priv->ops;
-	host = sdhci_pltfm_init(pdev, &brcmstb_pdata,
-				sizeof(struct sdhci_brcmstb_priv));
+	host = sdhci_pltfm_init(pdev, &sdhci_brcmstb_pdata, 0);
 	if (IS_ERR(host)) {
 		res = PTR_ERR(host);
 		goto err_clk;
 	}
 
-	pltfm_host = sdhci_priv(host);
-	priv = sdhci_pltfm_priv(pltfm_host);
-	priv->has_cqe = has_cqe;
-
-	/* Map in the non-standard CFG registers */
-	iomem = platform_get_resource(pdev, IORESOURCE_MEM, 1);
-	priv->cfg_regs = devm_ioremap_resource(&pdev->dev, iomem);
-	if (IS_ERR(priv->cfg_regs)) {
-		res = PTR_ERR(priv->cfg_regs);
-		goto err;
-	}
-
 	sdhci_get_of_property(pdev);
 	res = mmc_of_parse(host->mmc);
 	if (res)
 		goto err;
 
-	/*
-	 * If the chip has enhanced strobe and it's enabled, add
-	 * callback
-	 */
-	if (match_priv->hs400es &&
-	    (host->mmc->caps2 & MMC_CAP2_HS400_ES))
-		host->mmc_host_ops.hs400_enhanced_strobe = match_priv->hs400es;
-
 	/*
 	 * Supply the existing CAPS, but clear the UHS modes. This
 	 * will allow these modes to be specified by device tree
 	 * properties through mmc_of_parse().
 	 */
 	host->caps = sdhci_readl(host, SDHCI_CAPABILITIES);
-	if (match_priv->flags & BRCMSTB_PRIV_FLAGS_NO_64BIT)
+	if (of_device_is_compatible(pdev->dev.of_node, "brcm,bcm7425-sdhci"))
 		host->caps &= ~SDHCI_CAN_64BIT;
 	host->caps1 = sdhci_readl(host, SDHCI_CAPABILITIES_1);
 	host->caps1 &= ~(SDHCI_SUPPORT_SDR50 | SDHCI_SUPPORT_SDR104 |
-			 SDHCI_SUPPORT_DDR50);
-	host->quirks |= SDHCI_QUIRK_MISSING_CAPS;
+			SDHCI_SUPPORT_DDR50);
+	host->quirks |= SDHCI_QUIRK_MISSING_CAPS |
+		SDHCI_QUIRK_BROKEN_TIMEOUT_VAL;
 
-	if (match_priv->flags & BRCMSTB_PRIV_FLAGS_BROKEN_TIMEOUT)
-		host->quirks |= SDHCI_QUIRK_BROKEN_TIMEOUT_VAL;
-
-	res = sdhci_brcmstb_add_host(host, priv);
+	res = sdhci_add_host(host);
 	if (res)
 		goto err;
 
+	pltfm_host = sdhci_priv(host);
 	pltfm_host->clk = clk;
 	return res;
 
@@ -311,23 +79,21 @@ static int sdhci_brcmstb_probe(struct platform_device *pdev)
 	return res;
 }
 
-static void sdhci_brcmstb_shutdown(struct platform_device *pdev)
-{
-	sdhci_pltfm_suspend(&pdev->dev);
-}
-
+static const struct of_device_id sdhci_brcm_of_match[] = {
+	{ .compatible = "brcm,bcm7425-sdhci" },
+	{ .compatible = "brcm,bcm7445-sdhci" },
+	{},
+};
 MODULE_DEVICE_TABLE(of, sdhci_brcm_of_match);
 
 static struct platform_driver sdhci_brcmstb_driver = {
 	.driver		= {
 		.name	= "sdhci-brcmstb",
-		.probe_type = PROBE_PREFER_ASYNCHRONOUS,
 		.pm	= &sdhci_pltfm_pmops,
 		.of_match_table = of_match_ptr(sdhci_brcm_of_match),
 	},
 	.probe		= sdhci_brcmstb_probe,
 	.remove		= sdhci_pltfm_unregister,
-	.shutdown	= sdhci_brcmstb_shutdown,
 };
 
 module_platform_driver(sdhci_brcmstb_driver);
diff --git a/drivers/mmc/host/sdhci-cadence.c b/drivers/mmc/host/sdhci-cadence.c
index 6f2de54a5..ae0ec27dd 100644
--- a/drivers/mmc/host/sdhci-cadence.c
+++ b/drivers/mmc/host/sdhci-cadence.c
@@ -11,7 +11,6 @@
 #include <linux/mmc/host.h>
 #include <linux/mmc/mmc.h>
 #include <linux/of.h>
-#include <linux/of_device.h>
 
 #include "sdhci-pltfm.h"
 
@@ -68,7 +67,7 @@ struct sdhci_cdns_priv {
 	void __iomem *hrs_addr;
 	bool enhanced_strobe;
 	unsigned int nr_phy_params;
-	struct sdhci_cdns_phy_param phy_params[];
+	struct sdhci_cdns_phy_param phy_params[0];
 };
 
 struct sdhci_cdns_phy_cfg {
@@ -97,11 +96,6 @@ static int sdhci_cdns_write_phy_reg(struct sdhci_cdns_priv *priv,
 	u32 tmp;
 	int ret;
 
-	ret = readl_poll_timeout(reg, tmp, !(tmp & SDHCI_CDNS_HRS04_ACK),
-				 0, 10);
-	if (ret)
-		return ret;
-
 	tmp = FIELD_PREP(SDHCI_CDNS_HRS04_WDATA, data) |
 	      FIELD_PREP(SDHCI_CDNS_HRS04_ADDR, addr);
 	writel(tmp, reg);
@@ -116,10 +110,7 @@ static int sdhci_cdns_write_phy_reg(struct sdhci_cdns_priv *priv,
 	tmp &= ~SDHCI_CDNS_HRS04_WR;
 	writel(tmp, reg);
 
-	ret = readl_poll_timeout(reg, tmp, !(tmp & SDHCI_CDNS_HRS04_ACK),
-				 0, 10);
-
-	return ret;
+	return 0;
 }
 
 static unsigned int sdhci_cdns_phy_param_count(struct device_node *np)
@@ -167,7 +158,7 @@ static int sdhci_cdns_phy_init(struct sdhci_cdns_priv *priv)
 	return 0;
 }
 
-static void *sdhci_cdns_priv(struct sdhci_host *host)
+static inline void *sdhci_cdns_priv(struct sdhci_host *host)
 {
 	struct sdhci_pltfm_host *pltfm_host = sdhci_priv(host);
 
@@ -202,6 +193,52 @@ static u32 sdhci_cdns_get_emmc_mode(struct sdhci_cdns_priv *priv)
 	return FIELD_GET(SDHCI_CDNS_HRS06_MODE, tmp);
 }
 
+static void sdhci_cdns_set_uhs_signaling(struct sdhci_host *host,
+					 unsigned int timing)
+{
+	struct sdhci_cdns_priv *priv = sdhci_cdns_priv(host);
+	u32 mode;
+
+	switch (timing) {
+	case MMC_TIMING_MMC_HS:
+		mode = SDHCI_CDNS_HRS06_MODE_MMC_SDR;
+		break;
+	case MMC_TIMING_MMC_DDR52:
+		mode = SDHCI_CDNS_HRS06_MODE_MMC_DDR;
+		break;
+	case MMC_TIMING_MMC_HS200:
+		mode = SDHCI_CDNS_HRS06_MODE_MMC_HS200;
+		break;
+	case MMC_TIMING_MMC_HS400:
+		if (priv->enhanced_strobe)
+			mode = SDHCI_CDNS_HRS06_MODE_MMC_HS400ES;
+		else
+			mode = SDHCI_CDNS_HRS06_MODE_MMC_HS400;
+		break;
+	default:
+		mode = SDHCI_CDNS_HRS06_MODE_SD;
+		break;
+	}
+
+	sdhci_cdns_set_emmc_mode(priv, mode);
+
+	/* For SD, fall back to the default handler */
+	if (mode == SDHCI_CDNS_HRS06_MODE_SD)
+		sdhci_set_uhs_signaling(host, timing);
+}
+
+static const struct sdhci_ops sdhci_cdns_ops = {
+	.set_clock = sdhci_set_clock,
+	.get_timeout_clock = sdhci_cdns_get_timeout_clock,
+	.set_bus_width = sdhci_set_bus_width,
+	.reset = sdhci_reset,
+	.set_uhs_signaling = sdhci_cdns_set_uhs_signaling,
+};
+
+static const struct sdhci_pltfm_data sdhci_cdns_pltfm_data = {
+	.ops = &sdhci_cdns_ops,
+};
+
 static int sdhci_cdns_set_tune_val(struct sdhci_host *host, unsigned int val)
 {
 	struct sdhci_cdns_priv *priv = sdhci_cdns_priv(host);
@@ -235,24 +272,23 @@ static int sdhci_cdns_set_tune_val(struct sdhci_host *host, unsigned int val)
 	return 0;
 }
 
-/*
- * In SD mode, software must not use the hardware tuning and instead perform
- * an almost identical procedure to eMMC.
- */
-static int sdhci_cdns_execute_tuning(struct sdhci_host *host, u32 opcode)
+static int sdhci_cdns_execute_tuning(struct mmc_host *mmc, u32 opcode)
 {
+	struct sdhci_host *host = mmc_priv(mmc);
 	int cur_streak = 0;
 	int max_streak = 0;
 	int end_of_streak = 0;
 	int i;
 
 	/*
-	 * Do not execute tuning for UHS_SDR50 or UHS_DDR50.
-	 * The delay is set by probe, based on the DT properties.
+	 * This handler only implements the eMMC tuning that is specific to
+	 * this controller.  Fall back to the standard method for SD timing.
 	 */
-	if (host->timing != MMC_TIMING_MMC_HS200 &&
-	    host->timing != MMC_TIMING_UHS_SDR104)
-		return 0;
+	if (host->timing != MMC_TIMING_MMC_HS200)
+		return sdhci_execute_tuning(mmc, opcode);
+
+	if (WARN_ON(opcode != MMC_SEND_TUNING_BLOCK_HS200))
+		return -EINVAL;
 
 	for (i = 0; i < SDHCI_CDNS_MAX_TUNING_LOOP; i++) {
 		if (sdhci_cdns_set_tune_val(host, i) ||
@@ -275,58 +311,6 @@ static int sdhci_cdns_execute_tuning(struct sdhci_host *host, u32 opcode)
 	return sdhci_cdns_set_tune_val(host, end_of_streak - max_streak / 2);
 }
 
-static void sdhci_cdns_set_uhs_signaling(struct sdhci_host *host,
-					 unsigned int timing)
-{
-	struct sdhci_cdns_priv *priv = sdhci_cdns_priv(host);
-	u32 mode;
-
-	switch (timing) {
-	case MMC_TIMING_MMC_HS:
-		mode = SDHCI_CDNS_HRS06_MODE_MMC_SDR;
-		break;
-	case MMC_TIMING_MMC_DDR52:
-		mode = SDHCI_CDNS_HRS06_MODE_MMC_DDR;
-		break;
-	case MMC_TIMING_MMC_HS200:
-		mode = SDHCI_CDNS_HRS06_MODE_MMC_HS200;
-		break;
-	case MMC_TIMING_MMC_HS400:
-		if (priv->enhanced_strobe)
-			mode = SDHCI_CDNS_HRS06_MODE_MMC_HS400ES;
-		else
-			mode = SDHCI_CDNS_HRS06_MODE_MMC_HS400;
-		break;
-	default:
-		mode = SDHCI_CDNS_HRS06_MODE_SD;
-		break;
-	}
-
-	sdhci_cdns_set_emmc_mode(priv, mode);
-
-	/* For SD, fall back to the default handler */
-	if (mode == SDHCI_CDNS_HRS06_MODE_SD)
-		sdhci_set_uhs_signaling(host, timing);
-}
-
-static const struct sdhci_ops sdhci_cdns_ops = {
-	.set_clock = sdhci_set_clock,
-	.get_timeout_clock = sdhci_cdns_get_timeout_clock,
-	.set_bus_width = sdhci_set_bus_width,
-	.reset = sdhci_reset,
-	.platform_execute_tuning = sdhci_cdns_execute_tuning,
-	.set_uhs_signaling = sdhci_cdns_set_uhs_signaling,
-};
-
-static const struct sdhci_pltfm_data sdhci_cdns_uniphier_pltfm_data = {
-	.ops = &sdhci_cdns_ops,
-	.quirks2 = SDHCI_QUIRK2_PRESET_VALUE_BROKEN,
-};
-
-static const struct sdhci_pltfm_data sdhci_cdns_pltfm_data = {
-	.ops = &sdhci_cdns_ops,
-};
-
 static void sdhci_cdns_hs400_enhanced_strobe(struct mmc_host *mmc,
 					     struct mmc_ios *ios)
 {
@@ -350,7 +334,6 @@ static void sdhci_cdns_hs400_enhanced_strobe(struct mmc_host *mmc,
 static int sdhci_cdns_probe(struct platform_device *pdev)
 {
 	struct sdhci_host *host;
-	const struct sdhci_pltfm_data *data;
 	struct sdhci_pltfm_host *pltfm_host;
 	struct sdhci_cdns_priv *priv;
 	struct clk *clk;
@@ -367,12 +350,8 @@ static int sdhci_cdns_probe(struct platform_device *pdev)
 	if (ret)
 		return ret;
 
-	data = of_device_get_match_data(dev);
-	if (!data)
-		data = &sdhci_cdns_pltfm_data;
-
 	nr_phy_params = sdhci_cdns_phy_param_count(dev->of_node);
-	host = sdhci_pltfm_init(pdev, data,
+	host = sdhci_pltfm_init(pdev, &sdhci_cdns_pltfm_data,
 				struct_size(priv, phy_params, nr_phy_params));
 	if (IS_ERR(host)) {
 		ret = PTR_ERR(host);
@@ -387,6 +366,7 @@ static int sdhci_cdns_probe(struct platform_device *pdev)
 	priv->hrs_addr = host->ioaddr;
 	priv->enhanced_strobe = false;
 	host->ioaddr += SDHCI_CDNS_SRS_BASE;
+	host->mmc_host_ops.execute_tuning = sdhci_cdns_execute_tuning;
 	host->mmc_host_ops.hs400_enhanced_strobe =
 				sdhci_cdns_hs400_enhanced_strobe;
 	sdhci_enable_v4_mode(host);
@@ -451,10 +431,7 @@ static const struct dev_pm_ops sdhci_cdns_pm_ops = {
 };
 
 static const struct of_device_id sdhci_cdns_match[] = {
-	{
-		.compatible = "socionext,uniphier-sd4hc",
-		.data = &sdhci_cdns_uniphier_pltfm_data,
-	},
+	{ .compatible = "socionext,uniphier-sd4hc" },
 	{ .compatible = "cdns,sd4hc" },
 	{ /* sentinel */ }
 };
@@ -463,7 +440,6 @@ MODULE_DEVICE_TABLE(of, sdhci_cdns_match);
 static struct platform_driver sdhci_cdns_driver = {
 	.driver = {
 		.name = "sdhci-cdns",
-		.probe_type = PROBE_PREFER_ASYNCHRONOUS,
 		.pm = &sdhci_cdns_pm_ops,
 		.of_match_table = sdhci_cdns_match,
 	},
diff --git a/drivers/mmc/host/sdhci-esdhc-imx.c b/drivers/mmc/host/sdhci-esdhc-imx.c
index a4bd85b20..0bfc9ca9b 100644
--- a/drivers/mmc/host/sdhci-esdhc-imx.c
+++ b/drivers/mmc/host/sdhci-esdhc-imx.c
@@ -7,10 +7,8 @@
  * Copyright (c) 2010 Pengutronix e.K.
  *   Author: Wolfram Sang <kernel@pengutronix.de>
  */
-
-#include <linux/bitfield.h>
+#include <linux/busfreq-imx.h>
 #include <linux/io.h>
-#include <linux/iopoll.h>
 #include <linux/delay.h>
 #include <linux/err.h>
 #include <linux/clk.h>
@@ -23,6 +21,7 @@
 #include <linux/mmc/slot-gpio.h>
 #include <linux/of.h>
 #include <linux/of_device.h>
+#include <linux/iopoll.h>
 #include <linux/pinctrl/consumer.h>
 #include <linux/platform_data/mmc-esdhc-imx.h>
 #include <linux/pm_runtime.h>
@@ -38,16 +37,6 @@
 #define  ESDHC_VENDOR_SPEC_SDIO_QUIRK	(1 << 1)
 #define  ESDHC_VENDOR_SPEC_VSELECT	(1 << 1)
 #define  ESDHC_VENDOR_SPEC_FRC_SDCLK_ON	(1 << 8)
-#define ESDHC_DEBUG_SEL_AND_STATUS_REG		0xc2
-#define ESDHC_DEBUG_SEL_REG			0xc3
-#define ESDHC_DEBUG_SEL_MASK			0xf
-#define ESDHC_DEBUG_SEL_CMD_STATE		1
-#define ESDHC_DEBUG_SEL_DATA_STATE		2
-#define ESDHC_DEBUG_SEL_TRANS_STATE		3
-#define ESDHC_DEBUG_SEL_DMA_STATE		4
-#define ESDHC_DEBUG_SEL_ADMA_STATE		5
-#define ESDHC_DEBUG_SEL_FIFO_STATE		6
-#define ESDHC_DEBUG_SEL_ASYNC_FIFO_STATE	7
 #define ESDHC_WTMK_LVL			0x44
 #define  ESDHC_WTMK_DEFAULT_VAL		0x10401040
 #define  ESDHC_WTMK_LVL_RD_WML_MASK	0x000000FF
@@ -100,8 +89,7 @@
 #define ESDHC_STD_TUNING_EN		(1 << 24)
 /* NOTE: the minimum valid tuning start tap for mx6sl is 1 */
 #define ESDHC_TUNING_START_TAP_DEFAULT	0x1
-#define ESDHC_TUNING_START_TAP_MASK	0x7f
-#define ESDHC_TUNING_CMD_CRC_CHECK_DISABLE	(1 << 7)
+#define ESDHC_TUNING_START_TAP_MASK	0xff
 #define ESDHC_TUNING_STEP_MASK		0x00070000
 #define ESDHC_TUNING_STEP_SHIFT		16
 
@@ -178,18 +166,27 @@
 #define ESDHC_FLAG_STATE_LOST_IN_LPMODE		BIT(14)
 /* The IP lost clock rate in PM_RUNTIME */
 #define ESDHC_FLAG_CLK_RATE_LOST_IN_PM_RUNTIME	BIT(15)
-/*
- * The IP do not support the ACMD23 feature completely when use ADMA mode.
- * In ADMA mode, it only use the 16 bit block count of the register 0x4
- * (BLOCK_ATT) as the CMD23's argument for ACMD23 mode, which means it will
- * ignore the upper 16 bit of the CMD23's argument. This will block the reliable
- * write operation in RPMB, because RPMB reliable write need to set the bit31
- * of the CMD23's argument.
- * imx6qpdl/imx6sx/imx6sl/imx7d has this limitation only for ADMA mode, SDMA
- * do not has this limitation. so when these SoC use ADMA mode, it need to
- * disable the ACMD23 feature.
- */
-#define ESDHC_FLAG_BROKEN_AUTO_CMD23	BIT(16)
+/* need request bus freq during low power */
+#define ESDHC_FLAG_BUSFREQ		BIT(16)
+
+#define MCI_SLOT_NUM 3
+
+unsigned int slot_index = 0;
+struct sdhci_host *mci_host[MCI_SLOT_NUM] = {NULL};
+
+static struct mmc_host *wifi_mmc_host;
+void wifi_card_detect(bool on)
+{
+	WARN_ON(!wifi_mmc_host);
+	if (on) {
+		mmc_detect_change(wifi_mmc_host, 0);
+	} else {
+		if (wifi_mmc_host->card)
+			mmc_sdio_force_remove(wifi_mmc_host);
+	}
+}
+EXPORT_SYMBOL(wifi_card_detect);
+
 
 struct esdhc_soc_data {
 	u32 flags;
@@ -212,44 +209,34 @@ static const struct esdhc_soc_data esdhc_imx53_data = {
 };
 
 static const struct esdhc_soc_data usdhc_imx6q_data = {
-	.flags = ESDHC_FLAG_USDHC | ESDHC_FLAG_MAN_TUNING
-			| ESDHC_FLAG_BROKEN_AUTO_CMD23,
+	.flags = ESDHC_FLAG_USDHC | ESDHC_FLAG_MAN_TUNING,
 };
 
 static const struct esdhc_soc_data usdhc_imx6sl_data = {
 	.flags = ESDHC_FLAG_USDHC | ESDHC_FLAG_STD_TUNING
 			| ESDHC_FLAG_HAVE_CAP1 | ESDHC_FLAG_ERR004536
-			| ESDHC_FLAG_HS200
-			| ESDHC_FLAG_BROKEN_AUTO_CMD23,
-};
-
-static const struct esdhc_soc_data usdhc_imx6sll_data = {
-	.flags = ESDHC_FLAG_USDHC | ESDHC_FLAG_STD_TUNING
-			| ESDHC_FLAG_HAVE_CAP1 | ESDHC_FLAG_HS200
-			| ESDHC_FLAG_HS400
-			| ESDHC_FLAG_STATE_LOST_IN_LPMODE,
+			| ESDHC_FLAG_HS200 | ESDHC_FLAG_BUSFREQ,
 };
 
 static const struct esdhc_soc_data usdhc_imx6sx_data = {
 	.flags = ESDHC_FLAG_USDHC | ESDHC_FLAG_STD_TUNING
 			| ESDHC_FLAG_HAVE_CAP1 | ESDHC_FLAG_HS200
 			| ESDHC_FLAG_STATE_LOST_IN_LPMODE
-			| ESDHC_FLAG_BROKEN_AUTO_CMD23,
+			| ESDHC_FLAG_BUSFREQ,
 };
 
 static const struct esdhc_soc_data usdhc_imx6ull_data = {
 	.flags = ESDHC_FLAG_USDHC | ESDHC_FLAG_STD_TUNING
 			| ESDHC_FLAG_HAVE_CAP1 | ESDHC_FLAG_HS200
-			| ESDHC_FLAG_ERR010450
+			| ESDHC_FLAG_ERR010450 | ESDHC_FLAG_BUSFREQ
 			| ESDHC_FLAG_STATE_LOST_IN_LPMODE,
 };
 
 static const struct esdhc_soc_data usdhc_imx7d_data = {
 	.flags = ESDHC_FLAG_USDHC | ESDHC_FLAG_STD_TUNING
 			| ESDHC_FLAG_HAVE_CAP1 | ESDHC_FLAG_HS200
-			| ESDHC_FLAG_HS400
-			| ESDHC_FLAG_STATE_LOST_IN_LPMODE
-			| ESDHC_FLAG_BROKEN_AUTO_CMD23,
+			| ESDHC_FLAG_HS400 | ESDHC_FLAG_BUSFREQ
+			| ESDHC_FLAG_STATE_LOST_IN_LPMODE,
 };
 
 static struct esdhc_soc_data usdhc_imx7ulp_data = {
@@ -263,6 +250,7 @@ static struct esdhc_soc_data usdhc_imx8qxp_data = {
 	.flags = ESDHC_FLAG_USDHC | ESDHC_FLAG_STD_TUNING
 			| ESDHC_FLAG_HAVE_CAP1 | ESDHC_FLAG_HS200
 			| ESDHC_FLAG_HS400 | ESDHC_FLAG_HS400_ES
+			| ESDHC_FLAG_CQHCI
 			| ESDHC_FLAG_STATE_LOST_IN_LPMODE
 			| ESDHC_FLAG_CLK_RATE_LOST_IN_PM_RUNTIME,
 };
@@ -271,12 +259,18 @@ static struct esdhc_soc_data usdhc_imx8mm_data = {
 	.flags = ESDHC_FLAG_USDHC | ESDHC_FLAG_STD_TUNING
 			| ESDHC_FLAG_HAVE_CAP1 | ESDHC_FLAG_HS200
 			| ESDHC_FLAG_HS400 | ESDHC_FLAG_HS400_ES
+			| ESDHC_FLAG_CQHCI | ESDHC_FLAG_BUSFREQ
 			| ESDHC_FLAG_STATE_LOST_IN_LPMODE,
 };
 
+static struct esdhc_soc_data usdhc_s32v234_data = {
+	.flags = ESDHC_FLAG_USDHC,
+};
+
 struct pltfm_imx_data {
 	u32 scratchpad;
 	struct pinctrl *pinctrl;
+	struct pinctrl_state *pins_default;
 	struct pinctrl_state *pins_100mhz;
 	struct pinctrl_state *pins_200mhz;
 	const struct esdhc_soc_data *socdata;
@@ -317,13 +311,13 @@ static const struct of_device_id imx_esdhc_dt_ids[] = {
 	{ .compatible = "fsl,imx53-esdhc", .data = &esdhc_imx53_data, },
 	{ .compatible = "fsl,imx6sx-usdhc", .data = &usdhc_imx6sx_data, },
 	{ .compatible = "fsl,imx6sl-usdhc", .data = &usdhc_imx6sl_data, },
-	{ .compatible = "fsl,imx6sll-usdhc", .data = &usdhc_imx6sll_data, },
 	{ .compatible = "fsl,imx6q-usdhc", .data = &usdhc_imx6q_data, },
 	{ .compatible = "fsl,imx6ull-usdhc", .data = &usdhc_imx6ull_data, },
 	{ .compatible = "fsl,imx7d-usdhc", .data = &usdhc_imx7d_data, },
 	{ .compatible = "fsl,imx7ulp-usdhc", .data = &usdhc_imx7ulp_data, },
 	{ .compatible = "fsl,imx8qxp-usdhc", .data = &usdhc_imx8qxp_data, },
 	{ .compatible = "fsl,imx8mm-usdhc", .data = &usdhc_imx8mm_data, },
+	{ .compatible = "fsl,s32v234-usdhc", .data = &usdhc_s32v234_data, },
 	{ /* sentinel */ }
 };
 MODULE_DEVICE_TABLE(of, imx_esdhc_dt_ids);
@@ -343,6 +337,11 @@ static inline int is_imx6q_usdhc(struct pltfm_imx_data *data)
 	return data->socdata == &usdhc_imx6q_data;
 }
 
+static inline int is_s32v234_usdhc(struct pltfm_imx_data *data)
+{
+	return data->socdata == &usdhc_s32v234_data;
+}
+
 static inline int esdhc_is_usdhc(struct pltfm_imx_data *data)
 {
 	return !!(data->socdata->flags & ESDHC_FLAG_USDHC);
@@ -356,34 +355,6 @@ static inline void esdhc_clrset_le(struct sdhci_host *host, u32 mask, u32 val, i
 	writel(((readl(base) & ~(mask << shift)) | (val << shift)), base);
 }
 
-#define DRIVER_NAME "sdhci-esdhc-imx"
-#define ESDHC_IMX_DUMP(f, x...) \
-	pr_err("%s: " DRIVER_NAME ": " f, mmc_hostname(host->mmc), ## x)
-static void esdhc_dump_debug_regs(struct sdhci_host *host)
-{
-	int i;
-	char *debug_status[7] = {
-				 "cmd debug status",
-				 "data debug status",
-				 "trans debug status",
-				 "dma debug status",
-				 "adma debug status",
-				 "fifo debug status",
-				 "async fifo debug status"
-	};
-
-	ESDHC_IMX_DUMP("========= ESDHC IMX DEBUG STATUS DUMP =========\n");
-	for (i = 0; i < 7; i++) {
-		esdhc_clrset_le(host, ESDHC_DEBUG_SEL_MASK,
-			ESDHC_DEBUG_SEL_CMD_STATE + i, ESDHC_DEBUG_SEL_REG);
-		ESDHC_IMX_DUMP("%s:  0x%04x\n", debug_status[i],
-			readw(host->ioaddr + ESDHC_DEBUG_SEL_AND_STATUS_REG));
-	}
-
-	esdhc_clrset_le(host, ESDHC_DEBUG_SEL_MASK, 0, ESDHC_DEBUG_SEL_REG);
-
-}
-
 static inline void esdhc_wait_for_card_clock_gate_off(struct sdhci_host *host)
 {
 	u32 present_state;
@@ -433,13 +404,18 @@ static u32 esdhc_readl_le(struct sdhci_host *host, int reg)
 		if (esdhc_is_usdhc(imx_data)) {
 			if (imx_data->socdata->flags & ESDHC_FLAG_HAVE_CAP1)
 				val = readl(host->ioaddr + SDHCI_CAPABILITIES) & 0xFFFF;
+			else if (is_s32v234_usdhc(imx_data))
+				/* S32V234 HOST_CTRL_CAP register does not
+				 * provide speed info.
+				 * S32V234 has support for DDR50.
+				 */
+				val = SDHCI_SUPPORT_SDR50 | SDHCI_SUPPORT_DDR50;
 			else
 				/* imx6q/dl does not have cap_1 register, fake one */
 				val = SDHCI_SUPPORT_DDR50 | SDHCI_SUPPORT_SDR104
 					| SDHCI_SUPPORT_SDR50
 					| SDHCI_USE_SDR50_TUNING
-					| FIELD_PREP(SDHCI_RETUNING_MODE_MASK,
-						     SDHCI_TUNING_MODE_3);
+					| (SDHCI_TUNING_MODE_3 << SDHCI_RETUNING_MODE_SHIFT);
 
 			if (imx_data->socdata->flags & ESDHC_FLAG_HS400)
 				val |= SDHCI_SUPPORT_HS400;
@@ -457,9 +433,9 @@ static u32 esdhc_readl_le(struct sdhci_host *host, int reg)
 
 	if (unlikely(reg == SDHCI_MAX_CURRENT) && esdhc_is_usdhc(imx_data)) {
 		val = 0;
-		val |= FIELD_PREP(SDHCI_MAX_CURRENT_330_MASK, 0xFF);
-		val |= FIELD_PREP(SDHCI_MAX_CURRENT_300_MASK, 0xFF);
-		val |= FIELD_PREP(SDHCI_MAX_CURRENT_180_MASK, 0xFF);
+		val |= 0xFF << SDHCI_MAX_CURRENT_330_SHIFT;
+		val |= 0xFF << SDHCI_MAX_CURRENT_300_SHIFT;
+		val |= 0xFF << SDHCI_MAX_CURRENT_180_SHIFT;
 	}
 
 	if (unlikely(reg == SDHCI_INT_STATUS)) {
@@ -679,24 +655,10 @@ static void esdhc_writew_le(struct sdhci_host *host, u16 val, int reg)
 			 * For DMA access restore the levels to default value.
 			 */
 			m = readl(host->ioaddr + ESDHC_WTMK_LVL);
-			if (val & SDHCI_TRNS_DMA) {
+			if (val & SDHCI_TRNS_DMA)
 				wml = ESDHC_WTMK_LVL_WML_VAL_DEF;
-			} else {
-				u8 ctrl;
+			else
 				wml = ESDHC_WTMK_LVL_WML_VAL_MAX;
-
-				/*
-				 * Since already disable DMA mode, so also need
-				 * to clear the DMASEL. Otherwise, for standard
-				 * tuning, when send tuning command, usdhc will
-				 * still prefetch the ADMA script from wrong
-				 * DMA address, then we will see IOMMU report
-				 * some error which show lack of TLB mapping.
-				 */
-				ctrl = sdhci_readb(host, SDHCI_HOST_CONTROL);
-				ctrl &= ~SDHCI_CTRL_DMA_MASK;
-				sdhci_writeb(host, ctrl, SDHCI_HOST_CONTROL);
-			}
 			m &= ~(ESDHC_WTMK_LVL_RD_WML_MASK |
 			       ESDHC_WTMK_LVL_WR_WML_MASK);
 			m |= (wml << ESDHC_WTMK_LVL_RD_WML_SHIFT) |
@@ -985,20 +947,10 @@ static int usdhc_execute_tuning(struct mmc_host *mmc, u32 opcode)
 static void esdhc_prepare_tuning(struct sdhci_host *host, u32 val)
 {
 	u32 reg;
-	u8 sw_rst;
-	int ret;
 
 	/* FIXME: delay a bit for card to be ready for next tuning due to errors */
 	mdelay(1);
 
-	/* IC suggest to reset USDHC before every tuning command */
-	esdhc_clrset_le(host, 0xff, SDHCI_RESET_ALL, SDHCI_SOFTWARE_RESET);
-	ret = readb_poll_timeout(host->ioaddr + SDHCI_SOFTWARE_RESET, sw_rst,
-				!(sw_rst & SDHCI_RESET_ALL), 10, 100);
-	if (ret == -ETIMEDOUT)
-		dev_warn(mmc_dev(host->mmc),
-		"warning! RESET_ALL never complete before sending tuning command\n");
-
 	reg = readl(host->ioaddr + ESDHC_MIX_CTRL);
 	reg |= ESDHC_MIX_CTRL_EXE_TUNE | ESDHC_MIX_CTRL_SMPCLK_SEL |
 			ESDHC_MIX_CTRL_FBCLK_SEL;
@@ -1078,6 +1030,7 @@ static int esdhc_change_pinstate(struct sdhci_host *host,
 	dev_dbg(mmc_dev(host->mmc), "change pinctrl state for uhs %d\n", uhs);
 
 	if (IS_ERR(imx_data->pinctrl) ||
+		IS_ERR(imx_data->pins_default) ||
 		IS_ERR(imx_data->pins_100mhz) ||
 		IS_ERR(imx_data->pins_200mhz))
 		return -EINVAL;
@@ -1094,7 +1047,7 @@ static int esdhc_change_pinstate(struct sdhci_host *host,
 		break;
 	default:
 		/* back to default state for other legacy timing */
-		return pinctrl_select_default_state(mmc_dev(host->mmc));
+		pinctrl = imx_data->pins_default;
 	}
 
 	return pinctrl_select_state(imx_data->pinctrl, pinctrl);
@@ -1299,7 +1252,6 @@ static struct sdhci_ops sdhci_esdhc_ops = {
 	.set_uhs_signaling = esdhc_set_uhs_signaling,
 	.reset = esdhc_reset,
 	.irq = esdhc_cqhci_irq,
-	.dump_vendor_regs = esdhc_dump_debug_regs,
 };
 
 static const struct sdhci_pltfm_data sdhci_esdhc_imx_pdata = {
@@ -1314,7 +1266,6 @@ static void sdhci_esdhc_imx_hwinit(struct sdhci_host *host)
 {
 	struct sdhci_pltfm_host *pltfm_host = sdhci_priv(host);
 	struct pltfm_imx_data *imx_data = sdhci_pltfm_priv(pltfm_host);
-	struct cqhci_host *cq_host = host->mmc->cqe_private;
 	int tmp;
 
 	if (esdhc_is_usdhc(imx_data)) {
@@ -1343,8 +1294,9 @@ static void sdhci_esdhc_imx_hwinit(struct sdhci_host *host)
 		 * erratum ESDHC_FLAG_ERR004536 fix for MX6Q TO1.2 and MX6DL
 		 * TO1.1, it's harmless for MX6SL
 		 */
-		writel(readl(host->ioaddr + 0x6c) & ~BIT(7),
-			host->ioaddr + 0x6c);
+		if (!is_s32v234_usdhc(imx_data))
+			writel(readl(host->ioaddr + 0x6c) & ~BIT(7),
+				host->ioaddr + 0x6c);
 
 		/* disable DLL_CTRL delay line settings */
 		writel(0x0, host->ioaddr + ESDHC_DLL_CTRL);
@@ -1380,18 +1332,6 @@ static void sdhci_esdhc_imx_hwinit(struct sdhci_host *host)
 				tmp |= imx_data->boarddata.tuning_step
 					<< ESDHC_TUNING_STEP_SHIFT;
 			}
-
-			/* Disable the CMD CRC check for tuning, if not, need to
-			 * add some delay after every tuning command, because
-			 * hardware standard tuning logic will directly go to next
-			 * step once it detect the CMD CRC error, will not wait for
-			 * the card side to finally send out the tuning data, trigger
-			 * the buffer read ready interrupt immediately. If usdhc send
-			 * the next tuning command some eMMC card will stuck, can't
-			 * response, block the tuning procedure or the first command
-			 * after the whole tuning procedure always can't get any response.
-			 */
-			tmp |= ESDHC_TUNING_CMD_CRC_CHECK_DISABLE;
 			writel(tmp, host->ioaddr + ESDHC_TUNING_CTRL);
 		} else if (imx_data->socdata->flags & ESDHC_FLAG_MAN_TUNING) {
 			/*
@@ -1403,21 +1343,6 @@ static void sdhci_esdhc_imx_hwinit(struct sdhci_host *host)
 			tmp &= ~ESDHC_STD_TUNING_EN;
 			writel(tmp, host->ioaddr + ESDHC_TUNING_CTRL);
 		}
-
-		/*
-		 * On i.MX8MM, we are running Dual Linux OS, with 1st Linux using SD Card
-		 * as rootfs storage, 2nd Linux using eMMC as rootfs storage. We let the
-		 * the 1st linux configure power/clock for the 2nd Linux.
-		 *
-		 * When the 2nd Linux is booting into rootfs stage, we let the 1st Linux
-		 * to destroy the 2nd linux, then restart the 2nd linux, we met SDHCI dump.
-		 * After we clear the pending interrupt and halt CQCTL, issue gone.
-		 */
-		if (cq_host) {
-			tmp = cqhci_readl(cq_host, CQHCI_IS);
-			cqhci_writel(cq_host, tmp, CQHCI_IS);
-			cqhci_writel(cq_host, CQHCI_HALT, CQHCI_CTL);
-		}
 	}
 }
 
@@ -1513,12 +1438,16 @@ sdhci_esdhc_imx_probe_dt(struct platform_device *pdev,
 	if (of_find_property(np, "no-1-8-v", NULL))
 		host->quirks2 |= SDHCI_QUIRK2_NO_1_8_V;
 
+	if (of_find_property(np, "auto-cmd23-broken", NULL))
+		host->quirks2 |= SDHCI_QUIRK2_ACMD23_BROKEN;
+
 	if (of_property_read_u32(np, "fsl,delay-line", &boarddata->delay_line))
 		boarddata->delay_line = 0;
 
 	mmc_of_parse_voltage(np, &host->ocr_mask);
 
-	if (esdhc_is_usdhc(imx_data) && !IS_ERR(imx_data->pinctrl)) {
+	if (!is_s32v234_usdhc(imx_data) && esdhc_is_usdhc(imx_data) &&
+	    !IS_ERR(imx_data->pins_default)) {
 		imx_data->pins_100mhz = pinctrl_lookup_state(imx_data->pinctrl,
 						ESDHC_PINCTRL_STATE_100MHZ);
 		imx_data->pins_200mhz = pinctrl_lookup_state(imx_data->pinctrl,
@@ -1532,6 +1461,12 @@ sdhci_esdhc_imx_probe_dt(struct platform_device *pdev,
 
 	if (mmc_gpio_get_cd(host->mmc) >= 0)
 		host->quirks &= ~SDHCI_QUIRK_BROKEN_CARD_DETECTION;
+	
+	if (of_get_property(np, "wifi-host", NULL)) {
+		wifi_mmc_host = host->mmc;
+		host->quirks2 |= SDHCI_QUIRK2_SDIO_IRQ_THREAD;
+		dev_info(mmc_dev(host->mmc), "assigned as wifi host\n");
+	}
 
 	return 0;
 }
@@ -1561,26 +1496,25 @@ static int sdhci_esdhc_imx_probe_nondt(struct platform_device *pdev,
 				host->mmc->parent->platform_data);
 	/* write_protect */
 	if (boarddata->wp_type == ESDHC_WP_GPIO) {
-		host->mmc->caps2 |= MMC_CAP2_RO_ACTIVE_HIGH;
-
-		err = mmc_gpiod_request_ro(host->mmc, "wp", 0, 0);
+		err = mmc_gpiod_request_ro(host->mmc, "wp", 0, 0, NULL);
 		if (err) {
 			dev_err(mmc_dev(host->mmc),
 				"failed to request write-protect gpio!\n");
 			return err;
 		}
+		host->mmc->caps2 |= MMC_CAP2_RO_ACTIVE_HIGH;
 	}
 
 	/* card_detect */
 	switch (boarddata->cd_type) {
 	case ESDHC_CD_GPIO:
-		err = mmc_gpiod_request_cd(host->mmc, "cd", 0, false, 0);
+		err = mmc_gpiod_request_cd(host->mmc, "cd", 0, false, 0, NULL);
 		if (err) {
 			dev_err(mmc_dev(host->mmc),
 				"failed to request card-detect gpio!\n");
 			return err;
 		}
-		fallthrough;
+		/* fall through */
 
 	case ESDHC_CD_CONTROLLER:
 		/* we have a working card_detect back */
@@ -1620,6 +1554,7 @@ static int sdhci_esdhc_imx_probe(struct platform_device *pdev)
 	struct cqhci_host *cq_host;
 	int err;
 	struct pltfm_imx_data *imx_data;
+	u32 status;
 
 	host = sdhci_pltfm_init(pdev, &sdhci_esdhc_imx_pdata,
 				sizeof(*imx_data));
@@ -1633,6 +1568,9 @@ static int sdhci_esdhc_imx_probe(struct platform_device *pdev)
 	imx_data->socdata = of_id ? of_id->data : (struct esdhc_soc_data *)
 						  pdev->id_entry->driver_data;
 
+	if (imx_data->socdata->flags & ESDHC_FLAG_BUSFREQ)
+		request_bus_freq(BUS_FREQ_HIGH);
+
 	if (imx_data->socdata->flags & ESDHC_FLAG_PMQOS)
 		cpu_latency_qos_add_request(&imx_data->pm_qos_req, 0);
 
@@ -1667,16 +1605,20 @@ static int sdhci_esdhc_imx_probe(struct platform_device *pdev)
 		goto disable_ipg_clk;
 
 	imx_data->pinctrl = devm_pinctrl_get(&pdev->dev);
-	if (IS_ERR(imx_data->pinctrl))
+	if (IS_ERR(imx_data->pinctrl)) {
+		err = PTR_ERR(imx_data->pinctrl);
 		dev_warn(mmc_dev(host->mmc), "could not get pinctrl\n");
+		imx_data->pins_default = ERR_PTR(-EINVAL);
+	} else {
+		imx_data->pins_default = pinctrl_lookup_state(imx_data->pinctrl,
+						PINCTRL_STATE_DEFAULT);
+		if (IS_ERR(imx_data->pins_default))
+			dev_warn(mmc_dev(host->mmc), "could not get default state\n");
+	}
 
 	if (esdhc_is_usdhc(imx_data)) {
 		host->quirks2 |= SDHCI_QUIRK2_PRESET_VALUE_BROKEN;
 		host->mmc->caps |= MMC_CAP_1_8V_DDR | MMC_CAP_3_3V_DDR;
-
-		/* GPIO CD can be set as a wakeup source */
-		host->mmc->caps |= MMC_CAP_CD_WAKE;
-
 		if (!(imx_data->socdata->flags & ESDHC_FLAG_HS200))
 			host->quirks2 |= SDHCI_QUIRK2_BROKEN_HS200;
 
@@ -1702,9 +1644,6 @@ static int sdhci_esdhc_imx_probe(struct platform_device *pdev)
 	if (imx_data->socdata->flags & ESDHC_FLAG_HS400)
 		host->quirks2 |= SDHCI_QUIRK2_CAPS_BIT63_FOR_HS400;
 
-	if (imx_data->socdata->flags & ESDHC_FLAG_BROKEN_AUTO_CMD23)
-		host->quirks2 |= SDHCI_QUIRK2_ACMD23_BROKEN;
-
 	if (imx_data->socdata->flags & ESDHC_FLAG_HS400_ES) {
 		host->mmc->caps2 |= MMC_CAP2_HS400_ES;
 		host->mmc_host_ops.hs400_enhanced_strobe =
@@ -1725,6 +1664,10 @@ static int sdhci_esdhc_imx_probe(struct platform_device *pdev)
 		err = cqhci_init(cq_host, host->mmc, false);
 		if (err)
 			goto disable_ahb_clk;
+
+		status = cqhci_readl(cq_host, CQHCI_IS);
+		cqhci_writel(cq_host, status, CQHCI_IS);
+		cqhci_writel(cq_host, CQHCI_HALT, CQHCI_CTL);
 	}
 
 	if (of_id)
@@ -1734,8 +1677,14 @@ static int sdhci_esdhc_imx_probe(struct platform_device *pdev)
 	if (err)
 		goto disable_ahb_clk;
 
+	host->tuning_delay = 1;
+
 	sdhci_esdhc_imx_hwinit(host);
 
+	if ((host->mmc->pm_caps & MMC_PM_KEEP_POWER) &&
+		(host->mmc->pm_caps & MMC_PM_WAKE_SDIO_IRQ))
+		device_set_wakeup_capable(&pdev->dev, 1);
+
 	err = sdhci_add_host(host);
 	if (err)
 		goto disable_ahb_clk;
@@ -1746,6 +1695,10 @@ static int sdhci_esdhc_imx_probe(struct platform_device *pdev)
 	pm_suspend_ignore_children(&pdev->dev, 1);
 	pm_runtime_enable(&pdev->dev);
 
+	if (slot_index < MCI_SLOT_NUM) {
+            mci_host[slot_index++] = host;
+	}
+
 	return 0;
 
 disable_ahb_clk:
@@ -1757,6 +1710,9 @@ static int sdhci_esdhc_imx_probe(struct platform_device *pdev)
 free_sdhci:
 	if (imx_data->socdata->flags & ESDHC_FLAG_PMQOS)
 		cpu_latency_qos_remove_request(&imx_data->pm_qos_req);
+	if (imx_data->socdata->flags & ESDHC_FLAG_BUSFREQ)
+		release_bus_freq(BUS_FREQ_HIGH);
+
 	sdhci_pltfm_free(pdev);
 	return err;
 }
@@ -1766,10 +1722,9 @@ static int sdhci_esdhc_imx_remove(struct platform_device *pdev)
 	struct sdhci_host *host = platform_get_drvdata(pdev);
 	struct sdhci_pltfm_host *pltfm_host = sdhci_priv(host);
 	struct pltfm_imx_data *imx_data = sdhci_pltfm_priv(pltfm_host);
-	int dead;
+	int dead = (readl(host->ioaddr + SDHCI_INT_STATUS) == 0xffffffff);
 
 	pm_runtime_get_sync(&pdev->dev);
-	dead = (readl(host->ioaddr + SDHCI_INT_STATUS) == 0xffffffff);
 	pm_runtime_disable(&pdev->dev);
 	pm_runtime_put_noidle(&pdev->dev);
 
@@ -1781,12 +1736,43 @@ static int sdhci_esdhc_imx_remove(struct platform_device *pdev)
 
 	if (imx_data->socdata->flags & ESDHC_FLAG_PMQOS)
 		cpu_latency_qos_remove_request(&imx_data->pm_qos_req);
+	if (imx_data->socdata->flags & ESDHC_FLAG_BUSFREQ)
+		release_bus_freq(BUS_FREQ_HIGH);
 
 	sdhci_pltfm_free(pdev);
 
 	return 0;
 }
 
+void sdhci_esdhc_sdio_rescan(int slot)
+{
+    if (slot >= MCI_SLOT_NUM || slot < 0) {
+        return;
+    }
+
+    if (NULL == mci_host[slot] ||
+        NULL == mci_host[slot]->mmc) {
+        return;
+    }
+
+    mmc_detect_change(mci_host[slot]->mmc, 0);
+}
+EXPORT_SYMBOL(sdhci_esdhc_sdio_rescan);
+
+struct mmc_host *sdhci_esdhc_get_mmc_host(int slot)
+{
+    if (slot >= MCI_SLOT_NUM || slot < 0) {
+        return NULL;
+    }
+
+    if (mci_host[slot] == NULL) {
+        return NULL;
+    }
+
+    return mci_host[slot]->mmc;
+}
+EXPORT_SYMBOL(sdhci_esdhc_get_mmc_host);
+
 #ifdef CONFIG_PM_SLEEP
 static int sdhci_esdhc_suspend(struct device *dev)
 {
@@ -1795,6 +1781,8 @@ static int sdhci_esdhc_suspend(struct device *dev)
 	struct pltfm_imx_data *imx_data = sdhci_pltfm_priv(pltfm_host);
 	int ret;
 
+	pm_runtime_get_sync(dev);
+
 	if (host->mmc->caps2 & MMC_CAP2_CQE) {
 		ret = cqhci_suspend(host->mmc);
 		if (ret)
@@ -1811,14 +1799,17 @@ static int sdhci_esdhc_suspend(struct device *dev)
 		mmc_retune_needed(host->mmc);
 
 	ret = sdhci_suspend_host(host);
-	if (ret)
-		return ret;
+	pinctrl_pm_select_sleep_state(dev);
 
-	ret = pinctrl_pm_select_sleep_state(dev);
-	if (ret)
-		return ret;
+	if (!sdhci_sdio_irq_enabled(host)) {
+		clk_disable_unprepare(imx_data->clk_per);
+		clk_disable_unprepare(imx_data->clk_ipg);
+	}
+	clk_disable_unprepare(imx_data->clk_ahb);
+
+	pm_runtime_disable(dev);
+	pm_runtime_set_suspended(dev);
 
-	ret = mmc_gpio_set_cd_wake(host->mmc, true);
 
 	return ret;
 }
@@ -1826,11 +1817,20 @@ static int sdhci_esdhc_suspend(struct device *dev)
 static int sdhci_esdhc_resume(struct device *dev)
 {
 	struct sdhci_host *host = dev_get_drvdata(dev);
+	struct sdhci_pltfm_host *pltfm_host = sdhci_priv(host);
+	struct pltfm_imx_data *imx_data = sdhci_pltfm_priv(pltfm_host);
 	int ret;
 
-	ret = pinctrl_pm_select_default_state(dev);
-	if (ret)
-		return ret;
+	if (!sdhci_sdio_irq_enabled(host)) {
+		clk_prepare_enable(imx_data->clk_per);
+		clk_prepare_enable(imx_data->clk_ipg);
+	}
+	clk_prepare_enable(imx_data->clk_ahb);
+
+	pm_runtime_set_active(dev);
+	pm_runtime_enable(dev);
+
+	pinctrl_pm_select_default_state(dev);
 
 	/* re-initialize hw state in case it's lost in low power mode */
 	sdhci_esdhc_imx_hwinit(host);
@@ -1842,9 +1842,8 @@ static int sdhci_esdhc_resume(struct device *dev)
 	if (host->mmc->caps2 & MMC_CAP2_CQE)
 		ret = cqhci_resume(host->mmc);
 
-	if (!ret)
-		ret = mmc_gpio_set_cd_wake(host->mmc, false);
-
+	pm_runtime_mark_last_busy(dev);
+	pm_runtime_put_autosuspend(dev);
 	return ret;
 }
 #endif
@@ -1870,14 +1869,18 @@ static int sdhci_esdhc_runtime_suspend(struct device *dev)
 	if (host->tuning_mode != SDHCI_TUNING_MODE_3)
 		mmc_retune_needed(host->mmc);
 
-	imx_data->actual_clock = host->mmc->actual_clock;
-	esdhc_pltfm_set_clock(host, 0);
-	clk_disable_unprepare(imx_data->clk_per);
-	clk_disable_unprepare(imx_data->clk_ipg);
+	if (!sdhci_sdio_irq_enabled(host)) {
+		imx_data->actual_clock = host->mmc->actual_clock;
+		esdhc_pltfm_set_clock(host, 0);
+		clk_disable_unprepare(imx_data->clk_per);
+		clk_disable_unprepare(imx_data->clk_ipg);
+	}
 	clk_disable_unprepare(imx_data->clk_ahb);
 
 	if (imx_data->socdata->flags & ESDHC_FLAG_PMQOS)
 		cpu_latency_qos_remove_request(&imx_data->pm_qos_req);
+	if (imx_data->socdata->flags & ESDHC_FLAG_BUSFREQ)
+		release_bus_freq(BUS_FREQ_HIGH);
 
 	return ret;
 }
@@ -1889,6 +1892,9 @@ static int sdhci_esdhc_runtime_resume(struct device *dev)
 	struct pltfm_imx_data *imx_data = sdhci_pltfm_priv(pltfm_host);
 	int err;
 
+	if (imx_data->socdata->flags & ESDHC_FLAG_BUSFREQ)
+		request_bus_freq(BUS_FREQ_HIGH);
+
 	if (imx_data->socdata->flags & ESDHC_FLAG_PMQOS)
 		cpu_latency_qos_add_request(&imx_data->pm_qos_req, 0);
 
@@ -1899,15 +1905,15 @@ static int sdhci_esdhc_runtime_resume(struct device *dev)
 	if (err)
 		goto remove_pm_qos_request;
 
-	err = clk_prepare_enable(imx_data->clk_per);
-	if (err)
-		goto disable_ahb_clk;
-
-	err = clk_prepare_enable(imx_data->clk_ipg);
-	if (err)
-		goto disable_per_clk;
-
-	esdhc_pltfm_set_clock(host, imx_data->actual_clock);
+	if (!sdhci_sdio_irq_enabled(host)) {
+		err = clk_prepare_enable(imx_data->clk_per);
+		if (err)
+			goto disable_ahb_clk;
+		err = clk_prepare_enable(imx_data->clk_ipg);
+		if (err)
+			goto disable_per_clk;
+		esdhc_pltfm_set_clock(host, imx_data->actual_clock);
+	}
 
 	err = sdhci_runtime_resume_host(host, 0);
 	if (err)
@@ -1919,14 +1925,18 @@ static int sdhci_esdhc_runtime_resume(struct device *dev)
 	return err;
 
 disable_ipg_clk:
-	clk_disable_unprepare(imx_data->clk_ipg);
+	if (!sdhci_sdio_irq_enabled(host))
+		clk_disable_unprepare(imx_data->clk_ipg);
 disable_per_clk:
-	clk_disable_unprepare(imx_data->clk_per);
+	if (!sdhci_sdio_irq_enabled(host))
+		clk_disable_unprepare(imx_data->clk_per);
 disable_ahb_clk:
 	clk_disable_unprepare(imx_data->clk_ahb);
 remove_pm_qos_request:
 	if (imx_data->socdata->flags & ESDHC_FLAG_PMQOS)
 		cpu_latency_qos_remove_request(&imx_data->pm_qos_req);
+	if (imx_data->socdata->flags & ESDHC_FLAG_BUSFREQ)
+		release_bus_freq(BUS_FREQ_HIGH);
 	return err;
 }
 #endif
@@ -1940,7 +1950,6 @@ static const struct dev_pm_ops sdhci_esdhc_pmops = {
 static struct platform_driver sdhci_esdhc_imx_driver = {
 	.driver		= {
 		.name	= "sdhci-esdhc-imx",
-		.probe_type = PROBE_PREFER_ASYNCHRONOUS,
 		.of_match_table = imx_esdhc_dt_ids,
 		.pm	= &sdhci_esdhc_pmops,
 	},
diff --git a/drivers/mmc/host/sdhci-esdhc.h b/drivers/mmc/host/sdhci-esdhc.h
index 6de02f09c..947212f16 100644
--- a/drivers/mmc/host/sdhci-esdhc.h
+++ b/drivers/mmc/host/sdhci-esdhc.h
@@ -5,8 +5,7 @@
  * Copyright (c) 2007 Freescale Semiconductor, Inc.
  * Copyright (c) 2009 MontaVista Software, Inc.
  * Copyright (c) 2010 Pengutronix e.K.
- * Copyright 2020 NXP
- *   Author: Wolfram Sang <kernel@pengutronix.de>
+ *   Author: Wolfram Sang <w.sang@pengutronix.de>
  */
 
 #ifndef _DRIVERS_MMC_SDHCI_ESDHC_H
@@ -89,7 +88,6 @@
 /* DLL Config 0 Register */
 #define ESDHC_DLLCFG0			0x160
 #define ESDHC_DLL_ENABLE		0x80000000
-#define ESDHC_DLL_RESET			0x40000000
 #define ESDHC_DLL_FREQ_SEL		0x08000000
 
 /* DLL Config 1 Register */
diff --git a/drivers/mmc/host/sdhci-iproc.c b/drivers/mmc/host/sdhci-iproc.c
index b9eb2ec61..f4f5f0a70 100644
--- a/drivers/mmc/host/sdhci-iproc.c
+++ b/drivers/mmc/host/sdhci-iproc.c
@@ -173,23 +173,6 @@ static unsigned int sdhci_iproc_get_max_clock(struct sdhci_host *host)
 		return pltfm_host->clock;
 }
 
-/*
- * There is a known bug on BCM2711's SDHCI core integration where the
- * controller will hang when the difference between the core clock and the bus
- * clock is too great. Specifically this can be reproduced under the following
- * conditions:
- *
- *  - No SD card plugged in, polling thread is running, probing cards at
- *    100 kHz.
- *  - BCM2711's core clock configured at 500MHz or more
- *
- * So we set 200kHz as the minimum clock frequency available for that SoC.
- */
-static unsigned int sdhci_iproc_bcm2711_get_min_clock(struct sdhci_host *host)
-{
-	return 200000;
-}
-
 static const struct sdhci_ops sdhci_iproc_ops = {
 	.set_clock = sdhci_set_clock,
 	.get_max_clock = sdhci_iproc_get_max_clock,
@@ -278,30 +261,13 @@ static const struct sdhci_iproc_data bcm2835_data = {
 	.mmc_caps = 0x00000000,
 };
 
-static const struct sdhci_ops sdhci_iproc_bcm2711_ops = {
-	.read_l = sdhci_iproc_readl,
-	.read_w = sdhci_iproc_readw,
-	.read_b = sdhci_iproc_readb,
-	.write_l = sdhci_iproc_writel,
-	.write_w = sdhci_iproc_writew,
-	.write_b = sdhci_iproc_writeb,
-	.set_clock = sdhci_set_clock,
-	.set_power = sdhci_set_power_and_bus_voltage,
-	.get_max_clock = sdhci_iproc_get_max_clock,
-	.get_min_clock = sdhci_iproc_bcm2711_get_min_clock,
-	.set_bus_width = sdhci_set_bus_width,
-	.reset = sdhci_reset,
-	.set_uhs_signaling = sdhci_set_uhs_signaling,
-};
-
 static const struct sdhci_pltfm_data sdhci_bcm2711_pltfm_data = {
 	.quirks = SDHCI_QUIRK_MULTIBLOCK_READ_ACMD12,
-	.ops = &sdhci_iproc_bcm2711_ops,
+	.ops = &sdhci_iproc_32only_ops,
 };
 
 static const struct sdhci_iproc_data bcm2711_data = {
 	.pdata = &sdhci_bcm2711_pltfm_data,
-	.mmc_caps = MMC_CAP_3_3V_DDR,
 };
 
 static const struct of_device_id sdhci_iproc_of_match[] = {
@@ -313,32 +279,12 @@ static const struct of_device_id sdhci_iproc_of_match[] = {
 };
 MODULE_DEVICE_TABLE(of, sdhci_iproc_of_match);
 
-#ifdef CONFIG_ACPI
-/*
- * This is a duplicate of bcm2835_(pltfrm_)data without caps quirks
- * which are provided by the ACPI table.
- */
-static const struct sdhci_pltfm_data sdhci_bcm_arasan_data = {
-	.quirks = SDHCI_QUIRK_BROKEN_CARD_DETECTION |
-		  SDHCI_QUIRK_DATA_TIMEOUT_USES_SDCLK |
-		  SDHCI_QUIRK_NO_HISPD_BIT,
-	.quirks2 = SDHCI_QUIRK2_PRESET_VALUE_BROKEN,
-	.ops = &sdhci_iproc_32only_ops,
-};
-
-static const struct sdhci_iproc_data bcm_arasan_data = {
-	.pdata = &sdhci_bcm_arasan_data,
-};
-
 static const struct acpi_device_id sdhci_iproc_acpi_ids[] = {
 	{ .id = "BRCM5871", .driver_data = (kernel_ulong_t)&iproc_cygnus_data },
 	{ .id = "BRCM5872", .driver_data = (kernel_ulong_t)&iproc_data },
-	{ .id = "BCM2847",  .driver_data = (kernel_ulong_t)&bcm_arasan_data },
-	{ .id = "BRCME88C", .driver_data = (kernel_ulong_t)&bcm2711_data },
 	{ /* sentinel */ }
 };
 MODULE_DEVICE_TABLE(acpi, sdhci_iproc_acpi_ids);
-#endif
 
 static int sdhci_iproc_probe(struct platform_device *pdev)
 {
@@ -405,7 +351,6 @@ static int sdhci_iproc_probe(struct platform_device *pdev)
 static struct platform_driver sdhci_iproc_driver = {
 	.driver = {
 		.name = "sdhci-iproc",
-		.probe_type = PROBE_PREFER_ASYNCHRONOUS,
 		.of_match_table = sdhci_iproc_of_match,
 		.acpi_match_table = ACPI_PTR(sdhci_iproc_acpi_ids),
 		.pm = &sdhci_pltfm_pmops,
diff --git a/drivers/mmc/host/sdhci-msm.c b/drivers/mmc/host/sdhci-msm.c
index 588b9a564..b75c82d8d 100644
--- a/drivers/mmc/host/sdhci-msm.c
+++ b/drivers/mmc/host/sdhci-msm.c
@@ -10,15 +10,11 @@
 #include <linux/delay.h>
 #include <linux/mmc/mmc.h>
 #include <linux/pm_runtime.h>
-#include <linux/pm_opp.h>
 #include <linux/slab.h>
 #include <linux/iopoll.h>
 #include <linux/regulator/consumer.h>
-#include <linux/interconnect.h>
-#include <linux/pinctrl/consumer.h>
 
 #include "sdhci-pltfm.h"
-#include "cqhci.h"
 
 #define CORE_MCI_VERSION		0x50
 #define CORE_VERSION_MAJOR_SHIFT	28
@@ -38,9 +34,7 @@
 #define CORE_PWRCTL_IO_LOW	BIT(2)
 #define CORE_PWRCTL_IO_HIGH	BIT(3)
 #define CORE_PWRCTL_BUS_SUCCESS BIT(0)
-#define CORE_PWRCTL_BUS_FAIL    BIT(1)
 #define CORE_PWRCTL_IO_SUCCESS	BIT(2)
-#define CORE_PWRCTL_IO_FAIL     BIT(3)
 #define REQ_BUS_OFF		BIT(0)
 #define REQ_BUS_ON		BIT(1)
 #define REQ_IO_LOW		BIT(2)
@@ -61,27 +55,19 @@
 #define CORE_FLL_CYCLE_CNT	BIT(18)
 #define CORE_DLL_CLOCK_DISABLE	BIT(21)
 
-#define DLL_USR_CTL_POR_VAL	0x10800
-#define ENABLE_DLL_LOCK_STATUS	BIT(26)
-#define FINE_TUNE_MODE_EN	BIT(27)
-#define BIAS_OK_SIGNAL		BIT(29)
-
-#define DLL_CONFIG_3_LOW_FREQ_VAL	0x08
-#define DLL_CONFIG_3_HIGH_FREQ_VAL	0x10
-
-#define CORE_VENDOR_SPEC_POR_VAL 0xa9c
+#define CORE_VENDOR_SPEC_POR_VAL 0xa1c
 #define CORE_CLK_PWRSAVE	BIT(1)
 #define CORE_HC_MCLK_SEL_DFLT	(2 << 8)
 #define CORE_HC_MCLK_SEL_HS400	(3 << 8)
 #define CORE_HC_MCLK_SEL_MASK	(3 << 8)
-#define CORE_IO_PAD_PWR_SWITCH_EN	BIT(15)
-#define CORE_IO_PAD_PWR_SWITCH	BIT(16)
+#define CORE_IO_PAD_PWR_SWITCH_EN	(1 << 15)
+#define CORE_IO_PAD_PWR_SWITCH  (1 << 16)
 #define CORE_HC_SELECT_IN_EN	BIT(18)
 #define CORE_HC_SELECT_IN_HS400	(6 << 19)
 #define CORE_HC_SELECT_IN_MASK	(7 << 19)
 
-#define CORE_3_0V_SUPPORT	BIT(25)
-#define CORE_1_8V_SUPPORT	BIT(26)
+#define CORE_3_0V_SUPPORT	(1 << 25)
+#define CORE_1_8V_SUPPORT	(1 << 26)
 #define CORE_VOLT_SUPPORT	(CORE_3_0V_SUPPORT | CORE_1_8V_SUPPORT)
 
 #define CORE_CSR_CDC_CTLR_CFG0		0x130
@@ -113,7 +99,7 @@
 
 #define CORE_PWRSAVE_DLL	BIT(3)
 
-#define DDR_CONFIG_POR_VAL	0x80040873
+#define DDR_CONFIG_POR_VAL	0x80040853
 
 
 #define INVALID_TUNING_PHASE	-1
@@ -130,19 +116,12 @@
 /* Timeout value to avoid infinite waiting for pwr_irq */
 #define MSM_PWR_IRQ_TIMEOUT_MS 5000
 
-/* Max load for eMMC Vdd-io supply */
-#define MMC_VQMMC_MAX_LOAD_UA	325000
-
 #define msm_host_readl(msm_host, host, offset) \
 	msm_host->var_ops->msm_readl_relaxed(host, offset)
 
 #define msm_host_writel(msm_host, val, host, offset) \
 	msm_host->var_ops->msm_writel_relaxed(val, host, offset)
 
-/* CQHCI vendor specific registers */
-#define CQHCI_VENDOR_CFG1	0xA00
-#define CQHCI_VENDOR_DIS_RST_ON_CQ_EN	(0x3 << 13)
-
 struct sdhci_msm_offset {
 	u32 core_hc_mode;
 	u32 core_mci_data_cnt;
@@ -169,10 +148,8 @@ struct sdhci_msm_offset {
 	u32 core_ddr_200_cfg;
 	u32 core_vendor_spec3;
 	u32 core_dll_config_2;
-	u32 core_dll_config_3;
-	u32 core_ddr_config_old; /* Applicable to sdcc minor ver < 0x49 */
 	u32 core_ddr_config;
-	u32 core_dll_usr_ctl; /* Present on SDCC5.1 onwards */
+	u32 core_ddr_config_2;
 };
 
 static const struct sdhci_msm_offset sdhci_msm_v5_offset = {
@@ -200,9 +177,8 @@ static const struct sdhci_msm_offset sdhci_msm_v5_offset = {
 	.core_ddr_200_cfg = 0x224,
 	.core_vendor_spec3 = 0x250,
 	.core_dll_config_2 = 0x254,
-	.core_dll_config_3 = 0x258,
-	.core_ddr_config = 0x25c,
-	.core_dll_usr_ctl = 0x388,
+	.core_ddr_config = 0x258,
+	.core_ddr_config_2 = 0x25c,
 };
 
 static const struct sdhci_msm_offset sdhci_msm_mci_offset = {
@@ -231,8 +207,8 @@ static const struct sdhci_msm_offset sdhci_msm_mci_offset = {
 	.core_ddr_200_cfg = 0x184,
 	.core_vendor_spec3 = 0x1b0,
 	.core_dll_config_2 = 0x1b4,
-	.core_ddr_config_old = 0x1b8,
-	.core_ddr_config = 0x1bc,
+	.core_ddr_config = 0x1b8,
+	.core_ddr_config_2 = 0x1bc,
 };
 
 struct sdhci_msm_variant_ops {
@@ -248,7 +224,6 @@ struct sdhci_msm_variant_ops {
 struct sdhci_msm_variant_info {
 	bool mci_removed;
 	bool restore_dll_config;
-	bool uses_tassadar_dll;
 	const struct sdhci_msm_variant_ops *var_ops;
 	const struct sdhci_msm_offset *offset;
 };
@@ -262,7 +237,6 @@ struct sdhci_msm_host {
 	struct clk_bulk_data bulk_clks[4]; /* core, iface, cal, sleep clocks */
 	unsigned long clk_rate;
 	struct mmc_host *mmc;
-	struct opp_table *opp_table;
 	bool use_14lpp_dll_reset;
 	bool tuning_done;
 	bool calibration_done;
@@ -279,11 +253,6 @@ struct sdhci_msm_host {
 	const struct sdhci_msm_offset *offset;
 	bool use_cdr;
 	u32 transfer_mode;
-	bool updated_ddr_cfg;
-	bool uses_tassadar_dll;
-	u32 dll_config;
-	u32 ddr_config;
-	bool vqmmc_enabled;
 };
 
 static const struct sdhci_msm_offset *sdhci_priv_msm_offset(struct sdhci_host *host)
@@ -356,7 +325,7 @@ static void msm_set_clock_rate_for_bus_mode(struct sdhci_host *host,
 	int rc;
 
 	clock = msm_get_clock_rate_for_bus_mode(host, clock);
-	rc = dev_pm_opp_set_rate(mmc_dev(host->mmc), clock);
+	rc = clk_set_rate(core_clk, clock);
 	if (rc) {
 		pr_err("%s: Failed to set clock at rate %u at timing %d\n",
 		       mmc_hostname(host->mmc), clock,
@@ -625,10 +594,6 @@ static int msm_init_cm_dll(struct sdhci_host *host)
 	config &= ~CORE_CLK_PWRSAVE;
 	writel_relaxed(config, host->ioaddr + msm_offset->core_vendor_spec);
 
-	if (msm_host->dll_config)
-		writel_relaxed(msm_host->dll_config,
-				host->ioaddr + msm_offset->core_dll_config);
-
 	if (msm_host->use_14lpp_dll_reset) {
 		config = readl_relaxed(host->ioaddr +
 				msm_offset->core_dll_config);
@@ -654,9 +619,7 @@ static int msm_init_cm_dll(struct sdhci_host *host)
 	config |= CORE_DLL_PDN;
 	writel_relaxed(config, host->ioaddr +
 			msm_offset->core_dll_config);
-
-	if (!msm_host->dll_config)
-		msm_cm_dll_set_freq(host);
+	msm_cm_dll_set_freq(host);
 
 	if (msm_host->use_14lpp_dll_reset &&
 	    !IS_ERR_OR_NULL(msm_host->xo_clk)) {
@@ -696,8 +659,7 @@ static int msm_init_cm_dll(struct sdhci_host *host)
 			msm_offset->core_dll_config);
 
 	if (msm_host->use_14lpp_dll_reset) {
-		if (!msm_host->dll_config)
-			msm_cm_dll_set_freq(host);
+		msm_cm_dll_set_freq(host);
 		config = readl_relaxed(host->ioaddr +
 				msm_offset->core_dll_config_2);
 		config &= ~CORE_DLL_CLOCK_DISABLE;
@@ -705,27 +667,6 @@ static int msm_init_cm_dll(struct sdhci_host *host)
 				msm_offset->core_dll_config_2);
 	}
 
-	/*
-	 * Configure DLL user control register to enable DLL status.
-	 * This setting is applicable to SDCC v5.1 onwards only.
-	 */
-	if (msm_host->uses_tassadar_dll) {
-		config = DLL_USR_CTL_POR_VAL | FINE_TUNE_MODE_EN |
-			ENABLE_DLL_LOCK_STATUS | BIAS_OK_SIGNAL;
-		writel_relaxed(config, host->ioaddr +
-				msm_offset->core_dll_usr_ctl);
-
-		config = readl_relaxed(host->ioaddr +
-				msm_offset->core_dll_config_3);
-		config &= ~0xFF;
-		if (msm_host->clk_rate < 150000000)
-			config |= DLL_CONFIG_3_LOW_FREQ_VAL;
-		else
-			config |= DLL_CONFIG_3_HIGH_FREQ_VAL;
-		writel_relaxed(config, host->ioaddr +
-			msm_offset->core_dll_config_3);
-	}
-
 	config = readl_relaxed(host->ioaddr +
 			msm_offset->core_dll_config);
 	config |= CORE_DLL_EN;
@@ -983,10 +924,8 @@ static int sdhci_msm_cdclp533_calibration(struct sdhci_host *host)
 static int sdhci_msm_cm_dll_sdc4_calibration(struct sdhci_host *host)
 {
 	struct mmc_host *mmc = host->mmc;
-	u32 dll_status, config, ddr_cfg_offset;
+	u32 dll_status, config;
 	int ret;
-	struct sdhci_pltfm_host *pltfm_host = sdhci_priv(host);
-	struct sdhci_msm_host *msm_host = sdhci_pltfm_priv(pltfm_host);
 	const struct sdhci_msm_offset *msm_offset =
 					sdhci_priv_msm_offset(host);
 
@@ -999,11 +938,8 @@ static int sdhci_msm_cm_dll_sdc4_calibration(struct sdhci_host *host)
 	 * bootloaders. In the future, if this changes, then the desired
 	 * values will need to be programmed appropriately.
 	 */
-	if (msm_host->updated_ddr_cfg)
-		ddr_cfg_offset = msm_offset->core_ddr_config;
-	else
-		ddr_cfg_offset = msm_offset->core_ddr_config_old;
-	writel_relaxed(msm_host->ddr_config, host->ioaddr + ddr_cfg_offset);
+	writel_relaxed(DDR_CONFIG_POR_VAL, host->ioaddr +
+			msm_offset->core_ddr_config);
 
 	if (mmc->ios.enhanced_strobe) {
 		config = readl_relaxed(host->ioaddr +
@@ -1029,21 +965,9 @@ static int sdhci_msm_cm_dll_sdc4_calibration(struct sdhci_host *host)
 		goto out;
 	}
 
-	/*
-	 * Set CORE_PWRSAVE_DLL bit in CORE_VENDOR_SPEC3.
-	 * When MCLK is gated OFF, it is not gated for less than 0.5us
-	 * and MCLK must be switched on for at-least 1us before DATA
-	 * starts coming. Controllers with 14lpp and later tech DLL cannot
-	 * guarantee above requirement. So PWRSAVE_DLL should not be
-	 * turned on for host controllers using this DLL.
-	 */
-	if (!msm_host->use_14lpp_dll_reset) {
-		config = readl_relaxed(host->ioaddr +
-				msm_offset->core_vendor_spec3);
-		config |= CORE_PWRSAVE_DLL;
-		writel_relaxed(config, host->ioaddr +
-				msm_offset->core_vendor_spec3);
-	}
+	config = readl_relaxed(host->ioaddr + msm_offset->core_vendor_spec3);
+	config |= CORE_PWRSAVE_DLL;
+	writel_relaxed(config, host->ioaddr + msm_offset->core_vendor_spec3);
 
 	/*
 	 * Drain writebuffer to ensure above DLL calibration
@@ -1165,7 +1089,7 @@ static void sdhci_msm_set_cdr(struct sdhci_host *host, bool enable)
 static int sdhci_msm_execute_tuning(struct mmc_host *mmc, u32 opcode)
 {
 	struct sdhci_host *host = mmc_priv(mmc);
-	int tuning_seq_cnt = 10;
+	int tuning_seq_cnt = 3;
 	u8 phase, tuned_phases[16], tuned_phase_cnt = 0;
 	int rc;
 	struct mmc_ios ios = host->mmc->ios;
@@ -1181,12 +1105,6 @@ static int sdhci_msm_execute_tuning(struct mmc_host *mmc, u32 opcode)
 	/* Clock-Data-Recovery used to dynamically adjust RX sampling point */
 	msm_host->use_cdr = true;
 
-	/*
-	 * Clear tuning_done flag before tuning to ensure proper
-	 * HS400 settings.
-	 */
-	msm_host->tuning_done = 0;
-
 	/*
 	 * For HS400 tuning in HS200 timing requires:
 	 * - select MCLK/2 in VENDOR_SPEC
@@ -1221,22 +1139,6 @@ static int sdhci_msm_execute_tuning(struct mmc_host *mmc, u32 opcode)
 	} while (++phase < ARRAY_SIZE(tuned_phases));
 
 	if (tuned_phase_cnt) {
-		if (tuned_phase_cnt == ARRAY_SIZE(tuned_phases)) {
-			/*
-			 * All phases valid is _almost_ as bad as no phases
-			 * valid.  Probably all phases are not really reliable
-			 * but we didn't detect where the unreliable place is.
-			 * That means we'll essentially be guessing and hoping
-			 * we get a good phase.  Better to try a few times.
-			 */
-			dev_dbg(mmc_dev(mmc), "%s: All phases valid; try again\n",
-				mmc_hostname(mmc));
-			if (--tuning_seq_cnt) {
-				tuned_phase_cnt = 0;
-				goto retry;
-			}
-		}
-
 		rc = msm_find_most_appropriate_phase(host, tuned_phases,
 						     tuned_phase_cnt);
 		if (rc < 0)
@@ -1369,108 +1271,6 @@ static void sdhci_msm_set_uhs_signaling(struct sdhci_host *host,
 		sdhci_msm_hs400(host, &mmc->ios);
 }
 
-static int sdhci_msm_set_pincfg(struct sdhci_msm_host *msm_host, bool level)
-{
-	struct platform_device *pdev = msm_host->pdev;
-	int ret;
-
-	if (level)
-		ret = pinctrl_pm_select_default_state(&pdev->dev);
-	else
-		ret = pinctrl_pm_select_sleep_state(&pdev->dev);
-
-	return ret;
-}
-
-static int sdhci_msm_set_vmmc(struct mmc_host *mmc)
-{
-	if (IS_ERR(mmc->supply.vmmc))
-		return 0;
-
-	return mmc_regulator_set_ocr(mmc, mmc->supply.vmmc, mmc->ios.vdd);
-}
-
-static int msm_toggle_vqmmc(struct sdhci_msm_host *msm_host,
-			      struct mmc_host *mmc, bool level)
-{
-	int ret;
-	struct mmc_ios ios;
-
-	if (msm_host->vqmmc_enabled == level)
-		return 0;
-
-	if (level) {
-		/* Set the IO voltage regulator to default voltage level */
-		if (msm_host->caps_0 & CORE_3_0V_SUPPORT)
-			ios.signal_voltage = MMC_SIGNAL_VOLTAGE_330;
-		else if (msm_host->caps_0 & CORE_1_8V_SUPPORT)
-			ios.signal_voltage = MMC_SIGNAL_VOLTAGE_180;
-
-		if (msm_host->caps_0 & CORE_VOLT_SUPPORT) {
-			ret = mmc_regulator_set_vqmmc(mmc, &ios);
-			if (ret < 0) {
-				dev_err(mmc_dev(mmc), "%s: vqmmc set volgate failed: %d\n",
-					mmc_hostname(mmc), ret);
-				goto out;
-			}
-		}
-		ret = regulator_enable(mmc->supply.vqmmc);
-	} else {
-		ret = regulator_disable(mmc->supply.vqmmc);
-	}
-
-	if (ret)
-		dev_err(mmc_dev(mmc), "%s: vqmm %sable failed: %d\n",
-			mmc_hostname(mmc), level ? "en":"dis", ret);
-	else
-		msm_host->vqmmc_enabled = level;
-out:
-	return ret;
-}
-
-static int msm_config_vqmmc_mode(struct sdhci_msm_host *msm_host,
-			      struct mmc_host *mmc, bool hpm)
-{
-	int load, ret;
-
-	load = hpm ? MMC_VQMMC_MAX_LOAD_UA : 0;
-	ret = regulator_set_load(mmc->supply.vqmmc, load);
-	if (ret)
-		dev_err(mmc_dev(mmc), "%s: vqmmc set load failed: %d\n",
-			mmc_hostname(mmc), ret);
-	return ret;
-}
-
-static int sdhci_msm_set_vqmmc(struct sdhci_msm_host *msm_host,
-			      struct mmc_host *mmc, bool level)
-{
-	int ret;
-	bool always_on;
-
-	if (IS_ERR(mmc->supply.vqmmc) ||
-			(mmc->ios.power_mode == MMC_POWER_UNDEFINED))
-		return 0;
-	/*
-	 * For eMMC don't turn off Vqmmc, Instead just configure it in LPM
-	 * and HPM modes by setting the corresponding load.
-	 *
-	 * Till eMMC is initialized (i.e. always_on == 0), just turn on/off
-	 * Vqmmc. Vqmmc gets turned off only if init fails and mmc_power_off
-	 * gets invoked. Once eMMC is initialized (i.e. always_on == 1),
-	 * Vqmmc should remain ON, So just set the load instead of turning it
-	 * off/on.
-	 */
-	always_on = !mmc_card_is_removable(mmc) &&
-			mmc->card && mmc_card_mmc(mmc->card);
-
-	if (always_on)
-		ret = msm_config_vqmmc_mode(msm_host, mmc, level);
-	else
-		ret = msm_toggle_vqmmc(msm_host, mmc, level);
-
-	return ret;
-}
-
 static inline void sdhci_msm_init_pwr_irq_wait(struct sdhci_msm_host *msm_host)
 {
 	init_waitqueue_head(&msm_host->pwr_irq_wait);
@@ -1488,7 +1288,7 @@ static inline void sdhci_msm_complete_pwr_irq_wait(
  * To what state the register writes will change the IO lines should be passed
  * as the argument req_type. This API will check whether the IO line's state
  * is already the expected state and will wait for power irq only if
- * power irq is expected to be triggered based on the current IO line state
+ * power irq is expected to be trigerred based on the current IO line state
  * and expected IO line state.
  */
 static void sdhci_msm_check_power_status(struct sdhci_host *host, u32 req_type)
@@ -1574,9 +1374,8 @@ static void sdhci_msm_handle_pwr_irq(struct sdhci_host *host, int irq)
 {
 	struct sdhci_pltfm_host *pltfm_host = sdhci_priv(host);
 	struct sdhci_msm_host *msm_host = sdhci_pltfm_priv(pltfm_host);
-	struct mmc_host *mmc = host->mmc;
 	u32 irq_status, irq_ack = 0;
-	int retry = 10, ret;
+	int retry = 10;
 	u32 pwr_state = 0, io_level = 0;
 	u32 config;
 	const struct sdhci_msm_offset *msm_offset = msm_host->offset;
@@ -1614,45 +1413,21 @@ static void sdhci_msm_handle_pwr_irq(struct sdhci_host *host, int irq)
 	if (irq_status & CORE_PWRCTL_BUS_ON) {
 		pwr_state = REQ_BUS_ON;
 		io_level = REQ_IO_HIGH;
+		irq_ack |= CORE_PWRCTL_BUS_SUCCESS;
 	}
 	if (irq_status & CORE_PWRCTL_BUS_OFF) {
 		pwr_state = REQ_BUS_OFF;
 		io_level = REQ_IO_LOW;
+		irq_ack |= CORE_PWRCTL_BUS_SUCCESS;
 	}
-
-	if (pwr_state) {
-		ret = sdhci_msm_set_vmmc(mmc);
-		if (!ret)
-			ret = sdhci_msm_set_vqmmc(msm_host, mmc,
-					pwr_state & REQ_BUS_ON);
-		if (!ret)
-			ret = sdhci_msm_set_pincfg(msm_host,
-					pwr_state & REQ_BUS_ON);
-		if (!ret)
-			irq_ack |= CORE_PWRCTL_BUS_SUCCESS;
-		else
-			irq_ack |= CORE_PWRCTL_BUS_FAIL;
-	}
-
 	/* Handle IO LOW/HIGH */
-	if (irq_status & CORE_PWRCTL_IO_LOW)
+	if (irq_status & CORE_PWRCTL_IO_LOW) {
 		io_level = REQ_IO_LOW;
-
-	if (irq_status & CORE_PWRCTL_IO_HIGH)
+		irq_ack |= CORE_PWRCTL_IO_SUCCESS;
+	}
+	if (irq_status & CORE_PWRCTL_IO_HIGH) {
 		io_level = REQ_IO_HIGH;
-
-	if (io_level)
 		irq_ack |= CORE_PWRCTL_IO_SUCCESS;
-
-	if (io_level && !IS_ERR(mmc->supply.vqmmc) && !pwr_state) {
-		ret = mmc_regulator_set_vqmmc(mmc, &mmc->ios);
-		if (ret < 0) {
-			dev_err(mmc_dev(mmc), "%s: IO_level setting failed(%d). signal_voltage: %d, vdd: %d irq_status: 0x%08x\n",
-					mmc_hostname(mmc), ret,
-					mmc->ios.signal_voltage, mmc->ios.vdd,
-					irq_status);
-			irq_ack |= CORE_PWRCTL_IO_FAIL;
-		}
 	}
 
 	/*
@@ -1701,7 +1476,7 @@ static void sdhci_msm_handle_pwr_irq(struct sdhci_host *host, int irq)
 	if (io_level)
 		msm_host->curr_io_level = io_level;
 
-	dev_dbg(mmc_dev(mmc), "%s: %s: Handled IRQ(%d), irq_status=0x%x, ack=0x%x\n",
+	pr_debug("%s: %s: Handled IRQ(%d), irq_status=0x%x, ack=0x%x\n",
 		mmc_hostname(msm_host->mmc), __func__, irq, irq_status,
 		irq_ack);
 }
@@ -1734,7 +1509,7 @@ static unsigned int sdhci_msm_get_min_clock(struct sdhci_host *host)
 	return SDHCI_MSM_MIN_CLOCK;
 }
 
-/*
+/**
  * __sdhci_msm_set_clock - sdhci_msm clock control.
  *
  * Description:
@@ -1785,144 +1560,6 @@ static void sdhci_msm_set_clock(struct sdhci_host *host, unsigned int clock)
 	__sdhci_msm_set_clock(host, clock);
 }
 
-/*****************************************************************************\
- *                                                                           *
- * MSM Command Queue Engine (CQE)                                            *
- *                                                                           *
-\*****************************************************************************/
-
-static u32 sdhci_msm_cqe_irq(struct sdhci_host *host, u32 intmask)
-{
-	int cmd_error = 0;
-	int data_error = 0;
-
-	if (!sdhci_cqe_irq(host, intmask, &cmd_error, &data_error))
-		return intmask;
-
-	cqhci_irq(host->mmc, intmask, cmd_error, data_error);
-	return 0;
-}
-
-static void sdhci_msm_cqe_disable(struct mmc_host *mmc, bool recovery)
-{
-	struct sdhci_host *host = mmc_priv(mmc);
-	unsigned long flags;
-	u32 ctrl;
-
-	/*
-	 * When CQE is halted, the legacy SDHCI path operates only
-	 * on 16-byte descriptors in 64bit mode.
-	 */
-	if (host->flags & SDHCI_USE_64_BIT_DMA)
-		host->desc_sz = 16;
-
-	spin_lock_irqsave(&host->lock, flags);
-
-	/*
-	 * During CQE command transfers, command complete bit gets latched.
-	 * So s/w should clear command complete interrupt status when CQE is
-	 * either halted or disabled. Otherwise unexpected SDCHI legacy
-	 * interrupt gets triggered when CQE is halted/disabled.
-	 */
-	ctrl = sdhci_readl(host, SDHCI_INT_ENABLE);
-	ctrl |= SDHCI_INT_RESPONSE;
-	sdhci_writel(host,  ctrl, SDHCI_INT_ENABLE);
-	sdhci_writel(host, SDHCI_INT_RESPONSE, SDHCI_INT_STATUS);
-
-	spin_unlock_irqrestore(&host->lock, flags);
-
-	sdhci_cqe_disable(mmc, recovery);
-}
-
-static void sdhci_msm_set_timeout(struct sdhci_host *host, struct mmc_command *cmd)
-{
-	u32 count, start = 15;
-
-	__sdhci_set_timeout(host, cmd);
-	count = sdhci_readb(host, SDHCI_TIMEOUT_CONTROL);
-	/*
-	 * Update software timeout value if its value is less than hardware data
-	 * timeout value. Qcom SoC hardware data timeout value was calculated
-	 * using 4 * MCLK * 2^(count + 13). where MCLK = 1 / host->clock.
-	 */
-	if (cmd && cmd->data && host->clock > 400000 &&
-	    host->clock <= 50000000 &&
-	    ((1 << (count + start)) > (10 * host->clock)))
-		host->data_timeout = 22LL * NSEC_PER_SEC;
-}
-
-static const struct cqhci_host_ops sdhci_msm_cqhci_ops = {
-	.enable		= sdhci_cqe_enable,
-	.disable	= sdhci_msm_cqe_disable,
-};
-
-static int sdhci_msm_cqe_add_host(struct sdhci_host *host,
-				struct platform_device *pdev)
-{
-	struct sdhci_pltfm_host *pltfm_host = sdhci_priv(host);
-	struct sdhci_msm_host *msm_host = sdhci_pltfm_priv(pltfm_host);
-	struct cqhci_host *cq_host;
-	bool dma64;
-	u32 cqcfg;
-	int ret;
-
-	/*
-	 * When CQE is halted, SDHC operates only on 16byte ADMA descriptors.
-	 * So ensure ADMA table is allocated for 16byte descriptors.
-	 */
-	if (host->caps & SDHCI_CAN_64BIT)
-		host->alloc_desc_sz = 16;
-
-	ret = sdhci_setup_host(host);
-	if (ret)
-		return ret;
-
-	cq_host = cqhci_pltfm_init(pdev);
-	if (IS_ERR(cq_host)) {
-		ret = PTR_ERR(cq_host);
-		dev_err(&pdev->dev, "cqhci-pltfm init: failed: %d\n", ret);
-		goto cleanup;
-	}
-
-	msm_host->mmc->caps2 |= MMC_CAP2_CQE | MMC_CAP2_CQE_DCMD;
-	cq_host->ops = &sdhci_msm_cqhci_ops;
-
-	dma64 = host->flags & SDHCI_USE_64_BIT_DMA;
-
-	ret = cqhci_init(cq_host, host->mmc, dma64);
-	if (ret) {
-		dev_err(&pdev->dev, "%s: CQE init: failed (%d)\n",
-				mmc_hostname(host->mmc), ret);
-		goto cleanup;
-	}
-
-	/* Disable cqe reset due to cqe enable signal */
-	cqcfg = cqhci_readl(cq_host, CQHCI_VENDOR_CFG1);
-	cqcfg |= CQHCI_VENDOR_DIS_RST_ON_CQ_EN;
-	cqhci_writel(cq_host, cqcfg, CQHCI_VENDOR_CFG1);
-
-	/*
-	 * SDHC expects 12byte ADMA descriptors till CQE is enabled.
-	 * So limit desc_sz to 12 so that the data commands that are sent
-	 * during card initialization (before CQE gets enabled) would
-	 * get executed without any issues.
-	 */
-	if (host->flags & SDHCI_USE_64_BIT_DMA)
-		host->desc_sz = 12;
-
-	ret = __sdhci_add_host(host);
-	if (ret)
-		goto cleanup;
-
-	dev_info(&pdev->dev, "%s: CQE init: success\n",
-			mmc_hostname(host->mmc));
-	return ret;
-
-cleanup:
-	sdhci_cleanup_host(host);
-	return ret;
-}
-
 /*
  * Platform specific register write functions. This is so that, if any
  * register write needs to be followed up by platform specific actions,
@@ -2041,108 +1678,6 @@ static void sdhci_msm_set_regulator_caps(struct sdhci_msm_host *msm_host)
 	pr_debug("%s: supported caps: 0x%08x\n", mmc_hostname(mmc), caps);
 }
 
-static void sdhci_msm_reset(struct sdhci_host *host, u8 mask)
-{
-	if ((host->mmc->caps2 & MMC_CAP2_CQE) && (mask & SDHCI_RESET_ALL))
-		cqhci_deactivate(host->mmc);
-	sdhci_reset(host, mask);
-}
-
-static int sdhci_msm_register_vreg(struct sdhci_msm_host *msm_host)
-{
-	int ret;
-
-	ret = mmc_regulator_get_supply(msm_host->mmc);
-	if (ret)
-		return ret;
-
-	sdhci_msm_set_regulator_caps(msm_host);
-
-	return 0;
-}
-
-static int sdhci_msm_start_signal_voltage_switch(struct mmc_host *mmc,
-				      struct mmc_ios *ios)
-{
-	struct sdhci_host *host = mmc_priv(mmc);
-	u16 ctrl, status;
-
-	/*
-	 * Signal Voltage Switching is only applicable for Host Controllers
-	 * v3.00 and above.
-	 */
-	if (host->version < SDHCI_SPEC_300)
-		return 0;
-
-	ctrl = sdhci_readw(host, SDHCI_HOST_CONTROL2);
-
-	switch (ios->signal_voltage) {
-	case MMC_SIGNAL_VOLTAGE_330:
-		if (!(host->flags & SDHCI_SIGNALING_330))
-			return -EINVAL;
-
-		/* Set 1.8V Signal Enable in the Host Control2 register to 0 */
-		ctrl &= ~SDHCI_CTRL_VDD_180;
-		break;
-	case MMC_SIGNAL_VOLTAGE_180:
-		if (!(host->flags & SDHCI_SIGNALING_180))
-			return -EINVAL;
-
-		/* Enable 1.8V Signal Enable in the Host Control2 register */
-		ctrl |= SDHCI_CTRL_VDD_180;
-		break;
-
-	default:
-		return -EINVAL;
-	}
-
-	sdhci_writew(host, ctrl, SDHCI_HOST_CONTROL2);
-
-	/* Wait for 5ms */
-	usleep_range(5000, 5500);
-
-	/* regulator output should be stable within 5 ms */
-	status = ctrl & SDHCI_CTRL_VDD_180;
-	ctrl = sdhci_readw(host, SDHCI_HOST_CONTROL2);
-	if ((ctrl & SDHCI_CTRL_VDD_180) == status)
-		return 0;
-
-	dev_warn(mmc_dev(mmc), "%s: Regulator output did not became stable\n",
-		mmc_hostname(mmc));
-
-	return -EAGAIN;
-}
-
-#define DRIVER_NAME "sdhci_msm"
-#define SDHCI_MSM_DUMP(f, x...) \
-	pr_err("%s: " DRIVER_NAME ": " f, mmc_hostname(host->mmc), ## x)
-
-static void sdhci_msm_dump_vendor_regs(struct sdhci_host *host)
-{
-	struct sdhci_pltfm_host *pltfm_host = sdhci_priv(host);
-	struct sdhci_msm_host *msm_host = sdhci_pltfm_priv(pltfm_host);
-	const struct sdhci_msm_offset *msm_offset = msm_host->offset;
-
-	SDHCI_MSM_DUMP("----------- VENDOR REGISTER DUMP -----------\n");
-
-	SDHCI_MSM_DUMP(
-			"DLL sts: 0x%08x | DLL cfg:  0x%08x | DLL cfg2: 0x%08x\n",
-		readl_relaxed(host->ioaddr + msm_offset->core_dll_status),
-		readl_relaxed(host->ioaddr + msm_offset->core_dll_config),
-		readl_relaxed(host->ioaddr + msm_offset->core_dll_config_2));
-	SDHCI_MSM_DUMP(
-			"DLL cfg3: 0x%08x | DLL usr ctl:  0x%08x | DDR cfg: 0x%08x\n",
-		readl_relaxed(host->ioaddr + msm_offset->core_dll_config_3),
-		readl_relaxed(host->ioaddr + msm_offset->core_dll_usr_ctl),
-		readl_relaxed(host->ioaddr + msm_offset->core_ddr_config));
-	SDHCI_MSM_DUMP(
-			"Vndr func: 0x%08x | Vndr func2 : 0x%08x Vndr func3: 0x%08x\n",
-		readl_relaxed(host->ioaddr + msm_offset->core_vendor_spec),
-		readl_relaxed(host->ioaddr +
-			msm_offset->core_vendor_spec_func2),
-		readl_relaxed(host->ioaddr + msm_offset->core_vendor_spec3));
-}
-
 static const struct sdhci_msm_variant_ops mci_var_ops = {
 	.msm_readl_relaxed = sdhci_msm_mci_variant_readl_relaxed,
 	.msm_writel_relaxed = sdhci_msm_mci_variant_writel_relaxed,
@@ -2171,26 +1706,17 @@ static const struct sdhci_msm_variant_info sdm845_sdhci_var = {
 	.offset = &sdhci_msm_v5_offset,
 };
 
-static const struct sdhci_msm_variant_info sm8250_sdhci_var = {
-	.mci_removed = true,
-	.uses_tassadar_dll = true,
-	.var_ops = &v5_var_ops,
-	.offset = &sdhci_msm_v5_offset,
-};
-
 static const struct of_device_id sdhci_msm_dt_match[] = {
 	{.compatible = "qcom,sdhci-msm-v4", .data = &sdhci_msm_mci_var},
 	{.compatible = "qcom,sdhci-msm-v5", .data = &sdhci_msm_v5_var},
 	{.compatible = "qcom,sdm845-sdhci", .data = &sdm845_sdhci_var},
-	{.compatible = "qcom,sm8250-sdhci", .data = &sm8250_sdhci_var},
-	{.compatible = "qcom,sc7180-sdhci", .data = &sdm845_sdhci_var},
 	{},
 };
 
 MODULE_DEVICE_TABLE(of, sdhci_msm_dt_match);
 
 static const struct sdhci_ops sdhci_msm_ops = {
-	.reset = sdhci_msm_reset,
+	.reset = sdhci_reset,
 	.set_clock = sdhci_msm_set_clock,
 	.get_min_clock = sdhci_msm_get_min_clock,
 	.get_max_clock = sdhci_msm_get_max_clock,
@@ -2198,42 +1724,22 @@ static const struct sdhci_ops sdhci_msm_ops = {
 	.set_uhs_signaling = sdhci_msm_set_uhs_signaling,
 	.write_w = sdhci_msm_writew,
 	.write_b = sdhci_msm_writeb,
-	.irq	= sdhci_msm_cqe_irq,
-	.dump_vendor_regs = sdhci_msm_dump_vendor_regs,
-	.set_power = sdhci_set_power_noreg,
-	.set_timeout = sdhci_msm_set_timeout,
 };
 
 static const struct sdhci_pltfm_data sdhci_msm_pdata = {
 	.quirks = SDHCI_QUIRK_BROKEN_CARD_DETECTION |
 		  SDHCI_QUIRK_SINGLE_POWER_WRITE |
-		  SDHCI_QUIRK_CAP_CLOCK_BASE_BROKEN |
-		  SDHCI_QUIRK_MULTIBLOCK_READ_ACMD12,
-
+		  SDHCI_QUIRK_CAP_CLOCK_BASE_BROKEN,
 	.quirks2 = SDHCI_QUIRK2_PRESET_VALUE_BROKEN,
 	.ops = &sdhci_msm_ops,
 };
 
-static inline void sdhci_msm_get_of_property(struct platform_device *pdev,
-		struct sdhci_host *host)
-{
-	struct device_node *node = pdev->dev.of_node;
-	struct sdhci_pltfm_host *pltfm_host = sdhci_priv(host);
-	struct sdhci_msm_host *msm_host = sdhci_pltfm_priv(pltfm_host);
-
-	if (of_property_read_u32(node, "qcom,ddr-config",
-				&msm_host->ddr_config))
-		msm_host->ddr_config = DDR_CONFIG_POR_VAL;
-
-	of_property_read_u32(node, "qcom,dll-config", &msm_host->dll_config);
-}
-
-
 static int sdhci_msm_probe(struct platform_device *pdev)
 {
 	struct sdhci_host *host;
 	struct sdhci_pltfm_host *pltfm_host;
 	struct sdhci_msm_host *msm_host;
+	struct resource *core_memres;
 	struct clk *clk;
 	int ret;
 	u16 host_version, core_minor;
@@ -2241,7 +1747,6 @@ static int sdhci_msm_probe(struct platform_device *pdev)
 	u8 core_major;
 	const struct sdhci_msm_offset *msm_offset;
 	const struct sdhci_msm_variant_info *var_info;
-	struct device_node *node = pdev->dev.of_node;
 
 	host = sdhci_pltfm_init(pdev, &sdhci_msm_pdata, sizeof(*msm_host));
 	if (IS_ERR(host))
@@ -2267,12 +1772,10 @@ static int sdhci_msm_probe(struct platform_device *pdev)
 	msm_host->restore_dll_config = var_info->restore_dll_config;
 	msm_host->var_ops = var_info->var_ops;
 	msm_host->offset = var_info->offset;
-	msm_host->uses_tassadar_dll = var_info->uses_tassadar_dll;
 
 	msm_offset = msm_host->offset;
 
 	sdhci_get_of_property(pdev);
-	sdhci_msm_get_of_property(pdev, host);
 
 	msm_host->saved_tuning_phase = INVALID_TUNING_PHASE;
 
@@ -2306,26 +1809,8 @@ static int sdhci_msm_probe(struct platform_device *pdev)
 	}
 	msm_host->bulk_clks[0].clk = clk;
 
-	 /* Check for optional interconnect paths */
-	ret = dev_pm_opp_of_find_icc_paths(&pdev->dev, NULL);
-	if (ret)
-		goto bus_clk_disable;
-
-	msm_host->opp_table = dev_pm_opp_set_clkname(&pdev->dev, "core");
-	if (IS_ERR(msm_host->opp_table)) {
-		ret = PTR_ERR(msm_host->opp_table);
-		goto bus_clk_disable;
-	}
-
-	/* OPP table is optional */
-	ret = dev_pm_opp_of_add_table(&pdev->dev);
-	if (ret && ret != -ENODEV) {
-		dev_err(&pdev->dev, "Invalid OPP table in Device tree\n");
-		goto opp_put_clkname;
-	}
-
 	/* Vote for maximum clock rate for maximum performance */
-	ret = dev_pm_opp_set_rate(&pdev->dev, INT_MAX);
+	ret = clk_set_rate(clk, INT_MAX);
 	if (ret)
 		dev_warn(&pdev->dev, "core clock boost failed\n");
 
@@ -2342,7 +1827,7 @@ static int sdhci_msm_probe(struct platform_device *pdev)
 	ret = clk_bulk_prepare_enable(ARRAY_SIZE(msm_host->bulk_clks),
 				      msm_host->bulk_clks);
 	if (ret)
-		goto opp_cleanup;
+		goto bus_clk_disable;
 
 	/*
 	 * xo clock is needed for FLL feature of cm_dll.
@@ -2355,7 +1840,10 @@ static int sdhci_msm_probe(struct platform_device *pdev)
 	}
 
 	if (!msm_host->mci_removed) {
-		msm_host->core_mem = devm_platform_ioremap_resource(pdev, 1);
+		core_memres = platform_get_resource(pdev, IORESOURCE_MEM, 1);
+		msm_host->core_mem = devm_ioremap_resource(&pdev->dev,
+				core_memres);
+
 		if (IS_ERR(msm_host->core_mem)) {
 			ret = PTR_ERR(msm_host->core_mem);
 			goto clk_disable;
@@ -2411,13 +1899,6 @@ static int sdhci_msm_probe(struct platform_device *pdev)
 				msm_offset->core_vendor_spec_capabilities0);
 	}
 
-	if (core_major == 1 && core_minor >= 0x49)
-		msm_host->updated_ddr_cfg = true;
-
-	ret = sdhci_msm_register_vreg(msm_host);
-	if (ret)
-		goto clk_disable;
-
 	/*
 	 * Power on reset state may trigger power irq if previous status of
 	 * PWRCTL was either BUS_ON or IO_HIGH_V. So before enabling pwr irq
@@ -2453,8 +1934,6 @@ static int sdhci_msm_probe(struct platform_device *pdev)
 		goto clk_disable;
 	}
 
-	msm_host->mmc->caps |= MMC_CAP_WAIT_WHILE_BUSY | MMC_CAP_NEED_RSP_BUSY;
-
 	pm_runtime_get_noresume(&pdev->dev);
 	pm_runtime_set_active(&pdev->dev);
 	pm_runtime_enable(&pdev->dev);
@@ -2462,15 +1941,11 @@ static int sdhci_msm_probe(struct platform_device *pdev)
 					 MSM_MMC_AUTOSUSPEND_DELAY_MS);
 	pm_runtime_use_autosuspend(&pdev->dev);
 
-	host->mmc_host_ops.start_signal_voltage_switch =
-		sdhci_msm_start_signal_voltage_switch;
 	host->mmc_host_ops.execute_tuning = sdhci_msm_execute_tuning;
-	if (of_property_read_bool(node, "supports-cqe"))
-		ret = sdhci_msm_cqe_add_host(host, pdev);
-	else
-		ret = sdhci_add_host(host);
+	ret = sdhci_add_host(host);
 	if (ret)
 		goto pm_runtime_disable;
+	sdhci_msm_set_regulator_caps(msm_host);
 
 	pm_runtime_mark_last_busy(&pdev->dev);
 	pm_runtime_put_autosuspend(&pdev->dev);
@@ -2484,10 +1959,6 @@ static int sdhci_msm_probe(struct platform_device *pdev)
 clk_disable:
 	clk_bulk_disable_unprepare(ARRAY_SIZE(msm_host->bulk_clks),
 				   msm_host->bulk_clks);
-opp_cleanup:
-	dev_pm_opp_of_remove_table(&pdev->dev);
-opp_put_clkname:
-	dev_pm_opp_put_clkname(msm_host->opp_table);
 bus_clk_disable:
 	if (!IS_ERR(msm_host->bus_clk))
 		clk_disable_unprepare(msm_host->bus_clk);
@@ -2506,8 +1977,6 @@ static int sdhci_msm_remove(struct platform_device *pdev)
 
 	sdhci_remove_host(host, dead);
 
-	dev_pm_opp_of_remove_table(&pdev->dev);
-	dev_pm_opp_put_clkname(msm_host->opp_table);
 	pm_runtime_get_sync(&pdev->dev);
 	pm_runtime_disable(&pdev->dev);
 	pm_runtime_put_noidle(&pdev->dev);
@@ -2526,8 +1995,6 @@ static __maybe_unused int sdhci_msm_runtime_suspend(struct device *dev)
 	struct sdhci_pltfm_host *pltfm_host = sdhci_priv(host);
 	struct sdhci_msm_host *msm_host = sdhci_pltfm_priv(pltfm_host);
 
-	/* Drop the performance vote */
-	dev_pm_opp_set_rate(dev, 0);
 	clk_bulk_disable_unprepare(ARRAY_SIZE(msm_host->bulk_clks),
 				   msm_host->bulk_clks);
 
@@ -2550,11 +2017,9 @@ static __maybe_unused int sdhci_msm_runtime_resume(struct device *dev)
 	 * restore the SDR DLL settings when the clock is ungated.
 	 */
 	if (msm_host->restore_dll_config && msm_host->clk_rate)
-		ret = sdhci_msm_restore_sdr_dll_config(host);
+		return sdhci_msm_restore_sdr_dll_config(host);
 
-	dev_pm_opp_set_rate(dev, msm_host->clk_rate);
-
-	return ret;
+	return 0;
 }
 
 static const struct dev_pm_ops sdhci_msm_pm_ops = {
@@ -2572,7 +2037,6 @@ static struct platform_driver sdhci_msm_driver = {
 		   .name = "sdhci_msm",
 		   .of_match_table = sdhci_msm_dt_match,
 		   .pm = &sdhci_msm_pm_ops,
-		   .probe_type = PROBE_PREFER_ASYNCHRONOUS,
 	},
 };
 
diff --git a/drivers/mmc/host/sdhci-of-arasan.c b/drivers/mmc/host/sdhci-of-arasan.c
index fc38db64a..7023cbec4 100644
--- a/drivers/mmc/host/sdhci-of-arasan.c
+++ b/drivers/mmc/host/sdhci-of-arasan.c
@@ -22,35 +22,16 @@
 #include <linux/phy/phy.h>
 #include <linux/regmap.h>
 #include <linux/of.h>
-#include <linux/firmware/xlnx-zynqmp.h>
 
 #include "cqhci.h"
 #include "sdhci-pltfm.h"
 
 #define SDHCI_ARASAN_VENDOR_REGISTER	0x78
-
-#define SDHCI_ARASAN_ITAPDLY_REGISTER	0xF0F8
-#define SDHCI_ARASAN_ITAPDLY_SEL_MASK	0xFF
-
-#define SDHCI_ARASAN_OTAPDLY_REGISTER	0xF0FC
-#define SDHCI_ARASAN_OTAPDLY_SEL_MASK	0x3F
-
 #define SDHCI_ARASAN_CQE_BASE_ADDR	0x200
 #define VENDOR_ENHANCED_STROBE		BIT(0)
 
 #define PHY_CLK_TOO_SLOW_HZ		400000
 
-#define SDHCI_ITAPDLY_CHGWIN		0x200
-#define SDHCI_ITAPDLY_ENABLE		0x100
-#define SDHCI_OTAPDLY_ENABLE		0x40
-
-/* Default settings for ZynqMP Clock Phases */
-#define ZYNQMP_ICLK_PHASE {0, 63, 63, 0, 63,  0,   0, 183, 54,  0, 0}
-#define ZYNQMP_OCLK_PHASE {0, 72, 60, 0, 60, 72, 135, 48, 72, 135, 0}
-
-#define VERSAL_ICLK_PHASE {0, 132, 132, 0, 132, 0, 0, 162, 90, 0, 0}
-#define VERSAL_OCLK_PHASE {0,  60, 48, 0, 48, 72, 90, 36, 60, 90, 0}
-
 /*
  * On some SoCs the syscon area has a feature where the upper 16-bits of
  * each 32-bit register act as a write mask for the lower 16-bits.  This allows
@@ -76,69 +57,30 @@ struct sdhci_arasan_soc_ctl_field {
 /**
  * struct sdhci_arasan_soc_ctl_map - Map in syscon to corecfg registers
  *
- * @baseclkfreq:	Where to find corecfg_baseclkfreq
- * @clockmultiplier:	Where to find corecfg_clockmultiplier
- * @support64b:		Where to find SUPPORT64B bit
- * @hiword_update:	If true, use HIWORD_UPDATE to access the syscon
- *
  * It's up to the licensee of the Arsan IP block to make these available
  * somewhere if needed.  Presumably these will be scattered somewhere that's
  * accessible via the syscon API.
+ *
+ * @baseclkfreq:	Where to find corecfg_baseclkfreq
+ * @clockmultiplier:	Where to find corecfg_clockmultiplier
+ * @hiword_update:	If true, use HIWORD_UPDATE to access the syscon
  */
 struct sdhci_arasan_soc_ctl_map {
 	struct sdhci_arasan_soc_ctl_field	baseclkfreq;
 	struct sdhci_arasan_soc_ctl_field	clockmultiplier;
-	struct sdhci_arasan_soc_ctl_field	support64b;
 	bool					hiword_update;
 };
 
 /**
- * struct sdhci_arasan_clk_ops - Clock Operations for Arasan SD controller
- *
- * @sdcardclk_ops:	The output clock related operations
- * @sampleclk_ops:	The sample clock related operations
- */
-struct sdhci_arasan_clk_ops {
-	const struct clk_ops *sdcardclk_ops;
-	const struct clk_ops *sampleclk_ops;
-};
-
-/**
- * struct sdhci_arasan_clk_data - Arasan Controller Clock Data.
- *
- * @sdcardclk_hw:	Struct for the clock we might provide to a PHY.
- * @sdcardclk:		Pointer to normal 'struct clock' for sdcardclk_hw.
- * @sampleclk_hw:	Struct for the clock we might provide to a PHY.
- * @sampleclk:		Pointer to normal 'struct clock' for sampleclk_hw.
- * @clk_phase_in:	Array of Input Clock Phase Delays for all speed modes
- * @clk_phase_out:	Array of Output Clock Phase Delays for all speed modes
- * @set_clk_delays:	Function pointer for setting Clock Delays
- * @clk_of_data:	Platform specific runtime clock data storage pointer
- */
-struct sdhci_arasan_clk_data {
-	struct clk_hw	sdcardclk_hw;
-	struct clk      *sdcardclk;
-	struct clk_hw	sampleclk_hw;
-	struct clk      *sampleclk;
-	int		clk_phase_in[MMC_TIMING_MMC_HS400 + 1];
-	int		clk_phase_out[MMC_TIMING_MMC_HS400 + 1];
-	void		(*set_clk_delays)(struct sdhci_host *host);
-	void		*clk_of_data;
-};
-
-/**
- * struct sdhci_arasan_data - Arasan Controller Data
- *
+ * struct sdhci_arasan_data
  * @host:		Pointer to the main SDHCI host structure.
  * @clk_ahb:		Pointer to the AHB clock
  * @phy:		Pointer to the generic phy
  * @is_phy_on:		True if the PHY is on; false if not.
- * @has_cqe:		True if controller has command queuing engine.
- * @clk_data:		Struct for the Arasan Controller Clock Data.
- * @clk_ops:		Struct for the Arasan Controller Clock Operations.
+ * @sdcardclk_hw:	Struct for the clock we might provide to a PHY.
+ * @sdcardclk:		Pointer to normal 'struct clock' for sdcardclk_hw.
  * @soc_ctl_base:	Pointer to regmap for syscon for soc_ctl registers.
  * @soc_ctl_map:	Map to get offsets into soc_ctl registers.
- * @quirks:		Arasan deviations from spec.
  */
 struct sdhci_arasan_data {
 	struct sdhci_host *host;
@@ -147,30 +89,23 @@ struct sdhci_arasan_data {
 	bool		is_phy_on;
 
 	bool		has_cqe;
-	struct sdhci_arasan_clk_data clk_data;
-	const struct sdhci_arasan_clk_ops *clk_ops;
+	struct clk_hw	sdcardclk_hw;
+	struct clk      *sdcardclk;
 
 	struct regmap	*soc_ctl_base;
 	const struct sdhci_arasan_soc_ctl_map *soc_ctl_map;
-	unsigned int	quirks;
+	unsigned int	quirks; /* Arasan deviations from spec */
 
 /* Controller does not have CD wired and will not function normally without */
 #define SDHCI_ARASAN_QUIRK_FORCE_CDTEST	BIT(0)
 /* Controller immediately reports SDHCI_CLOCK_INT_STABLE after enabling the
  * internal clock even when the clock isn't stable */
 #define SDHCI_ARASAN_QUIRK_CLOCK_UNSTABLE BIT(1)
-/*
- * Some of the Arasan variations might not have timing requirements
- * met at 25MHz for Default Speed mode, those controllers work at
- * 19MHz instead
- */
-#define SDHCI_ARASAN_QUIRK_CLOCK_25_BROKEN BIT(2)
 };
 
 struct sdhci_arasan_of_data {
 	const struct sdhci_arasan_soc_ctl_map *soc_ctl_map;
 	const struct sdhci_pltfm_data *pdata;
-	const struct sdhci_arasan_clk_ops *clk_ops;
 };
 
 static const struct sdhci_arasan_soc_ctl_map rk3399_soc_ctl_map = {
@@ -185,32 +120,17 @@ static const struct sdhci_arasan_soc_ctl_map intel_lgm_emmc_soc_ctl_map = {
 	.hiword_update = false,
 };
 
-static const struct sdhci_arasan_soc_ctl_map intel_lgm_sdxc_soc_ctl_map = {
-	.baseclkfreq = { .reg = 0x80, .width = 8, .shift = 2 },
-	.clockmultiplier = { .reg = 0, .width = -1, .shift = -1 },
-	.hiword_update = false,
-};
-
-static const struct sdhci_arasan_soc_ctl_map intel_keembay_soc_ctl_map = {
-	.baseclkfreq = { .reg = 0x0, .width = 8, .shift = 14 },
-	.clockmultiplier = { .reg = 0x4, .width = 8, .shift = 14 },
-	.support64b = { .reg = 0x4, .width = 1, .shift = 24 },
-	.hiword_update = false,
-};
-
 /**
  * sdhci_arasan_syscon_write - Write to a field in soc_ctl registers
  *
- * @host:	The sdhci_host
- * @fld:	The field to write to
- * @val:	The value to write
- *
  * This function allows writing to fields in sdhci_arasan_soc_ctl_map.
  * Note that if a field is specified as not available (shift < 0) then
  * this function will silently return an error code.  It will be noisy
  * and print errors for any other (unexpected) errors.
  *
- * Return: 0 on success and error value on error
+ * @host:	The sdhci_host
+ * @fld:	The field to write to
+ * @val:	The value to write
  */
 static int sdhci_arasan_syscon_write(struct sdhci_host *host,
 				   const struct sdhci_arasan_soc_ctl_field *fld,
@@ -254,7 +174,6 @@ static void sdhci_arasan_set_clock(struct sdhci_host *host, unsigned int clock)
 {
 	struct sdhci_pltfm_host *pltfm_host = sdhci_priv(host);
 	struct sdhci_arasan_data *sdhci_arasan = sdhci_pltfm_priv(pltfm_host);
-	struct sdhci_arasan_clk_data *clk_data = &sdhci_arasan->clk_data;
 	bool ctrl_phy = false;
 
 	if (!IS_ERR(sdhci_arasan->phy)) {
@@ -273,12 +192,7 @@ static void sdhci_arasan_set_clock(struct sdhci_host *host, unsigned int clock)
 			 * through low speeds without power cycling.
 			 */
 			sdhci_set_clock(host, host->max_clk);
-			if (phy_power_on(sdhci_arasan->phy)) {
-				pr_err("%s: Cannot power on phy.\n",
-				       mmc_hostname(host->mmc));
-				return;
-			}
-
+			phy_power_on(sdhci_arasan->phy);
 			sdhci_arasan->is_phy_on = true;
 
 			/*
@@ -301,20 +215,6 @@ static void sdhci_arasan_set_clock(struct sdhci_host *host, unsigned int clock)
 		sdhci_arasan->is_phy_on = false;
 	}
 
-	if (sdhci_arasan->quirks & SDHCI_ARASAN_QUIRK_CLOCK_25_BROKEN) {
-		/*
-		 * Some of the Arasan variations might not have timing
-		 * requirements met at 25MHz for Default Speed mode,
-		 * those controllers work at 19MHz instead.
-		 */
-		if (clock == DEFAULT_SPEED_MAX_DTR)
-			clock = (DEFAULT_SPEED_MAX_DTR * 19) / 25;
-	}
-
-	/* Set the Input and Output Clock Phase Delays */
-	if (clk_data->set_clk_delays)
-		clk_data->set_clk_delays(host);
-
 	sdhci_set_clock(host, clock);
 
 	if (sdhci_arasan->quirks & SDHCI_ARASAN_QUIRK_CLOCK_UNSTABLE)
@@ -328,12 +228,7 @@ static void sdhci_arasan_set_clock(struct sdhci_host *host, unsigned int clock)
 		msleep(20);
 
 	if (ctrl_phy) {
-		if (phy_power_on(sdhci_arasan->phy)) {
-			pr_err("%s: Cannot power on phy.\n",
-			       mmc_hostname(host->mmc));
-			return;
-		}
-
+		phy_power_on(sdhci_arasan->phy);
 		sdhci_arasan->is_phy_on = true;
 	}
 }
@@ -390,6 +285,17 @@ static int sdhci_arasan_voltage_switch(struct mmc_host *mmc,
 	return -EINVAL;
 }
 
+static void sdhci_arasan_set_power(struct sdhci_host *host, unsigned char mode,
+		     unsigned short vdd)
+{
+	if (!IS_ERR(host->mmc->supply.vmmc)) {
+		struct mmc_host *mmc = host->mmc;
+
+		mmc_regulator_set_ocr(mmc, mmc->supply.vmmc, vdd);
+	}
+	sdhci_set_power_noreg(host, mode, vdd);
+}
+
 static const struct sdhci_ops sdhci_arasan_ops = {
 	.set_clock = sdhci_arasan_set_clock,
 	.get_max_clock = sdhci_pltfm_clk_get_max_clock,
@@ -397,7 +303,19 @@ static const struct sdhci_ops sdhci_arasan_ops = {
 	.set_bus_width = sdhci_set_bus_width,
 	.reset = sdhci_arasan_reset,
 	.set_uhs_signaling = sdhci_set_uhs_signaling,
-	.set_power = sdhci_set_power_and_bus_voltage,
+	.set_power = sdhci_arasan_set_power,
+};
+
+static const struct sdhci_pltfm_data sdhci_arasan_pdata = {
+	.ops = &sdhci_arasan_ops,
+	.quirks = SDHCI_QUIRK_CAP_CLOCK_BASE_BROKEN,
+	.quirks2 = SDHCI_QUIRK2_PRESET_VALUE_BROKEN |
+			SDHCI_QUIRK2_CLOCK_DIV_ZERO_BROKEN |
+			SDHCI_QUIRK2_STOP_WITH_TC,
+};
+
+static struct sdhci_arasan_of_data sdhci_arasan_data = {
+	.pdata = &sdhci_arasan_pdata,
 };
 
 static u32 sdhci_arasan_cqhci_irq(struct sdhci_host *host, u32 intmask)
@@ -445,7 +363,7 @@ static const struct sdhci_ops sdhci_arasan_cqe_ops = {
 	.set_bus_width = sdhci_set_bus_width,
 	.reset = sdhci_arasan_reset,
 	.set_uhs_signaling = sdhci_set_uhs_signaling,
-	.set_power = sdhci_set_power_and_bus_voltage,
+	.set_power = sdhci_arasan_set_power,
 	.irq = sdhci_arasan_cqhci_irq,
 };
 
@@ -456,14 +374,23 @@ static const struct sdhci_pltfm_data sdhci_arasan_cqe_pdata = {
 			SDHCI_QUIRK2_CLOCK_DIV_ZERO_BROKEN,
 };
 
+static struct sdhci_arasan_of_data sdhci_arasan_rk3399_data = {
+	.soc_ctl_map = &rk3399_soc_ctl_map,
+	.pdata = &sdhci_arasan_cqe_pdata,
+};
+
+static struct sdhci_arasan_of_data intel_lgm_emmc_data = {
+	.soc_ctl_map = &intel_lgm_emmc_soc_ctl_map,
+	.pdata = &sdhci_arasan_cqe_pdata,
+};
+
 #ifdef CONFIG_PM_SLEEP
 /**
  * sdhci_arasan_suspend - Suspend method for the driver
  * @dev:	Address of the device structure
+ * Returns 0 on success and error value on error
  *
  * Put the device in a low power state.
- *
- * Return: 0 on success and error value on error
  */
 static int sdhci_arasan_suspend(struct device *dev)
 {
@@ -489,9 +416,7 @@ static int sdhci_arasan_suspend(struct device *dev)
 		ret = phy_power_off(sdhci_arasan->phy);
 		if (ret) {
 			dev_err(dev, "Cannot power off phy.\n");
-			if (sdhci_resume_host(host))
-				dev_err(dev, "Cannot resume host.\n");
-
+			sdhci_resume_host(host);
 			return ret;
 		}
 		sdhci_arasan->is_phy_on = false;
@@ -506,10 +431,9 @@ static int sdhci_arasan_suspend(struct device *dev)
 /**
  * sdhci_arasan_resume - Resume method for the driver
  * @dev:	Address of the device structure
+ * Returns 0 on success and error value on error
  *
  * Resume operation after suspend
- *
- * Return: 0 on success and error value on error
  */
 static int sdhci_arasan_resume(struct device *dev)
 {
@@ -555,24 +479,49 @@ static int sdhci_arasan_resume(struct device *dev)
 static SIMPLE_DEV_PM_OPS(sdhci_arasan_dev_pm_ops, sdhci_arasan_suspend,
 			 sdhci_arasan_resume);
 
+static const struct of_device_id sdhci_arasan_of_match[] = {
+	/* SoC-specific compatible strings w/ soc_ctl_map */
+	{
+		.compatible = "rockchip,rk3399-sdhci-5.1",
+		.data = &sdhci_arasan_rk3399_data,
+	},
+	{
+		.compatible = "intel,lgm-sdhci-5.1-emmc",
+		.data = &intel_lgm_emmc_data,
+	},
+	/* Generic compatible below here */
+	{
+		.compatible = "arasan,sdhci-8.9a",
+		.data = &sdhci_arasan_data,
+	},
+	{
+		.compatible = "arasan,sdhci-5.1",
+		.data = &sdhci_arasan_data,
+	},
+	{
+		.compatible = "arasan,sdhci-4.9a",
+		.data = &sdhci_arasan_data,
+	},
+	{ /* sentinel */ }
+};
+MODULE_DEVICE_TABLE(of, sdhci_arasan_of_match);
+
 /**
  * sdhci_arasan_sdcardclk_recalc_rate - Return the card clock rate
  *
- * @hw:			Pointer to the hardware clock structure.
- * @parent_rate:		The parent rate (should be rate of clk_xin).
- *
  * Return the current actual rate of the SD card clock.  This can be used
  * to communicate with out PHY.
  *
- * Return: The card clock rate.
+ * @hw:			Pointer to the hardware clock structure.
+ * @parent_rate		The parent rate (should be rate of clk_xin).
+ * Returns the card clock rate.
  */
 static unsigned long sdhci_arasan_sdcardclk_recalc_rate(struct clk_hw *hw,
 						      unsigned long parent_rate)
+
 {
-	struct sdhci_arasan_clk_data *clk_data =
-		container_of(hw, struct sdhci_arasan_clk_data, sdcardclk_hw);
 	struct sdhci_arasan_data *sdhci_arasan =
-		container_of(clk_data, struct sdhci_arasan_data, clk_data);
+		container_of(hw, struct sdhci_arasan_data, sdcardclk_hw);
 	struct sdhci_host *host = sdhci_arasan->host;
 
 	return host->mmc->actual_clock;
@@ -583,908 +532,159 @@ static const struct clk_ops arasan_sdcardclk_ops = {
 };
 
 /**
- * sdhci_arasan_sampleclk_recalc_rate - Return the sampling clock rate
+ * sdhci_arasan_update_clockmultiplier - Set corecfg_clockmultiplier
  *
- * @hw:			Pointer to the hardware clock structure.
- * @parent_rate:		The parent rate (should be rate of clk_xin).
+ * The corecfg_clockmultiplier is supposed to contain clock multiplier
+ * value of programmable clock generator.
  *
- * Return the current actual rate of the sampling clock.  This can be used
- * to communicate with out PHY.
+ * NOTES:
+ * - Many existing devices don't seem to do this and work fine.  To keep
+ *   compatibility for old hardware where the device tree doesn't provide a
+ *   register map, this function is a noop if a soc_ctl_map hasn't been provided
+ *   for this platform.
+ * - The value of corecfg_clockmultiplier should sync with that of corresponding
+ *   value reading from sdhci_capability_register. So this function is called
+ *   once at probe time and never called again.
  *
- * Return: The sample clock rate.
+ * @host:		The sdhci_host
  */
-static unsigned long sdhci_arasan_sampleclk_recalc_rate(struct clk_hw *hw,
-						      unsigned long parent_rate)
+static void sdhci_arasan_update_clockmultiplier(struct sdhci_host *host,
+						u32 value)
 {
-	struct sdhci_arasan_clk_data *clk_data =
-		container_of(hw, struct sdhci_arasan_clk_data, sampleclk_hw);
-	struct sdhci_arasan_data *sdhci_arasan =
-		container_of(clk_data, struct sdhci_arasan_data, clk_data);
-	struct sdhci_host *host = sdhci_arasan->host;
+	struct sdhci_pltfm_host *pltfm_host = sdhci_priv(host);
+	struct sdhci_arasan_data *sdhci_arasan = sdhci_pltfm_priv(pltfm_host);
+	const struct sdhci_arasan_soc_ctl_map *soc_ctl_map =
+		sdhci_arasan->soc_ctl_map;
 
-	return host->mmc->actual_clock;
-}
+	/* Having a map is optional */
+	if (!soc_ctl_map)
+		return;
 
-static const struct clk_ops arasan_sampleclk_ops = {
-	.recalc_rate = sdhci_arasan_sampleclk_recalc_rate,
-};
+	/* If we have a map, we expect to have a syscon */
+	if (!sdhci_arasan->soc_ctl_base) {
+		pr_warn("%s: Have regmap, but no soc-ctl-syscon\n",
+			mmc_hostname(host->mmc));
+		return;
+	}
+
+	sdhci_arasan_syscon_write(host, &soc_ctl_map->clockmultiplier, value);
+}
 
 /**
- * sdhci_zynqmp_sdcardclk_set_phase - Set the SD Output Clock Tap Delays
+ * sdhci_arasan_update_baseclkfreq - Set corecfg_baseclkfreq
  *
- * @hw:			Pointer to the hardware clock structure.
- * @degrees:		The clock phase shift between 0 - 359.
+ * The corecfg_baseclkfreq is supposed to contain the MHz of clk_xin.  This
+ * function can be used to make that happen.
  *
- * Set the SD Output Clock Tap Delays for Output path
+ * NOTES:
+ * - Many existing devices don't seem to do this and work fine.  To keep
+ *   compatibility for old hardware where the device tree doesn't provide a
+ *   register map, this function is a noop if a soc_ctl_map hasn't been provided
+ *   for this platform.
+ * - It's assumed that clk_xin is not dynamic and that we use the SDHCI divider
+ *   to achieve lower clock rates.  That means that this function is called once
+ *   at probe time and never called again.
  *
- * Return: 0 on success and error value on error
+ * @host:		The sdhci_host
  */
-static int sdhci_zynqmp_sdcardclk_set_phase(struct clk_hw *hw, int degrees)
+static void sdhci_arasan_update_baseclkfreq(struct sdhci_host *host)
 {
-	struct sdhci_arasan_clk_data *clk_data =
-		container_of(hw, struct sdhci_arasan_clk_data, sdcardclk_hw);
-	struct sdhci_arasan_data *sdhci_arasan =
-		container_of(clk_data, struct sdhci_arasan_data, clk_data);
-	struct sdhci_host *host = sdhci_arasan->host;
-	const char *clk_name = clk_hw_get_name(hw);
-	u32 node_id = !strcmp(clk_name, "clk_out_sd0") ? NODE_SD_0 : NODE_SD_1;
-	u8 tap_delay, tap_max = 0;
-	int ret;
+	struct sdhci_pltfm_host *pltfm_host = sdhci_priv(host);
+	struct sdhci_arasan_data *sdhci_arasan = sdhci_pltfm_priv(pltfm_host);
+	const struct sdhci_arasan_soc_ctl_map *soc_ctl_map =
+		sdhci_arasan->soc_ctl_map;
+	u32 mhz = DIV_ROUND_CLOSEST(clk_get_rate(pltfm_host->clk), 1000000);
 
-	/* This is applicable for SDHCI_SPEC_300 and above */
-	if (host->version < SDHCI_SPEC_300)
-		return 0;
+	/* Having a map is optional */
+	if (!soc_ctl_map)
+		return;
 
-	switch (host->timing) {
-	case MMC_TIMING_MMC_HS:
-	case MMC_TIMING_SD_HS:
-	case MMC_TIMING_UHS_SDR25:
-	case MMC_TIMING_UHS_DDR50:
-	case MMC_TIMING_MMC_DDR52:
-		/* For 50MHz clock, 30 Taps are available */
-		tap_max = 30;
-		break;
-	case MMC_TIMING_UHS_SDR50:
-		/* For 100MHz clock, 15 Taps are available */
-		tap_max = 15;
-		break;
-	case MMC_TIMING_UHS_SDR104:
-	case MMC_TIMING_MMC_HS200:
-		/* For 200MHz clock, 8 Taps are available */
-		tap_max = 8;
-	default:
-		break;
+	/* If we have a map, we expect to have a syscon */
+	if (!sdhci_arasan->soc_ctl_base) {
+		pr_warn("%s: Have regmap, but no soc-ctl-syscon\n",
+			mmc_hostname(host->mmc));
+		return;
 	}
 
-	tap_delay = (degrees * tap_max) / 360;
-
-	/* Set the Clock Phase */
-	ret = zynqmp_pm_set_sd_tapdelay(node_id, PM_TAPDELAY_OUTPUT, tap_delay);
-	if (ret)
-		pr_err("Error setting Output Tap Delay\n");
-
-	/* Release DLL Reset */
-	zynqmp_pm_sd_dll_reset(node_id, PM_DLL_RESET_RELEASE);
-
-	return ret;
+	sdhci_arasan_syscon_write(host, &soc_ctl_map->baseclkfreq, mhz);
 }
 
-static const struct clk_ops zynqmp_sdcardclk_ops = {
-	.recalc_rate = sdhci_arasan_sdcardclk_recalc_rate,
-	.set_phase = sdhci_zynqmp_sdcardclk_set_phase,
-};
-
 /**
- * sdhci_zynqmp_sampleclk_set_phase - Set the SD Input Clock Tap Delays
+ * sdhci_arasan_register_sdclk - Register the sdclk for a PHY to use
  *
- * @hw:			Pointer to the hardware clock structure.
- * @degrees:		The clock phase shift between 0 - 359.
+ * Some PHY devices need to know what the actual card clock is.  In order for
+ * them to find out, we'll provide a clock through the common clock framework
+ * for them to query.
  *
- * Set the SD Input Clock Tap Delays for Input path
+ * Note: without seriously re-architecting SDHCI's clock code and testing on
+ * all platforms, there's no way to create a totally beautiful clock here
+ * with all clock ops implemented.  Instead, we'll just create a clock that can
+ * be queried and set the CLK_GET_RATE_NOCACHE attribute to tell common clock
+ * framework that we're doing things behind its back.  This should be sufficient
+ * to create nice clean device tree bindings and later (if needed) we can try
+ * re-architecting SDHCI if we see some benefit to it.
  *
- * Return: 0 on success and error value on error
+ * @sdhci_arasan:	Our private data structure.
+ * @clk_xin:		Pointer to the functional clock
+ * @dev:		Pointer to our struct device.
+ * Returns 0 on success and error value on error
  */
-static int sdhci_zynqmp_sampleclk_set_phase(struct clk_hw *hw, int degrees)
+static int sdhci_arasan_register_sdclk(struct sdhci_arasan_data *sdhci_arasan,
+				       struct clk *clk_xin,
+				       struct device *dev)
 {
-	struct sdhci_arasan_clk_data *clk_data =
-		container_of(hw, struct sdhci_arasan_clk_data, sampleclk_hw);
-	struct sdhci_arasan_data *sdhci_arasan =
-		container_of(clk_data, struct sdhci_arasan_data, clk_data);
-	struct sdhci_host *host = sdhci_arasan->host;
-	const char *clk_name = clk_hw_get_name(hw);
-	u32 node_id = !strcmp(clk_name, "clk_in_sd0") ? NODE_SD_0 : NODE_SD_1;
-	u8 tap_delay, tap_max = 0;
+	struct device_node *np = dev->of_node;
+	struct clk_init_data sdcardclk_init;
+	const char *parent_clk_name;
 	int ret;
 
-	/* This is applicable for SDHCI_SPEC_300 and above */
-	if (host->version < SDHCI_SPEC_300)
+	/* Providing a clock to the PHY is optional; no error if missing */
+	if (!of_find_property(np, "#clock-cells", NULL))
 		return 0;
 
-	/* Assert DLL Reset */
-	zynqmp_pm_sd_dll_reset(node_id, PM_DLL_RESET_ASSERT);
-
-	switch (host->timing) {
-	case MMC_TIMING_MMC_HS:
-	case MMC_TIMING_SD_HS:
-	case MMC_TIMING_UHS_SDR25:
-	case MMC_TIMING_UHS_DDR50:
-	case MMC_TIMING_MMC_DDR52:
-		/* For 50MHz clock, 120 Taps are available */
-		tap_max = 120;
-		break;
-	case MMC_TIMING_UHS_SDR50:
-		/* For 100MHz clock, 60 Taps are available */
-		tap_max = 60;
-		break;
-	case MMC_TIMING_UHS_SDR104:
-	case MMC_TIMING_MMC_HS200:
-		/* For 200MHz clock, 30 Taps are available */
-		tap_max = 30;
-	default:
-		break;
+	ret = of_property_read_string_index(np, "clock-output-names", 0,
+					    &sdcardclk_init.name);
+	if (ret) {
+		dev_err(dev, "DT has #clock-cells but no clock-output-names\n");
+		return ret;
 	}
 
-	tap_delay = (degrees * tap_max) / 360;
+	parent_clk_name = __clk_get_name(clk_xin);
+	sdcardclk_init.parent_names = &parent_clk_name;
+	sdcardclk_init.num_parents = 1;
+	sdcardclk_init.flags = CLK_GET_RATE_NOCACHE;
+	sdcardclk_init.ops = &arasan_sdcardclk_ops;
+
+	sdhci_arasan->sdcardclk_hw.init = &sdcardclk_init;
+	sdhci_arasan->sdcardclk =
+		devm_clk_register(dev, &sdhci_arasan->sdcardclk_hw);
+	sdhci_arasan->sdcardclk_hw.init = NULL;
 
-	/* Set the Clock Phase */
-	ret = zynqmp_pm_set_sd_tapdelay(node_id, PM_TAPDELAY_INPUT, tap_delay);
+	ret = of_clk_add_provider(np, of_clk_src_simple_get,
+				  sdhci_arasan->sdcardclk);
 	if (ret)
-		pr_err("Error setting Input Tap Delay\n");
+		dev_err(dev, "Failed to add clock provider\n");
 
 	return ret;
 }
 
-static const struct clk_ops zynqmp_sampleclk_ops = {
-	.recalc_rate = sdhci_arasan_sampleclk_recalc_rate,
-	.set_phase = sdhci_zynqmp_sampleclk_set_phase,
-};
-
 /**
- * sdhci_versal_sdcardclk_set_phase - Set the SD Output Clock Tap Delays
- *
- * @hw:			Pointer to the hardware clock structure.
- * @degrees:		The clock phase shift between 0 - 359.
+ * sdhci_arasan_unregister_sdclk - Undoes sdhci_arasan_register_sdclk()
  *
- * Set the SD Output Clock Tap Delays for Output path
+ * Should be called any time we're exiting and sdhci_arasan_register_sdclk()
+ * returned success.
  *
- * Return: 0 on success and error value on error
+ * @dev:		Pointer to our struct device.
  */
-static int sdhci_versal_sdcardclk_set_phase(struct clk_hw *hw, int degrees)
+static void sdhci_arasan_unregister_sdclk(struct device *dev)
 {
-	struct sdhci_arasan_clk_data *clk_data =
-		container_of(hw, struct sdhci_arasan_clk_data, sdcardclk_hw);
-	struct sdhci_arasan_data *sdhci_arasan =
-		container_of(clk_data, struct sdhci_arasan_data, clk_data);
-	struct sdhci_host *host = sdhci_arasan->host;
-	u8 tap_delay, tap_max = 0;
-
-	/* This is applicable for SDHCI_SPEC_300 and above */
-	if (host->version < SDHCI_SPEC_300)
-		return 0;
-
-	switch (host->timing) {
-	case MMC_TIMING_MMC_HS:
-	case MMC_TIMING_SD_HS:
-	case MMC_TIMING_UHS_SDR25:
-	case MMC_TIMING_UHS_DDR50:
-	case MMC_TIMING_MMC_DDR52:
-		/* For 50MHz clock, 30 Taps are available */
-		tap_max = 30;
-		break;
-	case MMC_TIMING_UHS_SDR50:
-		/* For 100MHz clock, 15 Taps are available */
-		tap_max = 15;
-		break;
-	case MMC_TIMING_UHS_SDR104:
-	case MMC_TIMING_MMC_HS200:
-		/* For 200MHz clock, 8 Taps are available */
-		tap_max = 8;
-	default:
-		break;
-	}
+	struct device_node *np = dev->of_node;
 
-	tap_delay = (degrees * tap_max) / 360;
+	if (!of_find_property(np, "#clock-cells", NULL))
+		return;
 
-	/* Set the Clock Phase */
-	if (tap_delay) {
-		u32 regval;
-
-		regval = sdhci_readl(host, SDHCI_ARASAN_OTAPDLY_REGISTER);
-		regval |= SDHCI_OTAPDLY_ENABLE;
-		sdhci_writel(host, regval, SDHCI_ARASAN_OTAPDLY_REGISTER);
-		regval &= ~SDHCI_ARASAN_OTAPDLY_SEL_MASK;
-		regval |= tap_delay;
-		sdhci_writel(host, regval, SDHCI_ARASAN_OTAPDLY_REGISTER);
-	}
-
-	return 0;
-}
-
-static const struct clk_ops versal_sdcardclk_ops = {
-	.recalc_rate = sdhci_arasan_sdcardclk_recalc_rate,
-	.set_phase = sdhci_versal_sdcardclk_set_phase,
-};
-
-/**
- * sdhci_versal_sampleclk_set_phase - Set the SD Input Clock Tap Delays
- *
- * @hw:			Pointer to the hardware clock structure.
- * @degrees:		The clock phase shift between 0 - 359.
- *
- * Set the SD Input Clock Tap Delays for Input path
- *
- * Return: 0 on success and error value on error
- */
-static int sdhci_versal_sampleclk_set_phase(struct clk_hw *hw, int degrees)
-{
-	struct sdhci_arasan_clk_data *clk_data =
-		container_of(hw, struct sdhci_arasan_clk_data, sampleclk_hw);
-	struct sdhci_arasan_data *sdhci_arasan =
-		container_of(clk_data, struct sdhci_arasan_data, clk_data);
-	struct sdhci_host *host = sdhci_arasan->host;
-	u8 tap_delay, tap_max = 0;
-
-	/* This is applicable for SDHCI_SPEC_300 and above */
-	if (host->version < SDHCI_SPEC_300)
-		return 0;
-
-	switch (host->timing) {
-	case MMC_TIMING_MMC_HS:
-	case MMC_TIMING_SD_HS:
-	case MMC_TIMING_UHS_SDR25:
-	case MMC_TIMING_UHS_DDR50:
-	case MMC_TIMING_MMC_DDR52:
-		/* For 50MHz clock, 120 Taps are available */
-		tap_max = 120;
-		break;
-	case MMC_TIMING_UHS_SDR50:
-		/* For 100MHz clock, 60 Taps are available */
-		tap_max = 60;
-		break;
-	case MMC_TIMING_UHS_SDR104:
-	case MMC_TIMING_MMC_HS200:
-		/* For 200MHz clock, 30 Taps are available */
-		tap_max = 30;
-	default:
-		break;
-	}
-
-	tap_delay = (degrees * tap_max) / 360;
-
-	/* Set the Clock Phase */
-	if (tap_delay) {
-		u32 regval;
-
-		regval = sdhci_readl(host, SDHCI_ARASAN_ITAPDLY_REGISTER);
-		regval |= SDHCI_ITAPDLY_CHGWIN;
-		sdhci_writel(host, regval, SDHCI_ARASAN_ITAPDLY_REGISTER);
-		regval |= SDHCI_ITAPDLY_ENABLE;
-		sdhci_writel(host, regval, SDHCI_ARASAN_ITAPDLY_REGISTER);
-		regval &= ~SDHCI_ARASAN_ITAPDLY_SEL_MASK;
-		regval |= tap_delay;
-		sdhci_writel(host, regval, SDHCI_ARASAN_ITAPDLY_REGISTER);
-		regval &= ~SDHCI_ITAPDLY_CHGWIN;
-		sdhci_writel(host, regval, SDHCI_ARASAN_ITAPDLY_REGISTER);
-	}
-
-	return 0;
-}
-
-static const struct clk_ops versal_sampleclk_ops = {
-	.recalc_rate = sdhci_arasan_sampleclk_recalc_rate,
-	.set_phase = sdhci_versal_sampleclk_set_phase,
-};
-
-static void arasan_zynqmp_dll_reset(struct sdhci_host *host, u32 deviceid)
-{
-	u16 clk;
-
-	clk = sdhci_readw(host, SDHCI_CLOCK_CONTROL);
-	clk &= ~(SDHCI_CLOCK_CARD_EN | SDHCI_CLOCK_INT_EN);
-	sdhci_writew(host, clk, SDHCI_CLOCK_CONTROL);
-
-	/* Issue DLL Reset */
-	zynqmp_pm_sd_dll_reset(deviceid, PM_DLL_RESET_PULSE);
-
-	clk = sdhci_readw(host, SDHCI_CLOCK_CONTROL);
-
-	sdhci_enable_clk(host, clk);
-}
-
-static int arasan_zynqmp_execute_tuning(struct mmc_host *mmc, u32 opcode)
-{
-	struct sdhci_host *host = mmc_priv(mmc);
-	struct sdhci_pltfm_host *pltfm_host = sdhci_priv(host);
-	struct sdhci_arasan_data *sdhci_arasan = sdhci_pltfm_priv(pltfm_host);
-	struct clk_hw *hw = &sdhci_arasan->clk_data.sdcardclk_hw;
-	const char *clk_name = clk_hw_get_name(hw);
-	u32 device_id = !strcmp(clk_name, "clk_out_sd0") ? NODE_SD_0 :
-							   NODE_SD_1;
-	int err;
-
-	arasan_zynqmp_dll_reset(host, device_id);
-
-	err = sdhci_execute_tuning(mmc, opcode);
-	if (err)
-		return err;
-
-	arasan_zynqmp_dll_reset(host, device_id);
-
-	return 0;
-}
-
-/**
- * sdhci_arasan_update_clockmultiplier - Set corecfg_clockmultiplier
- *
- * @host:		The sdhci_host
- * @value:		The value to write
- *
- * The corecfg_clockmultiplier is supposed to contain clock multiplier
- * value of programmable clock generator.
- *
- * NOTES:
- * - Many existing devices don't seem to do this and work fine.  To keep
- *   compatibility for old hardware where the device tree doesn't provide a
- *   register map, this function is a noop if a soc_ctl_map hasn't been provided
- *   for this platform.
- * - The value of corecfg_clockmultiplier should sync with that of corresponding
- *   value reading from sdhci_capability_register. So this function is called
- *   once at probe time and never called again.
- */
-static void sdhci_arasan_update_clockmultiplier(struct sdhci_host *host,
-						u32 value)
-{
-	struct sdhci_pltfm_host *pltfm_host = sdhci_priv(host);
-	struct sdhci_arasan_data *sdhci_arasan = sdhci_pltfm_priv(pltfm_host);
-	const struct sdhci_arasan_soc_ctl_map *soc_ctl_map =
-		sdhci_arasan->soc_ctl_map;
-
-	/* Having a map is optional */
-	if (!soc_ctl_map)
-		return;
-
-	/* If we have a map, we expect to have a syscon */
-	if (!sdhci_arasan->soc_ctl_base) {
-		pr_warn("%s: Have regmap, but no soc-ctl-syscon\n",
-			mmc_hostname(host->mmc));
-		return;
-	}
-
-	sdhci_arasan_syscon_write(host, &soc_ctl_map->clockmultiplier, value);
-}
-
-/**
- * sdhci_arasan_update_baseclkfreq - Set corecfg_baseclkfreq
- *
- * @host:		The sdhci_host
- *
- * The corecfg_baseclkfreq is supposed to contain the MHz of clk_xin.  This
- * function can be used to make that happen.
- *
- * NOTES:
- * - Many existing devices don't seem to do this and work fine.  To keep
- *   compatibility for old hardware where the device tree doesn't provide a
- *   register map, this function is a noop if a soc_ctl_map hasn't been provided
- *   for this platform.
- * - It's assumed that clk_xin is not dynamic and that we use the SDHCI divider
- *   to achieve lower clock rates.  That means that this function is called once
- *   at probe time and never called again.
- */
-static void sdhci_arasan_update_baseclkfreq(struct sdhci_host *host)
-{
-	struct sdhci_pltfm_host *pltfm_host = sdhci_priv(host);
-	struct sdhci_arasan_data *sdhci_arasan = sdhci_pltfm_priv(pltfm_host);
-	const struct sdhci_arasan_soc_ctl_map *soc_ctl_map =
-		sdhci_arasan->soc_ctl_map;
-	u32 mhz = DIV_ROUND_CLOSEST(clk_get_rate(pltfm_host->clk), 1000000);
-
-	/* Having a map is optional */
-	if (!soc_ctl_map)
-		return;
-
-	/* If we have a map, we expect to have a syscon */
-	if (!sdhci_arasan->soc_ctl_base) {
-		pr_warn("%s: Have regmap, but no soc-ctl-syscon\n",
-			mmc_hostname(host->mmc));
-		return;
-	}
-
-	sdhci_arasan_syscon_write(host, &soc_ctl_map->baseclkfreq, mhz);
-}
-
-static void sdhci_arasan_set_clk_delays(struct sdhci_host *host)
-{
-	struct sdhci_pltfm_host *pltfm_host = sdhci_priv(host);
-	struct sdhci_arasan_data *sdhci_arasan = sdhci_pltfm_priv(pltfm_host);
-	struct sdhci_arasan_clk_data *clk_data = &sdhci_arasan->clk_data;
-
-	clk_set_phase(clk_data->sampleclk,
-		      clk_data->clk_phase_in[host->timing]);
-	clk_set_phase(clk_data->sdcardclk,
-		      clk_data->clk_phase_out[host->timing]);
-}
-
-static void arasan_dt_read_clk_phase(struct device *dev,
-				     struct sdhci_arasan_clk_data *clk_data,
-				     unsigned int timing, const char *prop)
-{
-	struct device_node *np = dev->of_node;
-
-	int clk_phase[2] = {0};
-
-	/*
-	 * Read Tap Delay values from DT, if the DT does not contain the
-	 * Tap Values then use the pre-defined values.
-	 */
-	if (of_property_read_variable_u32_array(np, prop, &clk_phase[0],
-						2, 0)) {
-		dev_dbg(dev, "Using predefined clock phase for %s = %d %d\n",
-			prop, clk_data->clk_phase_in[timing],
-			clk_data->clk_phase_out[timing]);
-		return;
-	}
-
-	/* The values read are Input and Output Clock Delays in order */
-	clk_data->clk_phase_in[timing] = clk_phase[0];
-	clk_data->clk_phase_out[timing] = clk_phase[1];
-}
-
-/**
- * arasan_dt_parse_clk_phases - Read Clock Delay values from DT
- *
- * @dev:		Pointer to our struct device.
- * @clk_data:		Pointer to the Clock Data structure
- *
- * Called at initialization to parse the values of Clock Delays.
- */
-static void arasan_dt_parse_clk_phases(struct device *dev,
-				       struct sdhci_arasan_clk_data *clk_data)
-{
-	u32 mio_bank = 0;
-	int i;
-
-	/*
-	 * This has been kept as a pointer and is assigned a function here.
-	 * So that different controller variants can assign their own handling
-	 * function.
-	 */
-	clk_data->set_clk_delays = sdhci_arasan_set_clk_delays;
-
-	if (of_device_is_compatible(dev->of_node, "xlnx,zynqmp-8.9a")) {
-		u32 zynqmp_iclk_phase[MMC_TIMING_MMC_HS400 + 1] =
-			ZYNQMP_ICLK_PHASE;
-		u32 zynqmp_oclk_phase[MMC_TIMING_MMC_HS400 + 1] =
-			ZYNQMP_OCLK_PHASE;
-
-		of_property_read_u32(dev->of_node, "xlnx,mio-bank", &mio_bank);
-		if (mio_bank == 2) {
-			zynqmp_oclk_phase[MMC_TIMING_UHS_SDR104] = 90;
-			zynqmp_oclk_phase[MMC_TIMING_MMC_HS200] = 90;
-		}
-
-		for (i = 0; i <= MMC_TIMING_MMC_HS400; i++) {
-			clk_data->clk_phase_in[i] = zynqmp_iclk_phase[i];
-			clk_data->clk_phase_out[i] = zynqmp_oclk_phase[i];
-		}
-	}
-
-	if (of_device_is_compatible(dev->of_node, "xlnx,versal-8.9a")) {
-		u32 versal_iclk_phase[MMC_TIMING_MMC_HS400 + 1] =
-			VERSAL_ICLK_PHASE;
-		u32 versal_oclk_phase[MMC_TIMING_MMC_HS400 + 1] =
-			VERSAL_OCLK_PHASE;
-
-		for (i = 0; i <= MMC_TIMING_MMC_HS400; i++) {
-			clk_data->clk_phase_in[i] = versal_iclk_phase[i];
-			clk_data->clk_phase_out[i] = versal_oclk_phase[i];
-		}
-	}
-
-	arasan_dt_read_clk_phase(dev, clk_data, MMC_TIMING_LEGACY,
-				 "clk-phase-legacy");
-	arasan_dt_read_clk_phase(dev, clk_data, MMC_TIMING_MMC_HS,
-				 "clk-phase-mmc-hs");
-	arasan_dt_read_clk_phase(dev, clk_data, MMC_TIMING_SD_HS,
-				 "clk-phase-sd-hs");
-	arasan_dt_read_clk_phase(dev, clk_data, MMC_TIMING_UHS_SDR12,
-				 "clk-phase-uhs-sdr12");
-	arasan_dt_read_clk_phase(dev, clk_data, MMC_TIMING_UHS_SDR25,
-				 "clk-phase-uhs-sdr25");
-	arasan_dt_read_clk_phase(dev, clk_data, MMC_TIMING_UHS_SDR50,
-				 "clk-phase-uhs-sdr50");
-	arasan_dt_read_clk_phase(dev, clk_data, MMC_TIMING_UHS_SDR104,
-				 "clk-phase-uhs-sdr104");
-	arasan_dt_read_clk_phase(dev, clk_data, MMC_TIMING_UHS_DDR50,
-				 "clk-phase-uhs-ddr50");
-	arasan_dt_read_clk_phase(dev, clk_data, MMC_TIMING_MMC_DDR52,
-				 "clk-phase-mmc-ddr52");
-	arasan_dt_read_clk_phase(dev, clk_data, MMC_TIMING_MMC_HS200,
-				 "clk-phase-mmc-hs200");
-	arasan_dt_read_clk_phase(dev, clk_data, MMC_TIMING_MMC_HS400,
-				 "clk-phase-mmc-hs400");
-}
-
-static const struct sdhci_pltfm_data sdhci_arasan_pdata = {
-	.ops = &sdhci_arasan_ops,
-	.quirks = SDHCI_QUIRK_CAP_CLOCK_BASE_BROKEN,
-	.quirks2 = SDHCI_QUIRK2_PRESET_VALUE_BROKEN |
-			SDHCI_QUIRK2_CLOCK_DIV_ZERO_BROKEN |
-			SDHCI_QUIRK2_STOP_WITH_TC,
-};
-
-static const struct sdhci_arasan_clk_ops arasan_clk_ops = {
-	.sdcardclk_ops = &arasan_sdcardclk_ops,
-	.sampleclk_ops = &arasan_sampleclk_ops,
-};
-
-static struct sdhci_arasan_of_data sdhci_arasan_generic_data = {
-	.pdata = &sdhci_arasan_pdata,
-	.clk_ops = &arasan_clk_ops,
-};
-
-static const struct sdhci_pltfm_data sdhci_keembay_emmc_pdata = {
-	.ops = &sdhci_arasan_cqe_ops,
-	.quirks = SDHCI_QUIRK_CAP_CLOCK_BASE_BROKEN |
-		SDHCI_QUIRK_NO_ENDATTR_IN_NOPDESC |
-		SDHCI_QUIRK_NO_LED |
-		SDHCI_QUIRK_32BIT_DMA_ADDR |
-		SDHCI_QUIRK_32BIT_DMA_SIZE |
-		SDHCI_QUIRK_32BIT_ADMA_SIZE,
-	.quirks2 = SDHCI_QUIRK2_PRESET_VALUE_BROKEN |
-		SDHCI_QUIRK2_CLOCK_DIV_ZERO_BROKEN |
-		SDHCI_QUIRK2_CAPS_BIT63_FOR_HS400 |
-		SDHCI_QUIRK2_STOP_WITH_TC |
-		SDHCI_QUIRK2_BROKEN_64_BIT_DMA,
-};
-
-static const struct sdhci_pltfm_data sdhci_keembay_sd_pdata = {
-	.ops = &sdhci_arasan_ops,
-	.quirks = SDHCI_QUIRK_CAP_CLOCK_BASE_BROKEN |
-		SDHCI_QUIRK_NO_ENDATTR_IN_NOPDESC |
-		SDHCI_QUIRK_NO_LED |
-		SDHCI_QUIRK_32BIT_DMA_ADDR |
-		SDHCI_QUIRK_32BIT_DMA_SIZE |
-		SDHCI_QUIRK_32BIT_ADMA_SIZE,
-	.quirks2 = SDHCI_QUIRK2_PRESET_VALUE_BROKEN |
-		SDHCI_QUIRK2_CLOCK_DIV_ZERO_BROKEN |
-		SDHCI_QUIRK2_CARD_ON_NEEDS_BUS_ON |
-		SDHCI_QUIRK2_STOP_WITH_TC |
-		SDHCI_QUIRK2_BROKEN_64_BIT_DMA,
-};
-
-static const struct sdhci_pltfm_data sdhci_keembay_sdio_pdata = {
-	.ops = &sdhci_arasan_ops,
-	.quirks = SDHCI_QUIRK_CAP_CLOCK_BASE_BROKEN |
-		SDHCI_QUIRK_NO_ENDATTR_IN_NOPDESC |
-		SDHCI_QUIRK_NO_LED |
-		SDHCI_QUIRK_32BIT_DMA_ADDR |
-		SDHCI_QUIRK_32BIT_DMA_SIZE |
-		SDHCI_QUIRK_32BIT_ADMA_SIZE,
-	.quirks2 = SDHCI_QUIRK2_PRESET_VALUE_BROKEN |
-		SDHCI_QUIRK2_CLOCK_DIV_ZERO_BROKEN |
-		SDHCI_QUIRK2_HOST_OFF_CARD_ON |
-		SDHCI_QUIRK2_BROKEN_64_BIT_DMA,
-};
-
-static struct sdhci_arasan_of_data sdhci_arasan_rk3399_data = {
-	.soc_ctl_map = &rk3399_soc_ctl_map,
-	.pdata = &sdhci_arasan_cqe_pdata,
-	.clk_ops = &arasan_clk_ops,
-};
-
-static struct sdhci_arasan_of_data intel_lgm_emmc_data = {
-	.soc_ctl_map = &intel_lgm_emmc_soc_ctl_map,
-	.pdata = &sdhci_arasan_cqe_pdata,
-	.clk_ops = &arasan_clk_ops,
-};
-
-static struct sdhci_arasan_of_data intel_lgm_sdxc_data = {
-	.soc_ctl_map = &intel_lgm_sdxc_soc_ctl_map,
-	.pdata = &sdhci_arasan_cqe_pdata,
-	.clk_ops = &arasan_clk_ops,
-};
-
-static const struct sdhci_pltfm_data sdhci_arasan_zynqmp_pdata = {
-	.ops = &sdhci_arasan_ops,
-	.quirks2 = SDHCI_QUIRK2_PRESET_VALUE_BROKEN |
-			SDHCI_QUIRK2_CLOCK_DIV_ZERO_BROKEN |
-			SDHCI_QUIRK2_STOP_WITH_TC,
-};
-
-static const struct sdhci_arasan_clk_ops zynqmp_clk_ops = {
-	.sdcardclk_ops = &zynqmp_sdcardclk_ops,
-	.sampleclk_ops = &zynqmp_sampleclk_ops,
-};
-
-static struct sdhci_arasan_of_data sdhci_arasan_zynqmp_data = {
-	.pdata = &sdhci_arasan_zynqmp_pdata,
-	.clk_ops = &zynqmp_clk_ops,
-};
-
-static const struct sdhci_arasan_clk_ops versal_clk_ops = {
-	.sdcardclk_ops = &versal_sdcardclk_ops,
-	.sampleclk_ops = &versal_sampleclk_ops,
-};
-
-static struct sdhci_arasan_of_data sdhci_arasan_versal_data = {
-	.pdata = &sdhci_arasan_zynqmp_pdata,
-	.clk_ops = &versal_clk_ops,
-};
-
-static struct sdhci_arasan_of_data intel_keembay_emmc_data = {
-	.soc_ctl_map = &intel_keembay_soc_ctl_map,
-	.pdata = &sdhci_keembay_emmc_pdata,
-	.clk_ops = &arasan_clk_ops,
-};
-
-static struct sdhci_arasan_of_data intel_keembay_sd_data = {
-	.soc_ctl_map = &intel_keembay_soc_ctl_map,
-	.pdata = &sdhci_keembay_sd_pdata,
-	.clk_ops = &arasan_clk_ops,
-};
-
-static struct sdhci_arasan_of_data intel_keembay_sdio_data = {
-	.soc_ctl_map = &intel_keembay_soc_ctl_map,
-	.pdata = &sdhci_keembay_sdio_pdata,
-	.clk_ops = &arasan_clk_ops,
-};
-
-static const struct of_device_id sdhci_arasan_of_match[] = {
-	/* SoC-specific compatible strings w/ soc_ctl_map */
-	{
-		.compatible = "rockchip,rk3399-sdhci-5.1",
-		.data = &sdhci_arasan_rk3399_data,
-	},
-	{
-		.compatible = "intel,lgm-sdhci-5.1-emmc",
-		.data = &intel_lgm_emmc_data,
-	},
-	{
-		.compatible = "intel,lgm-sdhci-5.1-sdxc",
-		.data = &intel_lgm_sdxc_data,
-	},
-	{
-		.compatible = "intel,keembay-sdhci-5.1-emmc",
-		.data = &intel_keembay_emmc_data,
-	},
-	{
-		.compatible = "intel,keembay-sdhci-5.1-sd",
-		.data = &intel_keembay_sd_data,
-	},
-	{
-		.compatible = "intel,keembay-sdhci-5.1-sdio",
-		.data = &intel_keembay_sdio_data,
-	},
-	/* Generic compatible below here */
-	{
-		.compatible = "arasan,sdhci-8.9a",
-		.data = &sdhci_arasan_generic_data,
-	},
-	{
-		.compatible = "arasan,sdhci-5.1",
-		.data = &sdhci_arasan_generic_data,
-	},
-	{
-		.compatible = "arasan,sdhci-4.9a",
-		.data = &sdhci_arasan_generic_data,
-	},
-	{
-		.compatible = "xlnx,zynqmp-8.9a",
-		.data = &sdhci_arasan_zynqmp_data,
-	},
-	{
-		.compatible = "xlnx,versal-8.9a",
-		.data = &sdhci_arasan_versal_data,
-	},
-	{ /* sentinel */ }
-};
-MODULE_DEVICE_TABLE(of, sdhci_arasan_of_match);
-
-/**
- * sdhci_arasan_register_sdcardclk - Register the sdcardclk for a PHY to use
- *
- * @sdhci_arasan:	Our private data structure.
- * @clk_xin:		Pointer to the functional clock
- * @dev:		Pointer to our struct device.
- *
- * Some PHY devices need to know what the actual card clock is.  In order for
- * them to find out, we'll provide a clock through the common clock framework
- * for them to query.
- *
- * Return: 0 on success and error value on error
- */
-static int
-sdhci_arasan_register_sdcardclk(struct sdhci_arasan_data *sdhci_arasan,
-				struct clk *clk_xin,
-				struct device *dev)
-{
-	struct sdhci_arasan_clk_data *clk_data = &sdhci_arasan->clk_data;
-	struct device_node *np = dev->of_node;
-	struct clk_init_data sdcardclk_init;
-	const char *parent_clk_name;
-	int ret;
-
-	ret = of_property_read_string_index(np, "clock-output-names", 0,
-					    &sdcardclk_init.name);
-	if (ret) {
-		dev_err(dev, "DT has #clock-cells but no clock-output-names\n");
-		return ret;
-	}
-
-	parent_clk_name = __clk_get_name(clk_xin);
-	sdcardclk_init.parent_names = &parent_clk_name;
-	sdcardclk_init.num_parents = 1;
-	sdcardclk_init.flags = CLK_GET_RATE_NOCACHE;
-	sdcardclk_init.ops = sdhci_arasan->clk_ops->sdcardclk_ops;
-
-	clk_data->sdcardclk_hw.init = &sdcardclk_init;
-	clk_data->sdcardclk =
-		devm_clk_register(dev, &clk_data->sdcardclk_hw);
-	if (IS_ERR(clk_data->sdcardclk))
-		return PTR_ERR(clk_data->sdcardclk);
-	clk_data->sdcardclk_hw.init = NULL;
-
-	ret = of_clk_add_provider(np, of_clk_src_simple_get,
-				  clk_data->sdcardclk);
-	if (ret)
-		dev_err(dev, "Failed to add sdcard clock provider\n");
-
-	return ret;
-}
-
-/**
- * sdhci_arasan_register_sampleclk - Register the sampleclk for a PHY to use
- *
- * @sdhci_arasan:	Our private data structure.
- * @clk_xin:		Pointer to the functional clock
- * @dev:		Pointer to our struct device.
- *
- * Some PHY devices need to know what the actual card clock is.  In order for
- * them to find out, we'll provide a clock through the common clock framework
- * for them to query.
- *
- * Return: 0 on success and error value on error
- */
-static int
-sdhci_arasan_register_sampleclk(struct sdhci_arasan_data *sdhci_arasan,
-				struct clk *clk_xin,
-				struct device *dev)
-{
-	struct sdhci_arasan_clk_data *clk_data = &sdhci_arasan->clk_data;
-	struct device_node *np = dev->of_node;
-	struct clk_init_data sampleclk_init;
-	const char *parent_clk_name;
-	int ret;
-
-	ret = of_property_read_string_index(np, "clock-output-names", 1,
-					    &sampleclk_init.name);
-	if (ret) {
-		dev_err(dev, "DT has #clock-cells but no clock-output-names\n");
-		return ret;
-	}
-
-	parent_clk_name = __clk_get_name(clk_xin);
-	sampleclk_init.parent_names = &parent_clk_name;
-	sampleclk_init.num_parents = 1;
-	sampleclk_init.flags = CLK_GET_RATE_NOCACHE;
-	sampleclk_init.ops = sdhci_arasan->clk_ops->sampleclk_ops;
-
-	clk_data->sampleclk_hw.init = &sampleclk_init;
-	clk_data->sampleclk =
-		devm_clk_register(dev, &clk_data->sampleclk_hw);
-	if (IS_ERR(clk_data->sampleclk))
-		return PTR_ERR(clk_data->sampleclk);
-	clk_data->sampleclk_hw.init = NULL;
-
-	ret = of_clk_add_provider(np, of_clk_src_simple_get,
-				  clk_data->sampleclk);
-	if (ret)
-		dev_err(dev, "Failed to add sample clock provider\n");
-
-	return ret;
-}
-
-/**
- * sdhci_arasan_unregister_sdclk - Undoes sdhci_arasan_register_sdclk()
- *
- * @dev:		Pointer to our struct device.
- *
- * Should be called any time we're exiting and sdhci_arasan_register_sdclk()
- * returned success.
- */
-static void sdhci_arasan_unregister_sdclk(struct device *dev)
-{
-	struct device_node *np = dev->of_node;
-
-	if (!of_find_property(np, "#clock-cells", NULL))
-		return;
-
-	of_clk_del_provider(dev->of_node);
-}
-
-/**
- * sdhci_arasan_update_support64b - Set SUPPORT_64B (64-bit System Bus Support)
- *
- * This should be set based on the System Address Bus.
- * 0: the Core supports only 32-bit System Address Bus.
- * 1: the Core supports 64-bit System Address Bus.
- *
- * NOTES:
- * - For Keem Bay, it is required to clear this bit. Its default value is 1'b1.
- *   Keem Bay does not support 64-bit access.
- *
- * @host:		The sdhci_host
- * @value:		The value to write
- */
-static void sdhci_arasan_update_support64b(struct sdhci_host *host, u32 value)
-{
-	struct sdhci_pltfm_host *pltfm_host = sdhci_priv(host);
-	struct sdhci_arasan_data *sdhci_arasan = sdhci_pltfm_priv(pltfm_host);
-	const struct sdhci_arasan_soc_ctl_map *soc_ctl_map =
-		sdhci_arasan->soc_ctl_map;
-
-	/* Having a map is optional */
-	if (!soc_ctl_map)
-		return;
-
-	/* If we have a map, we expect to have a syscon */
-	if (!sdhci_arasan->soc_ctl_base) {
-		pr_warn("%s: Have regmap, but no soc-ctl-syscon\n",
-			mmc_hostname(host->mmc));
-		return;
-	}
-
-	sdhci_arasan_syscon_write(host, &soc_ctl_map->support64b, value);
-}
-
-/**
- * sdhci_arasan_register_sdclk - Register the sdcardclk for a PHY to use
- *
- * @sdhci_arasan:	Our private data structure.
- * @clk_xin:		Pointer to the functional clock
- * @dev:		Pointer to our struct device.
- *
- * Some PHY devices need to know what the actual card clock is.  In order for
- * them to find out, we'll provide a clock through the common clock framework
- * for them to query.
- *
- * Note: without seriously re-architecting SDHCI's clock code and testing on
- * all platforms, there's no way to create a totally beautiful clock here
- * with all clock ops implemented.  Instead, we'll just create a clock that can
- * be queried and set the CLK_GET_RATE_NOCACHE attribute to tell common clock
- * framework that we're doing things behind its back.  This should be sufficient
- * to create nice clean device tree bindings and later (if needed) we can try
- * re-architecting SDHCI if we see some benefit to it.
- *
- * Return: 0 on success and error value on error
- */
-static int sdhci_arasan_register_sdclk(struct sdhci_arasan_data *sdhci_arasan,
-				       struct clk *clk_xin,
-				       struct device *dev)
-{
-	struct device_node *np = dev->of_node;
-	u32 num_clks = 0;
-	int ret;
-
-	/* Providing a clock to the PHY is optional; no error if missing */
-	if (of_property_read_u32(np, "#clock-cells", &num_clks) < 0)
-		return 0;
-
-	ret = sdhci_arasan_register_sdcardclk(sdhci_arasan, clk_xin, dev);
-	if (ret)
-		return ret;
-
-	if (num_clks) {
-		ret = sdhci_arasan_register_sampleclk(sdhci_arasan, clk_xin,
-						      dev);
-		if (ret) {
-			sdhci_arasan_unregister_sdclk(dev);
-			return ret;
-		}
-	}
-
-	return 0;
-}
+	of_clk_del_provider(dev->of_node);
+}
 
 static int sdhci_arasan_add_host(struct sdhci_arasan_data *sdhci_arasan)
 {
@@ -1553,7 +753,6 @@ static int sdhci_arasan_probe(struct platform_device *pdev)
 	sdhci_arasan->host = host;
 
 	sdhci_arasan->soc_ctl_map = data->soc_ctl_map;
-	sdhci_arasan->clk_ops = data->clk_ops;
 
 	node = of_parse_phandle(pdev->dev.of_node, "arasan,soc-ctl-syscon", 0);
 	if (node) {
@@ -1561,9 +760,10 @@ static int sdhci_arasan_probe(struct platform_device *pdev)
 		of_node_put(node);
 
 		if (IS_ERR(sdhci_arasan->soc_ctl_base)) {
-			ret = dev_err_probe(&pdev->dev,
-					    PTR_ERR(sdhci_arasan->soc_ctl_base),
-					    "Can't get syscon\n");
+			ret = PTR_ERR(sdhci_arasan->soc_ctl_base);
+			if (ret != -EPROBE_DEFER)
+				dev_err(&pdev->dev, "Can't get syscon: %d\n",
+					ret);
 			goto err_pltfm_free;
 		}
 	}
@@ -1608,30 +808,12 @@ static int sdhci_arasan_probe(struct platform_device *pdev)
 				    "rockchip,rk3399-sdhci-5.1"))
 		sdhci_arasan_update_clockmultiplier(host, 0x0);
 
-	if (of_device_is_compatible(np, "intel,keembay-sdhci-5.1-emmc") ||
-	    of_device_is_compatible(np, "intel,keembay-sdhci-5.1-sd") ||
-	    of_device_is_compatible(np, "intel,keembay-sdhci-5.1-sdio")) {
-		sdhci_arasan_update_clockmultiplier(host, 0x0);
-		sdhci_arasan_update_support64b(host, 0x0);
-
-		host->mmc->caps |= MMC_CAP_WAIT_WHILE_BUSY;
-	}
-
 	sdhci_arasan_update_baseclkfreq(host);
 
 	ret = sdhci_arasan_register_sdclk(sdhci_arasan, clk_xin, &pdev->dev);
 	if (ret)
 		goto clk_disable_all;
 
-	if (of_device_is_compatible(np, "xlnx,zynqmp-8.9a")) {
-		host->mmc_host_ops.execute_tuning =
-			arasan_zynqmp_execute_tuning;
-
-		sdhci_arasan->quirks |= SDHCI_ARASAN_QUIRK_CLOCK_25_BROKEN;
-	}
-
-	arasan_dt_parse_clk_phases(&pdev->dev, &sdhci_arasan->clk_data);
-
 	ret = mmc_of_parse(host->mmc);
 	if (ret) {
 		if (ret != -EPROBE_DEFER)
@@ -1713,7 +895,6 @@ static int sdhci_arasan_remove(struct platform_device *pdev)
 static struct platform_driver sdhci_arasan_driver = {
 	.driver = {
 		.name = "sdhci-arasan",
-		.probe_type = PROBE_PREFER_ASYNCHRONOUS,
 		.of_match_table = sdhci_arasan_of_match,
 		.pm = &sdhci_arasan_dev_pm_ops,
 	},
diff --git a/drivers/mmc/host/sdhci-of-esdhc.c b/drivers/mmc/host/sdhci-of-esdhc.c
index ab5ab969f..3d87102e9 100644
--- a/drivers/mmc/host/sdhci-of-esdhc.c
+++ b/drivers/mmc/host/sdhci-of-esdhc.c
@@ -4,7 +4,6 @@
  *
  * Copyright (c) 2007, 2010, 2012 Freescale Semiconductor, Inc.
  * Copyright (c) 2009 MontaVista Software, Inc.
- * Copyright 2020 NXP
  *
  * Authors: Xiaobo Xie <X.Xie@freescale.com>
  *	    Anton Vorontsov <avorontsov@ru.mvista.com>
@@ -20,7 +19,6 @@
 #include <linux/clk.h>
 #include <linux/ktime.h>
 #include <linux/dma-mapping.h>
-#include <linux/iopoll.h>
 #include <linux/mmc/host.h>
 #include <linux/mmc/mmc.h>
 #include "sdhci-pltfm.h"
@@ -82,8 +80,6 @@ struct sdhci_esdhc {
 	bool quirk_tuning_erratum_type1;
 	bool quirk_tuning_erratum_type2;
 	bool quirk_ignore_data_inhibit;
-	bool quirk_delay_before_data_reset;
-	bool quirk_trans_complete_erratum;
 	bool in_sw_tuning;
 	unsigned int peripheral_clock;
 	const struct esdhc_clk_fixup *clk_fixup;
@@ -176,9 +172,6 @@ static u16 esdhc_readw_fixup(struct sdhci_host *host,
 	u16 ret;
 	int shift = (spec_reg & 0x2) * 8;
 
-	if (spec_reg == SDHCI_TRANSFER_MODE)
-		return pltfm_host->xfer_mode_shadow;
-
 	if (spec_reg == SDHCI_HOST_VERSION)
 		ret = value & 0xffff;
 	else
@@ -568,46 +561,32 @@ static unsigned int esdhc_of_get_min_clock(struct sdhci_host *host)
 
 static void esdhc_clock_enable(struct sdhci_host *host, bool enable)
 {
-	struct sdhci_pltfm_host *pltfm_host = sdhci_priv(host);
-	struct sdhci_esdhc *esdhc = sdhci_pltfm_priv(pltfm_host);
+	u32 val;
 	ktime_t timeout;
-	u32 val, clk_en;
-
-	clk_en = ESDHC_CLOCK_SDCLKEN;
-
-	/*
-	 * IPGEN/HCKEN/PEREN bits exist on eSDHC whose vendor version
-	 * is 2.2 or lower.
-	 */
-	if (esdhc->vendor_ver <= VENDOR_V_22)
-		clk_en |= (ESDHC_CLOCK_IPGEN | ESDHC_CLOCK_HCKEN |
-			   ESDHC_CLOCK_PEREN);
 
 	val = sdhci_readl(host, ESDHC_SYSTEM_CONTROL);
 
 	if (enable)
-		val |= clk_en;
+		val |= ESDHC_CLOCK_SDCLKEN;
 	else
-		val &= ~clk_en;
+		val &= ~ESDHC_CLOCK_SDCLKEN;
 
 	sdhci_writel(host, val, ESDHC_SYSTEM_CONTROL);
 
-	/*
-	 * Wait max 20 ms. If vendor version is 2.2 or lower, do not
-	 * wait clock stable bit which does not exist.
-	 */
+	/* Wait max 20 ms */
 	timeout = ktime_add_ms(ktime_get(), 20);
-	while (esdhc->vendor_ver > VENDOR_V_22) {
+	val = ESDHC_CLOCK_STABLE;
+	while  (1) {
 		bool timedout = ktime_after(ktime_get(), timeout);
 
-		if (sdhci_readl(host, ESDHC_PRSSTAT) & ESDHC_CLOCK_STABLE)
+		if (sdhci_readl(host, ESDHC_PRSSTAT) & val)
 			break;
 		if (timedout) {
 			pr_err("%s: Internal clock never stabilised.\n",
 				mmc_hostname(host->mmc));
 			break;
 		}
-		usleep_range(10, 20);
+		udelay(10);
 	}
 }
 
@@ -641,97 +620,77 @@ static void esdhc_of_set_clock(struct sdhci_host *host, unsigned int clock)
 {
 	struct sdhci_pltfm_host *pltfm_host = sdhci_priv(host);
 	struct sdhci_esdhc *esdhc = sdhci_pltfm_priv(pltfm_host);
-	unsigned int pre_div = 1, div = 1;
-	unsigned int clock_fixup = 0;
+	int pre_div = 1;
+	int div = 1;
+	int division;
 	ktime_t timeout;
+	long fixup = 0;
 	u32 temp;
 
+	host->mmc->actual_clock = 0;
+
 	if (clock == 0) {
-		host->mmc->actual_clock = 0;
 		esdhc_clock_enable(host, false);
 		return;
 	}
 
-	/* Start pre_div at 2 for vendor version < 2.3. */
+	/* Workaround to start pre_div at 2 for VNN < VENDOR_V_23 */
 	if (esdhc->vendor_ver < VENDOR_V_23)
 		pre_div = 2;
 
-	/* Fix clock value. */
 	if (host->mmc->card && mmc_card_sd(host->mmc->card) &&
-	    esdhc->clk_fixup && host->mmc->ios.timing == MMC_TIMING_LEGACY)
-		clock_fixup = esdhc->clk_fixup->sd_dflt_max_clk;
+		esdhc->clk_fixup && host->mmc->ios.timing == MMC_TIMING_LEGACY)
+		fixup = esdhc->clk_fixup->sd_dflt_max_clk;
 	else if (esdhc->clk_fixup)
-		clock_fixup = esdhc->clk_fixup->max_clk[host->mmc->ios.timing];
+		fixup = esdhc->clk_fixup->max_clk[host->mmc->ios.timing];
 
-	if (clock_fixup == 0 || clock < clock_fixup)
-		clock_fixup = clock;
+	if (fixup && clock > fixup)
+		clock = fixup;
 
-	/* Calculate pre_div and div. */
-	while (host->max_clk / pre_div / 16 > clock_fixup && pre_div < 256)
+	temp = sdhci_readl(host, ESDHC_SYSTEM_CONTROL);
+	temp &= ~(ESDHC_CLOCK_SDCLKEN | ESDHC_CLOCK_IPGEN | ESDHC_CLOCK_HCKEN |
+		  ESDHC_CLOCK_PEREN | ESDHC_CLOCK_MASK);
+	sdhci_writel(host, temp, ESDHC_SYSTEM_CONTROL);
+
+	while (host->max_clk / pre_div / 16 > clock && pre_div < 256)
 		pre_div *= 2;
 
-	while (host->max_clk / pre_div / div > clock_fixup && div < 16)
+	while (host->max_clk / pre_div / div > clock && div < 16)
 		div++;
 
-	esdhc->div_ratio = pre_div * div;
-
-	/* Limit clock division for HS400 200MHz clock for quirk. */
 	if (esdhc->quirk_limited_clk_division &&
 	    clock == MMC_HS200_MAX_DTR &&
 	    (host->mmc->ios.timing == MMC_TIMING_MMC_HS400 ||
 	     host->flags & SDHCI_HS400_TUNING)) {
-		if (esdhc->div_ratio <= 4) {
+		division = pre_div * div;
+		if (division <= 4) {
 			pre_div = 4;
 			div = 1;
-		} else if (esdhc->div_ratio <= 8) {
+		} else if (division <= 8) {
 			pre_div = 4;
 			div = 2;
-		} else if (esdhc->div_ratio <= 12) {
+		} else if (division <= 12) {
 			pre_div = 4;
 			div = 3;
 		} else {
 			pr_warn("%s: using unsupported clock division.\n",
 				mmc_hostname(host->mmc));
 		}
-		esdhc->div_ratio = pre_div * div;
 	}
 
-	host->mmc->actual_clock = host->max_clk / esdhc->div_ratio;
-
 	dev_dbg(mmc_dev(host->mmc), "desired SD clock: %d, actual: %d\n",
-		clock, host->mmc->actual_clock);
-
-	/* Set clock division into register. */
+		clock, host->max_clk / pre_div / div);
+	host->mmc->actual_clock = host->max_clk / pre_div / div;
+	esdhc->div_ratio = pre_div * div;
 	pre_div >>= 1;
 	div--;
 
-	esdhc_clock_enable(host, false);
-
 	temp = sdhci_readl(host, ESDHC_SYSTEM_CONTROL);
-	temp &= ~ESDHC_CLOCK_MASK;
-	temp |= ((div << ESDHC_DIVIDER_SHIFT) |
-		(pre_div << ESDHC_PREDIV_SHIFT));
+	temp |= (ESDHC_CLOCK_IPGEN | ESDHC_CLOCK_HCKEN | ESDHC_CLOCK_PEREN
+		| (div << ESDHC_DIVIDER_SHIFT)
+		| (pre_div << ESDHC_PREDIV_SHIFT));
 	sdhci_writel(host, temp, ESDHC_SYSTEM_CONTROL);
 
-	/*
-	 * Wait max 20 ms. If vendor version is 2.2 or lower, do not
-	 * wait clock stable bit which does not exist.
-	 */
-	timeout = ktime_add_ms(ktime_get(), 20);
-	while (esdhc->vendor_ver > VENDOR_V_22) {
-		bool timedout = ktime_after(ktime_get(), timeout);
-
-		if (sdhci_readl(host, ESDHC_PRSSTAT) & ESDHC_CLOCK_STABLE)
-			break;
-		if (timedout) {
-			pr_err("%s: Internal clock never stabilised.\n",
-				mmc_hostname(host->mmc));
-			break;
-		}
-		usleep_range(10, 20);
-	}
-
-	/* Additional setting for HS400. */
 	if (host->mmc->ios.timing == MMC_TIMING_MMC_HS400 &&
 	    clock == MMC_HS200_MAX_DTR) {
 		temp = sdhci_readl(host, ESDHC_TBCTL);
@@ -745,28 +704,31 @@ static void esdhc_of_set_clock(struct sdhci_host *host, unsigned int clock)
 		if (host->mmc->actual_clock == MMC_HS200_MAX_DTR)
 			temp |= ESDHC_DLL_FREQ_SEL;
 		sdhci_writel(host, temp, ESDHC_DLLCFG0);
-
-		temp |= ESDHC_DLL_RESET;
-		sdhci_writel(host, temp, ESDHC_DLLCFG0);
-		udelay(1);
-		temp &= ~ESDHC_DLL_RESET;
-		sdhci_writel(host, temp, ESDHC_DLLCFG0);
-
-		/* Wait max 20 ms */
-		if (read_poll_timeout(sdhci_readl, temp,
-				      temp & ESDHC_DLL_STS_SLV_LOCK,
-				      10, 20000, false,
-				      host, ESDHC_DLLSTAT0))
-			pr_err("%s: timeout for delay chain lock.\n",
-			       mmc_hostname(host->mmc));
-
 		temp = sdhci_readl(host, ESDHC_TBCTL);
 		sdhci_writel(host, temp | ESDHC_HS400_WNDW_ADJUST, ESDHC_TBCTL);
 
 		esdhc_clock_enable(host, false);
 		esdhc_flush_async_fifo(host);
 	}
-	esdhc_clock_enable(host, true);
+
+	/* Wait max 20 ms */
+	timeout = ktime_add_ms(ktime_get(), 20);
+	while (1) {
+		bool timedout = ktime_after(ktime_get(), timeout);
+
+		if (sdhci_readl(host, ESDHC_PRSSTAT) & ESDHC_CLOCK_STABLE)
+			break;
+		if (timedout) {
+			pr_err("%s: Internal clock never stabilised.\n",
+				mmc_hostname(host->mmc));
+			return;
+		}
+		udelay(10);
+	}
+
+	temp = sdhci_readl(host, ESDHC_SYSTEM_CONTROL);
+	temp |= ESDHC_CLOCK_SDCLKEN;
+	sdhci_writel(host, temp, ESDHC_SYSTEM_CONTROL);
 }
 
 static void esdhc_pltfm_set_bus_width(struct sdhci_host *host, int width)
@@ -795,58 +757,21 @@ static void esdhc_reset(struct sdhci_host *host, u8 mask)
 {
 	struct sdhci_pltfm_host *pltfm_host = sdhci_priv(host);
 	struct sdhci_esdhc *esdhc = sdhci_pltfm_priv(pltfm_host);
-	u32 val, bus_width = 0;
-
-	/*
-	 * Add delay to make sure all the DMA transfers are finished
-	 * for quirk.
-	 */
-	if (esdhc->quirk_delay_before_data_reset &&
-	    (mask & SDHCI_RESET_DATA) &&
-	    (host->flags & SDHCI_REQ_USE_DMA))
-		mdelay(5);
-
-	/*
-	 * Save bus-width for eSDHC whose vendor version is 2.2
-	 * or lower for data reset.
-	 */
-	if ((mask & SDHCI_RESET_DATA) &&
-	    (esdhc->vendor_ver <= VENDOR_V_22)) {
-		val = sdhci_readl(host, ESDHC_PROCTL);
-		bus_width = val & ESDHC_CTRL_BUSWIDTH_MASK;
-	}
+	u32 val;
 
 	sdhci_reset(host, mask);
 
-	/*
-	 * Restore bus-width setting and interrupt registers for eSDHC
-	 * whose vendor version is 2.2 or lower for data reset.
-	 */
-	if ((mask & SDHCI_RESET_DATA) &&
-	    (esdhc->vendor_ver <= VENDOR_V_22)) {
-		val = sdhci_readl(host, ESDHC_PROCTL);
-		val &= ~ESDHC_CTRL_BUSWIDTH_MASK;
-		val |= bus_width;
-		sdhci_writel(host, val, ESDHC_PROCTL);
+	sdhci_writel(host, host->ier, SDHCI_INT_ENABLE);
+	sdhci_writel(host, host->ier, SDHCI_SIGNAL_ENABLE);
 
-		sdhci_writel(host, host->ier, SDHCI_INT_ENABLE);
-		sdhci_writel(host, host->ier, SDHCI_SIGNAL_ENABLE);
-	}
+	if (of_find_compatible_node(NULL, NULL, "fsl,p2020-esdhc"))
+		mdelay(5);
 
-	/*
-	 * Some bits have to be cleaned manually for eSDHC whose spec
-	 * version is higher than 3.0 for all reset.
-	 */
-	if ((mask & SDHCI_RESET_ALL) &&
-	    (esdhc->spec_ver >= SDHCI_SPEC_300)) {
+	if (mask & SDHCI_RESET_ALL) {
 		val = sdhci_readl(host, ESDHC_TBCTL);
 		val &= ~ESDHC_TB_EN;
 		sdhci_writel(host, val, ESDHC_TBCTL);
 
-		/*
-		 * Initialize eSDHC_DLLCFG1[DLL_PD_PULSE_STRETCH_SEL] to
-		 * 0 for quirk.
-		 */
 		if (esdhc->quirk_unreliable_pulse_detection) {
 			val = sdhci_readl(host, ESDHC_DLLCFG1);
 			val &= ~ESDHC_DLL_PD_PULSE_STRETCH_SEL;
@@ -1069,17 +994,6 @@ static int esdhc_execute_tuning(struct mmc_host *mmc, u32 opcode)
 
 	esdhc_tuning_block_enable(host, true);
 
-	/*
-	 * The eSDHC controller takes the data timeout value into account
-	 * during tuning. If the SD card is too slow sending the response, the
-	 * timer will expire and a "Buffer Read Ready" interrupt without data
-	 * is triggered. This leads to tuning errors.
-	 *
-	 * Just set the timeout to the maximum value because the core will
-	 * already take care of it in sdhci_send_tuning().
-	 */
-	sdhci_writeb(host, 0xe, SDHCI_TIMEOUT_CONTROL);
-
 	hs400_tuning = host->flags & SDHCI_HS400_TUNING;
 
 	do {
@@ -1164,40 +1078,6 @@ static int esdhc_execute_tuning(struct mmc_host *mmc, u32 opcode)
 static void esdhc_set_uhs_signaling(struct sdhci_host *host,
 				   unsigned int timing)
 {
-	u32 val;
-
-	/*
-	 * There are specific registers setting for HS400 mode.
-	 * Clean all of them if controller is in HS400 mode to
-	 * exit HS400 mode before re-setting any speed mode.
-	 */
-	val = sdhci_readl(host, ESDHC_TBCTL);
-	if (val & ESDHC_HS400_MODE) {
-		val = sdhci_readl(host, ESDHC_SDTIMNGCTL);
-		val &= ~ESDHC_FLW_CTL_BG;
-		sdhci_writel(host, val, ESDHC_SDTIMNGCTL);
-
-		val = sdhci_readl(host, ESDHC_SDCLKCTL);
-		val &= ~ESDHC_CMD_CLK_CTL;
-		sdhci_writel(host, val, ESDHC_SDCLKCTL);
-
-		esdhc_clock_enable(host, false);
-		val = sdhci_readl(host, ESDHC_TBCTL);
-		val &= ~ESDHC_HS400_MODE;
-		sdhci_writel(host, val, ESDHC_TBCTL);
-		esdhc_clock_enable(host, true);
-
-		val = sdhci_readl(host, ESDHC_DLLCFG0);
-		val &= ~(ESDHC_DLL_ENABLE | ESDHC_DLL_FREQ_SEL);
-		sdhci_writel(host, val, ESDHC_DLLCFG0);
-
-		val = sdhci_readl(host, ESDHC_TBCTL);
-		val &= ~ESDHC_HS400_WNDW_ADJUST;
-		sdhci_writel(host, val, ESDHC_TBCTL);
-
-		esdhc_tuning_block_enable(host, false);
-	}
-
 	if (timing == MMC_TIMING_MMC_HS400)
 		esdhc_tuning_block_enable(host, true);
 	else
@@ -1206,11 +1086,10 @@ static void esdhc_set_uhs_signaling(struct sdhci_host *host,
 
 static u32 esdhc_irq(struct sdhci_host *host, u32 intmask)
 {
-	struct sdhci_pltfm_host *pltfm_host = sdhci_priv(host);
-	struct sdhci_esdhc *esdhc = sdhci_pltfm_priv(pltfm_host);
 	u32 command;
 
-	if (esdhc->quirk_trans_complete_erratum) {
+	if (of_find_compatible_node(NULL, NULL,
+				"fsl,p2020-esdhc")) {
 		command = SDHCI_GET_CMD(sdhci_readw(host,
 					SDHCI_COMMAND));
 		if (command == MMC_WRITE_MULTIPLE_BLOCK &&
@@ -1324,8 +1203,6 @@ static struct soc_device_attribute soc_fixup_sdhc_clkdivs[] = {
 
 static struct soc_device_attribute soc_unreliable_pulse_detection[] = {
 	{ .family = "QorIQ LX2160A", .revision = "1.0", },
-	{ .family = "QorIQ LX2160A", .revision = "2.0", },
-	{ .family = "QorIQ LS1028A", .revision = "1.0", },
 	{ },
 };
 
@@ -1365,12 +1242,6 @@ static void esdhc_init(struct platform_device *pdev, struct sdhci_host *host)
 	if (match)
 		esdhc->clk_fixup = match->data;
 	np = pdev->dev.of_node;
-
-	if (of_device_is_compatible(np, "fsl,p2020-esdhc")) {
-		esdhc->quirk_delay_before_data_reset = true;
-		esdhc->quirk_trans_complete_erratum = true;
-	}
-
 	clk = of_clk_get(np, 0);
 	if (!IS_ERR(clk)) {
 		/*
@@ -1381,8 +1252,7 @@ static void esdhc_init(struct platform_device *pdev, struct sdhci_host *host)
 		 * 1/2 peripheral clock.
 		 */
 		if (of_device_is_compatible(np, "fsl,ls1046a-esdhc") ||
-		    of_device_is_compatible(np, "fsl,ls1028a-esdhc") ||
-		    of_device_is_compatible(np, "fsl,ls1088a-esdhc"))
+		    of_device_is_compatible(np, "fsl,ls1028a-esdhc"))
 			esdhc->peripheral_clock = clk_get_rate(clk) / 2;
 		else
 			esdhc->peripheral_clock = clk_get_rate(clk);
@@ -1390,19 +1260,13 @@ static void esdhc_init(struct platform_device *pdev, struct sdhci_host *host)
 		clk_put(clk);
 	}
 
-	esdhc_clock_enable(host, false);
-	val = sdhci_readl(host, ESDHC_DMA_SYSCTL);
-	/*
-	 * This bit is not able to be reset by SDHCI_RESET_ALL. Need to
-	 * initialize it as 1 or 0 once, to override the different value
-	 * which may be configured in bootloader.
-	 */
-	if (esdhc->peripheral_clock)
+	if (esdhc->peripheral_clock) {
+		esdhc_clock_enable(host, false);
+		val = sdhci_readl(host, ESDHC_DMA_SYSCTL);
 		val |= ESDHC_PERIPHERAL_CLK_SEL;
-	else
-		val &= ~ESDHC_PERIPHERAL_CLK_SEL;
-	sdhci_writel(host, val, ESDHC_DMA_SYSCTL);
-	esdhc_clock_enable(host, true);
+		sdhci_writel(host, val, ESDHC_DMA_SYSCTL);
+		esdhc_clock_enable(host, true);
+	}
 }
 
 static int esdhc_hs400_prepare_ddr(struct mmc_host *mmc)
@@ -1460,8 +1324,8 @@ static int sdhci_esdhc_probe(struct platform_device *pdev)
 		host->quirks &= ~SDHCI_QUIRK_NO_BUSY_IRQ;
 
 	if (of_find_compatible_node(NULL, NULL, "fsl,p2020-esdhc")) {
-		host->quirks |= SDHCI_QUIRK_RESET_AFTER_REQUEST;
-		host->quirks |= SDHCI_QUIRK_BROKEN_TIMEOUT_VAL;
+		host->quirks2 |= SDHCI_QUIRK_RESET_AFTER_REQUEST;
+		host->quirks2 |= SDHCI_QUIRK_BROKEN_TIMEOUT_VAL;
 	}
 
 	if (of_device_is_compatible(np, "fsl,p5040-esdhc") ||
@@ -1504,7 +1368,6 @@ static int sdhci_esdhc_probe(struct platform_device *pdev)
 static struct platform_driver sdhci_esdhc_driver = {
 	.driver = {
 		.name = "sdhci-esdhc",
-		.probe_type = PROBE_PREFER_ASYNCHRONOUS,
 		.of_match_table = sdhci_esdhc_of_match,
 		.pm = &esdhc_of_dev_pm_ops,
 	},
diff --git a/drivers/mmc/host/sdhci-pltfm.h b/drivers/mmc/host/sdhci-pltfm.h
index 9bd717ff7..2af445b8c 100644
--- a/drivers/mmc/host/sdhci-pltfm.h
+++ b/drivers/mmc/host/sdhci-pltfm.h
@@ -25,7 +25,7 @@ struct sdhci_pltfm_host {
 	unsigned int clock;
 	u16 xfer_mode_shadow;
 
-	unsigned long private[] ____cacheline_aligned;
+	unsigned long private[0] ____cacheline_aligned;
 };
 
 #ifdef CONFIG_MMC_SDHCI_BIG_ENDIAN_32BIT_BYTE_SWAPPER
@@ -111,13 +111,8 @@ static inline void *sdhci_pltfm_priv(struct sdhci_pltfm_host *host)
 	return host->private;
 }
 
-extern const struct dev_pm_ops sdhci_pltfm_pmops;
-#ifdef CONFIG_PM_SLEEP
 int sdhci_pltfm_suspend(struct device *dev);
 int sdhci_pltfm_resume(struct device *dev);
-#else
-static inline int sdhci_pltfm_suspend(struct device *dev) { return 0; }
-static inline int sdhci_pltfm_resume(struct device *dev) { return 0; }
-#endif
+extern const struct dev_pm_ops sdhci_pltfm_pmops;
 
 #endif /* _DRIVERS_MMC_SDHCI_PLTFM_H */
diff --git a/drivers/mmc/host/sdhci-tegra.c b/drivers/mmc/host/sdhci-tegra.c
index d50b691f6..b117d1f06 100644
--- a/drivers/mmc/host/sdhci-tegra.c
+++ b/drivers/mmc/host/sdhci-tegra.c
@@ -45,7 +45,6 @@
 #define SDHCI_TEGRA_CAP_OVERRIDES_DQS_TRIM_SHIFT	8
 
 #define SDHCI_TEGRA_VENDOR_MISC_CTRL			0x120
-#define SDHCI_MISC_CTRL_ERASE_TIMEOUT_LIMIT		BIT(0)
 #define SDHCI_MISC_CTRL_ENABLE_SDR104			0x8
 #define SDHCI_MISC_CTRL_ENABLE_SDR50			0x10
 #define SDHCI_MISC_CTRL_ENABLE_SDHCI_SPEC_300		0x20
@@ -96,33 +95,14 @@
 #define NVQUIRK_ENABLE_SDR50				BIT(3)
 #define NVQUIRK_ENABLE_SDR104				BIT(4)
 #define NVQUIRK_ENABLE_DDR50				BIT(5)
-/*
- * HAS_PADCALIB NVQUIRK is for SoC's supporting auto calibration of pads
- * drive strength.
- */
 #define NVQUIRK_HAS_PADCALIB				BIT(6)
-/*
- * NEEDS_PAD_CONTROL NVQUIRK is for SoC's having separate 3V3 and 1V8 pads.
- * 3V3/1V8 pad selection happens through pinctrl state selection depending
- * on the signaling mode.
- */
 #define NVQUIRK_NEEDS_PAD_CONTROL			BIT(7)
 #define NVQUIRK_DIS_CARD_CLK_CONFIG_TAP			BIT(8)
 #define NVQUIRK_CQHCI_DCMD_R1B_CMD_TIMING		BIT(9)
 
-/*
- * NVQUIRK_HAS_TMCLK is for SoC's having separate timeout clock for Tegra
- * SDMMC hardware data timeout.
- */
-#define NVQUIRK_HAS_TMCLK				BIT(10)
-
 /* SDMMC CQE Base Address for Tegra Host Ver 4.1 and Higher */
 #define SDHCI_TEGRA_CQE_BASE_ADDR			0xF000
 
-#define SDHCI_TEGRA_CQE_TRNS_MODE	(SDHCI_TRNS_MULTI | \
-					 SDHCI_TRNS_BLK_CNT_EN | \
-					 SDHCI_TRNS_DMA)
-
 struct sdhci_tegra_soc_data {
 	const struct sdhci_pltfm_data *pdata;
 	u64 dma_mask;
@@ -150,7 +130,6 @@ struct sdhci_tegra_autocal_offsets {
 struct sdhci_tegra {
 	const struct sdhci_tegra_soc_data *soc_data;
 	struct gpio_desc *power_gpio;
-	struct clk *tmclk;
 	bool ddr_signaling;
 	bool pad_calib_required;
 	bool pad_control_available;
@@ -390,7 +369,7 @@ static void tegra_sdhci_reset(struct sdhci_host *host, u8 mask)
 			misc_ctrl |= SDHCI_MISC_CTRL_ENABLE_DDR50;
 		if (soc_data->nvquirks & NVQUIRK_ENABLE_SDR104)
 			misc_ctrl |= SDHCI_MISC_CTRL_ENABLE_SDR104;
-		if (soc_data->nvquirks & NVQUIRK_ENABLE_SDR50)
+		if (soc_data->nvquirks & SDHCI_MISC_CTRL_ENABLE_SDR50)
 			clk_ctrl |= SDHCI_CLOCK_CTRL_SDR50_TUNING_OVERRIDE;
 	}
 
@@ -607,39 +586,6 @@ static void tegra_sdhci_parse_pad_autocal_dt(struct sdhci_host *host)
 	if (err)
 		autocal->pull_down_1v8 = 0;
 
-	err = device_property_read_u32(host->mmc->parent,
-			"nvidia,pad-autocal-pull-up-offset-sdr104",
-			&autocal->pull_up_sdr104);
-	if (err)
-		autocal->pull_up_sdr104 = autocal->pull_up_1v8;
-
-	err = device_property_read_u32(host->mmc->parent,
-			"nvidia,pad-autocal-pull-down-offset-sdr104",
-			&autocal->pull_down_sdr104);
-	if (err)
-		autocal->pull_down_sdr104 = autocal->pull_down_1v8;
-
-	err = device_property_read_u32(host->mmc->parent,
-			"nvidia,pad-autocal-pull-up-offset-hs400",
-			&autocal->pull_up_hs400);
-	if (err)
-		autocal->pull_up_hs400 = autocal->pull_up_1v8;
-
-	err = device_property_read_u32(host->mmc->parent,
-			"nvidia,pad-autocal-pull-down-offset-hs400",
-			&autocal->pull_down_hs400);
-	if (err)
-		autocal->pull_down_hs400 = autocal->pull_down_1v8;
-
-	/*
-	 * Different fail-safe drive strength values based on the signaling
-	 * voltage are applicable for SoCs supporting 3V3 and 1V8 pad controls.
-	 * So, avoid reading below device tree properties for SoCs that don't
-	 * have NVQUIRK_NEEDS_PAD_CONTROL.
-	 */
-	if (!(tegra_host->soc_data->nvquirks & NVQUIRK_NEEDS_PAD_CONTROL))
-		return;
-
 	err = device_property_read_u32(host->mmc->parent,
 			"nvidia,pad-autocal-pull-up-offset-3v3-timeout",
 			&autocal->pull_up_3v3_timeout);
@@ -683,6 +629,30 @@ static void tegra_sdhci_parse_pad_autocal_dt(struct sdhci_host *host)
 				mmc_hostname(host->mmc));
 		autocal->pull_down_1v8_timeout = 0;
 	}
+
+	err = device_property_read_u32(host->mmc->parent,
+			"nvidia,pad-autocal-pull-up-offset-sdr104",
+			&autocal->pull_up_sdr104);
+	if (err)
+		autocal->pull_up_sdr104 = autocal->pull_up_1v8;
+
+	err = device_property_read_u32(host->mmc->parent,
+			"nvidia,pad-autocal-pull-down-offset-sdr104",
+			&autocal->pull_down_sdr104);
+	if (err)
+		autocal->pull_down_sdr104 = autocal->pull_down_1v8;
+
+	err = device_property_read_u32(host->mmc->parent,
+			"nvidia,pad-autocal-pull-up-offset-hs400",
+			&autocal->pull_up_hs400);
+	if (err)
+		autocal->pull_up_hs400 = autocal->pull_up_1v8;
+
+	err = device_property_read_u32(host->mmc->parent,
+			"nvidia,pad-autocal-pull-down-offset-hs400",
+			&autocal->pull_down_hs400);
+	if (err)
+		autocal->pull_down_hs400 = autocal->pull_down_1v8;
 }
 
 static void tegra_sdhci_request(struct mmc_host *mmc, struct mmc_request *mrq)
@@ -1169,7 +1139,6 @@ static void tegra_sdhci_voltage_switch(struct sdhci_host *host)
 static void tegra_cqhci_writel(struct cqhci_host *cq_host, u32 val, int reg)
 {
 	struct mmc_host *mmc = cq_host->mmc;
-	struct sdhci_host *host = mmc_priv(mmc);
 	u8 ctrl;
 	ktime_t timeout;
 	bool timed_out;
@@ -1184,7 +1153,6 @@ static void tegra_cqhci_writel(struct cqhci_host *cq_host, u32 val, int reg)
 	 */
 	if (reg == CQHCI_CTL && !(val & CQHCI_HALT) &&
 	    cqhci_readl(cq_host, CQHCI_CTL) & CQHCI_HALT) {
-		sdhci_writew(host, SDHCI_TEGRA_CQE_TRNS_MODE, SDHCI_TRANSFER_MODE);
 		sdhci_cqe_enable(mmc);
 		writel(val, cq_host->mmio + reg);
 		timeout = ktime_add_us(ktime_get(), 50);
@@ -1220,7 +1188,6 @@ static void sdhci_tegra_update_dcmd_desc(struct mmc_host *mmc,
 static void sdhci_tegra_cqe_enable(struct mmc_host *mmc)
 {
 	struct cqhci_host *cq_host = mmc->cqe_private;
-	struct sdhci_host *host = mmc_priv(mmc);
 	u32 val;
 
 	/*
@@ -1234,7 +1201,6 @@ static void sdhci_tegra_cqe_enable(struct mmc_host *mmc)
 		if (val & CQHCI_ENABLE)
 			cqhci_writel(cq_host, (val & ~CQHCI_ENABLE),
 				     CQHCI_CFG);
-		sdhci_writew(host, SDHCI_TEGRA_CQE_TRNS_MODE, SDHCI_TRANSFER_MODE);
 		sdhci_cqe_enable(mmc);
 		if (val & CQHCI_ENABLE)
 			cqhci_writel(cq_host, val, CQHCI_CFG);
@@ -1270,64 +1236,12 @@ static u32 sdhci_tegra_cqhci_irq(struct sdhci_host *host, u32 intmask)
 	return 0;
 }
 
-static void tegra_sdhci_set_timeout(struct sdhci_host *host,
-				    struct mmc_command *cmd)
-{
-	u32 val;
-
-	/*
-	 * HW busy detection timeout is based on programmed data timeout
-	 * counter and maximum supported timeout is 11s which may not be
-	 * enough for long operations like cache flush, sleep awake, erase.
-	 *
-	 * ERASE_TIMEOUT_LIMIT bit of VENDOR_MISC_CTRL register allows
-	 * host controller to wait for busy state until the card is busy
-	 * without HW timeout.
-	 *
-	 * So, use infinite busy wait mode for operations that may take
-	 * more than maximum HW busy timeout of 11s otherwise use finite
-	 * busy wait mode.
-	 */
-	val = sdhci_readl(host, SDHCI_TEGRA_VENDOR_MISC_CTRL);
-	if (cmd && cmd->busy_timeout >= 11 * MSEC_PER_SEC)
-		val |= SDHCI_MISC_CTRL_ERASE_TIMEOUT_LIMIT;
-	else
-		val &= ~SDHCI_MISC_CTRL_ERASE_TIMEOUT_LIMIT;
-	sdhci_writel(host, val, SDHCI_TEGRA_VENDOR_MISC_CTRL);
-
-	__sdhci_set_timeout(host, cmd);
-}
-
-static void sdhci_tegra_cqe_pre_enable(struct mmc_host *mmc)
-{
-	struct cqhci_host *cq_host = mmc->cqe_private;
-	u32 reg;
-
-	reg = cqhci_readl(cq_host, CQHCI_CFG);
-	reg |= CQHCI_ENABLE;
-	cqhci_writel(cq_host, reg, CQHCI_CFG);
-}
-
-static void sdhci_tegra_cqe_post_disable(struct mmc_host *mmc)
-{
-	struct cqhci_host *cq_host = mmc->cqe_private;
-	struct sdhci_host *host = mmc_priv(mmc);
-	u32 reg;
-
-	reg = cqhci_readl(cq_host, CQHCI_CFG);
-	reg &= ~CQHCI_ENABLE;
-	cqhci_writel(cq_host, reg, CQHCI_CFG);
-	sdhci_writew(host, 0x0, SDHCI_TRANSFER_MODE);
-}
-
 static const struct cqhci_host_ops sdhci_tegra_cqhci_ops = {
 	.write_l    = tegra_cqhci_writel,
 	.enable	= sdhci_tegra_cqe_enable,
 	.disable = sdhci_cqe_disable,
 	.dumpregs = sdhci_tegra_dumpregs,
 	.update_dcmd_desc = sdhci_tegra_update_dcmd_desc,
-	.pre_enable = sdhci_tegra_cqe_pre_enable,
-	.post_disable = sdhci_tegra_cqe_post_disable,
 };
 
 static int tegra_sdhci_set_dma_mask(struct sdhci_host *host)
@@ -1461,11 +1375,11 @@ static const struct sdhci_ops tegra210_sdhci_ops = {
 	.set_uhs_signaling = tegra_sdhci_set_uhs_signaling,
 	.voltage_switch = tegra_sdhci_voltage_switch,
 	.get_max_clock = tegra_sdhci_get_max_clock,
-	.set_timeout = tegra_sdhci_set_timeout,
 };
 
 static const struct sdhci_pltfm_data sdhci_tegra210_pdata = {
 	.quirks = SDHCI_QUIRK_BROKEN_TIMEOUT_VAL |
+		  SDHCI_QUIRK_DATA_TIMEOUT_USES_SDCLK |
 		  SDHCI_QUIRK_SINGLE_POWER_WRITE |
 		  SDHCI_QUIRK_NO_HISPD_BIT |
 		  SDHCI_QUIRK_BROKEN_ADMA_ZEROLEN_DESC |
@@ -1481,8 +1395,7 @@ static const struct sdhci_tegra_soc_data soc_data_tegra210 = {
 		    NVQUIRK_HAS_PADCALIB |
 		    NVQUIRK_DIS_CARD_CLK_CONFIG_TAP |
 		    NVQUIRK_ENABLE_SDR50 |
-		    NVQUIRK_ENABLE_SDR104 |
-		    NVQUIRK_HAS_TMCLK,
+		    NVQUIRK_ENABLE_SDR104,
 	.min_tap_delay = 106,
 	.max_tap_delay = 185,
 };
@@ -1499,11 +1412,11 @@ static const struct sdhci_ops tegra186_sdhci_ops = {
 	.voltage_switch = tegra_sdhci_voltage_switch,
 	.get_max_clock = tegra_sdhci_get_max_clock,
 	.irq = sdhci_tegra_cqhci_irq,
-	.set_timeout = tegra_sdhci_set_timeout,
 };
 
 static const struct sdhci_pltfm_data sdhci_tegra186_pdata = {
 	.quirks = SDHCI_QUIRK_BROKEN_TIMEOUT_VAL |
+		  SDHCI_QUIRK_DATA_TIMEOUT_USES_SDCLK |
 		  SDHCI_QUIRK_SINGLE_POWER_WRITE |
 		  SDHCI_QUIRK_NO_HISPD_BIT |
 		  SDHCI_QUIRK_BROKEN_ADMA_ZEROLEN_DESC |
@@ -1520,7 +1433,6 @@ static const struct sdhci_tegra_soc_data soc_data_tegra186 = {
 		    NVQUIRK_DIS_CARD_CLK_CONFIG_TAP |
 		    NVQUIRK_ENABLE_SDR50 |
 		    NVQUIRK_ENABLE_SDR104 |
-		    NVQUIRK_HAS_TMCLK |
 		    NVQUIRK_CQHCI_DCMD_R1B_CMD_TIMING,
 	.min_tap_delay = 84,
 	.max_tap_delay = 136,
@@ -1533,8 +1445,7 @@ static const struct sdhci_tegra_soc_data soc_data_tegra194 = {
 		    NVQUIRK_HAS_PADCALIB |
 		    NVQUIRK_DIS_CARD_CLK_CONFIG_TAP |
 		    NVQUIRK_ENABLE_SDR50 |
-		    NVQUIRK_ENABLE_SDR104 |
-		    NVQUIRK_HAS_TMCLK,
+		    NVQUIRK_ENABLE_SDR104,
 	.min_tap_delay = 96,
 	.max_tap_delay = 139,
 };
@@ -1650,9 +1561,6 @@ static int sdhci_tegra_probe(struct platform_device *pdev)
 	if (tegra_host->soc_data->nvquirks & NVQUIRK_ENABLE_DDR50)
 		host->mmc->caps |= MMC_CAP_1_8V_DDR;
 
-	/* HW busy detection is supported, but R1B responses are required. */
-	host->mmc->caps |= MMC_CAP_WAIT_WHILE_BUSY | MMC_CAP_NEED_RSP_BUSY;
-
 	tegra_sdhci_parse_dt(host);
 
 	tegra_host->power_gpio = devm_gpiod_get_optional(&pdev->dev, "power",
@@ -1662,47 +1570,13 @@ static int sdhci_tegra_probe(struct platform_device *pdev)
 		goto err_power_req;
 	}
 
-	/*
-	 * Tegra210 has a separate SDMMC_LEGACY_TM clock used for host
-	 * timeout clock and SW can choose TMCLK or SDCLK for hardware
-	 * data timeout through the bit USE_TMCLK_FOR_DATA_TIMEOUT of
-	 * the register SDHCI_TEGRA_VENDOR_SYS_SW_CTRL.
-	 *
-	 * USE_TMCLK_FOR_DATA_TIMEOUT bit default is set to 1 and SDMMC uses
-	 * 12Mhz TMCLK which is advertised in host capability register.
-	 * With TMCLK of 12Mhz provides maximum data timeout period that can
-	 * be achieved is 11s better than using SDCLK for data timeout.
-	 *
-	 * So, TMCLK is set to 12Mhz and kept enabled all the time on SoC's
-	 * supporting separate TMCLK.
-	 */
-
-	if (soc_data->nvquirks & NVQUIRK_HAS_TMCLK) {
-		clk = devm_clk_get(&pdev->dev, "tmclk");
-		if (IS_ERR(clk)) {
-			rc = PTR_ERR(clk);
-			if (rc == -EPROBE_DEFER)
-				goto err_power_req;
-
-			dev_warn(&pdev->dev, "failed to get tmclk: %d\n", rc);
-			clk = NULL;
-		}
-
-		clk_set_rate(clk, 12000000);
-		rc = clk_prepare_enable(clk);
-		if (rc) {
-			dev_err(&pdev->dev,
-				"failed to enable tmclk: %d\n", rc);
-			goto err_power_req;
-		}
-
-		tegra_host->tmclk = clk;
-	}
-
 	clk = devm_clk_get(mmc_dev(host->mmc), NULL);
 	if (IS_ERR(clk)) {
-		rc = dev_err_probe(&pdev->dev, PTR_ERR(clk),
-				   "failed to get clock\n");
+		rc = PTR_ERR(clk);
+
+		if (rc != -EPROBE_DEFER)
+			dev_err(&pdev->dev, "failed to get clock: %d\n", rc);
+
 		goto err_clk_get;
 	}
 	clk_prepare_enable(clk);
@@ -1739,7 +1613,6 @@ static int sdhci_tegra_probe(struct platform_device *pdev)
 err_rst_get:
 	clk_disable_unprepare(pltfm_host->clk);
 err_clk_get:
-	clk_disable_unprepare(tegra_host->tmclk);
 err_power_req:
 err_parse_dt:
 	sdhci_pltfm_free(pdev);
@@ -1757,7 +1630,6 @@ static int sdhci_tegra_remove(struct platform_device *pdev)
 	reset_control_assert(tegra_host->rst);
 	usleep_range(2000, 4000);
 	clk_disable_unprepare(pltfm_host->clk);
-	clk_disable_unprepare(tegra_host->tmclk);
 
 	sdhci_pltfm_free(pdev);
 
@@ -1823,7 +1695,6 @@ static SIMPLE_DEV_PM_OPS(sdhci_tegra_dev_pm_ops, sdhci_tegra_suspend,
 static struct platform_driver sdhci_tegra_driver = {
 	.driver		= {
 		.name	= "sdhci-tegra",
-		.probe_type = PROBE_PREFER_ASYNCHRONOUS,
 		.of_match_table = sdhci_tegra_dt_match,
 		.pm	= &sdhci_tegra_dev_pm_ops,
 	},
diff --git a/drivers/mmc/host/sdhci-xenon-phy.c b/drivers/mmc/host/sdhci-xenon-phy.c
index 03ce57ef4..e6e9e286c 100644
--- a/drivers/mmc/host/sdhci-xenon-phy.c
+++ b/drivers/mmc/host/sdhci-xenon-phy.c
@@ -527,7 +527,7 @@ static bool xenon_emmc_phy_slow_mode(struct sdhci_host *host,
 			ret = true;
 			break;
 		}
-		fallthrough;
+		/* fall through */
 	default:
 		reg &= ~XENON_TIMING_ADJUST_SLOW_MODE;
 		ret = false;
diff --git a/drivers/mmc/host/sdhci-xenon.c b/drivers/mmc/host/sdhci-xenon.c
index 0e5234a5c..1dea1ba66 100644
--- a/drivers/mmc/host/sdhci-xenon.c
+++ b/drivers/mmc/host/sdhci-xenon.c
@@ -167,12 +167,7 @@ static void xenon_reset_exit(struct sdhci_host *host,
 	/* Disable tuning request and auto-retuning again */
 	xenon_retune_setup(host);
 
-	/*
-	 * The ACG should be turned off at the early init time, in order
-	 * to solve a possible issues with the 1.8V regulator stabilization.
-	 * The feature is enabled in later stage.
-	 */
-	xenon_set_acg(host, false);
+	xenon_set_acg(host, true);
 
 	xenon_set_sdclk_off_idle(host, sdhc_id, false);
 
@@ -240,16 +235,6 @@ static void xenon_voltage_switch(struct sdhci_host *host)
 {
 	/* Wait for 5ms after set 1.8V signal enable bit */
 	usleep_range(5000, 5500);
-
-	/*
-	 * For some reason the controller's Host Control2 register reports
-	 * the bit representing 1.8V signaling as 0 when read after it was
-	 * written as 1. Subsequent read reports 1.
-	 *
-	 * Since this may cause some issues, do an empty read of the Host
-	 * Control2 register here to circumvent this.
-	 */
-	sdhci_readw(host, SDHCI_HOST_CONTROL2);
 }
 
 static const struct sdhci_ops sdhci_xenon_ops = {
@@ -682,7 +667,6 @@ MODULE_DEVICE_TABLE(of, sdhci_xenon_dt_ids);
 static struct platform_driver sdhci_xenon_driver = {
 	.driver	= {
 		.name	= "xenon-sdhci",
-		.probe_type = PROBE_PREFER_ASYNCHRONOUS,
 		.of_match_table = sdhci_xenon_dt_ids,
 		.pm = &sdhci_xenon_dev_pm_ops,
 	},
diff --git a/drivers/mmc/host/sdhci.c b/drivers/mmc/host/sdhci.c
index d42e86cdf..95ad631ec 100644
--- a/drivers/mmc/host/sdhci.c
+++ b/drivers/mmc/host/sdhci.c
@@ -9,9 +9,7 @@
  *     - JMicron (hardware and technical support)
  */
 
-#include <linux/bitfield.h>
 #include <linux/delay.h>
-#include <linux/dmaengine.h>
 #include <linux/ktime.h>
 #include <linux/highmem.h>
 #include <linux/io.h>
@@ -48,9 +46,9 @@
 static unsigned int debug_quirks = 0;
 static unsigned int debug_quirks2;
 
-static void sdhci_enable_preset_value(struct sdhci_host *host, bool enable);
+static void sdhci_finish_data(struct sdhci_host *);
 
-static bool sdhci_send_command(struct sdhci_host *host, struct mmc_command *cmd);
+static void sdhci_enable_preset_value(struct sdhci_host *host, bool enable);
 
 void sdhci_dumpregs(struct sdhci_host *host)
 {
@@ -111,9 +109,6 @@ void sdhci_dumpregs(struct sdhci_host *host)
 		}
 	}
 
-	if (host->ops->dump_vendor_regs)
-		host->ops->dump_vendor_regs(host);
-
 	SDHCI_DUMP("============================================\n");
 }
 EXPORT_SYMBOL_GPL(sdhci_dumpregs);
@@ -320,7 +315,6 @@ static void sdhci_config_dma(struct sdhci_host *host)
 static void sdhci_init(struct sdhci_host *host, int soft)
 {
 	struct mmc_host *mmc = host->mmc;
-	unsigned long flags;
 
 	if (soft)
 		sdhci_do_reset(host, SDHCI_RESET_CMD | SDHCI_RESET_DATA);
@@ -330,9 +324,7 @@ static void sdhci_init(struct sdhci_host *host, int soft)
 	if (host->v4_mode)
 		sdhci_do_enable_v4_mode(host);
 
-	spin_lock_irqsave(&host->lock, flags);
 	sdhci_set_default_irqs(host);
-	spin_unlock_irqrestore(&host->lock, flags);
 
 	host->cqe_on = false;
 
@@ -345,19 +337,8 @@ static void sdhci_init(struct sdhci_host *host, int soft)
 
 static void sdhci_reinit(struct sdhci_host *host)
 {
-	u32 cd = host->ier & (SDHCI_INT_CARD_REMOVE | SDHCI_INT_CARD_INSERT);
-
 	sdhci_init(host, 0);
 	sdhci_enable_card_detection(host);
-
-	/*
-	 * A change to the card detect bits indicates a change in present state,
-	 * refer sdhci_set_card_detection(). A card detect interrupt might have
-	 * been missed while the host controller was being reset, so trigger a
-	 * rescan to check.
-	 */
-	if (cd != (host->ier & (SDHCI_INT_CARD_REMOVE | SDHCI_INT_CARD_INSERT)))
-		mmc_detect_change(host->mmc, msecs_to_jiffies(200));
 }
 
 static void __sdhci_led_activate(struct sdhci_host *host)
@@ -640,13 +621,9 @@ static int sdhci_pre_dma_transfer(struct sdhci_host *host,
 		}
 		if (mmc_get_dma_dir(data) == DMA_TO_DEVICE) {
 			/* Copy the data to the bounce buffer */
-			if (host->ops->copy_to_bounce_buffer) {
-				host->ops->copy_to_bounce_buffer(host,
-								 data, length);
-			} else {
-				sg_copy_to_buffer(data->sg, data->sg_len,
-						  host->bounce_buffer, length);
-			}
+			sg_copy_to_buffer(data->sg, data->sg_len,
+					  host->bounce_buffer,
+					  length);
 		}
 		/* Switch ownership to the DMA */
 		dma_sync_single_for_device(host->mmc->parent,
@@ -1016,7 +993,7 @@ static void sdhci_set_transfer_irqs(struct sdhci_host *host)
 	sdhci_writel(host, host->ier, SDHCI_SIGNAL_ENABLE);
 }
 
-void sdhci_set_data_timeout_irq(struct sdhci_host *host, bool enable)
+static void sdhci_set_data_timeout_irq(struct sdhci_host *host, bool enable)
 {
 	if (enable)
 		host->ier |= SDHCI_INT_DATA_TIMEOUT;
@@ -1025,36 +1002,42 @@ void sdhci_set_data_timeout_irq(struct sdhci_host *host, bool enable)
 	sdhci_writel(host, host->ier, SDHCI_INT_ENABLE);
 	sdhci_writel(host, host->ier, SDHCI_SIGNAL_ENABLE);
 }
-EXPORT_SYMBOL_GPL(sdhci_set_data_timeout_irq);
-
-void __sdhci_set_timeout(struct sdhci_host *host, struct mmc_command *cmd)
-{
-	bool too_big = false;
-	u8 count = sdhci_calc_timeout(host, cmd, &too_big);
-
-	if (too_big &&
-	    host->quirks2 & SDHCI_QUIRK2_DISABLE_HW_TIMEOUT) {
-		sdhci_calc_sw_timeout(host, cmd);
-		sdhci_set_data_timeout_irq(host, false);
-	} else if (!(host->ier & SDHCI_INT_DATA_TIMEOUT)) {
-		sdhci_set_data_timeout_irq(host, true);
-	}
-
-	sdhci_writeb(host, count, SDHCI_TIMEOUT_CONTROL);
-}
-EXPORT_SYMBOL_GPL(__sdhci_set_timeout);
 
 static void sdhci_set_timeout(struct sdhci_host *host, struct mmc_command *cmd)
 {
-	if (host->ops->set_timeout)
+	u8 count;
+
+	if (host->ops->set_timeout) {
 		host->ops->set_timeout(host, cmd);
-	else
-		__sdhci_set_timeout(host, cmd);
+	} else {
+		bool too_big = false;
+
+		count = sdhci_calc_timeout(host, cmd, &too_big);
+
+		if (too_big &&
+		    host->quirks2 & SDHCI_QUIRK2_DISABLE_HW_TIMEOUT) {
+			sdhci_calc_sw_timeout(host, cmd);
+			sdhci_set_data_timeout_irq(host, false);
+		} else if (!(host->ier & SDHCI_INT_DATA_TIMEOUT)) {
+			sdhci_set_data_timeout_irq(host, true);
+		}
+
+		sdhci_writeb(host, count, SDHCI_TIMEOUT_CONTROL);
+	}
 }
 
-static void sdhci_initialize_data(struct sdhci_host *host,
-				  struct mmc_data *data)
+static void sdhci_prepare_data(struct sdhci_host *host, struct mmc_command *cmd)
 {
+	struct mmc_data *data = cmd->data;
+
+	host->data_timeout = 0;
+
+	if (sdhci_data_line_cmd(cmd))
+		sdhci_set_timeout(host, cmd);
+
+	if (!data)
+		return;
+
 	WARN_ON(host->data);
 
 	/* Sanity checks */
@@ -1065,34 +1048,6 @@ static void sdhci_initialize_data(struct sdhci_host *host,
 	host->data = data;
 	host->data_early = 0;
 	host->data->bytes_xfered = 0;
-}
-
-static inline void sdhci_set_block_info(struct sdhci_host *host,
-					struct mmc_data *data)
-{
-	/* Set the DMA boundary value and block size */
-	sdhci_writew(host,
-		     SDHCI_MAKE_BLKSZ(host->sdma_boundary, data->blksz),
-		     SDHCI_BLOCK_SIZE);
-	/*
-	 * For Version 4.10 onwards, if v4 mode is enabled, 32-bit Block Count
-	 * can be supported, in that case 16-bit block count register must be 0.
-	 */
-	if (host->version >= SDHCI_SPEC_410 && host->v4_mode &&
-	    (host->quirks2 & SDHCI_QUIRK2_USE_32BIT_BLK_CNT)) {
-		if (sdhci_readw(host, SDHCI_BLOCK_COUNT))
-			sdhci_writew(host, 0, SDHCI_BLOCK_COUNT);
-		sdhci_writew(host, data->blocks, SDHCI_32BIT_BLK_CNT);
-	} else {
-		sdhci_writew(host, data->blocks, SDHCI_BLOCK_COUNT);
-	}
-}
-
-static void sdhci_prepare_data(struct sdhci_host *host, struct mmc_command *cmd)
-{
-	struct mmc_data *data = cmd->data;
-
-	sdhci_initialize_data(host, data);
 
 	if (host->flags & (SDHCI_USE_SDMA | SDHCI_USE_ADMA)) {
 		struct scatterlist *sg;
@@ -1179,193 +1134,24 @@ static void sdhci_prepare_data(struct sdhci_host *host, struct mmc_command *cmd)
 
 	sdhci_set_transfer_irqs(host);
 
-	sdhci_set_block_info(host, data);
-}
-
-#if IS_ENABLED(CONFIG_MMC_SDHCI_EXTERNAL_DMA)
-
-static int sdhci_external_dma_init(struct sdhci_host *host)
-{
-	int ret = 0;
-	struct mmc_host *mmc = host->mmc;
-
-	host->tx_chan = dma_request_chan(mmc->parent, "tx");
-	if (IS_ERR(host->tx_chan)) {
-		ret = PTR_ERR(host->tx_chan);
-		if (ret != -EPROBE_DEFER)
-			pr_warn("Failed to request TX DMA channel.\n");
-		host->tx_chan = NULL;
-		return ret;
-	}
-
-	host->rx_chan = dma_request_chan(mmc->parent, "rx");
-	if (IS_ERR(host->rx_chan)) {
-		if (host->tx_chan) {
-			dma_release_channel(host->tx_chan);
-			host->tx_chan = NULL;
-		}
-
-		ret = PTR_ERR(host->rx_chan);
-		if (ret != -EPROBE_DEFER)
-			pr_warn("Failed to request RX DMA channel.\n");
-		host->rx_chan = NULL;
-	}
-
-	return ret;
-}
-
-static struct dma_chan *sdhci_external_dma_channel(struct sdhci_host *host,
-						   struct mmc_data *data)
-{
-	return data->flags & MMC_DATA_WRITE ? host->tx_chan : host->rx_chan;
-}
-
-static int sdhci_external_dma_setup(struct sdhci_host *host,
-				    struct mmc_command *cmd)
-{
-	int ret, i;
-	enum dma_transfer_direction dir;
-	struct dma_async_tx_descriptor *desc;
-	struct mmc_data *data = cmd->data;
-	struct dma_chan *chan;
-	struct dma_slave_config cfg;
-	dma_cookie_t cookie;
-	int sg_cnt;
-
-	if (!host->mapbase)
-		return -EINVAL;
-
-	memset(&cfg, 0, sizeof(cfg));
-	cfg.src_addr = host->mapbase + SDHCI_BUFFER;
-	cfg.dst_addr = host->mapbase + SDHCI_BUFFER;
-	cfg.src_addr_width = DMA_SLAVE_BUSWIDTH_4_BYTES;
-	cfg.dst_addr_width = DMA_SLAVE_BUSWIDTH_4_BYTES;
-	cfg.src_maxburst = data->blksz / 4;
-	cfg.dst_maxburst = data->blksz / 4;
-
-	/* Sanity check: all the SG entries must be aligned by block size. */
-	for (i = 0; i < data->sg_len; i++) {
-		if ((data->sg + i)->length % data->blksz)
-			return -EINVAL;
-	}
-
-	chan = sdhci_external_dma_channel(host, data);
-
-	ret = dmaengine_slave_config(chan, &cfg);
-	if (ret)
-		return ret;
-
-	sg_cnt = sdhci_pre_dma_transfer(host, data, COOKIE_MAPPED);
-	if (sg_cnt <= 0)
-		return -EINVAL;
-
-	dir = data->flags & MMC_DATA_WRITE ? DMA_MEM_TO_DEV : DMA_DEV_TO_MEM;
-	desc = dmaengine_prep_slave_sg(chan, data->sg, data->sg_len, dir,
-				       DMA_PREP_INTERRUPT | DMA_CTRL_ACK);
-	if (!desc)
-		return -EINVAL;
-
-	desc->callback = NULL;
-	desc->callback_param = NULL;
-
-	cookie = dmaengine_submit(desc);
-	if (dma_submit_error(cookie))
-		ret = cookie;
-
-	return ret;
-}
-
-static void sdhci_external_dma_release(struct sdhci_host *host)
-{
-	if (host->tx_chan) {
-		dma_release_channel(host->tx_chan);
-		host->tx_chan = NULL;
-	}
-
-	if (host->rx_chan) {
-		dma_release_channel(host->rx_chan);
-		host->rx_chan = NULL;
-	}
-
-	sdhci_switch_external_dma(host, false);
-}
-
-static void __sdhci_external_dma_prepare_data(struct sdhci_host *host,
-					      struct mmc_command *cmd)
-{
-	struct mmc_data *data = cmd->data;
-
-	sdhci_initialize_data(host, data);
-
-	host->flags |= SDHCI_REQ_USE_DMA;
-	sdhci_set_transfer_irqs(host);
-
-	sdhci_set_block_info(host, data);
-}
+	/* Set the DMA boundary value and block size */
+	sdhci_writew(host, SDHCI_MAKE_BLKSZ(host->sdma_boundary, data->blksz),
+		     SDHCI_BLOCK_SIZE);
 
-static void sdhci_external_dma_prepare_data(struct sdhci_host *host,
-					    struct mmc_command *cmd)
-{
-	if (!sdhci_external_dma_setup(host, cmd)) {
-		__sdhci_external_dma_prepare_data(host, cmd);
+	/*
+	 * For Version 4.10 onwards, if v4 mode is enabled, 32-bit Block Count
+	 * can be supported, in that case 16-bit block count register must be 0.
+	 */
+	if (host->version >= SDHCI_SPEC_410 && host->v4_mode &&
+	    (host->quirks2 & SDHCI_QUIRK2_USE_32BIT_BLK_CNT)) {
+		if (sdhci_readw(host, SDHCI_BLOCK_COUNT))
+			sdhci_writew(host, 0, SDHCI_BLOCK_COUNT);
+		sdhci_writew(host, data->blocks, SDHCI_32BIT_BLK_CNT);
 	} else {
-		sdhci_external_dma_release(host);
-		pr_err("%s: Cannot use external DMA, switch to the DMA/PIO which standard SDHCI provides.\n",
-		       mmc_hostname(host->mmc));
-		sdhci_prepare_data(host, cmd);
+		sdhci_writew(host, data->blocks, SDHCI_BLOCK_COUNT);
 	}
 }
 
-static void sdhci_external_dma_pre_transfer(struct sdhci_host *host,
-					    struct mmc_command *cmd)
-{
-	struct dma_chan *chan;
-
-	if (!cmd->data)
-		return;
-
-	chan = sdhci_external_dma_channel(host, cmd->data);
-	if (chan)
-		dma_async_issue_pending(chan);
-}
-
-#else
-
-static inline int sdhci_external_dma_init(struct sdhci_host *host)
-{
-	return -EOPNOTSUPP;
-}
-
-static inline void sdhci_external_dma_release(struct sdhci_host *host)
-{
-}
-
-static inline void sdhci_external_dma_prepare_data(struct sdhci_host *host,
-						   struct mmc_command *cmd)
-{
-	/* This should never happen */
-	WARN_ON_ONCE(1);
-}
-
-static inline void sdhci_external_dma_pre_transfer(struct sdhci_host *host,
-						   struct mmc_command *cmd)
-{
-}
-
-static inline struct dma_chan *sdhci_external_dma_channel(struct sdhci_host *host,
-							  struct mmc_data *data)
-{
-	return NULL;
-}
-
-#endif
-
-void sdhci_switch_external_dma(struct sdhci_host *host, bool en)
-{
-	host->use_external_dma = en;
-}
-EXPORT_SYMBOL_GPL(sdhci_switch_external_dma);
-
 static inline bool sdhci_auto_cmd12(struct sdhci_host *host,
 				    struct mmc_request *mrq)
 {
@@ -1373,35 +1159,21 @@ static inline bool sdhci_auto_cmd12(struct sdhci_host *host,
 	       !mrq->cap_cmd_during_tfr;
 }
 
-static inline bool sdhci_auto_cmd23(struct sdhci_host *host,
-				    struct mmc_request *mrq)
-{
-	return mrq->sbc && (host->flags & SDHCI_AUTO_CMD23);
-}
-
-static inline bool sdhci_manual_cmd23(struct sdhci_host *host,
-				      struct mmc_request *mrq)
-{
-	return mrq->sbc && !(host->flags & SDHCI_AUTO_CMD23);
-}
-
 static inline void sdhci_auto_cmd_select(struct sdhci_host *host,
 					 struct mmc_command *cmd,
 					 u16 *mode)
 {
 	bool use_cmd12 = sdhci_auto_cmd12(host, cmd->mrq) &&
 			 (cmd->opcode != SD_IO_RW_EXTENDED);
-	bool use_cmd23 = sdhci_auto_cmd23(host, cmd->mrq);
+	bool use_cmd23 = cmd->mrq->sbc && (host->flags & SDHCI_AUTO_CMD23);
 	u16 ctrl2;
 
 	/*
 	 * In case of Version 4.10 or later, use of 'Auto CMD Auto
 	 * Select' is recommended rather than use of 'Auto CMD12
-	 * Enable' or 'Auto CMD23 Enable'. We require Version 4 Mode
-	 * here because some controllers (e.g sdhci-of-dwmshc) expect it.
+	 * Enable' or 'Auto CMD23 Enable'.
 	 */
-	if (host->version >= SDHCI_SPEC_410 && host->v4_mode &&
-	    (use_cmd12 || use_cmd23)) {
+	if (host->version >= SDHCI_SPEC_410 && (use_cmd12 || use_cmd23)) {
 		*mode |= SDHCI_TRNS_AUTO_SEL;
 
 		ctrl2 = sdhci_readw(host, SDHCI_HOST_CONTROL2);
@@ -1453,7 +1225,7 @@ static void sdhci_set_transfer_mode(struct sdhci_host *host,
 	if (mmc_op_multi(cmd->opcode) || data->blocks > 1) {
 		mode = SDHCI_TRNS_BLK_CNT_EN | SDHCI_TRNS_MULTI;
 		sdhci_auto_cmd_select(host, cmd, &mode);
-		if (sdhci_auto_cmd23(host, cmd->mrq))
+		if (cmd->mrq->sbc && (host->flags & SDHCI_AUTO_CMD23))
 			sdhci_writel(host, cmd->mrq->sbc->arg, SDHCI_ARGUMENT2);
 	}
 
@@ -1474,10 +1246,22 @@ static bool sdhci_needs_reset(struct sdhci_host *host, struct mmc_request *mrq)
 		 (host->quirks & SDHCI_QUIRK_RESET_AFTER_REQUEST)));
 }
 
-static void sdhci_set_mrq_done(struct sdhci_host *host, struct mmc_request *mrq)
+static void __sdhci_finish_mrq(struct sdhci_host *host, struct mmc_request *mrq)
 {
 	int i;
 
+	if (host->cmd && host->cmd->mrq == mrq)
+		host->cmd = NULL;
+
+	if (host->data_cmd && host->data_cmd->mrq == mrq)
+		host->data_cmd = NULL;
+
+	if (host->data && host->data->mrq == mrq)
+		host->data = NULL;
+
+	if (sdhci_needs_reset(host, mrq))
+		host->pending_reset = true;
+
 	for (i = 0; i < SDHCI_MAX_MRQS; i++) {
 		if (host->mrqs_done[i] == mrq) {
 			WARN_ON(1);
@@ -1493,26 +1277,6 @@ static void sdhci_set_mrq_done(struct sdhci_host *host, struct mmc_request *mrq)
 	}
 
 	WARN_ON(i >= SDHCI_MAX_MRQS);
-}
-
-static void __sdhci_finish_mrq(struct sdhci_host *host, struct mmc_request *mrq)
-{
-	if (host->cmd && host->cmd->mrq == mrq)
-		host->cmd = NULL;
-
-	if (host->data_cmd && host->data_cmd->mrq == mrq)
-		host->data_cmd = NULL;
-
-	if (host->deferred_cmd && host->deferred_cmd->mrq == mrq)
-		host->deferred_cmd = NULL;
-
-	if (host->data && host->data->mrq == mrq)
-		host->data = NULL;
-
-	if (sdhci_needs_reset(host, mrq))
-		host->pending_reset = true;
-
-	sdhci_set_mrq_done(host, mrq);
 
 	sdhci_del_timer(host, mrq);
 
@@ -1527,7 +1291,7 @@ static void sdhci_finish_mrq(struct sdhci_host *host, struct mmc_request *mrq)
 	queue_work(host->complete_wq, &host->complete_work);
 }
 
-static void __sdhci_finish_data(struct sdhci_host *host, bool sw_data_timeout)
+static void sdhci_finish_data(struct sdhci_host *host)
 {
 	struct mmc_command *data_cmd = host->data_cmd;
 	struct mmc_data *data = host->data;
@@ -1563,12 +1327,12 @@ static void __sdhci_finish_data(struct sdhci_host *host, bool sw_data_timeout)
 
 	/*
 	 * Need to send CMD12 if -
-	 * a) open-ended multiblock transfer not using auto CMD12 (no CMD23)
+	 * a) open-ended multiblock transfer (no CMD23)
 	 * b) error in multiblock transfer
 	 */
 	if (data->stop &&
-	    ((!data->mrq->sbc && !sdhci_auto_cmd12(host, data->mrq)) ||
-	     data->error)) {
+	    (data->error ||
+	     !data->mrq->sbc)) {
 		/*
 		 * 'cap_cmd_during_tfr' request must not use the command line
 		 * after mmc_command_done() has been called. It is upper layer's
@@ -1579,31 +1343,14 @@ static void __sdhci_finish_data(struct sdhci_host *host, bool sw_data_timeout)
 		} else {
 			/* Avoid triggering warning in sdhci_send_command() */
 			host->cmd = NULL;
-			if (!sdhci_send_command(host, data->stop)) {
-				if (sw_data_timeout) {
-					/*
-					 * This is anyway a sw data timeout, so
-					 * give up now.
-					 */
-					data->stop->error = -EIO;
-					__sdhci_finish_mrq(host, data->mrq);
-				} else {
-					WARN_ON(host->deferred_cmd);
-					host->deferred_cmd = data->stop;
-				}
-			}
+			sdhci_send_command(host, data->stop);
 		}
 	} else {
 		__sdhci_finish_mrq(host, data->mrq);
 	}
 }
 
-static void sdhci_finish_data(struct sdhci_host *host)
-{
-	__sdhci_finish_data(host, false);
-}
-
-static bool sdhci_send_command(struct sdhci_host *host, struct mmc_command *cmd)
+void sdhci_send_command(struct sdhci_host *host, struct mmc_command *cmd)
 {
 	int flags;
 	u32 mask;
@@ -1618,6 +1365,9 @@ static bool sdhci_send_command(struct sdhci_host *host, struct mmc_command *cmd)
 	    cmd->opcode == MMC_STOP_TRANSMISSION)
 		cmd->flags |= MMC_RSP_BUSY;
 
+	/* Wait max 10 ms */
+	timeout = 10;
+
 	mask = SDHCI_CMD_INHIBIT;
 	if (sdhci_data_line_cmd(cmd))
 		mask |= SDHCI_DATA_INHIBIT;
@@ -1627,36 +1377,37 @@ static bool sdhci_send_command(struct sdhci_host *host, struct mmc_command *cmd)
 	if (cmd->mrq->data && (cmd == cmd->mrq->data->stop))
 		mask &= ~SDHCI_DATA_INHIBIT;
 
-	if (sdhci_readl(host, SDHCI_PRESENT_STATE) & mask)
-		return false;
+	while (sdhci_readl(host, SDHCI_PRESENT_STATE) & mask) {
+		if (timeout == 0) {
+			pr_err("%s: Controller never released inhibit bit(s).\n",
+			       mmc_hostname(host->mmc));
+			sdhci_dumpregs(host);
+			cmd->error = -EIO;
+			sdhci_finish_mrq(host, cmd->mrq);
+			return;
+		}
+		timeout--;
+		mdelay(1);
+	}
 
 	host->cmd = cmd;
-	host->data_timeout = 0;
 	if (sdhci_data_line_cmd(cmd)) {
 		WARN_ON(host->data_cmd);
 		host->data_cmd = cmd;
-		sdhci_set_timeout(host, cmd);
 	}
 
-	if (cmd->data) {
-		if (host->use_external_dma)
-			sdhci_external_dma_prepare_data(host, cmd);
-		else
-			sdhci_prepare_data(host, cmd);
-	}
+	sdhci_prepare_data(host, cmd);
 
 	sdhci_writel(host, cmd->arg, SDHCI_ARGUMENT);
 
 	sdhci_set_transfer_mode(host, cmd);
 
 	if ((cmd->flags & MMC_RSP_136) && (cmd->flags & MMC_RSP_BUSY)) {
-		WARN_ONCE(1, "Unsupported response type!\n");
-		/*
-		 * This does not happen in practice because 136-bit response
-		 * commands never have busy waiting, so rather than complicate
-		 * the error path, just remove busy waiting and continue.
-		 */
-		cmd->flags &= ~MMC_RSP_BUSY;
+		pr_err("%s: Unsupported response type!\n",
+			mmc_hostname(host->mmc));
+		cmd->error = -EINVAL;
+		sdhci_finish_mrq(host, cmd->mrq);
+		return;
 	}
 
 	if (!(cmd->flags & MMC_RSP_PRESENT))
@@ -1687,65 +1438,9 @@ static bool sdhci_send_command(struct sdhci_host *host, struct mmc_command *cmd)
 		timeout += 10 * HZ;
 	sdhci_mod_timer(host, cmd->mrq, timeout);
 
-	if (host->use_external_dma)
-		sdhci_external_dma_pre_transfer(host, cmd);
-
 	sdhci_writew(host, SDHCI_MAKE_CMD(cmd->opcode, flags), SDHCI_COMMAND);
-
-	return true;
-}
-
-static bool sdhci_present_error(struct sdhci_host *host,
-				struct mmc_command *cmd, bool present)
-{
-	if (!present || host->flags & SDHCI_DEVICE_DEAD) {
-		cmd->error = -ENOMEDIUM;
-		return true;
-	}
-
-	return false;
-}
-
-static bool sdhci_send_command_retry(struct sdhci_host *host,
-				     struct mmc_command *cmd,
-				     unsigned long flags)
-	__releases(host->lock)
-	__acquires(host->lock)
-{
-	struct mmc_command *deferred_cmd = host->deferred_cmd;
-	int timeout = 10; /* Approx. 10 ms */
-	bool present;
-
-	while (!sdhci_send_command(host, cmd)) {
-		if (!timeout--) {
-			pr_err("%s: Controller never released inhibit bit(s).\n",
-			       mmc_hostname(host->mmc));
-			sdhci_dumpregs(host);
-			cmd->error = -EIO;
-			return false;
-		}
-
-		spin_unlock_irqrestore(&host->lock, flags);
-
-		usleep_range(1000, 1250);
-
-		present = host->mmc->ops->get_cd(host->mmc);
-
-		spin_lock_irqsave(&host->lock, flags);
-
-		/* A deferred command might disappear, handle that */
-		if (cmd == deferred_cmd && cmd != host->deferred_cmd)
-			return true;
-
-		if (sdhci_present_error(host, cmd, present))
-			return false;
-	}
-
-	if (cmd == host->deferred_cmd)
-		host->deferred_cmd = NULL;
-
-	return true;
 }
+EXPORT_SYMBOL_GPL(sdhci_send_command);
 
 static void sdhci_read_rsp_136(struct sdhci_host *host, struct mmc_command *cmd)
 {
@@ -1806,10 +1501,7 @@ static void sdhci_finish_command(struct sdhci_host *host)
 
 	/* Finished CMD23, now send actual command. */
 	if (cmd == cmd->mrq->sbc) {
-		if (!sdhci_send_command(host, cmd->mrq->cmd)) {
-			WARN_ON(host->deferred_cmd);
-			host->deferred_cmd = cmd->mrq->cmd;
-		}
+		sdhci_send_command(host, cmd->mrq->cmd);
 	} else {
 
 		/* Processed actual command. */
@@ -1826,10 +1518,6 @@ static u16 sdhci_get_preset_value(struct sdhci_host *host)
 	u16 preset = 0;
 
 	switch (host->timing) {
-	case MMC_TIMING_MMC_HS:
-	case MMC_TIMING_SD_HS:
-		preset = sdhci_readw(host, SDHCI_PRESET_FOR_HIGH_SPEED);
-		break;
 	case MMC_TIMING_UHS_SDR12:
 		preset = sdhci_readw(host, SDHCI_PRESET_FOR_SDR12);
 		break;
@@ -1873,9 +1561,10 @@ u16 sdhci_calc_clk(struct sdhci_host *host, unsigned int clock,
 
 			clk = sdhci_readw(host, SDHCI_CLOCK_CONTROL);
 			pre_val = sdhci_get_preset_value(host);
-			div = FIELD_GET(SDHCI_PRESET_SDCLK_FREQ_MASK, pre_val);
+			div = (pre_val & SDHCI_PRESET_SDCLK_FREQ_MASK)
+				>> SDHCI_PRESET_SDCLK_FREQ_SHIFT;
 			if (host->clk_mul &&
-				(pre_val & SDHCI_PRESET_CLKGEN_SEL)) {
+				(pre_val & SDHCI_PRESET_CLKGEN_SEL_MASK)) {
 				clk = SDHCI_PROG_CLOCK_MODE;
 				real_div = div + 1;
 				clk_mul = host->clk_mul;
@@ -2122,25 +1811,6 @@ void sdhci_set_power(struct sdhci_host *host, unsigned char mode,
 }
 EXPORT_SYMBOL_GPL(sdhci_set_power);
 
-/*
- * Some controllers need to configure a valid bus voltage on their power
- * register regardless of whether an external regulator is taking care of power
- * supply. This helper function takes care of it if set as the controller's
- * sdhci_ops.set_power callback.
- */
-void sdhci_set_power_and_bus_voltage(struct sdhci_host *host,
-				     unsigned char mode,
-				     unsigned short vdd)
-{
-	if (!IS_ERR(host->mmc->supply.vmmc)) {
-		struct mmc_host *mmc = host->mmc;
-
-		mmc_regulator_set_ocr(mmc, mmc->supply.vmmc, vdd);
-	}
-	sdhci_set_power_noreg(host, mode, vdd);
-}
-EXPORT_SYMBOL_GPL(sdhci_set_power_and_bus_voltage);
-
 /*****************************************************************************\
  *                                                                           *
  * MMC callbacks                                                             *
@@ -2149,10 +1819,11 @@ EXPORT_SYMBOL_GPL(sdhci_set_power_and_bus_voltage);
 
 void sdhci_request(struct mmc_host *mmc, struct mmc_request *mrq)
 {
-	struct sdhci_host *host = mmc_priv(mmc);
-	struct mmc_command *cmd;
+	struct sdhci_host *host;
+	int present;
 	unsigned long flags;
-	bool present;
+
+	host = mmc_priv(mmc);
 
 	/* Firstly check card presence */
 	present = mmc->ops->get_cd(mmc);
@@ -2161,57 +1832,30 @@ void sdhci_request(struct mmc_host *mmc, struct mmc_request *mrq)
 
 	sdhci_led_activate(host);
 
-	if (sdhci_present_error(host, mrq->cmd, present))
-		goto out_finish;
-
-	cmd = sdhci_manual_cmd23(host, mrq) ? mrq->sbc : mrq->cmd;
-
-	if (!sdhci_send_command_retry(host, cmd, flags))
-		goto out_finish;
-
-	spin_unlock_irqrestore(&host->lock, flags);
-
-	return;
-
-out_finish:
-	sdhci_finish_mrq(host, mrq);
-	spin_unlock_irqrestore(&host->lock, flags);
-}
-EXPORT_SYMBOL_GPL(sdhci_request);
-
-int sdhci_request_atomic(struct mmc_host *mmc, struct mmc_request *mrq)
-{
-	struct sdhci_host *host = mmc_priv(mmc);
-	struct mmc_command *cmd;
-	unsigned long flags;
-	int ret = 0;
-
-	spin_lock_irqsave(&host->lock, flags);
+	/*
+	 * Ensure we don't send the STOP for non-SET_BLOCK_COUNTED
+	 * requests if Auto-CMD12 is enabled.
+	 */
+	if (sdhci_auto_cmd12(host, mrq)) {
+		if (mrq->stop) {
+			mrq->data->stop = NULL;
+			mrq->stop = NULL;
+		}
+	}
 
-	if (sdhci_present_error(host, mrq->cmd, true)) {
+	if (!present || host->flags & SDHCI_DEVICE_DEAD) {
+		mrq->cmd->error = -ENOMEDIUM;
 		sdhci_finish_mrq(host, mrq);
-		goto out_finish;
+	} else {
+		if (mrq->sbc && !(host->flags & SDHCI_AUTO_CMD23))
+			sdhci_send_command(host, mrq->sbc);
+		else
+			sdhci_send_command(host, mrq->cmd);
 	}
 
-	cmd = sdhci_manual_cmd23(host, mrq) ? mrq->sbc : mrq->cmd;
-
-	/*
-	 * The HSQ may send a command in interrupt context without polling
-	 * the busy signaling, which means we should return BUSY if controller
-	 * has not released inhibit bits to allow HSQ trying to send request
-	 * again in non-atomic context. So we should not finish this request
-	 * here.
-	 */
-	if (!sdhci_send_command(host, cmd))
-		ret = -EBUSY;
-	else
-		sdhci_led_activate(host);
-
-out_finish:
 	spin_unlock_irqrestore(&host->lock, flags);
-	return ret;
 }
-EXPORT_SYMBOL_GPL(sdhci_request_atomic);
+EXPORT_SYMBOL_GPL(sdhci_request);
 
 void sdhci_set_bus_width(struct sdhci_host *host, int width)
 {
@@ -2245,7 +1889,9 @@ void sdhci_set_uhs_signaling(struct sdhci_host *host, unsigned timing)
 		ctrl_2 |= SDHCI_CTRL_UHS_SDR104;
 	else if (timing == MMC_TIMING_UHS_SDR12)
 		ctrl_2 |= SDHCI_CTRL_UHS_SDR12;
-	else if (timing == MMC_TIMING_UHS_SDR25)
+	else if (timing == MMC_TIMING_SD_HS ||
+		 timing == MMC_TIMING_MMC_HS ||
+		 timing == MMC_TIMING_UHS_SDR25)
 		ctrl_2 |= SDHCI_CTRL_UHS_SDR25;
 	else if (timing == MMC_TIMING_UHS_SDR50)
 		ctrl_2 |= SDHCI_CTRL_UHS_SDR50;
@@ -2395,8 +2041,8 @@ void sdhci_set_ios(struct mmc_host *mmc, struct mmc_ios *ios)
 
 			sdhci_enable_preset_value(host, true);
 			preset = sdhci_get_preset_value(host);
-			ios->drv_type = FIELD_GET(SDHCI_PRESET_DRV_MASK,
-						  preset);
+			ios->drv_type = (preset & SDHCI_PRESET_DRV_MASK)
+				>> SDHCI_PRESET_DRV_SHIFT;
 		}
 
 		/* Re-enable SD Clock */
@@ -2516,6 +2162,11 @@ void sdhci_enable_sdio_irq(struct mmc_host *mmc, int enable)
 		pm_runtime_get_noresume(host->mmc->parent);
 
 	spin_lock_irqsave(&host->lock, flags);
+	if (enable)
+		host->flags |= SDHCI_SDIO_IRQ_ENABLED;
+	else
+		host->flags &= ~SDHCI_SDIO_IRQ_ENABLED;
+
 	sdhci_enable_sdio_irq_nolock(host, enable);
 	spin_unlock_irqrestore(&host->lock, flags);
 
@@ -2560,7 +2211,7 @@ int sdhci_start_signal_voltage_switch(struct mmc_host *mmc,
 
 		if (!IS_ERR(mmc->supply.vqmmc)) {
 			ret = mmc_regulator_set_vqmmc(mmc, ios);
-			if (ret < 0) {
+			if (ret) {
 				pr_warn("%s: Switching to 3.3V signalling voltage failed\n",
 					mmc_hostname(mmc));
 				return -EIO;
@@ -2574,7 +2225,7 @@ int sdhci_start_signal_voltage_switch(struct mmc_host *mmc,
 		if (!(ctrl & SDHCI_CTRL_VDD_180))
 			return 0;
 
-		pr_warn("%s: 3.3V regulator output did not become stable\n",
+		pr_warn("%s: 3.3V regulator output did not became stable\n",
 			mmc_hostname(mmc));
 
 		return -EAGAIN;
@@ -2583,7 +2234,7 @@ int sdhci_start_signal_voltage_switch(struct mmc_host *mmc,
 			return -EINVAL;
 		if (!IS_ERR(mmc->supply.vqmmc)) {
 			ret = mmc_regulator_set_vqmmc(mmc, ios);
-			if (ret < 0) {
+			if (ret) {
 				pr_warn("%s: Switching to 1.8V signalling voltage failed\n",
 					mmc_hostname(mmc));
 				return -EIO;
@@ -2606,7 +2257,7 @@ int sdhci_start_signal_voltage_switch(struct mmc_host *mmc,
 		if (ctrl & SDHCI_CTRL_VDD_180)
 			return 0;
 
-		pr_warn("%s: 1.8V regulator output did not become stable\n",
+		pr_warn("%s: 1.8V regulator output did not became stable\n",
 			mmc_hostname(mmc));
 
 		return -EAGAIN;
@@ -2615,7 +2266,7 @@ int sdhci_start_signal_voltage_switch(struct mmc_host *mmc,
 			return -EINVAL;
 		if (!IS_ERR(mmc->supply.vqmmc)) {
 			ret = mmc_regulator_set_vqmmc(mmc, ios);
-			if (ret < 0) {
+			if (ret) {
 				pr_warn("%s: Switching to 1.2V signalling voltage failed\n",
 					mmc_hostname(mmc));
 				return -EIO;
@@ -2722,6 +2373,7 @@ void sdhci_send_tuning(struct sdhci_host *host, u32 opcode)
 	struct mmc_request mrq = {};
 	unsigned long flags;
 	u32 b = host->sdma_boundary;
+	u8 ctrl;
 
 	spin_lock_irqsave(&host->lock, flags);
 
@@ -2749,11 +2401,18 @@ void sdhci_send_tuning(struct sdhci_host *host, u32 opcode)
 	 */
 	sdhci_writew(host, SDHCI_TRNS_READ, SDHCI_TRANSFER_MODE);
 
-	if (!sdhci_send_command_retry(host, &cmd, flags)) {
-		spin_unlock_irqrestore(&host->lock, flags);
-		host->tuning_done = 0;
-		return;
-	}
+	/*
+	 * DMA already disabled, so clear the DMA Select here.
+	 * Otherwise, if use ADMA2, even disable DMA, some
+	 * controllers like i.MX usdhc will still prefetch the
+	 * ADMA script when send tuning command, which will cause
+	 * IOMMU report lack of TLB mapping error
+	 */
+	ctrl = sdhci_readb(host, SDHCI_HOST_CONTROL);
+	ctrl &= ~SDHCI_CTRL_DMA_MASK;
+	sdhci_writeb(host, ctrl, SDHCI_HOST_CONTROL);
+
+	sdhci_send_command(host, &cmd);
 
 	host->cmd = NULL;
 
@@ -2784,8 +2443,8 @@ static int __sdhci_execute_tuning(struct sdhci_host *host, u32 opcode)
 		sdhci_send_tuning(host, opcode);
 
 		if (!host->tuning_done) {
-			pr_debug("%s: Tuning timeout, falling back to fixed sampling clock\n",
-				 mmc_hostname(host->mmc));
+			pr_info("%s: Tuning timeout, falling back to fixed sampling clock\n",
+				mmc_hostname(host->mmc));
 			sdhci_abort_tuning(host, opcode);
 			return -ETIMEDOUT;
 		}
@@ -2850,7 +2509,7 @@ int sdhci_execute_tuning(struct mmc_host *mmc, u32 opcode)
 	case MMC_TIMING_UHS_SDR50:
 		if (host->flags & SDHCI_SDR50_NEEDS_TUNING)
 			break;
-		fallthrough;
+		/* FALLTHROUGH */
 
 	default:
 		goto out;
@@ -3020,37 +2679,6 @@ static bool sdhci_request_done(struct sdhci_host *host)
 		return true;
 	}
 
-	/*
-	 * The controller needs a reset of internal state machines
-	 * upon error conditions.
-	 */
-	if (sdhci_needs_reset(host, mrq)) {
-		/*
-		 * Do not finish until command and data lines are available for
-		 * reset. Note there can only be one other mrq, so it cannot
-		 * also be in mrqs_done, otherwise host->cmd and host->data_cmd
-		 * would both be null.
-		 */
-		if (host->cmd || host->data_cmd) {
-			spin_unlock_irqrestore(&host->lock, flags);
-			return true;
-		}
-
-		/* Some controllers need this kick or reset won't work here */
-		if (host->quirks & SDHCI_QUIRK_CLOCK_BEFORE_RESET)
-			/* This is to force an update */
-			host->ops->set_clock(host, host->clock);
-
-		/*
-		 * Spec says we should do both at the same time, but Ricoh
-		 * controllers do not like that.
-		 */
-		sdhci_do_reset(host, SDHCI_RESET_CMD);
-		sdhci_do_reset(host, SDHCI_RESET_DATA);
-
-		host->pending_reset = false;
-	}
-
 	/*
 	 * Always unmap the data buffers if they were mapped by
 	 * sdhci_prepare_data() whenever we finish with a request.
@@ -3059,17 +2687,6 @@ static bool sdhci_request_done(struct sdhci_host *host)
 	if (host->flags & SDHCI_REQ_USE_DMA) {
 		struct mmc_data *data = mrq->data;
 
-		if (host->use_external_dma && data &&
-		    (mrq->cmd->error || data->error)) {
-			struct dma_chan *chan = sdhci_external_dma_channel(host, data);
-
-			host->mrqs_done[i] = NULL;
-			spin_unlock_irqrestore(&host->lock, flags);
-			dmaengine_terminate_sync(chan);
-			spin_lock_irqsave(&host->lock, flags);
-			sdhci_set_mrq_done(host, mrq);
-		}
-
 		if (data && data->host_cookie == COOKIE_MAPPED) {
 			if (host->bounce_buffer) {
 				/*
@@ -3114,14 +2731,40 @@ static bool sdhci_request_done(struct sdhci_host *host)
 		}
 	}
 
+	/*
+	 * The controller needs a reset of internal state machines
+	 * upon error conditions.
+	 */
+	if (sdhci_needs_reset(host, mrq)) {
+		/*
+		 * Do not finish until command and data lines are available for
+		 * reset. Note there can only be one other mrq, so it cannot
+		 * also be in mrqs_done, otherwise host->cmd and host->data_cmd
+		 * would both be null.
+		 */
+		if (host->cmd || host->data_cmd) {
+			spin_unlock_irqrestore(&host->lock, flags);
+			return true;
+		}
+
+		/* Some controllers need this kick or reset won't work here */
+		if (host->quirks & SDHCI_QUIRK_CLOCK_BEFORE_RESET)
+			/* This is to force an update */
+			host->ops->set_clock(host, host->clock);
+
+		/* Spec says we should do both at the same time, but Ricoh
+		   controllers do not like that. */
+		sdhci_do_reset(host, SDHCI_RESET_CMD);
+		sdhci_do_reset(host, SDHCI_RESET_DATA);
+
+		host->pending_reset = false;
+	}
+
 	host->mrqs_done[i] = NULL;
 
 	spin_unlock_irqrestore(&host->lock, flags);
 
-	if (host->ops->request_done)
-		host->ops->request_done(host, mrq);
-	else
-		mmc_request_done(host->mmc, mrq);
+	mmc_request_done(host->mmc, mrq);
 
 	return false;
 }
@@ -3173,7 +2816,7 @@ static void sdhci_timeout_data_timer(struct timer_list *t)
 
 		if (host->data) {
 			host->data->error = -ETIMEDOUT;
-			__sdhci_finish_data(host, true);
+			sdhci_finish_data(host);
 			queue_work(host->complete_wq, &host->complete_work);
 		} else if (host->data_cmd) {
 			host->data_cmd->error = -ETIMEDOUT;
@@ -3424,7 +3067,7 @@ static inline bool sdhci_defer_done(struct sdhci_host *host,
 {
 	struct mmc_data *data = mrq->data;
 
-	return host->pending_reset || host->always_defer_done ||
+	return host->pending_reset ||
 	       ((host->flags & SDHCI_REQ_USE_DMA) && data &&
 		data->host_cookie == COOKIE_MAPPED);
 }
@@ -3440,7 +3083,7 @@ static irqreturn_t sdhci_irq(int irq, void *dev_id)
 
 	spin_lock(&host->lock);
 
-	if (host->runtime_suspended) {
+	if (host->runtime_suspended && !sdhci_sdio_irq_enabled(host)) {
 		spin_unlock(&host->lock);
 		return IRQ_NONE;
 	}
@@ -3545,19 +3188,11 @@ static irqreturn_t sdhci_irq(int irq, void *dev_id)
 		}
 	}
 out:
-	if (host->deferred_cmd)
-		result = IRQ_WAKE_THREAD;
-
 	spin_unlock(&host->lock);
 
 	/* Process mrqs ready for immediate completion */
 	for (i = 0; i < SDHCI_MAX_MRQS; i++) {
-		if (!mrqs_done[i])
-			continue;
-
-		if (host->ops->request_done)
-			host->ops->request_done(host, mrqs_done[i]);
-		else
+		if (mrqs_done[i])
 			mmc_request_done(host->mmc, mrqs_done[i]);
 	}
 
@@ -3573,7 +3208,6 @@ static irqreturn_t sdhci_irq(int irq, void *dev_id)
 static irqreturn_t sdhci_thread_irq(int irq, void *dev_id)
 {
 	struct sdhci_host *host = dev_id;
-	struct mmc_command *cmd;
 	unsigned long flags;
 	u32 isr;
 
@@ -3581,14 +3215,8 @@ static irqreturn_t sdhci_thread_irq(int irq, void *dev_id)
 		;
 
 	spin_lock_irqsave(&host->lock, flags);
-
 	isr = host->thread_isr;
 	host->thread_isr = 0;
-
-	cmd = host->deferred_cmd;
-	if (cmd && !sdhci_send_command_retry(host, cmd, flags))
-		sdhci_finish_mrq(host, cmd->mrq);
-
 	spin_unlock_irqrestore(&host->lock, flags);
 
 	if (isr & (SDHCI_INT_CARD_INSERT | SDHCI_INT_CARD_REMOVE)) {
@@ -3683,7 +3311,7 @@ int sdhci_suspend_host(struct sdhci_host *host)
 		host->ier = 0;
 		sdhci_writel(host, 0, SDHCI_INT_ENABLE);
 		sdhci_writel(host, 0, SDHCI_SIGNAL_ENABLE);
-		free_irq(host->irq, host);
+		disable_irq(host->irq);
 	}
 
 	return 0;
@@ -3694,7 +3322,6 @@ EXPORT_SYMBOL_GPL(sdhci_suspend_host);
 int sdhci_resume_host(struct sdhci_host *host)
 {
 	struct mmc_host *mmc = host->mmc;
-	int ret = 0;
 
 	if (host->flags & (SDHCI_USE_SDMA | SDHCI_USE_ADMA)) {
 		if (host->ops->enable_dma)
@@ -3715,16 +3342,12 @@ int sdhci_resume_host(struct sdhci_host *host)
 	if (host->irq_wake_enabled) {
 		sdhci_disable_irq_wakeups(host);
 	} else {
-		ret = request_threaded_irq(host->irq, sdhci_irq,
-					   sdhci_thread_irq, IRQF_SHARED,
-					   mmc_hostname(host->mmc), host);
-		if (ret)
-			return ret;
+		enable_irq(host->irq);
 	}
 
 	sdhci_enable_card_detection(host);
 
-	return ret;
+	return 0;
 }
 
 EXPORT_SYMBOL_GPL(sdhci_resume_host);
@@ -3789,7 +3412,7 @@ int sdhci_runtime_resume_host(struct sdhci_host *host, int soft_reset)
 	host->runtime_suspended = false;
 
 	/* Enable SDIO IRQ */
-	if (sdio_irq_claimed(mmc))
+	if (host->flags & SDHCI_SDIO_IRQ_ENABLED)
 		sdhci_enable_sdio_irq_nolock(host, true);
 
 	/* Enable Card Detection */
@@ -4020,10 +3643,10 @@ void __sdhci_read_caps(struct sdhci_host *host, const u16 *ver,
 	if (host->v4_mode)
 		sdhci_do_enable_v4_mode(host);
 
-	device_property_read_u64_array(mmc_dev(host->mmc),
-				       "sdhci-caps-mask", &dt_caps_mask, 1);
-	device_property_read_u64_array(mmc_dev(host->mmc),
-				       "sdhci-caps", &dt_caps, 1);
+	of_property_read_u64(mmc_dev(host->mmc)->of_node,
+			     "sdhci-caps-mask", &dt_caps_mask);
+	of_property_read_u64(mmc_dev(host->mmc)->of_node,
+			     "sdhci-caps", &dt_caps);
 
 	v = ver ? *ver : sdhci_readw(host, SDHCI_HOST_VERSION);
 	host->version = (v & SDHCI_SPEC_VER_MASK) >> SDHCI_SPEC_VER_SHIFT;
@@ -4128,18 +3751,19 @@ static inline bool sdhci_can_64bit_dma(struct sdhci_host *host)
 int sdhci_setup_host(struct sdhci_host *host)
 {
 	struct mmc_host *mmc;
+	struct device *dev;
 	u32 max_current_caps;
 	unsigned int ocr_avail;
 	unsigned int override_timeout_clk;
 	u32 max_clk;
-	int ret = 0;
-	bool enable_vqmmc = false;
+	int ret;
 
 	WARN_ON(host == NULL);
 	if (host == NULL)
 		return -EINVAL;
 
 	mmc = host->mmc;
+	dev = mmc_dev(mmc);
 
 	/*
 	 * If there are external regulators, get them. Note this must be done
@@ -4147,12 +3771,9 @@ int sdhci_setup_host(struct sdhci_host *host)
 	 * the host can take the appropriate action if regulators are not
 	 * available.
 	 */
-	if (!mmc->supply.vqmmc) {
-		ret = mmc_regulator_get_supply(mmc);
-		if (ret)
-			return ret;
-		enable_vqmmc  = true;
-	}
+	ret = mmc_regulator_get_supply(mmc);
+	if (ret)
+		return ret;
 
 	DBG("Version:   0x%08x | Present:  0x%08x\n",
 	    sdhci_readw(host, SDHCI_HOST_VERSION),
@@ -4196,21 +3817,6 @@ int sdhci_setup_host(struct sdhci_host *host)
 	if (sdhci_can_64bit_dma(host))
 		host->flags |= SDHCI_USE_64_BIT_DMA;
 
-	if (host->use_external_dma) {
-		ret = sdhci_external_dma_init(host);
-		if (ret == -EPROBE_DEFER)
-			goto unreg;
-		/*
-		 * Fall back to use the DMA/PIO integrated in standard SDHCI
-		 * instead of external DMA devices.
-		 */
-		else if (ret)
-			sdhci_switch_external_dma(host, false);
-		/* Disable internal DMA sources */
-		else
-			host->flags &= ~(SDHCI_USE_SDMA | SDHCI_USE_ADMA);
-	}
-
 	if (host->flags & (SDHCI_USE_SDMA | SDHCI_USE_ADMA)) {
 		if (host->ops->set_dma_mask)
 			ret = host->ops->set_dma_mask(host);
@@ -4237,13 +3843,15 @@ int sdhci_setup_host(struct sdhci_host *host)
 		dma_addr_t dma;
 		void *buf;
 
-		if (!(host->flags & SDHCI_USE_64_BIT_DMA))
-			host->alloc_desc_sz = SDHCI_ADMA2_32_DESC_SZ;
-		else if (!host->alloc_desc_sz)
-			host->alloc_desc_sz = SDHCI_ADMA2_64_DESC_SZ(host);
-
-		host->desc_sz = host->alloc_desc_sz;
-		host->adma_table_sz = host->adma_table_cnt * host->desc_sz;
+		if (host->flags & SDHCI_USE_64_BIT_DMA) {
+			host->adma_table_sz = host->adma_table_cnt *
+					      SDHCI_ADMA2_64_DESC_SZ(host);
+			host->desc_sz = SDHCI_ADMA2_64_DESC_SZ(host);
+		} else {
+			host->adma_table_sz = host->adma_table_cnt *
+					      SDHCI_ADMA2_32_DESC_SZ;
+			host->desc_sz = SDHCI_ADMA2_32_DESC_SZ;
+		}
 
 		host->align_buffer_sz = SDHCI_MAX_SEGS * SDHCI_ADMA2_ALIGN;
 		/*
@@ -4284,9 +3892,11 @@ int sdhci_setup_host(struct sdhci_host *host)
 	}
 
 	if (host->version >= SDHCI_SPEC_300)
-		host->max_clk = FIELD_GET(SDHCI_CLOCK_V3_BASE_MASK, host->caps);
+		host->max_clk = (host->caps & SDHCI_CLOCK_V3_BASE_MASK)
+			>> SDHCI_CLOCK_BASE_SHIFT;
 	else
-		host->max_clk = FIELD_GET(SDHCI_CLOCK_BASE_MASK, host->caps);
+		host->max_clk = (host->caps & SDHCI_CLOCK_BASE_MASK)
+			>> SDHCI_CLOCK_BASE_SHIFT;
 
 	host->max_clk *= 1000000;
 	if (host->max_clk == 0 || host->quirks &
@@ -4304,7 +3914,8 @@ int sdhci_setup_host(struct sdhci_host *host)
 	 * In case of Host Controller v3.00, find out whether clock
 	 * multiplier is supported.
 	 */
-	host->clk_mul = FIELD_GET(SDHCI_CLOCK_MUL_MASK, host->caps1);
+	host->clk_mul = (host->caps1 & SDHCI_CLOCK_MUL_MASK) >>
+			SDHCI_CLOCK_MUL_SHIFT;
 
 	/*
 	 * In case the value in Clock Multiplier is 0, then programmable
@@ -4323,13 +3934,11 @@ int sdhci_setup_host(struct sdhci_host *host)
 	if (host->ops->get_min_clock)
 		mmc->f_min = host->ops->get_min_clock(host);
 	else if (host->version >= SDHCI_SPEC_300) {
-		if (host->clk_mul)
+		if (host->clk_mul) {
+			mmc->f_min = (host->max_clk * host->clk_mul) / 1024;
 			max_clk = host->max_clk * host->clk_mul;
-		/*
-		 * Divided Clock Mode minimum clock rate is always less than
-		 * Programmable Clock Mode minimum clock rate.
-		 */
-		mmc->f_min = host->max_clk / SDHCI_MAX_DIV_SPEC_300;
+		} else
+			mmc->f_min = host->max_clk / SDHCI_MAX_DIV_SPEC_300;
 	} else
 		mmc->f_min = host->max_clk / SDHCI_MAX_DIV_SPEC_200;
 
@@ -4337,7 +3946,8 @@ int sdhci_setup_host(struct sdhci_host *host)
 		mmc->f_max = max_clk;
 
 	if (!(host->quirks & SDHCI_QUIRK_DATA_TIMEOUT_USES_SDCLK)) {
-		host->timeout_clk = FIELD_GET(SDHCI_TIMEOUT_CLK_MASK, host->caps);
+		host->timeout_clk = (host->caps & SDHCI_TIMEOUT_CLK_MASK) >>
+					SDHCI_TIMEOUT_CLK_SHIFT;
 
 		if (host->caps & SDHCI_TIMEOUT_CLK_UNIT)
 			host->timeout_clk *= 1000;
@@ -4367,8 +3977,9 @@ int sdhci_setup_host(struct sdhci_host *host)
 	    !host->ops->get_max_timeout_count)
 		mmc->max_busy_timeout = 0;
 
-	mmc->caps |= MMC_CAP_SDIO_IRQ | MMC_CAP_CMD23;
-	mmc->caps2 |= MMC_CAP2_SDIO_IRQ_NOTHREAD;
+	mmc->caps |= MMC_CAP_SDIO_IRQ | MMC_CAP_ERASE | MMC_CAP_CMD23;
+	if (!(host->quirks2 & SDHCI_QUIRK2_SDIO_IRQ_THREAD))
+		mmc->caps2 |= MMC_CAP2_SDIO_IRQ_NOTHREAD;
 
 	if (host->quirks & SDHCI_QUIRK_MULTIBLOCK_READ_ACMD12)
 		host->flags |= SDHCI_AUTO_CMD12;
@@ -4403,16 +4014,8 @@ int sdhci_setup_host(struct sdhci_host *host)
 	if (host->caps & SDHCI_CAN_DO_HISPD)
 		mmc->caps |= MMC_CAP_SD_HIGHSPEED | MMC_CAP_MMC_HIGHSPEED;
 
-	if ((host->quirks & SDHCI_QUIRK_BROKEN_CARD_DETECTION) &&
-	    mmc_card_is_removable(mmc) &&
-	    mmc_gpio_get_cd(host->mmc) < 0)
-		mmc->caps |= MMC_CAP_NEEDS_POLL;
-
 	if (!IS_ERR(mmc->supply.vqmmc)) {
-		if (enable_vqmmc) {
-			ret = regulator_enable(mmc->supply.vqmmc);
-			host->sdhci_core_to_disable_vqmmc = !ret;
-		}
+		ret = regulator_enable(mmc->supply.vqmmc);
 
 		/* If vqmmc provides no 1.8V signalling, then there's no UHS */
 		if (!regulator_is_supported_voltage(mmc->supply.vqmmc, 1700000,
@@ -4431,7 +4034,6 @@ int sdhci_setup_host(struct sdhci_host *host)
 				mmc_hostname(mmc), ret);
 			mmc->supply.vqmmc = ERR_PTR(-EINVAL);
 		}
-
 	}
 
 	if (host->quirks2 & SDHCI_QUIRK2_NO_1_8_V) {
@@ -4493,8 +4095,8 @@ int sdhci_setup_host(struct sdhci_host *host)
 		mmc->caps |= MMC_CAP_DRIVER_TYPE_D;
 
 	/* Initial value for re-tuning timer count */
-	host->tuning_count = FIELD_GET(SDHCI_RETUNING_TIMER_COUNT_MASK,
-				       host->caps1);
+	host->tuning_count = (host->caps1 & SDHCI_RETUNING_TIMER_COUNT_MASK) >>
+			     SDHCI_RETUNING_TIMER_COUNT_SHIFT;
 
 	/*
 	 * In case Re-tuning Timer is not disabled, the actual value of
@@ -4504,7 +4106,8 @@ int sdhci_setup_host(struct sdhci_host *host)
 		host->tuning_count = 1 << (host->tuning_count - 1);
 
 	/* Re-tuning mode supported by the Host Controller */
-	host->tuning_mode = FIELD_GET(SDHCI_RETUNING_MODE_MASK, host->caps1);
+	host->tuning_mode = (host->caps1 & SDHCI_RETUNING_MODE_MASK) >>
+			     SDHCI_RETUNING_MODE_SHIFT;
 
 	ocr_avail = 0;
 
@@ -4526,32 +4129,35 @@ int sdhci_setup_host(struct sdhci_host *host)
 
 			curr = min_t(u32, curr, SDHCI_MAX_CURRENT_LIMIT);
 			max_current_caps =
-				FIELD_PREP(SDHCI_MAX_CURRENT_330_MASK, curr) |
-				FIELD_PREP(SDHCI_MAX_CURRENT_300_MASK, curr) |
-				FIELD_PREP(SDHCI_MAX_CURRENT_180_MASK, curr);
+				(curr << SDHCI_MAX_CURRENT_330_SHIFT) |
+				(curr << SDHCI_MAX_CURRENT_300_SHIFT) |
+				(curr << SDHCI_MAX_CURRENT_180_SHIFT);
 		}
 	}
 
 	if (host->caps & SDHCI_CAN_VDD_330) {
 		ocr_avail |= MMC_VDD_32_33 | MMC_VDD_33_34;
 
-		mmc->max_current_330 = FIELD_GET(SDHCI_MAX_CURRENT_330_MASK,
-						 max_current_caps) *
-						SDHCI_MAX_CURRENT_MULTIPLIER;
+		mmc->max_current_330 = ((max_current_caps &
+				   SDHCI_MAX_CURRENT_330_MASK) >>
+				   SDHCI_MAX_CURRENT_330_SHIFT) *
+				   SDHCI_MAX_CURRENT_MULTIPLIER;
 	}
 	if (host->caps & SDHCI_CAN_VDD_300) {
 		ocr_avail |= MMC_VDD_29_30 | MMC_VDD_30_31;
 
-		mmc->max_current_300 = FIELD_GET(SDHCI_MAX_CURRENT_300_MASK,
-						 max_current_caps) *
-						SDHCI_MAX_CURRENT_MULTIPLIER;
+		mmc->max_current_300 = ((max_current_caps &
+				   SDHCI_MAX_CURRENT_300_MASK) >>
+				   SDHCI_MAX_CURRENT_300_SHIFT) *
+				   SDHCI_MAX_CURRENT_MULTIPLIER;
 	}
 	if (host->caps & SDHCI_CAN_VDD_180) {
 		ocr_avail |= MMC_VDD_165_195;
 
-		mmc->max_current_180 = FIELD_GET(SDHCI_MAX_CURRENT_180_MASK,
-						 max_current_caps) *
-						SDHCI_MAX_CURRENT_MULTIPLIER;
+		mmc->max_current_180 = ((max_current_caps &
+				   SDHCI_MAX_CURRENT_180_MASK) >>
+				   SDHCI_MAX_CURRENT_180_SHIFT) *
+				   SDHCI_MAX_CURRENT_MULTIPLIER;
 	}
 
 	/* If OCR set by host, use it instead. */
@@ -4623,16 +4229,23 @@ int sdhci_setup_host(struct sdhci_host *host)
 	 * of bytes. When doing hardware scatter/gather, each entry cannot
 	 * be larger than 64 KiB though.
 	 */
-	if (host->flags & SDHCI_USE_ADMA) {
+ 	if (host->flags & SDHCI_USE_ADMA) {
 		if (host->quirks & SDHCI_QUIRK_BROKEN_ADMA_ZEROLEN_DESC) {
-			host->max_adma = 65532; /* 32-bit alignment */
 			mmc->max_seg_size = 65535;
+			/*
+			 * send the ADMA limitation to IOMMU. In default,
+			 * the max segment size of IOMMU is 64KB, this exceed
+			 * the ADMA max segment limitation, which is 65535.
+			 */
+			dev->dma_parms = devm_kzalloc(dev,
+			                sizeof(*dev->dma_parms), GFP_KERNEL);
+			dma_set_max_seg_size(dev, SZ_64K - 1);
 		} else {
-			mmc->max_seg_size = 65536;
+ 			mmc->max_seg_size = 65536;
 		}
-	} else {
-		mmc->max_seg_size = mmc->max_req_size;
-	}
+ 	} else {
+ 		mmc->max_seg_size = mmc->max_req_size;
+ 	}	
 
 	/*
 	 * Maximum block size. This varies from controller to controller and
@@ -4664,7 +4277,7 @@ int sdhci_setup_host(struct sdhci_host *host)
 	return 0;
 
 unreg:
-	if (host->sdhci_core_to_disable_vqmmc)
+	if (!IS_ERR(mmc->supply.vqmmc))
 		regulator_disable(mmc->supply.vqmmc);
 undma:
 	if (host->align_buffer)
@@ -4682,17 +4295,13 @@ void sdhci_cleanup_host(struct sdhci_host *host)
 {
 	struct mmc_host *mmc = host->mmc;
 
-	if (host->sdhci_core_to_disable_vqmmc)
+	if (!IS_ERR(mmc->supply.vqmmc))
 		regulator_disable(mmc->supply.vqmmc);
 
 	if (host->align_buffer)
 		dma_free_coherent(mmc_dev(mmc), host->align_buffer_sz +
 				  host->adma_table_sz, host->align_buffer,
 				  host->align_addr);
-
-	if (host->use_external_dma)
-		sdhci_external_dma_release(host);
-
 	host->adma_table = NULL;
 	host->align_buffer = NULL;
 }
@@ -4704,12 +4313,6 @@ int __sdhci_add_host(struct sdhci_host *host)
 	struct mmc_host *mmc = host->mmc;
 	int ret;
 
-	if ((mmc->caps2 & MMC_CAP2_CQE) &&
-	    (host->quirks & SDHCI_QUIRK_BROKEN_CQE)) {
-		mmc->caps2 &= ~MMC_CAP2_CQE;
-		mmc->cqe_ops = NULL;
-	}
-
 	host->complete_wq = alloc_workqueue("sdhci", flags, 0);
 	if (!host->complete_wq)
 		return -ENOMEM;
@@ -4744,7 +4347,6 @@ int __sdhci_add_host(struct sdhci_host *host)
 
 	pr_info("%s: SDHCI controller on %s [%s] using %s\n",
 		mmc_hostname(mmc), host->hw_name, dev_name(mmc_dev(mmc)),
-		host->use_external_dma ? "External DMA" :
 		(host->flags & SDHCI_USE_ADMA) ?
 		(host->flags & SDHCI_USE_64_BIT_DMA) ? "ADMA 64-bit" : "ADMA" :
 		(host->flags & SDHCI_USE_SDMA) ? "DMA" : "PIO");
@@ -4825,7 +4427,7 @@ void sdhci_remove_host(struct sdhci_host *host, int dead)
 
 	destroy_workqueue(host->complete_wq);
 
-	if (host->sdhci_core_to_disable_vqmmc)
+	if (!IS_ERR(mmc->supply.vqmmc))
 		regulator_disable(mmc->supply.vqmmc);
 
 	if (host->align_buffer)
@@ -4833,9 +4435,6 @@ void sdhci_remove_host(struct sdhci_host *host, int dead)
 				  host->adma_table_sz, host->align_buffer,
 				  host->align_addr);
 
-	if (host->use_external_dma)
-		sdhci_external_dma_release(host);
-
 	host->adma_table = NULL;
 	host->align_buffer = NULL;
 }
diff --git a/drivers/mmc/host/sdhci.h b/drivers/mmc/host/sdhci.h
old mode 100644
new mode 100755
index 8b1650f37..7b3c7a424
--- a/drivers/mmc/host/sdhci.h
+++ b/drivers/mmc/host/sdhci.h
@@ -9,7 +9,6 @@
 #ifndef __SDHCI_HW_H
 #define __SDHCI_HW_H
 
-#include <linux/bits.h>
 #include <linux/scatterlist.h>
 #include <linux/compiler.h>
 #include <linux/types.h>
@@ -200,10 +199,12 @@
 #define  SDHCI_CTRL_PRESET_VAL_ENABLE	0x8000
 
 #define SDHCI_CAPABILITIES	0x40
-#define  SDHCI_TIMEOUT_CLK_MASK		GENMASK(5, 0)
+#define  SDHCI_TIMEOUT_CLK_MASK	0x0000003F
+#define  SDHCI_TIMEOUT_CLK_SHIFT 0
 #define  SDHCI_TIMEOUT_CLK_UNIT	0x00000080
-#define  SDHCI_CLOCK_BASE_MASK		GENMASK(13, 8)
-#define  SDHCI_CLOCK_V3_BASE_MASK	GENMASK(15, 8)
+#define  SDHCI_CLOCK_BASE_MASK	0x00003F00
+#define  SDHCI_CLOCK_V3_BASE_MASK	0x0000FF00
+#define  SDHCI_CLOCK_BASE_SHIFT	8
 #define  SDHCI_MAX_BLOCK_MASK	0x00030000
 #define  SDHCI_MAX_BLOCK_SHIFT  16
 #define  SDHCI_CAN_DO_8BIT	0x00040000
@@ -218,25 +219,32 @@
 #define  SDHCI_CAN_64BIT_V4	0x08000000
 #define  SDHCI_CAN_64BIT	0x10000000
 
-#define SDHCI_CAPABILITIES_1	0x44
 #define  SDHCI_SUPPORT_SDR50	0x00000001
 #define  SDHCI_SUPPORT_SDR104	0x00000002
 #define  SDHCI_SUPPORT_DDR50	0x00000004
 #define  SDHCI_DRIVER_TYPE_A	0x00000010
 #define  SDHCI_DRIVER_TYPE_C	0x00000020
 #define  SDHCI_DRIVER_TYPE_D	0x00000040
-#define  SDHCI_RETUNING_TIMER_COUNT_MASK	GENMASK(11, 8)
+#define  SDHCI_RETUNING_TIMER_COUNT_MASK	0x00000F00
+#define  SDHCI_RETUNING_TIMER_COUNT_SHIFT	8
 #define  SDHCI_USE_SDR50_TUNING			0x00002000
-#define  SDHCI_RETUNING_MODE_MASK		GENMASK(15, 14)
-#define  SDHCI_CLOCK_MUL_MASK			GENMASK(23, 16)
+#define  SDHCI_RETUNING_MODE_MASK		0x0000C000
+#define  SDHCI_RETUNING_MODE_SHIFT		14
+#define  SDHCI_CLOCK_MUL_MASK	0x00FF0000
+#define  SDHCI_CLOCK_MUL_SHIFT	16
 #define  SDHCI_CAN_DO_ADMA3	0x08000000
 #define  SDHCI_SUPPORT_HS400	0x80000000 /* Non-standard */
 
+#define SDHCI_CAPABILITIES_1	0x44
+
 #define SDHCI_MAX_CURRENT		0x48
-#define  SDHCI_MAX_CURRENT_LIMIT	GENMASK(7, 0)
-#define  SDHCI_MAX_CURRENT_330_MASK	GENMASK(7, 0)
-#define  SDHCI_MAX_CURRENT_300_MASK	GENMASK(15, 8)
-#define  SDHCI_MAX_CURRENT_180_MASK	GENMASK(23, 16)
+#define  SDHCI_MAX_CURRENT_LIMIT	0xFF
+#define  SDHCI_MAX_CURRENT_330_MASK	0x0000FF
+#define  SDHCI_MAX_CURRENT_330_SHIFT	0
+#define  SDHCI_MAX_CURRENT_300_MASK	0x00FF00
+#define  SDHCI_MAX_CURRENT_300_SHIFT	8
+#define  SDHCI_MAX_CURRENT_180_MASK	0xFF0000
+#define  SDHCI_MAX_CURRENT_180_SHIFT	16
 #define   SDHCI_MAX_CURRENT_MULTIPLIER	4
 
 /* 4C-4F reserved for more max current */
@@ -253,16 +261,18 @@
 
 /* 60-FB reserved */
 
-#define SDHCI_PRESET_FOR_HIGH_SPEED	0x64
 #define SDHCI_PRESET_FOR_SDR12 0x66
 #define SDHCI_PRESET_FOR_SDR25 0x68
 #define SDHCI_PRESET_FOR_SDR50 0x6A
 #define SDHCI_PRESET_FOR_SDR104        0x6C
 #define SDHCI_PRESET_FOR_DDR50 0x6E
 #define SDHCI_PRESET_FOR_HS400 0x74 /* Non-standard */
-#define SDHCI_PRESET_DRV_MASK		GENMASK(15, 14)
-#define SDHCI_PRESET_CLKGEN_SEL		BIT(10)
-#define SDHCI_PRESET_SDCLK_FREQ_MASK	GENMASK(9, 0)
+#define SDHCI_PRESET_DRV_MASK  0xC000
+#define SDHCI_PRESET_DRV_SHIFT  14
+#define SDHCI_PRESET_CLKGEN_SEL_MASK   0x400
+#define SDHCI_PRESET_CLKGEN_SEL_SHIFT	10
+#define SDHCI_PRESET_SDCLK_FREQ_MASK   0x3FF
+#define SDHCI_PRESET_SDCLK_FREQ_SHIFT	0
 
 #define SDHCI_SLOT_INT_STATUS	0xFC
 
@@ -400,8 +410,6 @@ struct sdhci_host {
 #define SDHCI_QUIRK_BROKEN_CARD_DETECTION		(1<<15)
 /* Controller reports inverted write-protect state */
 #define SDHCI_QUIRK_INVERTED_WRITE_PROTECT		(1<<16)
-/* Controller has unusable command queue engine */
-#define SDHCI_QUIRK_BROKEN_CQE				(1<<17)
 /* Controller does not like fast PIO transfers */
 #define SDHCI_QUIRK_PIO_NEEDS_DELAY			(1<<18)
 /* Controller does not have a LED */
@@ -475,10 +483,11 @@ struct sdhci_host {
  * block count.
  */
 #define SDHCI_QUIRK2_USE_32BIT_BLK_CNT			(1<<18)
+	/* Host or Card can't support no thread sdio irq */
+#define SDHCI_QUIRK2_SDIO_IRQ_THREAD			(1<<19)
 
 	int irq;		/* Device IRQ */
 	void __iomem *ioaddr;	/* Mapped address */
-	phys_addr_t mapbase;	/* physical address base */
 	char *bounce_buffer;	/* For packing SDMA reads/writes */
 	dma_addr_t bounce_addr;
 	unsigned int bounce_buffer_size;
@@ -506,6 +515,7 @@ struct sdhci_host {
 #define SDHCI_AUTO_CMD12	(1<<6)	/* Auto CMD12 support */
 #define SDHCI_AUTO_CMD23	(1<<7)	/* Auto CMD23 support */
 #define SDHCI_PV_ENABLED	(1<<8)	/* Preset value enabled */
+#define SDHCI_SDIO_IRQ_ENABLED	(1<<9)	/* SDIO irq enabled */
 #define SDHCI_USE_64_BIT_DMA	(1<<12)	/* Use 64-bit DMA */
 #define SDHCI_HS400_TUNING	(1<<13)	/* Tuning for HS400 */
 #define SDHCI_SIGNALING_330	(1<<14)	/* Host is capable of 3.3V signaling */
@@ -527,13 +537,10 @@ struct sdhci_host {
 	bool pending_reset;	/* Cmd/data reset is pending */
 	bool irq_wake_enabled;	/* IRQ wakeup is enabled */
 	bool v4_mode;		/* Host Version 4 Enable */
-	bool use_external_dma;	/* Host selects to use external DMA */
-	bool always_defer_done;	/* Always defer to complete requests */
 
 	struct mmc_request *mrqs_done[SDHCI_MAX_MRQS];	/* Requests done */
 	struct mmc_command *cmd;	/* Current command */
 	struct mmc_command *data_cmd;	/* Current data command */
-	struct mmc_command *deferred_cmd;	/* Deferred command */
 	struct mmc_data *data;	/* Current data request */
 	unsigned int data_early:1;	/* Data finished before cmd */
 
@@ -552,8 +559,7 @@ struct sdhci_host {
 	dma_addr_t adma_addr;	/* Mapped ADMA descr. table */
 	dma_addr_t align_addr;	/* Mapped bounce buffer */
 
-	unsigned int desc_sz;	/* ADMA current descriptor size */
-	unsigned int alloc_desc_sz;	/* ADMA descr. max size host supports */
+	unsigned int desc_sz;	/* ADMA descriptor size */
 
 	struct workqueue_struct *complete_wq;	/* Request completion wq */
 	struct work_struct	complete_work;	/* Request completion work */
@@ -561,16 +567,10 @@ struct sdhci_host {
 	struct timer_list timer;	/* Timer for timeouts */
 	struct timer_list data_timer;	/* Timer for data timeouts */
 
-#if IS_ENABLED(CONFIG_MMC_SDHCI_EXTERNAL_DMA)
-	struct dma_chan *rx_chan;
-	struct dma_chan *tx_chan;
-#endif
-
 	u32 caps;		/* CAPABILITY_0 */
 	u32 caps1;		/* CAPABILITY_1 */
 	bool read_caps;		/* Capability flags have been read */
 
-	bool sdhci_core_to_disable_vqmmc;  /* sdhci core can disable vqmmc */
 	unsigned int            ocr_avail_sdio;	/* OCR bit masks */
 	unsigned int            ocr_avail_sd;
 	unsigned int            ocr_avail_mmc;
@@ -608,7 +608,7 @@ struct sdhci_host {
 
 	u64			data_timeout;
 
-	unsigned long private[] ____cacheline_aligned;
+	unsigned long private[0] ____cacheline_aligned;
 };
 
 struct sdhci_ops {
@@ -649,12 +649,6 @@ struct sdhci_ops {
 	void	(*voltage_switch)(struct sdhci_host *host);
 	void	(*adma_write_desc)(struct sdhci_host *host, void **desc,
 				   dma_addr_t addr, int len, unsigned int cmd);
-	void	(*copy_to_bounce_buffer)(struct sdhci_host *host,
-					 struct mmc_data *data,
-					 unsigned int length);
-	void	(*request_done)(struct sdhci_host *host,
-				struct mmc_request *mrq);
-	void    (*dump_vendor_regs)(struct sdhci_host *host);
 };
 
 #ifdef CONFIG_MMC_SDHCI_IO_ACCESSORS
@@ -757,25 +751,27 @@ void sdhci_cleanup_host(struct sdhci_host *host);
 int __sdhci_add_host(struct sdhci_host *host);
 int sdhci_add_host(struct sdhci_host *host);
 void sdhci_remove_host(struct sdhci_host *host, int dead);
+void sdhci_send_command(struct sdhci_host *host, struct mmc_command *cmd);
 
 static inline void sdhci_read_caps(struct sdhci_host *host)
 {
 	__sdhci_read_caps(host, NULL, NULL, NULL);
 }
 
+static inline bool sdhci_sdio_irq_enabled(struct sdhci_host *host)
+{
+	return !!(host->flags & SDHCI_SDIO_IRQ_ENABLED);
+}
+
 u16 sdhci_calc_clk(struct sdhci_host *host, unsigned int clock,
 		   unsigned int *actual_clock);
 void sdhci_set_clock(struct sdhci_host *host, unsigned int clock);
 void sdhci_enable_clk(struct sdhci_host *host, u16 clk);
 void sdhci_set_power(struct sdhci_host *host, unsigned char mode,
 		     unsigned short vdd);
-void sdhci_set_power_and_bus_voltage(struct sdhci_host *host,
-				     unsigned char mode,
-				     unsigned short vdd);
 void sdhci_set_power_noreg(struct sdhci_host *host, unsigned char mode,
 			   unsigned short vdd);
 void sdhci_request(struct mmc_host *mmc, struct mmc_request *mrq);
-int sdhci_request_atomic(struct mmc_host *mmc, struct mmc_request *mrq);
 void sdhci_set_bus_width(struct sdhci_host *host, int width);
 void sdhci_reset(struct sdhci_host *host, u8 mask);
 void sdhci_set_uhs_signaling(struct sdhci_host *host, unsigned timing);
@@ -807,8 +803,5 @@ void sdhci_end_tuning(struct sdhci_host *host);
 void sdhci_reset_tuning(struct sdhci_host *host);
 void sdhci_send_tuning(struct sdhci_host *host, u32 opcode);
 void sdhci_abort_tuning(struct sdhci_host *host, u32 opcode);
-void sdhci_switch_external_dma(struct sdhci_host *host, bool en);
-void sdhci_set_data_timeout_irq(struct sdhci_host *host, bool enable);
-void __sdhci_set_timeout(struct sdhci_host *host, struct mmc_command *cmd);
 
 #endif /* __SDHCI_HW_H */
diff --git a/drivers/mmc/host/sdhci_f_sdh30.c b/drivers/mmc/host/sdhci_f_sdh30.c
index 3f5977979..f8b939e63 100644
--- a/drivers/mmc/host/sdhci_f_sdh30.c
+++ b/drivers/mmc/host/sdhci_f_sdh30.c
@@ -16,7 +16,31 @@
 #include <linux/clk.h>
 
 #include "sdhci-pltfm.h"
-#include "sdhci_f_sdh30.h"
+
+/* F_SDH30 extended Controller registers */
+#define F_SDH30_AHB_CONFIG		0x100
+#define  F_SDH30_AHB_BIGED		0x00000040
+#define  F_SDH30_BUSLOCK_DMA		0x00000020
+#define  F_SDH30_BUSLOCK_EN		0x00000010
+#define  F_SDH30_SIN			0x00000008
+#define  F_SDH30_AHB_INCR_16		0x00000004
+#define  F_SDH30_AHB_INCR_8		0x00000002
+#define  F_SDH30_AHB_INCR_4		0x00000001
+
+#define F_SDH30_TUNING_SETTING		0x108
+#define  F_SDH30_CMD_CHK_DIS		0x00010000
+
+#define F_SDH30_IO_CONTROL2		0x114
+#define  F_SDH30_CRES_O_DN		0x00080000
+#define  F_SDH30_MSEL_O_1_8		0x00040000
+
+#define F_SDH30_ESD_CONTROL		0x124
+#define  F_SDH30_EMMC_RST		0x00000002
+#define  F_SDH30_EMMC_HS200		0x01000000
+
+#define F_SDH30_CMD_DAT_DELAY		0x200
+
+#define F_SDH30_MIN_CLOCK		400000
 
 struct f_sdhost_priv {
 	struct clk *clk_iface;
@@ -89,6 +113,7 @@ static int sdhci_f_sdh30_probe(struct platform_device *pdev)
 {
 	struct sdhci_host *host;
 	struct device *dev = &pdev->dev;
+	struct resource *res;
 	int irq, ctrl = 0, ret = 0;
 	struct f_sdhost_priv *priv;
 	u32 reg = 0;
@@ -122,7 +147,8 @@ static int sdhci_f_sdh30_probe(struct platform_device *pdev)
 	host->ops = &sdhci_f_sdh30_ops;
 	host->irq = irq;
 
-	host->ioaddr = devm_platform_ioremap_resource(pdev, 0);
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	host->ioaddr = devm_ioremap_resource(&pdev->dev, res);
 	if (IS_ERR(host->ioaddr)) {
 		ret = PTR_ERR(host->ioaddr);
 		goto err;
@@ -219,7 +245,6 @@ MODULE_DEVICE_TABLE(acpi, f_sdh30_acpi_ids);
 static struct platform_driver sdhci_f_sdh30_driver = {
 	.driver = {
 		.name = "f_sdh30",
-		.probe_type = PROBE_PREFER_ASYNCHRONOUS,
 		.of_match_table = of_match_ptr(f_sdh30_dt_ids),
 		.acpi_match_table = ACPI_PTR(f_sdh30_acpi_ids),
 		.pm	= &sdhci_pltfm_pmops,
diff --git a/drivers/mmc/host/sunxi-mmc.c b/drivers/mmc/host/sunxi-mmc.c
index fc6277360..d577a6b0c 100644
--- a/drivers/mmc/host/sunxi-mmc.c
+++ b/drivers/mmc/host/sunxi-mmc.c
@@ -951,13 +951,9 @@ static void sunxi_mmc_set_ios(struct mmc_host *mmc, struct mmc_ios *ios)
 
 static int sunxi_mmc_volt_switch(struct mmc_host *mmc, struct mmc_ios *ios)
 {
-	int ret;
-
 	/* vqmmc regulator is available */
-	if (!IS_ERR(mmc->supply.vqmmc)) {
-		ret = mmc_regulator_set_vqmmc(mmc, ios);
-		return ret < 0 ? ret : 0;
-	}
+	if (!IS_ERR(mmc->supply.vqmmc))
+		return mmc_regulator_set_vqmmc(mmc, ios);
 
 	/* no vqmmc regulator, assume fixed regulator at 3/3.3V */
 	if (mmc->ios.signal_voltage == MMC_SIGNAL_VOLTAGE_330)
@@ -1277,7 +1273,8 @@ static int sunxi_mmc_resource_request(struct sunxi_mmc_host *host,
 	if (ret)
 		return ret;
 
-	host->reg_base = devm_platform_ioremap_resource(pdev, 0);
+	host->reg_base = devm_ioremap_resource(&pdev->dev,
+			      platform_get_resource(pdev, IORESOURCE_MEM, 0));
 	if (IS_ERR(host->reg_base))
 		return PTR_ERR(host->reg_base);
 
@@ -1394,7 +1391,7 @@ static int sunxi_mmc_probe(struct platform_device *pdev)
 	mmc->f_min		=   400000;
 	mmc->f_max		= 52000000;
 	mmc->caps	       |= MMC_CAP_MMC_HIGHSPEED | MMC_CAP_SD_HIGHSPEED |
-				  MMC_CAP_SDIO_IRQ;
+				  MMC_CAP_ERASE | MMC_CAP_SDIO_IRQ;
 
 	/*
 	 * Some H5 devices do not have signal traces precise enough to
@@ -1514,7 +1511,6 @@ static const struct dev_pm_ops sunxi_mmc_pm_ops = {
 static struct platform_driver sunxi_mmc_driver = {
 	.driver = {
 		.name	= "sunxi-mmc",
-		.probe_type = PROBE_PREFER_ASYNCHRONOUS,
 		.of_match_table = of_match_ptr(sunxi_mmc_of_match),
 		.pm = &sunxi_mmc_pm_ops,
 	},
diff --git a/drivers/mmc/host/tmio_mmc.c b/drivers/mmc/host/tmio_mmc.c
index d2d3b8df1..93e83ad25 100644
--- a/drivers/mmc/host/tmio_mmc.c
+++ b/drivers/mmc/host/tmio_mmc.c
@@ -77,10 +77,18 @@ static void tmio_mmc_set_clock(struct tmio_mmc_host *host,
 
 static void tmio_mmc_reset(struct tmio_mmc_host *host)
 {
+	/* FIXME - should we set stop clock reg here */
+	sd_ctrl_write16(host, CTL_RESET_SD, 0x0000);
 	sd_ctrl_write16(host, CTL_RESET_SDIO, 0x0000);
 	usleep_range(10000, 11000);
+	sd_ctrl_write16(host, CTL_RESET_SD, 0x0001);
 	sd_ctrl_write16(host, CTL_RESET_SDIO, 0x0001);
 	usleep_range(10000, 11000);
+
+	if (host->pdata->flags & TMIO_MMC_SDIO_IRQ) {
+		sd_ctrl_write16(host, CTL_SDIO_IRQ_MASK, host->sdio_irq_mask);
+		sd_ctrl_write16(host, CTL_TRANSACTION_CTL, 0x0001);
+	}
 }
 
 #ifdef CONFIG_PM_SLEEP
@@ -213,7 +221,6 @@ static const struct dev_pm_ops tmio_mmc_dev_pm_ops = {
 static struct platform_driver tmio_mmc_driver = {
 	.driver = {
 		.name = "tmio-mmc",
-		.probe_type = PROBE_PREFER_ASYNCHRONOUS,
 		.pm = &tmio_mmc_dev_pm_ops,
 	},
 	.probe = tmio_mmc_probe,
diff --git a/drivers/mmc/host/tmio_mmc.h b/drivers/mmc/host/tmio_mmc.h
index 9546e5426..2f0b092d6 100644
--- a/drivers/mmc/host/tmio_mmc.h
+++ b/drivers/mmc/host/tmio_mmc.h
@@ -118,9 +118,6 @@ struct tmio_mmc_dma_ops {
 	void (*release)(struct tmio_mmc_host *host);
 	void (*abort)(struct tmio_mmc_host *host);
 	void (*dataend)(struct tmio_mmc_host *host);
-
-	/* optional */
-	void (*end)(struct tmio_mmc_host *host);	/* held host->lock */
 };
 
 struct tmio_mmc_host {
@@ -166,6 +163,7 @@ struct tmio_mmc_host {
 	unsigned long		last_req_ts;
 	struct mutex		ios_lock;	/* protect set_ios() context */
 	bool			native_hotplug;
+	bool			runtime_synced;
 	bool			sdio_irq_enabled;
 
 	/* Mandatory callback */
@@ -178,8 +176,21 @@ struct tmio_mmc_host {
 			      unsigned int direction, int blk_size);
 	int (*write16_hook)(struct tmio_mmc_host *host, int addr);
 	void (*reset)(struct tmio_mmc_host *host);
-	bool (*check_retune)(struct tmio_mmc_host *host);
-	void (*fixup_request)(struct tmio_mmc_host *host, struct mmc_request *mrq);
+	void (*hw_reset)(struct tmio_mmc_host *host);
+	void (*prepare_tuning)(struct tmio_mmc_host *host, unsigned long tap);
+	bool (*check_scc_error)(struct tmio_mmc_host *host);
+
+	/*
+	 * Mandatory callback for tuning to occur which is optional for SDR50
+	 * and mandatory for SDR104.
+	 */
+	unsigned int (*init_tuning)(struct tmio_mmc_host *host);
+	int (*select_tuning)(struct tmio_mmc_host *host);
+
+	/* Tuning values: 1 for success, 0 for failure */
+	DECLARE_BITMAP(taps, BITS_PER_BYTE * sizeof(long));
+	unsigned int tap_num;
+	unsigned long tap_set;
 
 	void (*prepare_hs400_tuning)(struct tmio_mmc_host *host);
 	void (*hs400_downgrade)(struct tmio_mmc_host *host);
diff --git a/drivers/mmc/host/tmio_mmc_core.c b/drivers/mmc/host/tmio_mmc_core.c
index ac4e7874a..9b6e1001e 100644
--- a/drivers/mmc/host/tmio_mmc_core.c
+++ b/drivers/mmc/host/tmio_mmc_core.c
@@ -57,12 +57,6 @@ static inline void tmio_mmc_start_dma(struct tmio_mmc_host *host,
 		host->dma_ops->start(host, data);
 }
 
-static inline void tmio_mmc_end_dma(struct tmio_mmc_host *host)
-{
-	if (host->dma_ops && host->dma_ops->end)
-		host->dma_ops->end(host);
-}
-
 static inline void tmio_mmc_enable_dma(struct tmio_mmc_host *host, bool enable)
 {
 	if (host->dma_ops)
@@ -172,17 +166,24 @@ static void tmio_mmc_reset(struct tmio_mmc_host *host)
 	sd_ctrl_write16(host, CTL_RESET_SD, 0x0001);
 	usleep_range(10000, 11000);
 
-	if (host->reset)
-		host->reset(host);
-
-	tmio_mmc_abort_dma(host);
-
 	if (host->pdata->flags & TMIO_MMC_SDIO_IRQ) {
 		sd_ctrl_write16(host, CTL_SDIO_IRQ_MASK, host->sdio_irq_mask);
 		sd_ctrl_write16(host, CTL_TRANSACTION_CTL, 0x0001);
 	}
 }
 
+static void tmio_mmc_hw_reset(struct mmc_host *mmc)
+{
+	struct tmio_mmc_host *host = mmc_priv(mmc);
+
+	host->reset(host);
+
+	tmio_mmc_abort_dma(host);
+
+	if (host->hw_reset)
+		host->hw_reset(host);
+}
+
 static void tmio_mmc_reset_work(struct work_struct *work)
 {
 	struct tmio_mmc_host *host = container_of(work, struct tmio_mmc_host,
@@ -221,10 +222,11 @@ static void tmio_mmc_reset_work(struct work_struct *work)
 
 	spin_unlock_irqrestore(&host->lock, flags);
 
-	tmio_mmc_reset(host);
+	tmio_mmc_hw_reset(host->mmc);
 
 	/* Ready for new calls */
 	host->mrq = NULL;
+
 	mmc_request_done(host->mmc, mrq);
 }
 
@@ -712,6 +714,49 @@ static int tmio_mmc_start_data(struct tmio_mmc_host *host,
 	return 0;
 }
 
+static int tmio_mmc_execute_tuning(struct mmc_host *mmc, u32 opcode)
+{
+	struct tmio_mmc_host *host = mmc_priv(mmc);
+	int i, ret = 0;
+
+	if (!host->init_tuning || !host->select_tuning)
+		/* Tuning is not supported */
+		goto out;
+
+	host->tap_num = host->init_tuning(host);
+	if (!host->tap_num)
+		/* Tuning is not supported */
+		goto out;
+
+	if (host->tap_num * 2 >= sizeof(host->taps) * BITS_PER_BYTE) {
+		dev_warn_once(&host->pdev->dev,
+			"Too many taps, skipping tuning. Please consider updating size of taps field of tmio_mmc_host\n");
+		goto out;
+	}
+
+	bitmap_zero(host->taps, host->tap_num * 2);
+
+	/* Issue CMD19 twice for each tap */
+	for (i = 0; i < 2 * host->tap_num; i++) {
+		if (host->prepare_tuning)
+			host->prepare_tuning(host, i % host->tap_num);
+
+		ret = mmc_send_tuning(mmc, opcode, NULL);
+		if (ret == 0)
+			set_bit(i, host->taps);
+	}
+
+	ret = host->select_tuning(host);
+
+out:
+	if (ret < 0) {
+		dev_warn(&host->pdev->dev, "Tuning procedure failed\n");
+		tmio_mmc_hw_reset(mmc);
+	}
+
+	return ret;
+}
+
 static void tmio_process_mrq(struct tmio_mmc_host *host,
 			     struct mmc_request *mrq)
 {
@@ -777,8 +822,6 @@ static void tmio_mmc_finish_request(struct tmio_mmc_host *host)
 
 	spin_lock_irqsave(&host->lock, flags);
 
-	tmio_mmc_end_dma(host);
-
 	mrq = host->mrq;
 	if (IS_ERR_OR_NULL(mrq)) {
 		spin_unlock_irqrestore(&host->lock, flags);
@@ -799,8 +842,8 @@ static void tmio_mmc_finish_request(struct tmio_mmc_host *host)
 	if (mrq->cmd->error || (mrq->data && mrq->data->error))
 		tmio_mmc_abort_dma(host);
 
-	/* Error means retune, but executed command was still successful */
-	if (host->check_retune && host->check_retune(host))
+	/* SCC error means retune, but executed command was still successful */
+	if (host->check_scc_error && host->check_scc_error(host))
 		mmc_retune_needed(host->mmc);
 
 	/* If SET_BLOCK_COUNT, continue with main command */
@@ -809,9 +852,6 @@ static void tmio_mmc_finish_request(struct tmio_mmc_host *host)
 		return;
 	}
 
-	if (host->fixup_request)
-		host->fixup_request(host, mrq);
-
 	mmc_request_done(host->mmc, mrq);
 }
 
@@ -927,9 +967,6 @@ static void tmio_mmc_set_ios(struct mmc_host *mmc, struct mmc_ios *ios)
 	switch (ios->power_mode) {
 	case MMC_POWER_OFF:
 		tmio_mmc_power_off(host);
-		/* For R-Car Gen2+, we need to reset SDHI specific SCC */
-		if (host->pdata->flags & TMIO_MMC_MIN_RCAR2)
-			host->reset(host);
 		host->set_clock(host, 0);
 		break;
 	case MMC_POWER_UP:
@@ -984,13 +1021,45 @@ static int tmio_multi_io_quirk(struct mmc_card *card,
 	return blk_size;
 }
 
-static struct mmc_host_ops tmio_mmc_ops = {
+static int tmio_mmc_prepare_hs400_tuning(struct mmc_host *mmc,
+					 struct mmc_ios *ios)
+{
+	struct tmio_mmc_host *host = mmc_priv(mmc);
+
+	if (host->prepare_hs400_tuning)
+		host->prepare_hs400_tuning(host);
+
+	return 0;
+}
+
+static void tmio_mmc_hs400_downgrade(struct mmc_host *mmc)
+{
+	struct tmio_mmc_host *host = mmc_priv(mmc);
+
+	if (host->hs400_downgrade)
+		host->hs400_downgrade(host);
+}
+
+static void tmio_mmc_hs400_complete(struct mmc_host *mmc)
+{
+	struct tmio_mmc_host *host = mmc_priv(mmc);
+
+	if (host->hs400_complete)
+		host->hs400_complete(host);
+}
+
+static const struct mmc_host_ops tmio_mmc_ops = {
 	.request	= tmio_mmc_request,
 	.set_ios	= tmio_mmc_set_ios,
 	.get_ro         = tmio_mmc_get_ro,
 	.get_cd		= tmio_mmc_get_cd,
 	.enable_sdio_irq = tmio_mmc_enable_sdio_irq,
 	.multi_io_quirk	= tmio_multi_io_quirk,
+	.hw_reset	= tmio_mmc_hw_reset,
+	.execute_tuning = tmio_mmc_execute_tuning,
+	.prepare_hs400_tuning = tmio_mmc_prepare_hs400_tuning,
+	.hs400_downgrade = tmio_mmc_hs400_downgrade,
+	.hs400_complete	= tmio_mmc_hs400_complete,
 };
 
 static int tmio_mmc_init_ocr(struct tmio_mmc_host *host)
@@ -1039,10 +1108,12 @@ struct tmio_mmc_host *tmio_mmc_host_alloc(struct platform_device *pdev,
 {
 	struct tmio_mmc_host *host;
 	struct mmc_host *mmc;
+	struct resource *res;
 	void __iomem *ctl;
 	int ret;
 
-	ctl = devm_platform_ioremap_resource(pdev, 0);
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	ctl = devm_ioremap_resource(&pdev->dev, res);
 	if (IS_ERR(ctl))
 		return ERR_CAST(ctl);
 
@@ -1109,7 +1180,7 @@ int tmio_mmc_host_probe(struct tmio_mmc_host *_host)
 	 * Look for a card detect GPIO, if it fails with anything
 	 * else than a probe deferral, just live without it.
 	 */
-	ret = mmc_gpiod_request_cd(mmc, "cd", 0, false, 0);
+	ret = mmc_gpiod_request_cd(mmc, "cd", 0, false, 0, NULL);
 	if (ret == -EPROBE_DEFER)
 		return ret;
 
@@ -1134,6 +1205,9 @@ int tmio_mmc_host_probe(struct tmio_mmc_host *_host)
 				  mmc->caps & MMC_CAP_NEEDS_POLL ||
 				  !mmc_card_is_removable(mmc));
 
+	if (!_host->reset)
+		_host->reset = tmio_mmc_reset;
+
 	/*
 	 * On Gen2+, eMMC with NONREMOVABLE currently fails because native
 	 * hotplug gets disabled. It seems RuntimePM related yet we need further
@@ -1155,7 +1229,7 @@ int tmio_mmc_host_probe(struct tmio_mmc_host *_host)
 		_host->sdio_irq_mask = TMIO_SDIO_MASK_ALL;
 
 	_host->set_clock(_host, 0);
-	tmio_mmc_reset(_host);
+	tmio_mmc_hw_reset(mmc);
 
 	_host->sdcard_irq_mask = sd_ctrl_read16_and_16_as_32(_host, CTL_IRQ_MASK);
 	tmio_mmc_disable_mmc_irqs(_host, TMIO_MASK_ALL);
@@ -1174,11 +1248,10 @@ int tmio_mmc_host_probe(struct tmio_mmc_host *_host)
 	/* See if we also get DMA */
 	tmio_mmc_request_dma(_host, pdata);
 
-	pm_runtime_get_noresume(&pdev->dev);
-	pm_runtime_set_active(&pdev->dev);
 	pm_runtime_set_autosuspend_delay(&pdev->dev, 50);
 	pm_runtime_use_autosuspend(&pdev->dev);
 	pm_runtime_enable(&pdev->dev);
+	pm_runtime_get_sync(&pdev->dev);
 
 	ret = mmc_add_host(mmc);
 	if (ret)
@@ -1212,14 +1285,12 @@ void tmio_mmc_host_remove(struct tmio_mmc_host *host)
 	cancel_work_sync(&host->done);
 	cancel_delayed_work_sync(&host->delayed_reset_work);
 	tmio_mmc_release_dma(host);
-	tmio_mmc_disable_mmc_irqs(host, TMIO_MASK_ALL);
 
+	pm_runtime_dont_use_autosuspend(&pdev->dev);
 	if (host->native_hotplug)
 		pm_runtime_put_noidle(&pdev->dev);
-
+	pm_runtime_put_sync(&pdev->dev);
 	pm_runtime_disable(&pdev->dev);
-	pm_runtime_dont_use_autosuspend(&pdev->dev);
-	pm_runtime_put_noidle(&pdev->dev);
 }
 EXPORT_SYMBOL_GPL(tmio_mmc_host_remove);
 
@@ -1253,12 +1324,22 @@ int tmio_mmc_host_runtime_suspend(struct device *dev)
 }
 EXPORT_SYMBOL_GPL(tmio_mmc_host_runtime_suspend);
 
+static bool tmio_mmc_can_retune(struct tmio_mmc_host *host)
+{
+	return host->tap_num && mmc_can_retune(host->mmc);
+}
+
 int tmio_mmc_host_runtime_resume(struct device *dev)
 {
 	struct tmio_mmc_host *host = dev_get_drvdata(dev);
 
+	if (!host->runtime_synced) {
+		host->runtime_synced = true;
+		return 0;
+	}
+
 	tmio_mmc_clk_enable(host);
-	tmio_mmc_reset(host);
+	tmio_mmc_hw_reset(host->mmc);
 
 	if (host->clk_cache)
 		host->set_clock(host, host->clk_cache);
@@ -1269,7 +1350,8 @@ int tmio_mmc_host_runtime_resume(struct device *dev)
 
 	tmio_mmc_enable_dma(host, true);
 
-	mmc_retune_needed(host->mmc);
+	if (tmio_mmc_can_retune(host) && host->select_tuning(host))
+		dev_warn(&host->pdev->dev, "Tuning selection failed\n");
 
 	return 0;
 }
diff --git a/drivers/mmc/host/uniphier-sd.c b/drivers/mmc/host/uniphier-sd.c
index 196e94bf3..0c72ec554 100644
--- a/drivers/mmc/host/uniphier-sd.c
+++ b/drivers/mmc/host/uniphier-sd.c
@@ -59,6 +59,7 @@
 struct uniphier_sd_priv {
 	struct tmio_mmc_data tmio_data;
 	struct pinctrl *pinctrl;
+	struct pinctrl_state *pinstate_default;
 	struct pinctrl_state *pinstate_uhs;
 	struct clk *clk;
 	struct reset_control *rst;
@@ -409,9 +410,8 @@ static void uniphier_sd_clk_disable(struct tmio_mmc_host *host)
 	clk_disable_unprepare(priv->clk);
 }
 
-static void uniphier_sd_hw_reset(struct mmc_host *mmc)
+static void uniphier_sd_hw_reset(struct tmio_mmc_host *host)
 {
-	struct tmio_mmc_host *host = mmc_priv(mmc);
 	struct uniphier_sd_priv *priv = uniphier_sd_priv(host);
 
 	reset_control_assert(priv->rst_hw);
@@ -500,12 +500,13 @@ static int uniphier_sd_start_signal_voltage_switch(struct mmc_host *mmc,
 {
 	struct tmio_mmc_host *host = mmc_priv(mmc);
 	struct uniphier_sd_priv *priv = uniphier_sd_priv(host);
-	struct pinctrl_state *pinstate = NULL;
+	struct pinctrl_state *pinstate;
 	u32 val, tmp;
 
 	switch (ios->signal_voltage) {
 	case MMC_SIGNAL_VOLTAGE_330:
 		val = UNIPHIER_SD_VOLT_330;
+		pinstate = priv->pinstate_default;
 		break;
 	case MMC_SIGNAL_VOLTAGE_180:
 		val = UNIPHIER_SD_VOLT_180;
@@ -520,10 +521,7 @@ static int uniphier_sd_start_signal_voltage_switch(struct mmc_host *mmc,
 	tmp |= FIELD_PREP(UNIPHIER_SD_VOLT_MASK, val);
 	writel(tmp, host->ctl + UNIPHIER_SD_VOLT);
 
-	if (pinstate)
-		pinctrl_select_state(priv->pinctrl, pinstate);
-	else
-		pinctrl_select_default_state(mmc_dev(mmc));
+	pinctrl_select_state(priv->pinctrl, pinstate);
 
 	return 0;
 }
@@ -535,6 +533,11 @@ static int uniphier_sd_uhs_init(struct tmio_mmc_host *host,
 	if (IS_ERR(priv->pinctrl))
 		return PTR_ERR(priv->pinctrl);
 
+	priv->pinstate_default = pinctrl_lookup_state(priv->pinctrl,
+						      PINCTRL_STATE_DEFAULT);
+	if (IS_ERR(priv->pinstate_default))
+		return PTR_ERR(priv->pinstate_default);
+
 	priv->pinstate_uhs = pinctrl_lookup_state(priv->pinctrl, "uhs");
 	if (IS_ERR(priv->pinstate_uhs))
 		return PTR_ERR(priv->pinstate_uhs);
@@ -598,7 +601,7 @@ static int uniphier_sd_probe(struct platform_device *pdev)
 			ret = PTR_ERR(priv->rst_hw);
 			goto free_host;
 		}
-		host->ops.hw_reset = uniphier_sd_hw_reset;
+		host->hw_reset = uniphier_sd_hw_reset;
 	}
 
 	if (host->mmc->caps & MMC_CAP_UHS) {
@@ -611,6 +614,11 @@ static int uniphier_sd_probe(struct platform_device *pdev)
 		}
 	}
 
+	ret = devm_request_irq(dev, irq, tmio_mmc_irq, IRQF_SHARED,
+			       dev_name(dev), host);
+	if (ret)
+		goto free_host;
+
 	if (priv->caps & UNIPHIER_SD_CAP_EXTENDED_IP)
 		host->dma_ops = &uniphier_sd_internal_dma_ops;
 	else
@@ -636,19 +644,10 @@ static int uniphier_sd_probe(struct platform_device *pdev)
 
 	ret = tmio_mmc_host_probe(host);
 	if (ret)
-		goto disable_clk;
-
-	ret = devm_request_irq(dev, irq, tmio_mmc_irq, IRQF_SHARED,
-			       dev_name(dev), host);
-	if (ret)
-		goto remove_host;
+		goto free_host;
 
 	return 0;
 
-remove_host:
-	tmio_mmc_host_remove(host);
-disable_clk:
-	uniphier_sd_clk_disable(host);
 free_host:
 	tmio_mmc_host_free(host);
 
@@ -661,7 +660,6 @@ static int uniphier_sd_remove(struct platform_device *pdev)
 
 	tmio_mmc_host_remove(host);
 	uniphier_sd_clk_disable(host);
-	tmio_mmc_host_free(host);
 
 	return 0;
 }
@@ -688,7 +686,6 @@ static struct platform_driver uniphier_sd_driver = {
 	.remove = uniphier_sd_remove,
 	.driver = {
 		.name = "uniphier-sd",
-		.probe_type = PROBE_PREFER_ASYNCHRONOUS,
 		.of_match_table = uniphier_sd_match,
 	},
 };
diff --git a/drivers/mtd/nand/raw/gpmi-nand/bch-regs.h b/drivers/mtd/nand/raw/gpmi-nand/bch-regs.h
index a22b8a506..1b05476e8 100644
--- a/drivers/mtd/nand/raw/gpmi-nand/bch-regs.h
+++ b/drivers/mtd/nand/raw/gpmi-nand/bch-regs.h
@@ -41,7 +41,7 @@
 #define MX6Q_BP_BCH_FLASH0LAYOUT0_ECC0		11
 #define MX6Q_BM_BCH_FLASH0LAYOUT0_ECC0	(0x1f << MX6Q_BP_BCH_FLASH0LAYOUT0_ECC0)
 #define BF_BCH_FLASH0LAYOUT0_ECC0(v, x)				\
-	(GPMI_IS_MX6(x)					\
+	((GPMI_IS_MX6(x) || GPMI_IS_MX8(x))			\
 		? (((v) << MX6Q_BP_BCH_FLASH0LAYOUT0_ECC0)	\
 			& MX6Q_BM_BCH_FLASH0LAYOUT0_ECC0)	\
 		: (((v) << BP_BCH_FLASH0LAYOUT0_ECC0)		\
@@ -52,7 +52,7 @@
 #define MX6Q_BM_BCH_FLASH0LAYOUT0_GF_13_14			\
 				(0x1 << MX6Q_BP_BCH_FLASH0LAYOUT0_GF_13_14)
 #define BF_BCH_FLASH0LAYOUT0_GF(v, x)				\
-	((GPMI_IS_MX6(x) && ((v) == 14))			\
+	(((GPMI_IS_MX6(x) || GPMI_IS_MX8(x)) && ((v) == 14))	\
 		? (((1) << MX6Q_BP_BCH_FLASH0LAYOUT0_GF_13_14)	\
 			& MX6Q_BM_BCH_FLASH0LAYOUT0_GF_13_14)	\
 		: 0						\
@@ -64,7 +64,7 @@
 #define MX6Q_BM_BCH_FLASH0LAYOUT0_DATA0_SIZE	\
 			(0x3ff << BP_BCH_FLASH0LAYOUT0_DATA0_SIZE)
 #define BF_BCH_FLASH0LAYOUT0_DATA0_SIZE(v, x)				\
-	(GPMI_IS_MX6(x)						\
+	((GPMI_IS_MX6(x) || GPMI_IS_MX8(x))				\
 		? (((v) >> 2) & MX6Q_BM_BCH_FLASH0LAYOUT0_DATA0_SIZE)	\
 		: ((v) & BM_BCH_FLASH0LAYOUT0_DATA0_SIZE)		\
 	)
@@ -83,7 +83,7 @@
 #define MX6Q_BP_BCH_FLASH0LAYOUT1_ECCN		11
 #define MX6Q_BM_BCH_FLASH0LAYOUT1_ECCN	(0x1f << MX6Q_BP_BCH_FLASH0LAYOUT1_ECCN)
 #define BF_BCH_FLASH0LAYOUT1_ECCN(v, x)				\
-	(GPMI_IS_MX6(x)					\
+	((GPMI_IS_MX6(x) || GPMI_IS_MX8(x))			\
 		? (((v) << MX6Q_BP_BCH_FLASH0LAYOUT1_ECCN)	\
 			& MX6Q_BM_BCH_FLASH0LAYOUT1_ECCN)	\
 		: (((v) << BP_BCH_FLASH0LAYOUT1_ECCN)		\
@@ -94,7 +94,7 @@
 #define MX6Q_BM_BCH_FLASH0LAYOUT1_GF_13_14			\
 				(0x1 << MX6Q_BP_BCH_FLASH0LAYOUT1_GF_13_14)
 #define BF_BCH_FLASH0LAYOUT1_GF(v, x)				\
-	((GPMI_IS_MX6(x) && ((v) == 14))			\
+	(((GPMI_IS_MX6(x) || GPMI_IS_MX8(x)) && ((v) == 14))	\
 		? (((1) << MX6Q_BP_BCH_FLASH0LAYOUT1_GF_13_14)	\
 			& MX6Q_BM_BCH_FLASH0LAYOUT1_GF_13_14)	\
 		: 0						\
@@ -106,7 +106,7 @@
 #define MX6Q_BM_BCH_FLASH0LAYOUT1_DATAN_SIZE	\
 			(0x3ff << BP_BCH_FLASH0LAYOUT1_DATAN_SIZE)
 #define BF_BCH_FLASH0LAYOUT1_DATAN_SIZE(v, x)				\
-	(GPMI_IS_MX6(x)						\
+	((GPMI_IS_MX6(x) || GPMI_IS_MX8(x))				\
 		? (((v) >> 2) & MX6Q_BM_BCH_FLASH0LAYOUT1_DATAN_SIZE)	\
 		: ((v) & BM_BCH_FLASH0LAYOUT1_DATAN_SIZE)		\
 	)
diff --git a/drivers/mtd/nand/raw/gpmi-nand/gpmi-nand.c b/drivers/mtd/nand/raw/gpmi-nand/gpmi-nand.c
index a6658567d..8d00adedc 100644
--- a/drivers/mtd/nand/raw/gpmi-nand/gpmi-nand.c
+++ b/drivers/mtd/nand/raw/gpmi-nand/gpmi-nand.c
@@ -1,4 +1,4 @@
-// SPDX-License-Identifier: GPL-2.0+
+// SPDX-License-Identifier: GPL- .0+
 /*
  * Freescale GPMI NAND Flash Driver
  *
@@ -14,12 +14,18 @@
 #include <linux/mtd/partitions.h>
 #include <linux/of.h>
 #include <linux/of_device.h>
+#include <linux/busfreq-imx.h>
 #include <linux/pm_runtime.h>
+#include <linux/debugfs.h>
+#include <linux/pinctrl/consumer.h>
 #include <linux/dma/mxs-dma.h>
 #include "gpmi-nand.h"
 #include "gpmi-regs.h"
 #include "bch-regs.h"
 
+/* export the bch geometry to dbgfs */
+static struct debugfs_blob_wrapper dbg_bch_geo;
+
 /* Resource names for the GPMI NAND driver. */
 #define GPMI_NAND_GPMI_REGS_ADDR_RES_NAME  "gpmi-nand"
 #define GPMI_NAND_BCH_REGS_ADDR_RES_NAME   "bch"
@@ -112,7 +118,7 @@ static int gpmi_reset_block(void __iomem *reset_addr, bool just_enable)
 	return 0;
 
 error:
-	pr_err("%s(%p): module reset timeout\n", __func__, reset_addr);
+	pr_err("%s(%px): module reset timeout\n", __func__, reset_addr);
 	return -ETIMEDOUT;
 }
 
@@ -146,7 +152,7 @@ static int __gpmi_enable_clk(struct gpmi_nand_data *this, bool v)
 static int gpmi_init(struct gpmi_nand_data *this)
 {
 	struct resources *r = &this->resources;
-	int ret;
+	int ret = 0;
 
 	ret = pm_runtime_get_sync(this->dev);
 	if (ret < 0) {
@@ -181,9 +187,11 @@ static int gpmi_init(struct gpmi_nand_data *this)
 
 	/*
 	 * Decouple the chip select from dma channel. We use dma0 for all
-	 * the chips.
+	 * the chips, force all NAND RDY_BUSY inputs to be sourced from
+	 * RDY_BUSY0.
 	 */
-	writel(BM_GPMI_CTRL1_DECOUPLE_CS, r->gpmi_regs + HW_GPMI_CTRL1_SET);
+	writel(BM_GPMI_CTRL1_DECOUPLE_CS | BM_GPMI_CTRL1_GANGED_RDYBUSY,
+	       r->gpmi_regs + HW_GPMI_CTRL1_SET);
 
 err_out:
 	pm_runtime_mark_last_busy(this->dev);
@@ -216,7 +224,8 @@ static void gpmi_dump_info(struct gpmi_nand_data *this)
 		"ECC Strength           : %u\n"
 		"Page Size in Bytes     : %u\n"
 		"Metadata Size in Bytes : %u\n"
-		"ECC Chunk Size in Bytes: %u\n"
+		"ECC Chunk0 Size in Bytes: %u\n"
+		"ECC Chunkn Size in Bytes: %u\n"
 		"ECC Chunk Count        : %u\n"
 		"Payload Size in Bytes  : %u\n"
 		"Auxiliary Size in Bytes: %u\n"
@@ -227,7 +236,8 @@ static void gpmi_dump_info(struct gpmi_nand_data *this)
 		geo->ecc_strength,
 		geo->page_size,
 		geo->metadata_size,
-		geo->ecc_chunk_size,
+		geo->ecc_chunk0_size,
+		geo->ecc_chunkn_size,
 		geo->ecc_chunk_count,
 		geo->payload_size,
 		geo->auxiliary_size,
@@ -249,6 +259,37 @@ static inline bool gpmi_check_ecc(struct gpmi_nand_data *this)
 	return geo->ecc_strength <= this->devdata->bch_max_ecc_strength;
 }
 
+static inline bool bbm_in_data_chunk(struct gpmi_nand_data *this,
+			unsigned int *chunk_num)
+{
+	struct bch_geometry *geo = &this->bch_geometry;
+	struct nand_chip *chip = &this->nand;
+	struct mtd_info *mtd = nand_to_mtd(chip);
+	unsigned int i, j;
+
+	if (geo->ecc_chunk0_size != geo->ecc_chunkn_size) {
+		dev_err(this->dev, "The size of chunk0 must equal to chunkn\n");
+		return false;
+	}
+
+	i = (mtd->writesize * 8 - geo->metadata_size * 8) /
+		(geo->gf_len * geo->ecc_strength +
+			geo->ecc_chunkn_size * 8);
+
+	j = (mtd->writesize * 8 - geo->metadata_size * 8) -
+		(geo->gf_len * geo->ecc_strength +
+			geo->ecc_chunkn_size * 8) * i;
+
+	if (j < geo->ecc_chunkn_size * 8) {
+		*chunk_num = i+1;
+		dev_dbg(this->dev, "Set ecc to %d and bbm in chunk %d\n",
+				geo->ecc_strength, *chunk_num);
+		return true;
+	}
+
+	return false;
+}
+
 /*
  * If we can get the ECC information from the nand chip, we do not
  * need to calculate them ourselves.
@@ -278,13 +319,14 @@ static int set_geometry_by_ecc_info(struct gpmi_nand_data *this,
 			nanddev_get_ecc_requirements(&chip->base)->step_size);
 		return -EINVAL;
 	}
-	geo->ecc_chunk_size = ecc_step;
+	geo->ecc_chunk0_size = ecc_step;
+	geo->ecc_chunkn_size = ecc_step;
 	geo->ecc_strength = round_up(ecc_strength, 2);
 	if (!gpmi_check_ecc(this))
 		return -EINVAL;
 
 	/* Keep the C >= O */
-	if (geo->ecc_chunk_size < mtd->oobsize) {
+	if (geo->ecc_chunkn_size < mtd->oobsize) {
 		dev_err(this->dev,
 			"unsupported nand chip. ecc size: %d, oob size : %d\n",
 			ecc_step, mtd->oobsize);
@@ -294,7 +336,7 @@ static int set_geometry_by_ecc_info(struct gpmi_nand_data *this,
 	/* The default value, see comment in the legacy_set_geometry(). */
 	geo->metadata_size = 10;
 
-	geo->ecc_chunk_count = mtd->writesize / geo->ecc_chunk_size;
+	geo->ecc_chunk_count = mtd->writesize / geo->ecc_chunkn_size;
 
 	/*
 	 * Now, the NAND chip with 2K page(data chunk is 512byte) shows below:
@@ -397,6 +439,134 @@ static inline int get_ecc_strength(struct gpmi_nand_data *this)
 	return round_down(ecc_strength, 2);
 }
 
+static int set_geometry_for_large_oob(struct gpmi_nand_data *this)
+{
+	struct bch_geometry *geo = &this->bch_geometry;
+	struct nand_chip *chip = &this->nand;
+	struct mtd_info *mtd = nand_to_mtd(chip);
+	const struct nand_ecc_props *requirements =
+		nanddev_get_ecc_requirements(&chip->base);
+	unsigned int block_mark_bit_offset;
+	unsigned int max_ecc;
+	unsigned int bbm_chunk;
+	unsigned int i;
+
+	/* sanity check for the minimum ecc nand required */
+	if (!(requirements->strength > 0 &&
+	      requirements->step_size > 0))
+		return -EINVAL;
+	geo->ecc_strength = requirements->strength;
+
+	/* check if platform can support this nand */
+	if (!gpmi_check_ecc(this)) {
+		dev_err(this->dev,
+				"unsupported NAND chip,\
+				minimum ecc required %d\n"
+				, geo->ecc_strength);
+		return -EINVAL;
+	}
+
+	/* calculate the maximum ecc platform can support*/
+	geo->metadata_size = 10;
+	geo->gf_len = 14;
+	geo->ecc_chunk0_size = 1024;
+	geo->ecc_chunkn_size = 1024;
+	geo->ecc_chunk_count = mtd->writesize / geo->ecc_chunkn_size;
+	max_ecc = min(get_ecc_strength(this),
+			this->devdata->bch_max_ecc_strength);
+
+	/* search a supported ecc strength that makes bbm */
+	/* located in data chunk  */
+	geo->ecc_strength = requirements->strength;
+	while (!(geo->ecc_strength > max_ecc)) {
+		if (bbm_in_data_chunk(this, &bbm_chunk))
+			goto geo_setting;
+		geo->ecc_strength += 2;
+	}
+
+	/* if none of them works, keep using the minimum ecc */
+	/* nand required but changing ecc page layout  */
+	geo->ecc_strength = requirements->strength;
+	/* add extra ecc for meta data */
+	geo->ecc_chunk0_size = 0;
+	geo->ecc_chunk_count = (mtd->writesize / geo->ecc_chunkn_size) + 1;
+	geo->ecc_for_meta = 1;
+	/* check if oob can afford this extra ecc chunk */
+	if (mtd->oobsize * 8 < geo->metadata_size * 8 +
+			geo->gf_len * geo->ecc_strength
+			* geo->ecc_chunk_count) {
+		dev_err(this->dev, "unsupported NAND chip with new layout\n");
+		return -EINVAL;
+	}
+
+	/* calculate in which chunk bbm located */
+	bbm_chunk = (mtd->writesize * 8 - geo->metadata_size * 8 -
+		geo->gf_len * geo->ecc_strength) /
+		(geo->gf_len * geo->ecc_strength +
+				geo->ecc_chunkn_size * 8) + 1;
+
+geo_setting:
+
+	geo->page_size = mtd->writesize + geo->metadata_size +
+		(geo->gf_len * geo->ecc_strength * geo->ecc_chunk_count) / 8;
+	geo->payload_size = mtd->writesize;
+
+	/*
+	 * The auxiliary buffer contains the metadata and the ECC status. The
+	 * metadata is padded to the nearest 32-bit boundary. The ECC status
+	 * contains one byte for every ECC chunk, and is also padded to the
+	 * nearest 32-bit boundary.
+	 */
+	geo->auxiliary_status_offset = ALIGN(geo->metadata_size, 4);
+	geo->auxiliary_size = ALIGN(geo->metadata_size, 4)
+				+ ALIGN(geo->ecc_chunk_count, 4);
+
+	if (!this->swap_block_mark)
+		return 0;
+
+	/* calculate the number of ecc chunk behind the bbm */
+	i = (mtd->writesize / geo->ecc_chunkn_size) - bbm_chunk + 1;
+
+	block_mark_bit_offset = mtd->writesize * 8 -
+		(geo->ecc_strength * geo->gf_len * (geo->ecc_chunk_count - i)
+				+ geo->metadata_size * 8);
+
+	geo->block_mark_byte_offset = block_mark_bit_offset / 8;
+	geo->block_mark_bit_offset  = block_mark_bit_offset % 8;
+
+	dev_dbg(this->dev, "BCH Geometry :\n"
+		"GF length              : %u\n"
+		"ECC Strength           : %u\n"
+		"Page Size in Bytes     : %u\n"
+		"Metadata Size in Bytes : %u\n"
+		"ECC Chunk0 Size in Bytes: %u\n"
+		"ECC Chunkn Size in Bytes: %u\n"
+		"ECC Chunk Count        : %u\n"
+		"Payload Size in Bytes  : %u\n"
+		"Auxiliary Size in Bytes: %u\n"
+		"Auxiliary Status Offset: %u\n"
+		"Block Mark Byte Offset : %u\n"
+		"Block Mark Bit Offset  : %u\n"
+		"Block Mark in chunk	: %u\n"
+		"Ecc for Meta data	: %u\n",
+		geo->gf_len,
+		geo->ecc_strength,
+		geo->page_size,
+		geo->metadata_size,
+		geo->ecc_chunk0_size,
+		geo->ecc_chunkn_size,
+		geo->ecc_chunk_count,
+		geo->payload_size,
+		geo->auxiliary_size,
+		geo->auxiliary_status_offset,
+		geo->block_mark_byte_offset,
+		geo->block_mark_bit_offset,
+		bbm_chunk,
+		geo->ecc_for_meta);
+
+	return 0;
+}
+
 static int legacy_set_geometry(struct gpmi_nand_data *this)
 {
 	struct bch_geometry *geo = &this->bch_geometry;
@@ -416,13 +586,15 @@ static int legacy_set_geometry(struct gpmi_nand_data *this)
 	geo->gf_len = 13;
 
 	/* The default for chunk size. */
-	geo->ecc_chunk_size = 512;
-	while (geo->ecc_chunk_size < mtd->oobsize) {
-		geo->ecc_chunk_size *= 2; /* keep C >= O */
+	geo->ecc_chunk0_size = 512;
+	geo->ecc_chunkn_size = 512;
+	while (geo->ecc_chunkn_size < mtd->oobsize) {
+		geo->ecc_chunk0_size *= 2; /* keep C >= O */
+		geo->ecc_chunkn_size *= 2; /* keep C >= O */
 		geo->gf_len = 14;
 	}
 
-	geo->ecc_chunk_count = mtd->writesize / geo->ecc_chunk_size;
+	geo->ecc_chunk_count = mtd->writesize / geo->ecc_chunkn_size;
 
 	/* We use the same ECC strength for all chunks. */
 	geo->ecc_strength = get_ecc_strength(this);
@@ -512,12 +684,19 @@ static int legacy_set_geometry(struct gpmi_nand_data *this)
 static int common_nfc_set_geometry(struct gpmi_nand_data *this)
 {
 	struct nand_chip *chip = &this->nand;
+	struct mtd_info *mtd = nand_to_mtd(&this->nand);
 	const struct nand_ecc_props *requirements =
 		nanddev_get_ecc_requirements(&chip->base);
 
-	if (chip->ecc.strength > 0 && chip->ecc.size > 0)
-		return set_geometry_by_ecc_info(this, chip->ecc.strength,
-						chip->ecc.size);
+	if (requirements->strength > 0 && requirements->step_size > 0) {
+		if (mtd->oobsize > 1024
+		    || requirements->step_size < mtd->oobsize)
+			return set_geometry_for_large_oob(this);
+		else
+			return set_geometry_by_ecc_info(this,
+						requirements->strength,
+						requirements->step_size);
+	}
 
 	if ((of_property_read_bool(this->dev->of_node, "fsl,use-minimum-ecc"))
 				|| legacy_set_geometry(this)) {
@@ -532,11 +711,40 @@ static int common_nfc_set_geometry(struct gpmi_nand_data *this)
 	return 0;
 }
 
+int bch_create_debugfs(struct gpmi_nand_data *this)
+{
+	struct bch_geometry *bch_geo = &this->bch_geometry;
+	struct dentry *dbg_root;
+
+	dbg_root = debugfs_create_dir("gpmi-nand", NULL);
+	if (!dbg_root) {
+		dev_err(this->dev, "failed to create debug directory\n");
+		return -EINVAL;
+	}
+
+	dbg_bch_geo.data = (void *)bch_geo;
+	dbg_bch_geo.size = sizeof(struct bch_geometry);
+	if (!debugfs_create_blob("bch_geometry", S_IRUGO,
+				dbg_root, &dbg_bch_geo)) {
+		dev_err(this->dev, "failed to create debug bch geometry\n");
+		return -EINVAL;
+	}
+
+	/* create raw mode flag */
+	if (!debugfs_create_file("raw_mode", S_IRUGO,
+				dbg_root, NULL, NULL)) {
+		dev_err(this->dev, "failed to create raw mode flag\n");
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
 /* Configures the geometry for BCH.  */
 static int bch_set_geometry(struct gpmi_nand_data *this)
 {
 	struct resources *r = &this->resources;
-	int ret;
+	int ret = 0;
 
 	ret = common_nfc_set_geometry(this);
 	if (ret)
@@ -560,7 +768,6 @@ static int bch_set_geometry(struct gpmi_nand_data *this)
 	/* Set *all* chip selects to use layout 0. */
 	writel(0, r->bch_regs + HW_BCH_LAYOUTSELECT);
 
-	ret = 0;
 err_out:
 	pm_runtime_mark_last_busy(this->dev);
 	pm_runtime_put_autosuspend(this->dev);
@@ -725,6 +932,9 @@ static int gpmi_nfc_apply_timings(struct gpmi_nand_data *this)
 	 */
 	if (GPMI_IS_MX6Q(this) || GPMI_IS_MX6SX(this))
 		clk_disable_unprepare(r->clock[0]);
+	
+	if (GPMI_IS_MX6SX(this) && hw->clk_rate > 88000000)
+		hw->clk_rate = 88000000;
 
 	ret = clk_set_rate(r->clock[0], hw->clk_rate);
 	if (ret) {
@@ -771,7 +981,7 @@ static int gpmi_setup_interface(struct nand_chip *chip, int chipnr,
 		return PTR_ERR(sdr);
 
 	/* Only MX6 GPMI controller can reach EDO timings */
-	if (sdr->tRC_min <= 25000 && !GPMI_IS_MX6(this))
+	if (sdr->tRC_min <= 25000 && !(GPMI_IS_MX6(this) || GPMI_IS_MX8(this)))
 		return -ENOTSUPP;
 
 	/* Stop here if this call was just a check */
@@ -824,7 +1034,7 @@ static int gpmi_raw_len_to_len(struct gpmi_nand_data *this, int raw_len)
 	 * we are passed in exec_op. Calculate the data length from it.
 	 */
 	if (this->bch)
-		return ALIGN_DOWN(raw_len, this->bch_geometry.ecc_chunk_size);
+		return ALIGN_DOWN(raw_len, this->bch_geometry.ecc_chunkn_size);
 	else
 		return raw_len;
 }
@@ -944,6 +1154,14 @@ static const struct gpmi_devdata gpmi_devdata_imx6q = {
 	.clks_count = ARRAY_SIZE(gpmi_clks_for_mx6),
 };
 
+static const struct gpmi_devdata gpmi_devdata_imx6qp = {
+	.type = IS_MX6QP,
+	.bch_max_ecc_strength = 40,
+	.max_chain_delay = 12000,
+	.clks = gpmi_clks_for_mx6,
+	.clks_count = ARRAY_SIZE(gpmi_clks_for_mx6),
+};
+
 static const struct gpmi_devdata gpmi_devdata_imx6sx = {
 	.type = IS_MX6SX,
 	.bch_max_ecc_strength = 62,
@@ -952,6 +1170,22 @@ static const struct gpmi_devdata gpmi_devdata_imx6sx = {
 	.clks_count = ARRAY_SIZE(gpmi_clks_for_mx6),
 };
 
+static const struct gpmi_devdata gpmi_devdata_imx6ul = {
+	.type = IS_MX6UL,
+	.bch_max_ecc_strength = 40,
+	.max_chain_delay = 12000,
+	.clks = gpmi_clks_for_mx6,
+	.clks_count = ARRAY_SIZE(gpmi_clks_for_mx6),
+};
+
+static const struct gpmi_devdata gpmi_devdata_imx6ull = {
+	.type = IS_MX6ULL,
+	.bch_max_ecc_strength = 40,
+	.max_chain_delay = 12000,
+	.clks = gpmi_clks_for_mx6,
+	.clks_count = ARRAY_SIZE(gpmi_clks_for_mx6),
+};
+
 static const char * const gpmi_clks_for_mx7d[] = {
 	"gpmi_io", "gpmi_bch_apb",
 };
@@ -963,6 +1197,17 @@ static const struct gpmi_devdata gpmi_devdata_imx7d = {
 	.clks = gpmi_clks_for_mx7d,
 	.clks_count = ARRAY_SIZE(gpmi_clks_for_mx7d),
 };
+static const char * gpmi_clks_for_mx8qxp[GPMI_CLK_MAX] = {
+	"gpmi_clk", "gpmi_apb_clk", "bch_clk", "bch_apb_clk",
+};
+
+static const struct gpmi_devdata gpmi_devdata_imx8qxp = {
+	.type = IS_MX8QXP,
+	.bch_max_ecc_strength = 62,
+	.max_chain_delay = 12000,
+	.clks = gpmi_clks_for_mx8qxp,
+	.clks_count = ARRAY_SIZE(gpmi_clks_for_mx8qxp),
+};
 
 static int acquire_register_block(struct gpmi_nand_data *this,
 				  const char *res_name)
@@ -1075,10 +1320,6 @@ static int acquire_resources(struct gpmi_nand_data *this)
 	if (ret)
 		goto exit_regs;
 
-	ret = acquire_dma_channels(this);
-	if (ret)
-		goto exit_regs;
-
 	ret = gpmi_get_clks(this);
 	if (ret)
 		goto exit_clock;
@@ -1221,7 +1462,7 @@ static int gpmi_count_bitflips(struct nand_chip *chip, void *buf, int first,
 
 			/* Read ECC bytes into our internal raw_buffer */
 			offset = nfc_geo->metadata_size * 8;
-			offset += ((8 * nfc_geo->ecc_chunk_size) + eccbits) * (i + 1);
+			offset += ((8 * nfc_geo->ecc_chunkn_size) + eccbits) * (i + 1);
 			offset -= eccbits;
 			bitoffset = offset % 8;
 			eccbytes = DIV_ROUND_UP(offset + eccbits, 8);
@@ -1258,16 +1499,16 @@ static int gpmi_count_bitflips(struct nand_chip *chip, void *buf, int first,
 			if (i == 0) {
 				/* The first block includes metadata */
 				flips = nand_check_erased_ecc_chunk(
-						buf + i * nfc_geo->ecc_chunk_size,
-						nfc_geo->ecc_chunk_size,
+						buf + i * nfc_geo->ecc_chunkn_size,
+						nfc_geo->ecc_chunkn_size,
 						eccbuf, eccbytes,
 						this->auxiliary_virt,
 						nfc_geo->metadata_size,
 						nfc_geo->ecc_strength);
 			} else {
 				flips = nand_check_erased_ecc_chunk(
-						buf + i * nfc_geo->ecc_chunk_size,
-						nfc_geo->ecc_chunk_size,
+						buf + i * nfc_geo->ecc_chunkn_size,
+						nfc_geo->ecc_chunkn_size,
 						eccbuf, eccbytes,
 						NULL, 0,
 						nfc_geo->ecc_strength);
@@ -1296,20 +1537,21 @@ static void gpmi_bch_layout_std(struct gpmi_nand_data *this)
 	struct bch_geometry *geo = &this->bch_geometry;
 	unsigned int ecc_strength = geo->ecc_strength >> 1;
 	unsigned int gf_len = geo->gf_len;
-	unsigned int block_size = geo->ecc_chunk_size;
+	unsigned int block0_size = geo->ecc_chunk0_size;
+	unsigned int blockn_size = geo->ecc_chunkn_size;
 
 	this->bch_flashlayout0 =
 		BF_BCH_FLASH0LAYOUT0_NBLOCKS(geo->ecc_chunk_count - 1) |
 		BF_BCH_FLASH0LAYOUT0_META_SIZE(geo->metadata_size) |
 		BF_BCH_FLASH0LAYOUT0_ECC0(ecc_strength, this) |
 		BF_BCH_FLASH0LAYOUT0_GF(gf_len, this) |
-		BF_BCH_FLASH0LAYOUT0_DATA0_SIZE(block_size, this);
+		BF_BCH_FLASH0LAYOUT0_DATA0_SIZE(block0_size, this);
 
 	this->bch_flashlayout1 =
 		BF_BCH_FLASH0LAYOUT1_PAGE_SIZE(geo->page_size) |
 		BF_BCH_FLASH0LAYOUT1_ECCN(ecc_strength, this) |
 		BF_BCH_FLASH0LAYOUT1_GF(gf_len, this) |
-		BF_BCH_FLASH0LAYOUT1_DATAN_SIZE(block_size, this);
+		BF_BCH_FLASH0LAYOUT1_DATAN_SIZE(blockn_size, this);
 }
 
 static int gpmi_ecc_read_page(struct nand_chip *chip, uint8_t *buf,
@@ -1392,9 +1634,22 @@ static int gpmi_ecc_read_subpage(struct nand_chip *chip, uint32_t offs,
 		}
 	}
 
+	/*
+	 * if there is an ECC dedicate for meta:
+	 * - need to add an extra ECC size when calculating col and page_size,
+	 *   if the meta size is NOT zero.
+	 * - chunk0 size need to set to the same size as other chunks,
+	 *   if the meta size is zero.
+	 */
+
 	meta = geo->metadata_size;
 	if (first) {
-		col = meta + (size + ecc_parity_size) * first;
+		if (geo->ecc_for_meta)
+			col = meta + ecc_parity_size
+				+ (size + ecc_parity_size) * first;
+		else
+			col = meta + (size + ecc_parity_size) * first;
+
 		meta = 0;
 		buf = buf + first * size;
 	}
@@ -1402,19 +1657,27 @@ static int gpmi_ecc_read_subpage(struct nand_chip *chip, uint32_t offs,
 	ecc_parity_size = geo->gf_len * geo->ecc_strength / 8;
 
 	n = last - first + 1;
-	page_size = meta + (size + ecc_parity_size) * n;
+
+	if (geo->ecc_for_meta && meta)
+		page_size = meta + ecc_parity_size
+			+ (size + ecc_parity_size) * n;
+	else
+		page_size = meta + (size + ecc_parity_size) * n;
+
 	ecc_strength = geo->ecc_strength >> 1;
 
-	this->bch_flashlayout0 = BF_BCH_FLASH0LAYOUT0_NBLOCKS(n - 1) |
+	this->bch_flashlayout0 = BF_BCH_FLASH0LAYOUT0_NBLOCKS(
+		(geo->ecc_for_meta ? n: n - 1)) |
 		BF_BCH_FLASH0LAYOUT0_META_SIZE(meta) |
 		BF_BCH_FLASH0LAYOUT0_ECC0(ecc_strength, this) |
 		BF_BCH_FLASH0LAYOUT0_GF(geo->gf_len, this) |
-		BF_BCH_FLASH0LAYOUT0_DATA0_SIZE(geo->ecc_chunk_size, this);
+		BF_BCH_FLASH0LAYOUT0_DATA0_SIZE((geo->ecc_for_meta ?
+		0: geo->ecc_chunk0_size), this);
 
 	this->bch_flashlayout1 = BF_BCH_FLASH0LAYOUT1_PAGE_SIZE(page_size) |
 		BF_BCH_FLASH0LAYOUT1_ECCN(ecc_strength, this) |
 		BF_BCH_FLASH0LAYOUT1_GF(geo->gf_len, this) |
-		BF_BCH_FLASH0LAYOUT1_DATAN_SIZE(geo->ecc_chunk_size, this);
+		BF_BCH_FLASH0LAYOUT1_DATAN_SIZE(geo->ecc_chunkn_size, this);
 
 	this->bch = true;
 
@@ -1586,7 +1849,7 @@ static int gpmi_ecc_read_page_raw(struct nand_chip *chip, uint8_t *buf,
 	struct mtd_info *mtd = nand_to_mtd(chip);
 	struct gpmi_nand_data *this = nand_get_controller_data(chip);
 	struct bch_geometry *nfc_geo = &this->bch_geometry;
-	int eccsize = nfc_geo->ecc_chunk_size;
+	int eccsize = nfc_geo->ecc_chunkn_size;
 	int eccbits = nfc_geo->ecc_strength * nfc_geo->gf_len;
 	u8 *tmp_buf = this->raw_buffer;
 	size_t src_bit_off;
@@ -1671,7 +1934,7 @@ static int gpmi_ecc_write_page_raw(struct nand_chip *chip, const uint8_t *buf,
 	struct mtd_info *mtd = nand_to_mtd(chip);
 	struct gpmi_nand_data *this = nand_get_controller_data(chip);
 	struct bch_geometry *nfc_geo = &this->bch_geometry;
-	int eccsize = nfc_geo->ecc_chunk_size;
+	int eccsize = nfc_geo->ecc_chunkn_size;
 	int eccbits = nfc_geo->ecc_strength * nfc_geo->gf_len;
 	u8 *tmp_buf = this->raw_buffer;
 	uint8_t *oob = chip->oob_poi;
@@ -1963,7 +2226,7 @@ static int mx23_boot_init(struct gpmi_nand_data  *this)
 		 */
 		chipnr = block >> (chip->chip_shift - chip->phys_erase_shift);
 		page = block << (chip->phys_erase_shift - chip->page_shift);
-		byte = block <<  chip->phys_erase_shift;
+		byte = (loff_t)block <<  chip->phys_erase_shift;
 
 		/* Send the command to read the conventional block mark. */
 		nand_select_target(chip, chipnr);
@@ -2035,6 +2298,11 @@ static int gpmi_init_last(struct gpmi_nand_data *this)
 	if (ret)
 		return ret;
 
+	/* Save the geometry to debugfs*/
+	ret = bch_create_debugfs(this);
+	if (ret)
+		return ret;
+
 	/* Init the nand_ecc_ctrl{} */
 	ecc->read_page	= gpmi_ecc_read_page;
 	ecc->write_page	= gpmi_ecc_write_page;
@@ -2045,7 +2313,7 @@ static int gpmi_init_last(struct gpmi_nand_data *this)
 	ecc->read_oob_raw = gpmi_ecc_read_oob_raw;
 	ecc->write_oob_raw = gpmi_ecc_write_oob_raw;
 	ecc->engine_type = NAND_ECC_ENGINE_TYPE_ON_HOST;
-	ecc->size	= bch_geo->ecc_chunk_size;
+	ecc->size	= bch_geo->ecc_chunkn_size;
 	ecc->strength	= bch_geo->ecc_strength;
 	mtd_set_ooblayout(mtd, &gpmi_ooblayout_ops);
 
@@ -2054,7 +2322,7 @@ static int gpmi_init_last(struct gpmi_nand_data *this)
 	 *  (1) the chip is imx6, and
 	 *  (2) the size of the ECC parity is byte aligned.
 	 */
-	if (GPMI_IS_MX6(this) &&
+	if ((GPMI_IS_MX6(this) || GPMI_IS_MX8(this))  &&
 		((bch_geo->gf_len * bch_geo->ecc_strength) % 8) == 0) {
 		ecc->read_subpage = gpmi_ecc_read_subpage;
 		chip->options |= NAND_SUBPAGE_READ;
@@ -2342,11 +2610,11 @@ static int gpmi_nfc_exec_op(struct nand_chip *chip,
 						   &direct);
 			break;
 		}
+	}
 
-		if (!desc) {
-			ret = -ENXIO;
-			goto unmap;
-		}
+	if (!desc) {
+		ret = -ENXIO;
+		goto unmap;
 	}
 
 	dev_dbg(this->dev, "%s setup done\n", __func__);
@@ -2436,6 +2704,7 @@ static int gpmi_nand_init(struct gpmi_nand_data *this)
 {
 	struct nand_chip *chip = &this->nand;
 	struct mtd_info  *mtd = nand_to_mtd(chip);
+	u32 max_cs;
 	int ret;
 
 	/* init the MTD data structures */
@@ -2466,7 +2735,12 @@ static int gpmi_nand_init(struct gpmi_nand_data *this)
 	this->base.ops = &gpmi_nand_controller_ops;
 	chip->controller = &this->base;
 
-	ret = nand_scan(chip, GPMI_IS_MX6(this) ? 2 : 1);
+	max_cs = (GPMI_IS_MX6(this) || GPMI_IS_MX8(this)) ? 2 : 1;
+
+	/* override the max_cs if board has other limitations */
+	of_property_read_u32(this->pdev->dev.of_node, "fsl,max-nand-cs", &max_cs);
+
+	ret = nand_scan(chip, max_cs);
 	if (ret)
 		goto err_out;
 
@@ -2499,12 +2773,24 @@ static const struct of_device_id gpmi_nand_id_table[] = {
 	}, {
 		.compatible = "fsl,imx6q-gpmi-nand",
 		.data = &gpmi_devdata_imx6q,
+	}, {
+		.compatible = "fsl,imx6qp-gpmi-nand",
+		.data = &gpmi_devdata_imx6qp,
 	}, {
 		.compatible = "fsl,imx6sx-gpmi-nand",
 		.data = &gpmi_devdata_imx6sx,
 	}, {
 		.compatible = "fsl,imx7d-gpmi-nand",
 		.data = &gpmi_devdata_imx7d,
+	}, {
+		.compatible = "fsl,imx6ul-gpmi-nand",
+		.data = &gpmi_devdata_imx6ul,
+	}, {
+		.compatible = "fsl,imx6ull-gpmi-nand",
+		.data = &gpmi_devdata_imx6ull,
+	}, {
+		.compatible = "fsl,imx8qxp-gpmi-nand",
+		.data = &gpmi_devdata_imx8qxp,
 	}, {}
 };
 MODULE_DEVICE_TABLE(of, gpmi_nand_id_table);
@@ -2535,15 +2821,9 @@ static int gpmi_nand_probe(struct platform_device *pdev)
 	if (ret)
 		goto exit_acquire_resources;
 
-	ret = __gpmi_enable_clk(this, true);
-	if (ret)
-		goto exit_acquire_resources;
-
+	pm_runtime_enable(&pdev->dev);
 	pm_runtime_set_autosuspend_delay(&pdev->dev, 500);
 	pm_runtime_use_autosuspend(&pdev->dev);
-	pm_runtime_set_active(&pdev->dev);
-	pm_runtime_enable(&pdev->dev);
-	pm_runtime_get_sync(&pdev->dev);
 
 	ret = gpmi_init(this);
 	if (ret)
@@ -2553,15 +2833,12 @@ static int gpmi_nand_probe(struct platform_device *pdev)
 	if (ret)
 		goto exit_nfc_init;
 
-	pm_runtime_mark_last_busy(&pdev->dev);
-	pm_runtime_put_autosuspend(&pdev->dev);
-
 	dev_info(this->dev, "driver registered.\n");
 
 	return 0;
 
 exit_nfc_init:
-	pm_runtime_put(&pdev->dev);
+	pm_runtime_dont_use_autosuspend(&pdev->dev);
 	pm_runtime_disable(&pdev->dev);
 	release_resources(this);
 exit_acquire_resources:
@@ -2575,7 +2852,6 @@ static int gpmi_nand_remove(struct platform_device *pdev)
 	struct nand_chip *chip = &this->nand;
 	int ret;
 
-	pm_runtime_put_sync(&pdev->dev);
 	pm_runtime_disable(&pdev->dev);
 
 	ret = mtd_device_unregister(nand_to_mtd(chip));
@@ -2589,10 +2865,12 @@ static int gpmi_nand_remove(struct platform_device *pdev)
 #ifdef CONFIG_PM_SLEEP
 static int gpmi_pm_suspend(struct device *dev)
 {
-	struct gpmi_nand_data *this = dev_get_drvdata(dev);
+	int ret;
 
-	release_dma_channels(this);
-	return 0;
+	pinctrl_pm_select_sleep_state(dev);
+	ret = pm_runtime_force_suspend(dev);
+
+	return ret;
 }
 
 static int gpmi_pm_resume(struct device *dev)
@@ -2600,9 +2878,13 @@ static int gpmi_pm_resume(struct device *dev)
 	struct gpmi_nand_data *this = dev_get_drvdata(dev);
 	int ret;
 
-	ret = acquire_dma_channels(this);
-	if (ret < 0)
+	ret = pm_runtime_force_resume(dev);
+	if (ret) {
+		dev_err(this->dev, "Error in resume %d\n", ret);
 		return ret;
+	}
+
+	pinctrl_pm_select_default_state(dev);
 
 	/* re-init the GPMI registers */
 	ret = gpmi_init(this);
@@ -2622,22 +2904,44 @@ static int gpmi_pm_resume(struct device *dev)
 		return ret;
 	}
 
+	/* re-apply the timing setting */
+	this->hw.must_apply_timings = true;
+
 	return 0;
 }
 #endif /* CONFIG_PM_SLEEP */
 
-static int __maybe_unused gpmi_runtime_suspend(struct device *dev)
+#define gpmi_enable_clk(x)	__gpmi_enable_clk(x, true)
+#define gpmi_disable_clk(x)	__gpmi_enable_clk(x, false)
+
+static int gpmi_runtime_suspend(struct device *dev)
 {
 	struct gpmi_nand_data *this = dev_get_drvdata(dev);
 
-	return __gpmi_enable_clk(this, false);
+	gpmi_disable_clk(this);
+	release_bus_freq(BUS_FREQ_HIGH);
+	release_dma_channels(this);
+
+	return 0;
 }
 
-static int __maybe_unused gpmi_runtime_resume(struct device *dev)
+static int gpmi_runtime_resume(struct device *dev)
 {
 	struct gpmi_nand_data *this = dev_get_drvdata(dev);
+	int ret;
+
+	ret = gpmi_enable_clk(this);
+	if (ret)
+		return ret;
+
+	request_bus_freq(BUS_FREQ_HIGH);
+
+	ret = acquire_dma_channels(this);
+	if (ret < 0)
+		return ret;
+
+	return 0;
 
-	return __gpmi_enable_clk(this, true);
 }
 
 static const struct dev_pm_ops gpmi_pm_ops = {
diff --git a/drivers/mtd/nand/raw/gpmi-nand/gpmi-nand.h b/drivers/mtd/nand/raw/gpmi-nand/gpmi-nand.h
index fdc5ed7de..e876d02d9 100644
--- a/drivers/mtd/nand/raw/gpmi-nand/gpmi-nand.h
+++ b/drivers/mtd/nand/raw/gpmi-nand/gpmi-nand.h
@@ -30,9 +30,9 @@ struct resources {
  * @page_size:                The size, in bytes, of a physical page, including
  *                            both data and OOB.
  * @metadata_size:            The size, in bytes, of the metadata.
- * @ecc_chunk_size:           The size, in bytes, of a single ECC chunk. Note
- *                            the first chunk in the page includes both data and
- *                            metadata, so it's a bit larger than this value.
+ * @ecc_chunk0_size:          The size, in bytes, of a first ECC chunk.
+ * @ecc_chunkn_size:          The size, in bytes, of a single ECC chunk after
+ *                            the first chunk in the page.
  * @ecc_chunk_count:          The number of ECC chunks in the page,
  * @payload_size:             The size, in bytes, of the payload buffer.
  * @auxiliary_size:           The size, in bytes, of the auxiliary buffer.
@@ -42,19 +42,23 @@ struct resources {
  *                            which the underlying physical block mark appears.
  * @block_mark_bit_offset:    The bit offset into the ECC-based page view at
  *                            which the underlying physical block mark appears.
+ * @ecc_for_meta:             The flag to indicate if there is a dedicate ecc
+ *                            for meta.
  */
 struct bch_geometry {
 	unsigned int  gf_len;
 	unsigned int  ecc_strength;
 	unsigned int  page_size;
 	unsigned int  metadata_size;
-	unsigned int  ecc_chunk_size;
+	unsigned int  ecc_chunk0_size;
+	unsigned int  ecc_chunkn_size;
 	unsigned int  ecc_chunk_count;
 	unsigned int  payload_size;
 	unsigned int  auxiliary_size;
 	unsigned int  auxiliary_status_offset;
 	unsigned int  block_mark_byte_offset;
 	unsigned int  block_mark_bit_offset;
+	unsigned int  ecc_for_meta; /* ECC for meta data */
 };
 
 /**
@@ -72,8 +76,12 @@ enum gpmi_type {
 	IS_MX23,
 	IS_MX28,
 	IS_MX6Q,
+	IS_MX6QP,
 	IS_MX6SX,
 	IS_MX7D,
+	IS_MX6UL,
+	IS_MX6ULL,
+	IS_MX8QXP,
 };
 
 struct gpmi_devdata {
@@ -166,10 +174,16 @@ struct gpmi_nand_data {
 #define GPMI_IS_MX23(x)		((x)->devdata->type == IS_MX23)
 #define GPMI_IS_MX28(x)		((x)->devdata->type == IS_MX28)
 #define GPMI_IS_MX6Q(x)		((x)->devdata->type == IS_MX6Q)
+#define GPMI_IS_MX6QP(x)	((x)->devdata->type == IS_MX6QP)
 #define GPMI_IS_MX6SX(x)	((x)->devdata->type == IS_MX6SX)
 #define GPMI_IS_MX7D(x)		((x)->devdata->type == IS_MX7D)
+#define GPMI_IS_MX6UL(x)	((x)->devdata->type == IS_MX6UL)
+#define GPMI_IS_MX6ULL(x)	((x)->devdata->type == IS_MX6ULL)
+#define GPMI_IS_MX8QXP(x)	((x)->devdata->type == IS_MX8QXP)
 
 #define GPMI_IS_MX6(x)		(GPMI_IS_MX6Q(x) || GPMI_IS_MX6SX(x) || \
-				 GPMI_IS_MX7D(x))
+				 GPMI_IS_MX7D(x) || GPMI_IS_MX6UL(x) || \
+				 GPMI_IS_MX6ULL(x) || GPMI_IS_MX6QP(x))
+#define GPMI_IS_MX8(x)		(GPMI_IS_MX8QXP(x))
 #define GPMI_IS_MXS(x)		(GPMI_IS_MX23(x) || GPMI_IS_MX28(x))
 #endif
diff --git a/drivers/mtd/nand/raw/gpmi-nand/gpmi-regs.h b/drivers/mtd/nand/raw/gpmi-nand/gpmi-regs.h
index f5e4f26c3..fc31fd084 100644
--- a/drivers/mtd/nand/raw/gpmi-nand/gpmi-regs.h
+++ b/drivers/mtd/nand/raw/gpmi-nand/gpmi-regs.h
@@ -107,6 +107,7 @@
 #define BV_GPMI_CTRL1_WRN_DLY_SEL_7_TO_12NS		0x2
 #define BV_GPMI_CTRL1_WRN_DLY_SEL_NO_DELAY		0x3
 
+#define BM_GPMI_CTRL1_GANGED_RDYBUSY			(1 << 19)
 #define BM_GPMI_CTRL1_BCH_MODE				(1 << 18)
 
 #define BP_GPMI_CTRL1_DLL_ENABLE			17
diff --git a/drivers/mtd/spi-nor/core.c b/drivers/mtd/spi-nor/core.c
index 2b26a875a..7231ef22f 100644
--- a/drivers/mtd/spi-nor/core.c
+++ b/drivers/mtd/spi-nor/core.c
@@ -40,6 +40,81 @@
 
 #define SPI_NOR_MAX_ADDR_WIDTH	4
 
+#define SPI_NOR_SRST_SLEEP_MIN 200
+#define SPI_NOR_SRST_SLEEP_MAX 400
+
+/**
+ * spi_nor_get_cmd_ext() - Get the command opcode extension based on the
+ *			   extension type.
+ * @nor:		pointer to a 'struct spi_nor'
+ * @op:			pointer to the 'struct spi_mem_op' whose properties
+ *			need to be initialized.
+ *
+ * Right now, only "repeat" and "invert" are supported.
+ *
+ * Return: The opcode extension.
+ */
+static u8 spi_nor_get_cmd_ext(const struct spi_nor *nor,
+			      const struct spi_mem_op *op)
+{
+	switch (nor->cmd_ext_type) {
+	case SPI_NOR_EXT_INVERT:
+		return ~op->cmd.opcode;
+
+	case SPI_NOR_EXT_REPEAT:
+		return op->cmd.opcode;
+
+	default:
+		dev_err(nor->dev, "Unknown command extension type\n");
+		return 0;
+	}
+}
+
+/**
+ * spi_nor_spimem_setup_op() - Set up common properties of a spi-mem op.
+ * @nor:		pointer to a 'struct spi_nor'
+ * @op:			pointer to the 'struct spi_mem_op' whose properties
+ *			need to be initialized.
+ * @proto:		the protocol from which the properties need to be set.
+ */
+void spi_nor_spimem_setup_op(const struct spi_nor *nor,
+			     struct spi_mem_op *op,
+			     const enum spi_nor_protocol proto)
+{
+	u8 ext;
+
+	op->cmd.buswidth = spi_nor_get_protocol_inst_nbits(proto);
+
+	if (op->addr.nbytes)
+		op->addr.buswidth = spi_nor_get_protocol_addr_nbits(proto);
+
+	if (op->dummy.nbytes)
+		op->dummy.buswidth = spi_nor_get_protocol_addr_nbits(proto);
+
+	if (op->data.nbytes)
+		op->data.buswidth = spi_nor_get_protocol_data_nbits(proto);
+
+	if (spi_nor_protocol_is_dtr(proto)) {
+		/*
+		 * SPIMEM supports mixed DTR modes, but right now we can only
+		 * have all phases either DTR or STR. IOW, SPIMEM can have
+		 * something like 4S-4D-4D, but SPI NOR can't. So, set all 4
+		 * phases to either DTR or STR.
+		 */
+		op->cmd.dtr = true;
+		op->addr.dtr = true;
+		op->dummy.dtr = true;
+		op->data.dtr = true;
+
+		/* 2 bytes per clock cycle in DTR mode. */
+		op->dummy.nbytes *= 2;
+
+		ext = spi_nor_get_cmd_ext(nor, op);
+		op->cmd.opcode = (op->cmd.opcode << 8) | ext;
+		op->cmd.nbytes = 2;
+	}
+}
+
 /**
  * spi_nor_spimem_bounce() - check if a bounce buffer is needed for the data
  *                           transfer
@@ -82,6 +157,32 @@ static int spi_nor_spimem_exec_op(struct spi_nor *nor, struct spi_mem_op *op)
 	return spi_mem_exec_op(nor->spimem, op);
 }
 
+static int spi_nor_controller_ops_read_reg(struct spi_nor *nor, u8 opcode,
+					   u8 *buf, size_t len)
+{
+	if (spi_nor_protocol_is_dtr(nor->reg_proto))
+		return -EOPNOTSUPP;
+
+	return nor->controller_ops->read_reg(nor, opcode, buf, len);
+}
+
+static int spi_nor_controller_ops_write_reg(struct spi_nor *nor, u8 opcode,
+					    const u8 *buf, size_t len)
+{
+	if (spi_nor_protocol_is_dtr(nor->reg_proto))
+		return -EOPNOTSUPP;
+
+	return nor->controller_ops->write_reg(nor, opcode, buf, len);
+}
+
+static int spi_nor_controller_ops_erase(struct spi_nor *nor, loff_t offs)
+{
+	if (spi_nor_protocol_is_dtr(nor->write_proto))
+		return -EOPNOTSUPP;
+
+	return nor->controller_ops->erase(nor, offs);
+}
+
 /**
  * spi_nor_spimem_read_data() - read data from flash's memory region via
  *                              spi-mem
@@ -96,22 +197,20 @@ static ssize_t spi_nor_spimem_read_data(struct spi_nor *nor, loff_t from,
 					size_t len, u8 *buf)
 {
 	struct spi_mem_op op =
-		SPI_MEM_OP(SPI_MEM_OP_CMD(nor->read_opcode, 1),
-			   SPI_MEM_OP_ADDR(nor->addr_width, from, 1),
-			   SPI_MEM_OP_DUMMY(nor->read_dummy, 1),
-			   SPI_MEM_OP_DATA_IN(len, buf, 1));
+		SPI_MEM_OP(SPI_MEM_OP_CMD(nor->read_opcode, 0),
+			   SPI_MEM_OP_ADDR(nor->addr_width, from, 0),
+			   SPI_MEM_OP_DUMMY(nor->read_dummy, 0),
+			   SPI_MEM_OP_DATA_IN(len, buf, 0));
 	bool usebouncebuf;
 	ssize_t nbytes;
 	int error;
 
-	/* get transfer protocols. */
-	op.cmd.buswidth = spi_nor_get_protocol_inst_nbits(nor->read_proto);
-	op.addr.buswidth = spi_nor_get_protocol_addr_nbits(nor->read_proto);
-	op.dummy.buswidth = op.addr.buswidth;
-	op.data.buswidth = spi_nor_get_protocol_data_nbits(nor->read_proto);
+	spi_nor_spimem_setup_op(nor, &op, nor->read_proto);
 
 	/* convert the dummy cycles to the number of bytes */
 	op.dummy.nbytes = (nor->read_dummy * op.dummy.buswidth) / 8;
+	if (spi_nor_protocol_is_dtr(nor->read_proto))
+		op.dummy.nbytes *= 2;
 
 	usebouncebuf = spi_nor_spimem_bounce(nor, &op);
 
@@ -162,20 +261,18 @@ static ssize_t spi_nor_spimem_write_data(struct spi_nor *nor, loff_t to,
 					 size_t len, const u8 *buf)
 {
 	struct spi_mem_op op =
-		SPI_MEM_OP(SPI_MEM_OP_CMD(nor->program_opcode, 1),
-			   SPI_MEM_OP_ADDR(nor->addr_width, to, 1),
+		SPI_MEM_OP(SPI_MEM_OP_CMD(nor->program_opcode, 0),
+			   SPI_MEM_OP_ADDR(nor->addr_width, to, 0),
 			   SPI_MEM_OP_NO_DUMMY,
-			   SPI_MEM_OP_DATA_OUT(len, buf, 1));
+			   SPI_MEM_OP_DATA_OUT(len, buf, 0));
 	ssize_t nbytes;
 	int error;
 
-	op.cmd.buswidth = spi_nor_get_protocol_inst_nbits(nor->write_proto);
-	op.addr.buswidth = spi_nor_get_protocol_addr_nbits(nor->write_proto);
-	op.data.buswidth = spi_nor_get_protocol_data_nbits(nor->write_proto);
-
 	if (nor->program_opcode == SPINOR_OP_AAI_WP && nor->sst_write_second)
 		op.addr.nbytes = 0;
 
+	spi_nor_spimem_setup_op(nor, &op, nor->write_proto);
+
 	if (spi_nor_spimem_bounce(nor, &op))
 		memcpy(nor->bouncebuf, buf, op.data.nbytes);
 
@@ -222,15 +319,17 @@ int spi_nor_write_enable(struct spi_nor *nor)
 
 	if (nor->spimem) {
 		struct spi_mem_op op =
-			SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_WREN, 1),
+			SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_WREN, 0),
 				   SPI_MEM_OP_NO_ADDR,
 				   SPI_MEM_OP_NO_DUMMY,
 				   SPI_MEM_OP_NO_DATA);
 
+		spi_nor_spimem_setup_op(nor, &op, nor->reg_proto);
+
 		ret = spi_mem_exec_op(nor->spimem, &op);
 	} else {
-		ret = nor->controller_ops->write_reg(nor, SPINOR_OP_WREN,
-						     NULL, 0);
+		ret = spi_nor_controller_ops_write_reg(nor, SPINOR_OP_WREN,
+						       NULL, 0);
 	}
 
 	if (ret)
@@ -251,15 +350,17 @@ int spi_nor_write_disable(struct spi_nor *nor)
 
 	if (nor->spimem) {
 		struct spi_mem_op op =
-			SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_WRDI, 1),
+			SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_WRDI, 0),
 				   SPI_MEM_OP_NO_ADDR,
 				   SPI_MEM_OP_NO_DUMMY,
 				   SPI_MEM_OP_NO_DATA);
 
+		spi_nor_spimem_setup_op(nor, &op, nor->reg_proto);
+
 		ret = spi_mem_exec_op(nor->spimem, &op);
 	} else {
-		ret = nor->controller_ops->write_reg(nor, SPINOR_OP_WRDI,
-						     NULL, 0);
+		ret = spi_nor_controller_ops_write_reg(nor, SPINOR_OP_WRDI,
+						       NULL, 0);
 	}
 
 	if (ret)
@@ -272,7 +373,7 @@ int spi_nor_write_disable(struct spi_nor *nor)
  * spi_nor_read_sr() - Read the Status Register.
  * @nor:	pointer to 'struct spi_nor'.
  * @sr:		pointer to a DMA-able buffer where the value of the
- *              Status Register will be written.
+ *              Status Register will be written. Should be at least 2 bytes.
  *
  * Return: 0 on success, -errno otherwise.
  */
@@ -282,15 +383,27 @@ static int spi_nor_read_sr(struct spi_nor *nor, u8 *sr)
 
 	if (nor->spimem) {
 		struct spi_mem_op op =
-			SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_RDSR, 1),
+			SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_RDSR, 0),
 				   SPI_MEM_OP_NO_ADDR,
 				   SPI_MEM_OP_NO_DUMMY,
-				   SPI_MEM_OP_DATA_IN(1, sr, 1));
+				   SPI_MEM_OP_DATA_IN(1, sr, 0));
+
+		if (nor->reg_proto == SNOR_PROTO_8_8_8_DTR) {
+			op.addr.nbytes = nor->params->rdsr_addr_nbytes;
+			op.dummy.nbytes = nor->params->rdsr_dummy;
+			/*
+			 * We don't want to read only one byte in DTR mode. So,
+			 * read 2 and then discard the second byte.
+			 */
+			op.data.nbytes = 2;
+		}
+
+		spi_nor_spimem_setup_op(nor, &op, nor->reg_proto);
 
 		ret = spi_mem_exec_op(nor->spimem, &op);
 	} else {
-		ret = nor->controller_ops->read_reg(nor, SPINOR_OP_RDSR,
-						    sr, 1);
+		ret = spi_nor_controller_ops_read_reg(nor, SPINOR_OP_RDSR, sr,
+						      1);
 	}
 
 	if (ret)
@@ -303,7 +416,8 @@ static int spi_nor_read_sr(struct spi_nor *nor, u8 *sr)
  * spi_nor_read_fsr() - Read the Flag Status Register.
  * @nor:	pointer to 'struct spi_nor'
  * @fsr:	pointer to a DMA-able buffer where the value of the
- *              Flag Status Register will be written.
+ *              Flag Status Register will be written. Should be at least 2
+ *              bytes.
  *
  * Return: 0 on success, -errno otherwise.
  */
@@ -313,15 +427,27 @@ static int spi_nor_read_fsr(struct spi_nor *nor, u8 *fsr)
 
 	if (nor->spimem) {
 		struct spi_mem_op op =
-			SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_RDFSR, 1),
+			SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_RDFSR, 0),
 				   SPI_MEM_OP_NO_ADDR,
 				   SPI_MEM_OP_NO_DUMMY,
-				   SPI_MEM_OP_DATA_IN(1, fsr, 1));
+				   SPI_MEM_OP_DATA_IN(1, fsr, 0));
+
+		if (nor->reg_proto == SNOR_PROTO_8_8_8_DTR) {
+			op.addr.nbytes = nor->params->rdsr_addr_nbytes;
+			op.dummy.nbytes = nor->params->rdsr_dummy;
+			/*
+			 * We don't want to read only one byte in DTR mode. So,
+			 * read 2 and then discard the second byte.
+			 */
+			op.data.nbytes = 2;
+		}
+
+		spi_nor_spimem_setup_op(nor, &op, nor->reg_proto);
 
 		ret = spi_mem_exec_op(nor->spimem, &op);
 	} else {
-		ret = nor->controller_ops->read_reg(nor, SPINOR_OP_RDFSR,
-						    fsr, 1);
+		ret = spi_nor_controller_ops_read_reg(nor, SPINOR_OP_RDFSR, fsr,
+						      1);
 	}
 
 	if (ret)
@@ -345,14 +471,17 @@ static int spi_nor_read_cr(struct spi_nor *nor, u8 *cr)
 
 	if (nor->spimem) {
 		struct spi_mem_op op =
-			SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_RDCR, 1),
+			SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_RDCR, 0),
 				   SPI_MEM_OP_NO_ADDR,
 				   SPI_MEM_OP_NO_DUMMY,
-				   SPI_MEM_OP_DATA_IN(1, cr, 1));
+				   SPI_MEM_OP_DATA_IN(1, cr, 0));
+
+		spi_nor_spimem_setup_op(nor, &op, nor->reg_proto);
 
 		ret = spi_mem_exec_op(nor->spimem, &op);
 	} else {
-		ret = nor->controller_ops->read_reg(nor, SPINOR_OP_RDCR, cr, 1);
+		ret = spi_nor_controller_ops_read_reg(nor, SPINOR_OP_RDCR, cr,
+						      1);
 	}
 
 	if (ret)
@@ -378,17 +507,19 @@ int spi_nor_set_4byte_addr_mode(struct spi_nor *nor, bool enable)
 			SPI_MEM_OP(SPI_MEM_OP_CMD(enable ?
 						  SPINOR_OP_EN4B :
 						  SPINOR_OP_EX4B,
-						  1),
+						  0),
 				  SPI_MEM_OP_NO_ADDR,
 				  SPI_MEM_OP_NO_DUMMY,
 				  SPI_MEM_OP_NO_DATA);
 
+		spi_nor_spimem_setup_op(nor, &op, nor->reg_proto);
+
 		ret = spi_mem_exec_op(nor->spimem, &op);
 	} else {
-		ret = nor->controller_ops->write_reg(nor,
-						     enable ? SPINOR_OP_EN4B :
-							      SPINOR_OP_EX4B,
-						     NULL, 0);
+		ret = spi_nor_controller_ops_write_reg(nor,
+						       enable ? SPINOR_OP_EN4B :
+								SPINOR_OP_EX4B,
+						       NULL, 0);
 	}
 
 	if (ret)
@@ -414,15 +545,17 @@ static int spansion_set_4byte_addr_mode(struct spi_nor *nor, bool enable)
 
 	if (nor->spimem) {
 		struct spi_mem_op op =
-			SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_BRWR, 1),
+			SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_BRWR, 0),
 				   SPI_MEM_OP_NO_ADDR,
 				   SPI_MEM_OP_NO_DUMMY,
-				   SPI_MEM_OP_DATA_OUT(1, nor->bouncebuf, 1));
+				   SPI_MEM_OP_DATA_OUT(1, nor->bouncebuf, 0));
+
+		spi_nor_spimem_setup_op(nor, &op, nor->reg_proto);
 
 		ret = spi_mem_exec_op(nor->spimem, &op);
 	} else {
-		ret = nor->controller_ops->write_reg(nor, SPINOR_OP_BRWR,
-						     nor->bouncebuf, 1);
+		ret = spi_nor_controller_ops_write_reg(nor, SPINOR_OP_BRWR,
+						       nor->bouncebuf, 1);
 	}
 
 	if (ret)
@@ -446,15 +579,17 @@ int spi_nor_write_ear(struct spi_nor *nor, u8 ear)
 
 	if (nor->spimem) {
 		struct spi_mem_op op =
-			SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_WREAR, 1),
+			SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_WREAR, 0),
 				   SPI_MEM_OP_NO_ADDR,
 				   SPI_MEM_OP_NO_DUMMY,
-				   SPI_MEM_OP_DATA_OUT(1, nor->bouncebuf, 1));
+				   SPI_MEM_OP_DATA_OUT(1, nor->bouncebuf, 0));
+
+		spi_nor_spimem_setup_op(nor, &op, nor->reg_proto);
 
 		ret = spi_mem_exec_op(nor->spimem, &op);
 	} else {
-		ret = nor->controller_ops->write_reg(nor, SPINOR_OP_WREAR,
-						     nor->bouncebuf, 1);
+		ret = spi_nor_controller_ops_write_reg(nor, SPINOR_OP_WREAR,
+						       nor->bouncebuf, 1);
 	}
 
 	if (ret)
@@ -477,15 +612,17 @@ int spi_nor_xread_sr(struct spi_nor *nor, u8 *sr)
 
 	if (nor->spimem) {
 		struct spi_mem_op op =
-			SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_XRDSR, 1),
+			SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_XRDSR, 0),
 				   SPI_MEM_OP_NO_ADDR,
 				   SPI_MEM_OP_NO_DUMMY,
-				   SPI_MEM_OP_DATA_IN(1, sr, 1));
+				   SPI_MEM_OP_DATA_IN(1, sr, 0));
+
+		spi_nor_spimem_setup_op(nor, &op, nor->reg_proto);
 
 		ret = spi_mem_exec_op(nor->spimem, &op);
 	} else {
-		ret = nor->controller_ops->read_reg(nor, SPINOR_OP_XRDSR,
-						    sr, 1);
+		ret = spi_nor_controller_ops_read_reg(nor, SPINOR_OP_XRDSR, sr,
+						      1);
 	}
 
 	if (ret)
@@ -522,15 +659,17 @@ static void spi_nor_clear_sr(struct spi_nor *nor)
 
 	if (nor->spimem) {
 		struct spi_mem_op op =
-			SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_CLSR, 1),
+			SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_CLSR, 0),
 				   SPI_MEM_OP_NO_ADDR,
 				   SPI_MEM_OP_NO_DUMMY,
 				   SPI_MEM_OP_NO_DATA);
 
+		spi_nor_spimem_setup_op(nor, &op, nor->reg_proto);
+
 		ret = spi_mem_exec_op(nor->spimem, &op);
 	} else {
-		ret = nor->controller_ops->write_reg(nor, SPINOR_OP_CLSR,
-						     NULL, 0);
+		ret = spi_nor_controller_ops_write_reg(nor, SPINOR_OP_CLSR,
+						       NULL, 0);
 	}
 
 	if (ret)
@@ -586,15 +725,17 @@ static void spi_nor_clear_fsr(struct spi_nor *nor)
 
 	if (nor->spimem) {
 		struct spi_mem_op op =
-			SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_CLFSR, 1),
+			SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_CLFSR, 0),
 				   SPI_MEM_OP_NO_ADDR,
 				   SPI_MEM_OP_NO_DUMMY,
 				   SPI_MEM_OP_NO_DATA);
 
+		spi_nor_spimem_setup_op(nor, &op, nor->reg_proto);
+
 		ret = spi_mem_exec_op(nor->spimem, &op);
 	} else {
-		ret = nor->controller_ops->write_reg(nor, SPINOR_OP_CLFSR,
-						     NULL, 0);
+		ret = spi_nor_controller_ops_write_reg(nor, SPINOR_OP_CLFSR,
+						       NULL, 0);
 	}
 
 	if (ret)
@@ -730,15 +871,17 @@ static int spi_nor_write_sr(struct spi_nor *nor, const u8 *sr, size_t len)
 
 	if (nor->spimem) {
 		struct spi_mem_op op =
-			SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_WRSR, 1),
+			SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_WRSR, 0),
 				   SPI_MEM_OP_NO_ADDR,
 				   SPI_MEM_OP_NO_DUMMY,
-				   SPI_MEM_OP_DATA_OUT(len, sr, 1));
+				   SPI_MEM_OP_DATA_OUT(len, sr, 0));
+
+		spi_nor_spimem_setup_op(nor, &op, nor->reg_proto);
 
 		ret = spi_mem_exec_op(nor->spimem, &op);
 	} else {
-		ret = nor->controller_ops->write_reg(nor, SPINOR_OP_WRSR,
-						     sr, len);
+		ret = spi_nor_controller_ops_write_reg(nor, SPINOR_OP_WRSR, sr,
+						       len);
 	}
 
 	if (ret) {
@@ -932,15 +1075,17 @@ static int spi_nor_write_sr2(struct spi_nor *nor, const u8 *sr2)
 
 	if (nor->spimem) {
 		struct spi_mem_op op =
-			SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_WRSR2, 1),
+			SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_WRSR2, 0),
 				   SPI_MEM_OP_NO_ADDR,
 				   SPI_MEM_OP_NO_DUMMY,
-				   SPI_MEM_OP_DATA_OUT(1, sr2, 1));
+				   SPI_MEM_OP_DATA_OUT(1, sr2, 0));
+
+		spi_nor_spimem_setup_op(nor, &op, nor->reg_proto);
 
 		ret = spi_mem_exec_op(nor->spimem, &op);
 	} else {
-		ret = nor->controller_ops->write_reg(nor, SPINOR_OP_WRSR2,
-						     sr2, 1);
+		ret = spi_nor_controller_ops_write_reg(nor, SPINOR_OP_WRSR2,
+						       sr2, 1);
 	}
 
 	if (ret) {
@@ -966,15 +1111,17 @@ static int spi_nor_read_sr2(struct spi_nor *nor, u8 *sr2)
 
 	if (nor->spimem) {
 		struct spi_mem_op op =
-			SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_RDSR2, 1),
+			SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_RDSR2, 0),
 				   SPI_MEM_OP_NO_ADDR,
 				   SPI_MEM_OP_NO_DUMMY,
-				   SPI_MEM_OP_DATA_IN(1, sr2, 1));
+				   SPI_MEM_OP_DATA_IN(1, sr2, 0));
+
+		spi_nor_spimem_setup_op(nor, &op, nor->reg_proto);
 
 		ret = spi_mem_exec_op(nor->spimem, &op);
 	} else {
-		ret = nor->controller_ops->read_reg(nor, SPINOR_OP_RDSR2,
-						    sr2, 1);
+		ret = spi_nor_controller_ops_read_reg(nor, SPINOR_OP_RDSR2, sr2,
+						      1);
 	}
 
 	if (ret)
@@ -997,15 +1144,18 @@ static int spi_nor_erase_chip(struct spi_nor *nor)
 
 	if (nor->spimem) {
 		struct spi_mem_op op =
-			SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_CHIP_ERASE, 1),
+			SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_CHIP_ERASE, 0),
 				   SPI_MEM_OP_NO_ADDR,
 				   SPI_MEM_OP_NO_DUMMY,
 				   SPI_MEM_OP_NO_DATA);
 
+		spi_nor_spimem_setup_op(nor, &op, nor->write_proto);
+
 		ret = spi_mem_exec_op(nor->spimem, &op);
 	} else {
-		ret = nor->controller_ops->write_reg(nor, SPINOR_OP_CHIP_ERASE,
-						     NULL, 0);
+		ret = spi_nor_controller_ops_write_reg(nor,
+						       SPINOR_OP_CHIP_ERASE,
+						       NULL, 0);
 	}
 
 	if (ret)
@@ -1139,14 +1289,16 @@ static int spi_nor_erase_sector(struct spi_nor *nor, u32 addr)
 
 	if (nor->spimem) {
 		struct spi_mem_op op =
-			SPI_MEM_OP(SPI_MEM_OP_CMD(nor->erase_opcode, 1),
-				   SPI_MEM_OP_ADDR(nor->addr_width, addr, 1),
+			SPI_MEM_OP(SPI_MEM_OP_CMD(nor->erase_opcode, 0),
+				   SPI_MEM_OP_ADDR(nor->addr_width, addr, 0),
 				   SPI_MEM_OP_NO_DUMMY,
 				   SPI_MEM_OP_NO_DATA);
 
+		spi_nor_spimem_setup_op(nor, &op, nor->write_proto);
+
 		return spi_mem_exec_op(nor->spimem, &op);
 	} else if (nor->controller_ops->erase) {
-		return nor->controller_ops->erase(nor, addr);
+		return spi_nor_controller_ops_erase(nor, addr);
 	}
 
 	/*
@@ -1158,8 +1310,8 @@ static int spi_nor_erase_sector(struct spi_nor *nor, u32 addr)
 		addr >>= 8;
 	}
 
-	return nor->controller_ops->write_reg(nor, nor->erase_opcode,
-					      nor->bouncebuf, nor->addr_width);
+	return spi_nor_controller_ops_write_reg(nor, nor->erase_opcode,
+						nor->bouncebuf, nor->addr_width);
 }
 
 /**
@@ -2206,7 +2358,7 @@ static int spi_nor_check(struct spi_nor *nor)
 	return 0;
 }
 
-static void
+void
 spi_nor_set_read_settings(struct spi_nor_read_command *read,
 			  u8 num_mode_clocks,
 			  u8 num_wait_states,
@@ -2255,6 +2407,7 @@ int spi_nor_hwcaps_read2cmd(u32 hwcaps)
 		{ SNOR_HWCAPS_READ_1_8_8,	SNOR_CMD_READ_1_8_8 },
 		{ SNOR_HWCAPS_READ_8_8_8,	SNOR_CMD_READ_8_8_8 },
 		{ SNOR_HWCAPS_READ_1_8_8_DTR,	SNOR_CMD_READ_1_8_8_DTR },
+		{ SNOR_HWCAPS_READ_8_8_8_DTR,	SNOR_CMD_READ_8_8_8_DTR },
 	};
 
 	return spi_nor_hwcaps2cmd(hwcaps, hwcaps_read2cmd,
@@ -2271,6 +2424,7 @@ static int spi_nor_hwcaps_pp2cmd(u32 hwcaps)
 		{ SNOR_HWCAPS_PP_1_1_8,		SNOR_CMD_PP_1_1_8 },
 		{ SNOR_HWCAPS_PP_1_8_8,		SNOR_CMD_PP_1_8_8 },
 		{ SNOR_HWCAPS_PP_8_8_8,		SNOR_CMD_PP_8_8_8 },
+		{ SNOR_HWCAPS_PP_8_8_8_DTR,	SNOR_CMD_PP_8_8_8_DTR },
 	};
 
 	return spi_nor_hwcaps2cmd(hwcaps, hwcaps_pp2cmd,
@@ -2283,7 +2437,7 @@ static int spi_nor_hwcaps_pp2cmd(u32 hwcaps)
  *@nor:        pointer to a 'struct spi_nor'
  *@op:         pointer to op template to be checked
  *
- * Returns 0 if operation is supported, -ENOTSUPP otherwise.
+ * Returns 0 if operation is supported, -EOPNOTSUPP otherwise.
  */
 static int spi_nor_spimem_check_op(struct spi_nor *nor,
 				   struct spi_mem_op *op)
@@ -2297,12 +2451,12 @@ static int spi_nor_spimem_check_op(struct spi_nor *nor,
 	op->addr.nbytes = 4;
 	if (!spi_mem_supports_op(nor->spimem, op)) {
 		if (nor->mtd.size > SZ_16M)
-			return -ENOTSUPP;
+			return -EOPNOTSUPP;
 
 		/* If flash size <= 16MB, 3 address bytes are sufficient */
 		op->addr.nbytes = 3;
 		if (!spi_mem_supports_op(nor->spimem, op))
-			return -ENOTSUPP;
+			return -EOPNOTSUPP;
 	}
 
 	return 0;
@@ -2314,22 +2468,22 @@ static int spi_nor_spimem_check_op(struct spi_nor *nor,
  *@nor:         pointer to a 'struct spi_nor'
  *@read:        pointer to op template to be checked
  *
- * Returns 0 if operation is supported, -ENOTSUPP otherwise.
+ * Returns 0 if operation is supported, -EOPNOTSUPP otherwise.
  */
 static int spi_nor_spimem_check_readop(struct spi_nor *nor,
 				       const struct spi_nor_read_command *read)
 {
-	struct spi_mem_op op = SPI_MEM_OP(SPI_MEM_OP_CMD(read->opcode, 1),
-					  SPI_MEM_OP_ADDR(3, 0, 1),
-					  SPI_MEM_OP_DUMMY(0, 1),
-					  SPI_MEM_OP_DATA_IN(0, NULL, 1));
+	struct spi_mem_op op = SPI_MEM_OP(SPI_MEM_OP_CMD(read->opcode, 0),
+					  SPI_MEM_OP_ADDR(3, 0, 0),
+					  SPI_MEM_OP_DUMMY(1, 0),
+					  SPI_MEM_OP_DATA_IN(1, NULL, 0));
 
-	op.cmd.buswidth = spi_nor_get_protocol_inst_nbits(read->proto);
-	op.addr.buswidth = spi_nor_get_protocol_addr_nbits(read->proto);
-	op.data.buswidth = spi_nor_get_protocol_data_nbits(read->proto);
-	op.dummy.buswidth = op.addr.buswidth;
-	op.dummy.nbytes = (read->num_mode_clocks + read->num_wait_states) *
-			  op.dummy.buswidth / 8;
+	spi_nor_spimem_setup_op(nor, &op, read->proto);
+
+	/* convert the dummy cycles to the number of bytes */
+	op.dummy.nbytes = (nor->read_dummy * op.dummy.buswidth) / 8;
+	if (spi_nor_protocol_is_dtr(nor->read_proto))
+		op.dummy.nbytes *= 2;
 
 	return spi_nor_spimem_check_op(nor, &op);
 }
@@ -2340,19 +2494,17 @@ static int spi_nor_spimem_check_readop(struct spi_nor *nor,
  *@nor:         pointer to a 'struct spi_nor'
  *@pp:          pointer to op template to be checked
  *
- * Returns 0 if operation is supported, -ENOTSUPP otherwise.
+ * Returns 0 if operation is supported, -EOPNOTSUPP otherwise.
  */
 static int spi_nor_spimem_check_pp(struct spi_nor *nor,
 				   const struct spi_nor_pp_command *pp)
 {
-	struct spi_mem_op op = SPI_MEM_OP(SPI_MEM_OP_CMD(pp->opcode, 1),
-					  SPI_MEM_OP_ADDR(3, 0, 1),
+	struct spi_mem_op op = SPI_MEM_OP(SPI_MEM_OP_CMD(pp->opcode, 0),
+					  SPI_MEM_OP_ADDR(3, 0, 0),
 					  SPI_MEM_OP_NO_DUMMY,
-					  SPI_MEM_OP_DATA_OUT(0, NULL, 1));
+					  SPI_MEM_OP_DATA_OUT(1, NULL, 0));
 
-	op.cmd.buswidth = spi_nor_get_protocol_inst_nbits(pp->proto);
-	op.addr.buswidth = spi_nor_get_protocol_addr_nbits(pp->proto);
-	op.data.buswidth = spi_nor_get_protocol_data_nbits(pp->proto);
+	spi_nor_spimem_setup_op(nor, &op, pp->proto);
 
 	return spi_nor_spimem_check_op(nor, &op);
 }
@@ -2370,12 +2522,16 @@ spi_nor_spimem_adjust_hwcaps(struct spi_nor *nor, u32 *hwcaps)
 	struct spi_nor_flash_parameter *params = nor->params;
 	unsigned int cap;
 
-	/* DTR modes are not supported yet, mask them all. */
-	*hwcaps &= ~SNOR_HWCAPS_DTR;
-
 	/* X-X-X modes are not supported yet, mask them all. */
 	*hwcaps &= ~SNOR_HWCAPS_X_X_X;
 
+	/*
+	 * If the reset line is broken, we do not want to enter a stateful
+	 * mode.
+	 */
+	if (nor->flags & SNOR_F_BROKEN_RESET)
+		*hwcaps &= ~(SNOR_HWCAPS_X_X_X | SNOR_HWCAPS_X_X_X_DTR);
+
 	for (cap = 0; cap < sizeof(*hwcaps) * BITS_PER_BYTE; cap++) {
 		int rdidx, ppidx;
 
@@ -2630,7 +2786,7 @@ static int spi_nor_default_setup(struct spi_nor *nor,
 		 * controller directly implements the spi_nor interface.
 		 * Yet another reason to switch to spi-mem.
 		 */
-		ignored_mask = SNOR_HWCAPS_X_X_X;
+		ignored_mask = SNOR_HWCAPS_X_X_X | SNOR_HWCAPS_X_X_X_DTR;
 		if (shared_mask & ignored_mask) {
 			dev_dbg(nor->dev,
 				"SPI n-n-n protocols are not supported.\n");
@@ -2775,11 +2931,28 @@ static void spi_nor_info_init_params(struct spi_nor *nor)
 					  SNOR_PROTO_1_1_8);
 	}
 
+	if (info->flags & SPI_NOR_OCTAL_DTR_READ) {
+		params->hwcaps.mask |= SNOR_HWCAPS_READ_8_8_8_DTR;
+		spi_nor_set_read_settings(&params->reads[SNOR_CMD_READ_8_8_8_DTR],
+					  0, 20, SPINOR_OP_READ_FAST,
+					  SNOR_PROTO_8_8_8_DTR);
+	}
+
 	/* Page Program settings. */
 	params->hwcaps.mask |= SNOR_HWCAPS_PP;
 	spi_nor_set_pp_settings(&params->page_programs[SNOR_CMD_PP],
 				SPINOR_OP_PP, SNOR_PROTO_1_1_1);
 
+	if (info->flags & SPI_NOR_OCTAL_DTR_PP) {
+		params->hwcaps.mask |= SNOR_HWCAPS_PP_8_8_8_DTR;
+		/*
+		 * Since xSPI Page Program opcode is backward compatible with
+		 * Legacy SPI, use Legacy SPI opcode there as well.
+		 */
+		spi_nor_set_pp_settings(&params->page_programs[SNOR_CMD_PP_8_8_8_DTR],
+					SPINOR_OP_PP, SNOR_PROTO_8_8_8_DTR);
+	}
+
 	/*
 	 * Sector Erase settings. Sort Erase Types in ascending order, with the
 	 * smallest erase size starting at BIT(0).
@@ -2887,7 +3060,8 @@ static int spi_nor_init_params(struct spi_nor *nor)
 
 	spi_nor_manufacturer_init_params(nor);
 
-	if ((nor->info->flags & (SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ)) &&
+	if ((nor->info->flags & (SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ |
+				 SPI_NOR_OCTAL_READ | SPI_NOR_OCTAL_DTR_READ)) &&
 	    !(nor->info->flags & SPI_NOR_SKIP_SFDP))
 		spi_nor_sfdp_init_params(nor);
 
@@ -2898,6 +3072,38 @@ static int spi_nor_init_params(struct spi_nor *nor)
 	return 0;
 }
 
+/** spi_nor_octal_dtr_enable() - enable Octal DTR I/O if needed
+ * @nor:                 pointer to a 'struct spi_nor'
+ * @enable:              whether to enable or disable Octal DTR
+ *
+ * Return: 0 on success, -errno otherwise.
+ */
+static int spi_nor_octal_dtr_enable(struct spi_nor *nor, bool enable)
+{
+	int ret;
+
+	if (!nor->params->octal_dtr_enable)
+		return 0;
+
+	if (!(nor->read_proto == SNOR_PROTO_8_8_8_DTR &&
+	      nor->write_proto == SNOR_PROTO_8_8_8_DTR))
+		return 0;
+
+	if (!(nor->flags & SNOR_F_IO_MODE_EN_VOLATILE))
+		return 0;
+
+	ret = nor->params->octal_dtr_enable(nor, enable);
+	if (ret)
+		return ret;
+
+	if (enable)
+		nor->reg_proto = SNOR_PROTO_8_8_8_DTR;
+	else
+		nor->reg_proto = SNOR_PROTO_1_1_1;
+
+	return 0;
+}
+
 /**
  * spi_nor_quad_enable() - enable Quad I/O if needed.
  * @nor:                pointer to a 'struct spi_nor'
@@ -2944,6 +3150,12 @@ static int spi_nor_init(struct spi_nor *nor)
 {
 	int err;
 
+	err = spi_nor_octal_dtr_enable(nor, true);
+	if (err) {
+		dev_dbg(nor->dev, "octal mode not supported\n");
+		return err;
+	}
+
 	err = spi_nor_quad_enable(nor);
 	if (err) {
 		dev_dbg(nor->dev, "quad mode not supported\n");
@@ -2952,7 +3164,9 @@ static int spi_nor_init(struct spi_nor *nor)
 
 	spi_nor_try_unlock_all(nor);
 
-	if (nor->addr_width == 4 && !(nor->flags & SNOR_F_4B_OPCODES)) {
+	if (nor->addr_width == 4 &&
+	    nor->read_proto != SNOR_PROTO_8_8_8_DTR &&
+	    !(nor->flags & SNOR_F_4B_OPCODES)) {
 		/*
 		 * If the RESET# pin isn't hooked up properly, or the system
 		 * otherwise doesn't perform a reset command in the boot
@@ -2968,6 +3182,59 @@ static int spi_nor_init(struct spi_nor *nor)
 	return 0;
 }
 
+static void spi_nor_soft_reset(struct spi_nor *nor)
+{
+	struct spi_mem_op op;
+	int ret;
+
+	op = (struct spi_mem_op)SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_SRSTEN, 0),
+			SPI_MEM_OP_NO_DUMMY,
+			SPI_MEM_OP_NO_ADDR,
+			SPI_MEM_OP_NO_DATA);
+
+	spi_nor_spimem_setup_op(nor, &op, nor->reg_proto);
+
+	ret = spi_mem_exec_op(nor->spimem, &op);
+	if (ret) {
+		dev_warn(nor->dev, "Software reset failed: %d\n", ret);
+		return;
+	}
+
+	op = (struct spi_mem_op)SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_SRST, 0),
+			SPI_MEM_OP_NO_DUMMY,
+			SPI_MEM_OP_NO_ADDR,
+			SPI_MEM_OP_NO_DATA);
+
+	spi_nor_spimem_setup_op(nor, &op, nor->reg_proto);
+
+	ret = spi_mem_exec_op(nor->spimem, &op);
+	if (ret) {
+		dev_warn(nor->dev, "Software reset failed: %d\n", ret);
+		return;
+	}
+
+	/*
+	 * Software Reset is not instant, and the delay varies from flash to
+	 * flash. Looking at a few flashes, most range somewhere below 100
+	 * microseconds. So, sleep for a range of 200-400 us.
+	 */
+	usleep_range(SPI_NOR_SRST_SLEEP_MIN, SPI_NOR_SRST_SLEEP_MAX);
+}
+
+/* mtd suspend handler */
+static int spi_nor_suspend(struct mtd_info *mtd)
+{
+	struct spi_nor *nor = mtd_to_spi_nor(mtd);
+	int ret;
+
+	/* Disable octal DTR mode if we enabled it. */
+	ret = spi_nor_octal_dtr_enable(nor, false);
+	if (ret)
+		dev_err(nor->dev, "suspend() failed\n");
+
+	return ret;
+}
+
 /* mtd resume handler */
 static void spi_nor_resume(struct mtd_info *mtd)
 {
@@ -3018,6 +3285,9 @@ void spi_nor_restore(struct spi_nor *nor)
 	if (nor->addr_width == 4 && !(nor->flags & SNOR_F_4B_OPCODES) &&
 	    nor->flags & SNOR_F_BROKEN_RESET)
 		nor->params->set_4byte_addr_mode(nor, false);
+
+	if (nor->flags & SNOR_F_SOFT_RESET)
+		spi_nor_soft_reset(nor);
 }
 EXPORT_SYMBOL_GPL(spi_nor_restore);
 
@@ -3042,6 +3312,20 @@ static int spi_nor_set_addr_width(struct spi_nor *nor)
 {
 	if (nor->addr_width) {
 		/* already configured from SFDP */
+	} else if (nor->read_proto == SNOR_PROTO_8_8_8_DTR) {
+		/*
+		 * In 8D-8D-8D mode, one byte takes half a cycle to transfer. So
+		 * in this protocol an odd address width cannot be used because
+		 * then the address phase would only span a cycle and a half.
+		 * Half a cycle would be left over. We would then have to start
+		 * the dummy phase in the middle of a cycle and so too the data
+		 * phase, and we will end the transaction with half a cycle left
+		 * over.
+		 *
+		 * Force all 8D-8D-8D flashes to use an address width of 4 to
+		 * avoid this situation.
+		 */
+		nor->addr_width = 4;
 	} else if (nor->info->addr_width) {
 		nor->addr_width = nor->info->addr_width;
 	} else {
@@ -3187,6 +3471,7 @@ int spi_nor_scan(struct spi_nor *nor, const char *name,
 	mtd->size = nor->params->size;
 	mtd->_erase = spi_nor_erase;
 	mtd->_read = spi_nor_read;
+	mtd->_suspend = spi_nor_suspend;
 	mtd->_resume = spi_nor_resume;
 	mtd->_get_device = spi_nor_get_device;
 	mtd->_put_device = spi_nor_put_device;
@@ -3239,6 +3524,9 @@ int spi_nor_scan(struct spi_nor *nor, const char *name,
 	if (info->flags & SPI_NOR_4B_OPCODES)
 		nor->flags |= SNOR_F_4B_OPCODES;
 
+	if (info->flags & SPI_NOR_IO_MODE_EN_VOLATILE)
+		nor->flags |= SNOR_F_IO_MODE_EN_VOLATILE;
+
 	ret = spi_nor_set_addr_width(nor);
 	if (ret)
 		return ret;
@@ -3274,23 +3562,28 @@ EXPORT_SYMBOL_GPL(spi_nor_scan);
 static int spi_nor_create_read_dirmap(struct spi_nor *nor)
 {
 	struct spi_mem_dirmap_info info = {
-		.op_tmpl = SPI_MEM_OP(SPI_MEM_OP_CMD(nor->read_opcode, 1),
-				      SPI_MEM_OP_ADDR(nor->addr_width, 0, 1),
-				      SPI_MEM_OP_DUMMY(nor->read_dummy, 1),
-				      SPI_MEM_OP_DATA_IN(0, NULL, 1)),
+		.op_tmpl = SPI_MEM_OP(SPI_MEM_OP_CMD(nor->read_opcode, 0),
+				      SPI_MEM_OP_ADDR(nor->addr_width, 0, 0),
+				      SPI_MEM_OP_DUMMY(nor->read_dummy, 0),
+				      SPI_MEM_OP_DATA_IN(0, NULL, 0)),
 		.offset = 0,
 		.length = nor->mtd.size,
 	};
 	struct spi_mem_op *op = &info.op_tmpl;
 
-	/* get transfer protocols. */
-	op->cmd.buswidth = spi_nor_get_protocol_inst_nbits(nor->read_proto);
-	op->addr.buswidth = spi_nor_get_protocol_addr_nbits(nor->read_proto);
-	op->dummy.buswidth = op->addr.buswidth;
-	op->data.buswidth = spi_nor_get_protocol_data_nbits(nor->read_proto);
+	spi_nor_spimem_setup_op(nor, op, nor->read_proto);
 
 	/* convert the dummy cycles to the number of bytes */
 	op->dummy.nbytes = (nor->read_dummy * op->dummy.buswidth) / 8;
+	if (spi_nor_protocol_is_dtr(nor->read_proto))
+		op->dummy.nbytes *= 2;
+
+	/*
+	 * Since spi_nor_spimem_setup_op() only sets buswidth when the number
+	 * of data bytes is non-zero, the data buswidth won't be set here. So,
+	 * do it explicitly.
+	 */
+	op->data.buswidth = spi_nor_get_protocol_data_nbits(nor->read_proto);
 
 	nor->dirmap.rdesc = devm_spi_mem_dirmap_create(nor->dev, nor->spimem,
 						       &info);
@@ -3300,24 +3593,27 @@ static int spi_nor_create_read_dirmap(struct spi_nor *nor)
 static int spi_nor_create_write_dirmap(struct spi_nor *nor)
 {
 	struct spi_mem_dirmap_info info = {
-		.op_tmpl = SPI_MEM_OP(SPI_MEM_OP_CMD(nor->program_opcode, 1),
-				      SPI_MEM_OP_ADDR(nor->addr_width, 0, 1),
+		.op_tmpl = SPI_MEM_OP(SPI_MEM_OP_CMD(nor->program_opcode, 0),
+				      SPI_MEM_OP_ADDR(nor->addr_width, 0, 0),
 				      SPI_MEM_OP_NO_DUMMY,
-				      SPI_MEM_OP_DATA_OUT(0, NULL, 1)),
+				      SPI_MEM_OP_DATA_OUT(0, NULL, 0)),
 		.offset = 0,
 		.length = nor->mtd.size,
 	};
 	struct spi_mem_op *op = &info.op_tmpl;
 
-	/* get transfer protocols. */
-	op->cmd.buswidth = spi_nor_get_protocol_inst_nbits(nor->write_proto);
-	op->addr.buswidth = spi_nor_get_protocol_addr_nbits(nor->write_proto);
-	op->dummy.buswidth = op->addr.buswidth;
-	op->data.buswidth = spi_nor_get_protocol_data_nbits(nor->write_proto);
-
 	if (nor->program_opcode == SPINOR_OP_AAI_WP && nor->sst_write_second)
 		op->addr.nbytes = 0;
 
+	spi_nor_spimem_setup_op(nor, op, nor->write_proto);
+
+	/*
+	 * Since spi_nor_spimem_setup_op() only sets buswidth when the number
+	 * of data bytes is non-zero, the data buswidth won't be set here. So,
+	 * do it explicitly.
+	 */
+	op->data.buswidth = spi_nor_get_protocol_data_nbits(nor->write_proto);
+
 	nor->dirmap.wdesc = devm_spi_mem_dirmap_create(nor->dev, nor->spimem,
 						       &info);
 	return PTR_ERR_OR_ZERO(nor->dirmap.wdesc);
diff --git a/drivers/mtd/spi-nor/core.h b/drivers/mtd/spi-nor/core.h
index 6f62ee861..7780169d4 100644
--- a/drivers/mtd/spi-nor/core.h
+++ b/drivers/mtd/spi-nor/core.h
@@ -26,6 +26,8 @@ enum spi_nor_option_flags {
 	SNOR_F_HAS_SR_TB_BIT6	= BIT(11),
 	SNOR_F_HAS_4BIT_BP      = BIT(12),
 	SNOR_F_HAS_SR_BP3_BIT6  = BIT(13),
+	SNOR_F_IO_MODE_EN_VOLATILE = BIT(14),
+	SNOR_F_SOFT_RESET	= BIT(15),
 };
 
 struct spi_nor_read_command {
@@ -62,6 +64,7 @@ enum spi_nor_read_command_index {
 	SNOR_CMD_READ_1_8_8,
 	SNOR_CMD_READ_8_8_8,
 	SNOR_CMD_READ_1_8_8_DTR,
+	SNOR_CMD_READ_8_8_8_DTR,
 
 	SNOR_CMD_READ_MAX
 };
@@ -78,6 +81,7 @@ enum spi_nor_pp_command_index {
 	SNOR_CMD_PP_1_1_8,
 	SNOR_CMD_PP_1_8_8,
 	SNOR_CMD_PP_8_8_8,
+	SNOR_CMD_PP_8_8_8_DTR,
 
 	SNOR_CMD_PP_MAX
 };
@@ -190,6 +194,9 @@ struct spi_nor_locking_ops {
  *
  * @size:		the flash memory density in bytes.
  * @page_size:		the page size of the SPI NOR flash memory.
+ * @rdsr_dummy:		dummy cycles needed for Read Status Register command.
+ * @rdsr_addr_nbytes:	dummy address bytes needed for Read Status Register
+ *			command.
  * @hwcaps:		describes the read and page program hardware
  *			capabilities.
  * @reads:		read capabilities ordered by priority: the higher index
@@ -198,6 +205,7 @@ struct spi_nor_locking_ops {
  *                      higher index in the array, the higher priority.
  * @erase_map:		the erase map parsed from the SFDP Sector Map Parameter
  *                      Table.
+ * @octal_dtr_enable:	enables SPI NOR octal DTR mode.
  * @quad_enable:	enables SPI NOR quad mode.
  * @set_4byte_addr_mode: puts the SPI NOR in 4 byte addressing mode.
  * @convert_addr:	converts an absolute address into something the flash
@@ -212,6 +220,8 @@ struct spi_nor_locking_ops {
 struct spi_nor_flash_parameter {
 	u64				size;
 	u32				page_size;
+	u8				rdsr_dummy;
+	u8				rdsr_addr_nbytes;
 
 	struct spi_nor_hwcaps		hwcaps;
 	struct spi_nor_read_command	reads[SNOR_CMD_READ_MAX];
@@ -219,6 +229,7 @@ struct spi_nor_flash_parameter {
 
 	struct spi_nor_erase_map        erase_map;
 
+	int (*octal_dtr_enable)(struct spi_nor *nor, bool enable);
 	int (*quad_enable)(struct spi_nor *nor);
 	int (*set_4byte_addr_mode)(struct spi_nor *nor, bool enable);
 	u32 (*convert_addr)(struct spi_nor *nor, u32 addr);
@@ -311,6 +322,13 @@ struct flash_info {
 					 * BP3 is bit 6 of status register.
 					 * Must be used with SPI_NOR_4BIT_BP.
 					 */
+#define SPI_NOR_OCTAL_DTR_READ	BIT(19) /* Flash supports octal DTR Read. */
+#define SPI_NOR_OCTAL_DTR_PP	BIT(20) /* Flash supports Octal DTR Page Program */
+#define SPI_NOR_IO_MODE_EN_VOLATILE	BIT(21) /*
+						 * Flash enables the best
+						 * available I/O mode via a
+						 * volatile bit.
+						 */
 
 	/* Part specific fixup hooks. */
 	const struct spi_nor_fixups *fixups;
@@ -399,6 +417,9 @@ extern const struct spi_nor_manufacturer spi_nor_winbond;
 extern const struct spi_nor_manufacturer spi_nor_xilinx;
 extern const struct spi_nor_manufacturer spi_nor_xmc;
 
+void spi_nor_spimem_setup_op(const struct spi_nor *nor,
+			     struct spi_mem_op *op,
+			     const enum spi_nor_protocol proto);
 int spi_nor_write_enable(struct spi_nor *nor);
 int spi_nor_write_disable(struct spi_nor *nor);
 int spi_nor_set_4byte_addr_mode(struct spi_nor *nor, bool enable);
@@ -419,6 +440,11 @@ ssize_t spi_nor_write_data(struct spi_nor *nor, loff_t to, size_t len,
 
 int spi_nor_hwcaps_read2cmd(u32 hwcaps);
 u8 spi_nor_convert_3to4_read(u8 opcode);
+void spi_nor_set_read_settings(struct spi_nor_read_command *read,
+			       u8 num_mode_clocks,
+			       u8 num_wait_states,
+			       u8 opcode,
+			       enum spi_nor_protocol proto);
 void spi_nor_set_pp_settings(struct spi_nor_pp_command *pp, u8 opcode,
 			     enum spi_nor_protocol proto);
 
diff --git a/drivers/mtd/spi-nor/macronix.c b/drivers/mtd/spi-nor/macronix.c
index 662b21278..c145a09ce 100644
--- a/drivers/mtd/spi-nor/macronix.c
+++ b/drivers/mtd/spi-nor/macronix.c
@@ -8,6 +8,13 @@
 
 #include "core.h"
 
+#define SPINOR_OP_RD_CR2		0x71		/* Read configuration register 2 */
+#define SPINOR_OP_WR_CR2		0x72		/* Write configuration register 2 */
+#define SPINOR_REG_MXIC_CR2_MODE	0x00000000	/* For setting octal DTR mode */
+#define SPINOR_REG_MXIC_OPI_DTR_EN	0x2		/* Enable Octal DTR */
+#define SPINOR_REG_MXIC_SPI_EN		0x0		/* Enable SPI */
+#define SPINOR_OP_OPI_DTR_RD		0xEE		/* OPI DTR first read opcode */
+
 static int
 mx25l25635_post_bfpt_fixups(struct spi_nor *nor,
 			    const struct sfdp_parameter_header *bfpt_header,
@@ -33,6 +40,98 @@ static struct spi_nor_fixups mx25l25635_fixups = {
 	.post_bfpt = mx25l25635_post_bfpt_fixups,
 };
 
+/**
+ * spi_nor_macronix_octal_dtr_enable() - Enable octal DTR on Macronix flashes.
+ * @nor:		pointer to a 'struct spi_nor'
+ * @enable:		whether to enable Octal DTR or switch back to SPI
+ *
+ * Return: 0 on success, -errno otherwise.
+ */
+static int spi_nor_macronix_octal_dtr_enable(struct spi_nor *nor, bool enable)
+{
+	struct spi_mem_op op;
+	u8 *buf = nor->bouncebuf, i;
+	int ret;
+
+	/* Set/unset the octal and DTR enable bits. */
+	ret = spi_nor_write_enable(nor);
+	if (ret)
+		return ret;
+
+	if (enable) {
+		buf[0] = SPINOR_REG_MXIC_OPI_DTR_EN;
+	} else {
+		/*
+		 * The register is 1-byte wide, but 1-byte transactions are not
+		 * allowed in 8D-8D-8D mode. Since there is no register at the
+		 * next location, just initialize the value to 0 and let the
+		 * transaction go on.
+		 */
+		buf[0] = SPINOR_REG_MXIC_SPI_EN;
+		buf[1] = 0x0;
+	}
+
+	op = (struct spi_mem_op)
+		SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_WR_CR2, 1),
+			   SPI_MEM_OP_ADDR(4, SPINOR_REG_MXIC_CR2_MODE, 1),
+			   SPI_MEM_OP_NO_DUMMY,
+			   SPI_MEM_OP_DATA_OUT(enable ? 1 : 2, buf, 1));
+
+	if (!enable)
+		spi_nor_spimem_setup_op(nor, &op, SNOR_PROTO_8_8_8_DTR);
+
+	ret = spi_mem_exec_op(nor->spimem, &op);
+	if (ret)
+		return ret;
+
+	/* Read flash ID to make sure the switch was successful. */
+	op = (struct spi_mem_op)
+		SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_RDID, 1),
+			   SPI_MEM_OP_ADDR(enable ? 4 : 0, 0, 1),
+			   SPI_MEM_OP_DUMMY(enable ? 4 : 0, 1),
+			   SPI_MEM_OP_DATA_IN(SPI_NOR_MAX_ID_LEN, buf, 1));
+
+	if (enable)
+		spi_nor_spimem_setup_op(nor, &op, SNOR_PROTO_8_8_8_DTR);
+
+	ret = spi_mem_exec_op(nor->spimem, &op);
+	if (ret)
+		return ret;
+
+	if (enable) {
+		for (i = 0; i < nor->info->id_len; i++)
+			if (buf[i * 2] != nor->info->id[i])
+				return -EINVAL;
+	} else {
+		if (memcmp(buf, nor->info->id, nor->info->id_len))
+			return -EINVAL;
+	}
+
+	return 0;
+}
+
+static void octaflash_default_init(struct spi_nor *nor)
+{
+	nor->params->octal_dtr_enable = spi_nor_macronix_octal_dtr_enable;
+}
+
+static struct spi_nor_fixups octaflash_fixups = {
+	.default_init = octaflash_default_init,
+};
+
+static void mx25uw51345g_post_sfdp_fixup(struct spi_nor *nor)
+{
+	nor->params->hwcaps.mask |= SNOR_HWCAPS_READ_8_8_8_DTR;
+	spi_nor_set_read_settings(&nor->params->reads[SNOR_CMD_READ_8_8_8_DTR],
+				  0, 20, SPINOR_OP_OPI_DTR_RD,
+				  SNOR_PROTO_8_8_8_DTR);
+}
+
+static struct spi_nor_fixups mx25uw51345g_fixups = {
+	.default_init = octaflash_default_init,
+	.post_sfdp = mx25uw51345g_post_sfdp_fixup,
+};
+
 static const struct flash_info macronix_parts[] = {
 	/* Macronix */
 	{ "mx25l512e",   INFO(0xc22010, 0, 64 * 1024,   1, SECT_4K) },
@@ -87,6 +186,106 @@ static const struct flash_info macronix_parts[] = {
 	{ "mx66u2g45g",	 INFO(0xc2253c, 0, 64 * 1024, 4096,
 			      SECT_4K | SPI_NOR_DUAL_READ |
 			      SPI_NOR_QUAD_READ | SPI_NOR_4B_OPCODES) },
+	{ "mx66lm2g45g", INFO(0xc2853c, 0, 64 * 1024, 4096,
+			      SECT_4K | SPI_NOR_OCTAL_DTR_READ |
+			      SPI_NOR_OCTAL_DTR_PP | SPI_NOR_4B_OPCODES)
+		.fixups = &octaflash_fixups },
+	{ "mx66lm1g45g", INFO(0xc2853b, 0, 32 * 1024, 4096,
+			      SECT_4K | SPI_NOR_OCTAL_DTR_READ |
+			      SPI_NOR_OCTAL_DTR_PP | SPI_NOR_4B_OPCODES)
+		.fixups = &octaflash_fixups },
+	{ "mx66lw1g45g", INFO(0xc2863b, 0, 32 * 1024, 4096,
+			      SECT_4K | SPI_NOR_OCTAL_DTR_READ |
+			      SPI_NOR_OCTAL_DTR_PP | SPI_NOR_4B_OPCODES)
+		.fixups = &octaflash_fixups },
+	{ "mx25lm51245g", INFO(0xc2853a, 0, 16 * 1024, 4096,
+			       SECT_4K | SPI_NOR_OCTAL_DTR_READ |
+			       SPI_NOR_OCTAL_DTR_PP | SPI_NOR_4B_OPCODES)
+		.fixups = &octaflash_fixups },
+	{ "mx25lw51245g", INFO(0xc2863a, 0, 16 * 1024, 4096,
+			       SECT_4K | SPI_NOR_OCTAL_DTR_READ |
+			       SPI_NOR_OCTAL_DTR_PP | SPI_NOR_4B_OPCODES)
+		.fixups = &octaflash_fixups },
+	{ "mx25lm25645g", INFO(0xc28539, 0, 8 * 1024, 4096,
+			       SECT_4K | SPI_NOR_OCTAL_DTR_READ |
+			       SPI_NOR_OCTAL_DTR_PP | SPI_NOR_4B_OPCODES)
+		.fixups = &octaflash_fixups },
+	{ "mx25lw25645g", INFO(0xc28639, 0, 8 * 1024, 4096,
+			       SECT_4K | SPI_NOR_OCTAL_DTR_READ |
+			       SPI_NOR_OCTAL_DTR_PP | SPI_NOR_4B_OPCODES)
+		.fixups = &octaflash_fixups },
+	{ "mx66um2g45g", INFO(0xc2803c, 0, 64 * 1024, 4096,
+			      SECT_4K | SPI_NOR_OCTAL_DTR_READ |
+			      SPI_NOR_OCTAL_DTR_PP | SPI_NOR_4B_OPCODES)
+		.fixups = &octaflash_fixups },
+	{ "mx66uw2g345g", INFO(0xc2843c, 0, 64 * 1024, 4096,
+			       SECT_4K | SPI_NOR_OCTAL_DTR_READ |
+			       SPI_NOR_OCTAL_DTR_PP | SPI_NOR_4B_OPCODES)
+		.fixups = &octaflash_fixups },
+	{ "mx66uw2g345gx0", INFO(0xc2943c, 0, 64 * 1024, 4096,
+				 SECT_4K | SPI_NOR_OCTAL_DTR_READ |
+				 SPI_NOR_OCTAL_DTR_PP | SPI_NOR_4B_OPCODES)
+		.fixups = &octaflash_fixups },
+	{ "mx66um1g45g", INFO(0xc2803b, 0, 32 * 1024, 4096,
+			      SECT_4K | SPI_NOR_OCTAL_DTR_READ |
+			      SPI_NOR_OCTAL_DTR_PP | SPI_NOR_4B_OPCODES)
+		.fixups = &octaflash_fixups },
+	{ "mx66um1g45g40", INFO(0xc2808b, 0, 32 * 1024, 4096,
+				SECT_4K | SPI_NOR_OCTAL_DTR_READ |
+				SPI_NOR_OCTAL_DTR_PP | SPI_NOR_4B_OPCODES)
+		.fixups = &octaflash_fixups },
+	{ "mx66uw1g45g", INFO(0xc2813b, 0, 32 * 1024, 4096,
+			      SECT_4K | SPI_NOR_OCTAL_DTR_READ |
+			      SPI_NOR_OCTAL_DTR_PP | SPI_NOR_4B_OPCODES)
+		.fixups = &octaflash_fixups },
+	{ "mx25um51245g", INFO(0xc2803a, 0, 16 * 1024, 4096,
+			       SECT_4K | SPI_NOR_OCTAL_DTR_READ |
+			       SPI_NOR_OCTAL_DTR_PP | SPI_NOR_4B_OPCODES)
+		.fixups = &octaflash_fixups },
+	{ "mx25uw51245g", INFO(0xc2813a, 0, 16 * 1024, 4096,
+			       SECT_4K | SPI_NOR_OCTAL_DTR_READ |
+			       SPI_NOR_OCTAL_DTR_PP | SPI_NOR_4B_OPCODES)
+		.fixups = &octaflash_fixups },
+	{ "mx25uw51345g", INFO(0xc2843a, 0, 16 * 1024, 4096,
+			       SECT_4K | SPI_NOR_OCTAL_DTR_READ |
+			       SPI_NOR_OCTAL_DTR_PP | SPI_NOR_4B_OPCODES)
+		.fixups = &mx25uw51345g_fixups },
+	{ "mx25um25645g", INFO(0xc28039, 0, 8 * 1024, 4096,
+			       SECT_4K | SPI_NOR_OCTAL_DTR_READ |
+			       SPI_NOR_OCTAL_DTR_PP | SPI_NOR_4B_OPCODES)
+		.fixups = &octaflash_fixups },
+	{ "mx25uw25645g", INFO(0xc28139, 0, 8 * 1024, 4096,
+			       SECT_4K | SPI_NOR_OCTAL_DTR_READ |
+			       SPI_NOR_OCTAL_DTR_PP | SPI_NOR_4B_OPCODES)
+		.fixups = &octaflash_fixups },
+	{ "mx25um25345g", INFO(0xc28339, 0, 8 * 1024, 4096,
+			       SECT_4K | SPI_NOR_OCTAL_DTR_READ |
+			       SPI_NOR_OCTAL_DTR_PP | SPI_NOR_4B_OPCODES)
+		.fixups = &octaflash_fixups },
+	{ "mx25uw25345g", INFO(0xc28439, 0, 8 * 1024, 4096,
+			       SECT_4K | SPI_NOR_OCTAL_DTR_READ |
+			       SPI_NOR_OCTAL_DTR_PP | SPI_NOR_4B_OPCODES)
+		.fixups = &octaflash_fixups },
+	{ "mx25uw12845g", INFO(0xc28138, 0, 4 * 1024, 4096,
+			       SECT_4K | SPI_NOR_OCTAL_DTR_READ |
+			       SPI_NOR_OCTAL_DTR_PP | SPI_NOR_4B_OPCODES)
+		.fixups = &octaflash_fixups },
+	{ "mx25uw12a45g", INFO(0xc28938, 0, 4 * 1024, 4096,
+			       SECT_4K | SPI_NOR_OCTAL_DTR_READ |
+			       SPI_NOR_OCTAL_DTR_PP | SPI_NOR_4B_OPCODES)
+		.fixups = &octaflash_fixups },
+	{ "mx25uw12345g", INFO(0xc28438, 0, 4 * 1024, 4096,
+			       SECT_4K | SPI_NOR_OCTAL_DTR_READ |
+			       SPI_NOR_OCTAL_DTR_PP | SPI_NOR_4B_OPCODES)
+		.fixups = &octaflash_fixups },
+	{ "mx25uw6445g", INFO(0xc28137, 0, 2 * 1024, 4096,
+			      SECT_4K | SPI_NOR_OCTAL_DTR_READ |
+			      SPI_NOR_OCTAL_DTR_PP | SPI_NOR_4B_OPCODES)
+		.fixups = &octaflash_fixups },
+	{ "mx25uw6345g", INFO(0xc28437, 0, 2 * 1024, 4096,
+			      SECT_4K | SPI_NOR_OCTAL_DTR_READ |
+			      SPI_NOR_OCTAL_DTR_PP | SPI_NOR_4B_OPCODES)
+		.fixups = &octaflash_fixups },
 };
 
 static void macronix_default_init(struct spi_nor *nor)
diff --git a/drivers/mtd/spi-nor/micron-st.c b/drivers/mtd/spi-nor/micron-st.c
index ef3695080..c224e5982 100644
--- a/drivers/mtd/spi-nor/micron-st.c
+++ b/drivers/mtd/spi-nor/micron-st.c
@@ -8,10 +8,123 @@
 
 #include "core.h"
 
+#define SPINOR_OP_MT_DTR_RD	0xfd	/* Fast Read opcode in DTR mode */
+#define SPINOR_OP_MT_RD_ANY_REG	0x85	/* Read volatile register */
+#define SPINOR_OP_MT_WR_ANY_REG	0x81	/* Write volatile register */
+#define SPINOR_REG_MT_CFR0V	0x00	/* For setting octal DTR mode */
+#define SPINOR_REG_MT_CFR1V	0x01	/* For setting dummy cycles */
+#define SPINOR_MT_OCT_DTR	0xe7	/* Enable Octal DTR. */
+#define SPINOR_MT_EXSPI		0xff	/* Enable Extended SPI (default) */
+
+static int spi_nor_micron_octal_dtr_enable(struct spi_nor *nor, bool enable)
+{
+	struct spi_mem_op op;
+	u8 *buf = nor->bouncebuf;
+	int ret;
+
+	if (enable) {
+		/* Use 20 dummy cycles for memory array reads. */
+		ret = spi_nor_write_enable(nor);
+		if (ret)
+			return ret;
+
+		*buf = 20;
+		op = (struct spi_mem_op)
+			SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_MT_WR_ANY_REG, 1),
+				   SPI_MEM_OP_ADDR(3, SPINOR_REG_MT_CFR1V, 1),
+				   SPI_MEM_OP_NO_DUMMY,
+				   SPI_MEM_OP_DATA_OUT(1, buf, 1));
+
+		ret = spi_mem_exec_op(nor->spimem, &op);
+		if (ret)
+			return ret;
+
+		ret = spi_nor_wait_till_ready(nor);
+		if (ret)
+			return ret;
+	}
+
+	ret = spi_nor_write_enable(nor);
+	if (ret)
+		return ret;
+
+	if (enable)
+		*buf = SPINOR_MT_OCT_DTR;
+	else
+		*buf = SPINOR_MT_EXSPI;
+
+	op = (struct spi_mem_op)
+		SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_MT_WR_ANY_REG, 1),
+			   SPI_MEM_OP_ADDR(enable ? 3 : 4,
+					   SPINOR_REG_MT_CFR0V, 1),
+			   SPI_MEM_OP_NO_DUMMY,
+			   SPI_MEM_OP_DATA_OUT(1, buf, 1));
+
+	if (!enable)
+		spi_nor_spimem_setup_op(nor, &op, SNOR_PROTO_8_8_8_DTR);
+
+	ret = spi_mem_exec_op(nor->spimem, &op);
+	if (ret)
+		return ret;
+
+	/* Read flash ID to make sure the switch was successful. */
+	op = (struct spi_mem_op)
+		SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_RDID, 1),
+			   SPI_MEM_OP_NO_ADDR,
+			   SPI_MEM_OP_DUMMY(enable ? 8 : 0, 1),
+			   SPI_MEM_OP_DATA_IN(round_up(nor->info->id_len, 2),
+					      buf, 1));
+
+	if (enable)
+		spi_nor_spimem_setup_op(nor, &op, SNOR_PROTO_8_8_8_DTR);
+
+	ret = spi_mem_exec_op(nor->spimem, &op);
+	if (ret)
+		return ret;
+
+	if (memcmp(buf, nor->info->id, nor->info->id_len))
+		return -EINVAL;
+
+	return 0;
+}
+
+static void mt35xu512aba_default_init(struct spi_nor *nor)
+{
+	nor->params->octal_dtr_enable = spi_nor_micron_octal_dtr_enable;
+}
+
+static void mt35xu512aba_post_sfdp_fixup(struct spi_nor *nor)
+{
+	/* Set the Fast Read settings. */
+	nor->params->hwcaps.mask |= SNOR_HWCAPS_READ_8_8_8_DTR;
+	spi_nor_set_read_settings(&nor->params->reads[SNOR_CMD_READ_8_8_8_DTR],
+				  0, 20, SPINOR_OP_MT_DTR_RD,
+				  SNOR_PROTO_8_8_8_DTR);
+
+	nor->cmd_ext_type = SPI_NOR_EXT_REPEAT;
+	nor->params->rdsr_dummy = 8;
+	nor->params->rdsr_addr_nbytes = 0;
+
+	/*
+	 * The BFPT quad enable field is set to a reserved value so the quad
+	 * enable function is ignored by spi_nor_parse_bfpt(). Make sure we
+	 * disable it.
+	 */
+	nor->params->quad_enable = NULL;
+}
+
+static struct spi_nor_fixups mt35xu512aba_fixups = {
+	.default_init = mt35xu512aba_default_init,
+	.post_sfdp = mt35xu512aba_post_sfdp_fixup,
+};
+
 static const struct flash_info micron_parts[] = {
 	{ "mt35xu512aba", INFO(0x2c5b1a, 0, 128 * 1024, 512,
 			       SECT_4K | USE_FSR | SPI_NOR_OCTAL_READ |
-			       SPI_NOR_4B_OPCODES) },
+			       SPI_NOR_4B_OPCODES | SPI_NOR_OCTAL_DTR_READ |
+			       SPI_NOR_OCTAL_DTR_PP |
+			       SPI_NOR_IO_MODE_EN_VOLATILE)
+	  .fixups = &mt35xu512aba_fixups},
 	{ "mt35xu02g", INFO(0x2c5b1c, 0, 128 * 1024, 2048,
 			    SECT_4K | USE_FSR | SPI_NOR_OCTAL_READ |
 			    SPI_NOR_4B_OPCODES) },
diff --git a/drivers/mtd/spi-nor/sfdp.c b/drivers/mtd/spi-nor/sfdp.c
index 08de2a2b4..5859564e6 100644
--- a/drivers/mtd/spi-nor/sfdp.c
+++ b/drivers/mtd/spi-nor/sfdp.c
@@ -4,6 +4,7 @@
  * Copyright (C) 2014, Freescale Semiconductor, Inc.
  */
 
+#include <linux/bitfield.h>
 #include <linux/slab.h>
 #include <linux/sort.h>
 #include <linux/mtd/spi-nor.h>
@@ -19,6 +20,11 @@
 #define SFDP_BFPT_ID		0xff00	/* Basic Flash Parameter Table */
 #define SFDP_SECTOR_MAP_ID	0xff81	/* Sector Map Table */
 #define SFDP_4BAIT_ID		0xff84  /* 4-byte Address Instruction Table */
+#define SFDP_PROFILE1_ID	0xff05	/* xSPI Profile 1.0 table. */
+#define SFDP_SCCR_MAP_ID	0xff87	/*
+					 * Status, Control and Configuration
+					 * Register Map.
+					 */
 
 #define SFDP_SIGNATURE		0x50444653U
 
@@ -602,10 +608,32 @@ static int spi_nor_parse_bfpt(struct spi_nor *nor,
 		break;
 	}
 
+	/* Soft Reset support. */
+	if (bfpt.dwords[BFPT_DWORD(16)] & BFPT_DWORD16_SWRST_EN_RST)
+		nor->flags |= SNOR_F_SOFT_RESET;
+
 	/* Stop here if not JESD216 rev C or later. */
 	if (bfpt_header->length == BFPT_DWORD_MAX_JESD216B)
 		return spi_nor_post_bfpt_fixups(nor, bfpt_header, &bfpt,
 						params);
+	/* 8D-8D-8D command extension. */
+	switch (bfpt.dwords[BFPT_DWORD(18)] & BFPT_DWORD18_CMD_EXT_MASK) {
+	case BFPT_DWORD18_CMD_EXT_REP:
+		nor->cmd_ext_type = SPI_NOR_EXT_REPEAT;
+		break;
+
+	case BFPT_DWORD18_CMD_EXT_INV:
+		nor->cmd_ext_type = SPI_NOR_EXT_INVERT;
+		break;
+
+	case BFPT_DWORD18_CMD_EXT_RES:
+		dev_dbg(nor->dev, "Reserved command extension used\n");
+		break;
+
+	case BFPT_DWORD18_CMD_EXT_16B:
+		dev_dbg(nor->dev, "16-bit opcodes not supported\n");
+		return -EOPNOTSUPP;
+	}
 
 	return spi_nor_post_bfpt_fixups(nor, bfpt_header, &bfpt, params);
 }
@@ -1046,9 +1074,16 @@ static int spi_nor_parse_4bait(struct spi_nor *nor,
 	}
 
 	/* 4BAIT is the only SFDP table that indicates page program support. */
-	if (pp_hwcaps & SNOR_HWCAPS_PP)
+	if (pp_hwcaps & SNOR_HWCAPS_PP) {
 		spi_nor_set_pp_settings(&params_pp[SNOR_CMD_PP],
 					SPINOR_OP_PP_4B, SNOR_PROTO_1_1_1);
+		/*
+		 * Since xSPI Page Program opcode is backward compatible with
+		 * Legacy SPI, use Legacy SPI opcode there as well.
+		 */
+		spi_nor_set_pp_settings(&params_pp[SNOR_CMD_PP_8_8_8_DTR],
+					SPINOR_OP_PP_4B, SNOR_PROTO_8_8_8_DTR);
+	}
 	if (pp_hwcaps & SNOR_HWCAPS_PP_1_1_4)
 		spi_nor_set_pp_settings(&params_pp[SNOR_CMD_PP_1_1_4],
 					SPINOR_OP_PP_1_1_4_4B,
@@ -1082,6 +1117,131 @@ static int spi_nor_parse_4bait(struct spi_nor *nor,
 	return ret;
 }
 
+#define PROFILE1_DWORD1_RDSR_ADDR_BYTES		BIT(29)
+#define PROFILE1_DWORD1_RDSR_DUMMY		BIT(28)
+#define PROFILE1_DWORD1_RD_FAST_CMD		GENMASK(15, 8)
+#define PROFILE1_DWORD4_DUMMY_200MHZ		GENMASK(11, 7)
+#define PROFILE1_DWORD5_DUMMY_166MHZ		GENMASK(31, 27)
+#define PROFILE1_DWORD5_DUMMY_133MHZ		GENMASK(21, 17)
+#define PROFILE1_DWORD5_DUMMY_100MHZ		GENMASK(11, 7)
+
+/**
+ * spi_nor_parse_profile1() - parse the xSPI Profile 1.0 table
+ * @nor:		pointer to a 'struct spi_nor'
+ * @profile1_header:	pointer to the 'struct sfdp_parameter_header' describing
+ *			the Profile 1.0 Table length and version.
+ * @params:		pointer to the 'struct spi_nor_flash_parameter' to be.
+ *
+ * Return: 0 on success, -errno otherwise.
+ */
+static int spi_nor_parse_profile1(struct spi_nor *nor,
+				  const struct sfdp_parameter_header *profile1_header,
+				  struct spi_nor_flash_parameter *params)
+{
+	u32 *dwords, addr;
+	size_t len;
+	int ret;
+	u8 dummy, opcode;
+
+	len = profile1_header->length * sizeof(*dwords);
+	dwords = kmalloc(len, GFP_KERNEL);
+	if (!dwords)
+		return -ENOMEM;
+
+	addr = SFDP_PARAM_HEADER_PTP(profile1_header);
+	ret = spi_nor_read_sfdp(nor, addr, len, dwords);
+	if (ret)
+		goto out;
+
+	le32_to_cpu_array(dwords, profile1_header->length);
+
+	/* Get 8D-8D-8D fast read opcode and dummy cycles. */
+	opcode = FIELD_GET(PROFILE1_DWORD1_RD_FAST_CMD, dwords[0]);
+
+	 /* Set the Read Status Register dummy cycles and dummy address bytes. */
+	if (dwords[0] & PROFILE1_DWORD1_RDSR_DUMMY)
+		params->rdsr_dummy = 8;
+	else
+		params->rdsr_dummy = 4;
+
+	if (dwords[0] & PROFILE1_DWORD1_RDSR_ADDR_BYTES)
+		params->rdsr_addr_nbytes = 4;
+	else
+		params->rdsr_addr_nbytes = 0;
+
+	/*
+	 * We don't know what speed the controller is running at. Find the
+	 * dummy cycles for the fastest frequency the flash can run at to be
+	 * sure we are never short of dummy cycles. A value of 0 means the
+	 * frequency is not supported.
+	 *
+	 * Default to PROFILE1_DUMMY_DEFAULT if we don't find anything, and let
+	 * flashes set the correct value if needed in their fixup hooks.
+	 */
+	dummy = FIELD_GET(PROFILE1_DWORD4_DUMMY_200MHZ, dwords[3]);
+	if (!dummy)
+		dummy = FIELD_GET(PROFILE1_DWORD5_DUMMY_166MHZ, dwords[4]);
+	if (!dummy)
+		dummy = FIELD_GET(PROFILE1_DWORD5_DUMMY_133MHZ, dwords[4]);
+	if (!dummy)
+		dummy = FIELD_GET(PROFILE1_DWORD5_DUMMY_100MHZ, dwords[4]);
+	if (!dummy)
+		dev_dbg(nor->dev,
+			"Can't find dummy cycles from Profile 1.0 table\n");
+
+	/* Round up to an even value to avoid tripping controllers up. */
+	dummy = round_up(dummy, 2);
+
+	/* Update the fast read settings. */
+	spi_nor_set_read_settings(&params->reads[SNOR_CMD_READ_8_8_8_DTR],
+				  0, dummy, opcode,
+				  SNOR_PROTO_8_8_8_DTR);
+
+out:
+	kfree(dwords);
+	return ret;
+}
+
+#define SCCR_DWORD22_OCTAL_DTR_EN_VOLATILE		BIT(31)
+
+/**
+ * spi_nor_parse_sccr() - Parse the Status, Control and Configuration Register
+ *                        Map.
+ * @nor:		pointer to a 'struct spi_nor'
+ * @sccr_header:	pointer to the 'struct sfdp_parameter_header' describing
+ *			the SCCR Map table length and version.
+ * @params:		pointer to the 'struct spi_nor_flash_parameter' to be.
+ *
+ * Return: 0 on success, -errno otherwise.
+ */
+static int spi_nor_parse_sccr(struct spi_nor *nor,
+			      const struct sfdp_parameter_header *sccr_header,
+			      struct spi_nor_flash_parameter *params)
+{
+	u32 *dwords, addr;
+	size_t len;
+	int ret;
+
+	len = sccr_header->length * sizeof(*dwords);
+	dwords = kmalloc(len, GFP_KERNEL);
+	if (!dwords)
+		return -ENOMEM;
+
+	addr = SFDP_PARAM_HEADER_PTP(sccr_header);
+	ret = spi_nor_read_sfdp(nor, addr, len, dwords);
+	if (ret)
+		goto out;
+
+	le32_to_cpu_array(dwords, sccr_header->length);
+
+	if (FIELD_GET(SCCR_DWORD22_OCTAL_DTR_EN_VOLATILE, dwords[22]))
+		nor->flags |= SNOR_F_IO_MODE_EN_VOLATILE;
+
+out:
+	kfree(dwords);
+	return ret;
+}
+
 /**
  * spi_nor_parse_sfdp() - parse the Serial Flash Discoverable Parameters.
  * @nor:		pointer to a 'struct spi_nor'
@@ -1183,6 +1343,14 @@ int spi_nor_parse_sfdp(struct spi_nor *nor,
 			err = spi_nor_parse_4bait(nor, param_header, params);
 			break;
 
+		case SFDP_PROFILE1_ID:
+			err = spi_nor_parse_profile1(nor, param_header, params);
+			break;
+
+		case SFDP_SCCR_MAP_ID:
+			err = spi_nor_parse_sccr(nor, param_header, params);
+			break;
+
 		default:
 			break;
 		}
diff --git a/drivers/mtd/spi-nor/sfdp.h b/drivers/mtd/spi-nor/sfdp.h
index 7f9846b3a..89152ae1c 100644
--- a/drivers/mtd/spi-nor/sfdp.h
+++ b/drivers/mtd/spi-nor/sfdp.h
@@ -90,6 +90,14 @@ struct sfdp_bfpt {
 #define BFPT_DWORD15_QER_SR2_BIT1_NO_RD		(0x4UL << 20)
 #define BFPT_DWORD15_QER_SR2_BIT1		(0x5UL << 20) /* Spansion */
 
+#define BFPT_DWORD16_SWRST_EN_RST		BIT(12)
+
+#define BFPT_DWORD18_CMD_EXT_MASK		GENMASK(30, 29)
+#define BFPT_DWORD18_CMD_EXT_REP		(0x0UL << 29) /* Repeat */
+#define BFPT_DWORD18_CMD_EXT_INV		(0x1UL << 29) /* Invert */
+#define BFPT_DWORD18_CMD_EXT_RES		(0x2UL << 29) /* Reserved */
+#define BFPT_DWORD18_CMD_EXT_16B		(0x3UL << 29) /* 16-bit opcode */
+
 struct sfdp_parameter_header {
 	u8		id_lsb;
 	u8		minor;
diff --git a/drivers/mtd/spi-nor/spansion.c b/drivers/mtd/spi-nor/spansion.c
index 8429b4af9..15b39b734 100644
--- a/drivers/mtd/spi-nor/spansion.c
+++ b/drivers/mtd/spi-nor/spansion.c
@@ -8,6 +8,172 @@
 
 #include "core.h"
 
+#define SPINOR_OP_RD_ANY_REG			0x65	/* Read any register */
+#define SPINOR_OP_WR_ANY_REG			0x71	/* Write any register */
+#define SPINOR_REG_CYPRESS_CFR2V		0x00800003
+#define SPINOR_REG_CYPRESS_CFR2V_MEMLAT_11_24	0xb
+#define SPINOR_REG_CYPRESS_CFR3V		0x00800004
+#define SPINOR_REG_CYPRESS_CFR3V_PGSZ		BIT(4) /* Page size. */
+#define SPINOR_REG_CYPRESS_CFR5V		0x00800006
+#define SPINOR_REG_CYPRESS_CFR5V_OCT_DTR_EN	0x3
+#define SPINOR_REG_CYPRESS_CFR5V_OCT_DTR_DS	0
+#define SPINOR_OP_CYPRESS_RD_FAST		0xee
+
+/**
+ * spi_nor_cypress_octal_dtr_enable() - Enable octal DTR on Cypress flashes.
+ * @nor:		pointer to a 'struct spi_nor'
+ * @enable:              whether to enable or disable Octal DTR
+ *
+ * This also sets the memory access latency cycles to 24 to allow the flash to
+ * run at up to 200MHz.
+ *
+ * Return: 0 on success, -errno otherwise.
+ */
+static int spi_nor_cypress_octal_dtr_enable(struct spi_nor *nor, bool enable)
+{
+	struct spi_mem_op op;
+	u8 *buf = nor->bouncebuf;
+	int ret;
+
+	if (enable) {
+		/* Use 24 dummy cycles for memory array reads. */
+		ret = spi_nor_write_enable(nor);
+		if (ret)
+			return ret;
+
+		*buf = SPINOR_REG_CYPRESS_CFR2V_MEMLAT_11_24;
+		op = (struct spi_mem_op)
+			SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_WR_ANY_REG, 1),
+				   SPI_MEM_OP_ADDR(3, SPINOR_REG_CYPRESS_CFR2V,
+						   1),
+				   SPI_MEM_OP_NO_DUMMY,
+				   SPI_MEM_OP_DATA_OUT(1, buf, 1));
+
+		ret = spi_mem_exec_op(nor->spimem, &op);
+		if (ret)
+			return ret;
+
+		ret = spi_nor_wait_till_ready(nor);
+		if (ret)
+			return ret;
+
+		nor->read_dummy = 24;
+	}
+
+	/* Set/unset the octal and DTR enable bits. */
+	ret = spi_nor_write_enable(nor);
+	if (ret)
+		return ret;
+
+	if (enable)
+		*buf = SPINOR_REG_CYPRESS_CFR5V_OCT_DTR_EN;
+	else
+		*buf = SPINOR_REG_CYPRESS_CFR5V_OCT_DTR_DS;
+
+	op = (struct spi_mem_op)
+		SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_WR_ANY_REG, 1),
+			   SPI_MEM_OP_ADDR(enable ? 3 : 4,
+					   SPINOR_REG_CYPRESS_CFR5V,
+					   1),
+			   SPI_MEM_OP_NO_DUMMY,
+			   SPI_MEM_OP_DATA_OUT(1, buf, 1));
+
+	if (!enable)
+		spi_nor_spimem_setup_op(nor, &op, SNOR_PROTO_8_8_8_DTR);
+
+	ret = spi_mem_exec_op(nor->spimem, &op);
+	if (ret)
+		return ret;
+
+	/* Read flash ID to make sure the switch was successful. */
+	op = (struct spi_mem_op)
+		SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_RDID, 1),
+			   SPI_MEM_OP_ADDR(enable ? 4 : 0, 0, 1),
+			   SPI_MEM_OP_DUMMY(enable ? 3 : 0, 1),
+			   SPI_MEM_OP_DATA_IN(round_up(nor->info->id_len, 2),
+					      buf, 1));
+
+	if (enable)
+		spi_nor_spimem_setup_op(nor, &op, SNOR_PROTO_8_8_8_DTR);
+
+	ret = spi_mem_exec_op(nor->spimem, &op);
+	if (ret)
+		return ret;
+
+	if (memcmp(buf, nor->info->id, nor->info->id_len))
+		return -EINVAL;
+
+	return 0;
+}
+
+static void s28hs512t_default_init(struct spi_nor *nor)
+{
+	nor->params->octal_dtr_enable = spi_nor_cypress_octal_dtr_enable;
+}
+
+static void s28hs512t_post_sfdp_fixup(struct spi_nor *nor)
+{
+	/*
+	 * On older versions of the flash the xSPI Profile 1.0 table has the
+	 * 8D-8D-8D Fast Read opcode as 0x00. But it actually should be 0xEE.
+	 */
+	if (nor->params->reads[SNOR_CMD_READ_8_8_8_DTR].opcode == 0)
+		nor->params->reads[SNOR_CMD_READ_8_8_8_DTR].opcode =
+			SPINOR_OP_CYPRESS_RD_FAST;
+
+	/* This flash is also missing the 4-byte Page Program opcode bit. */
+	spi_nor_set_pp_settings(&nor->params->page_programs[SNOR_CMD_PP],
+				SPINOR_OP_PP_4B, SNOR_PROTO_1_1_1);
+	/*
+	 * Since xSPI Page Program opcode is backward compatible with
+	 * Legacy SPI, use Legacy SPI opcode there as well.
+	 */
+	spi_nor_set_pp_settings(&nor->params->page_programs[SNOR_CMD_PP_8_8_8_DTR],
+				SPINOR_OP_PP_4B, SNOR_PROTO_8_8_8_DTR);
+
+	/*
+	 * The xSPI Profile 1.0 table advertises the number of additional
+	 * address bytes needed for Read Status Register command as 0 but the
+	 * actual value for that is 4.
+	 */
+	nor->params->rdsr_addr_nbytes = 4;
+}
+
+static int s28hs512t_post_bfpt_fixup(struct spi_nor *nor,
+				     const struct sfdp_parameter_header *bfpt_header,
+				     const struct sfdp_bfpt *bfpt,
+				     struct spi_nor_flash_parameter *params)
+{
+	/*
+	 * The BFPT table advertises a 512B page size but the page size is
+	 * actually configurable (with the default being 256B). Read from
+	 * CFR3V[4] and set the correct size.
+	 */
+	struct spi_mem_op op =
+		SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_RD_ANY_REG, 1),
+			   SPI_MEM_OP_ADDR(3, SPINOR_REG_CYPRESS_CFR3V, 1),
+			   SPI_MEM_OP_NO_DUMMY,
+			   SPI_MEM_OP_DATA_IN(1, nor->bouncebuf, 1));
+	int ret;
+
+	ret = spi_mem_exec_op(nor->spimem, &op);
+	if (ret)
+		return ret;
+
+	if (nor->bouncebuf[0] & SPINOR_REG_CYPRESS_CFR3V_PGSZ)
+		params->page_size = 512;
+	else
+		params->page_size = 256;
+
+	return 0;
+}
+
+static struct spi_nor_fixups s28hs512t_fixups = {
+	.default_init = s28hs512t_default_init,
+	.post_sfdp = s28hs512t_post_sfdp_fixup,
+	.post_bfpt = s28hs512t_post_bfpt_fixup,
+};
+
 static int
 s25fs_s_post_bfpt_fixups(struct spi_nor *nor,
 			 const struct sfdp_parameter_header *bfpt_header,
@@ -62,7 +228,7 @@ static const struct flash_info spansion_parts[] = {
 			      SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ |
 			      USE_CLSR) },
 	{ "s25fs512s",  INFO6(0x010220, 0x4d0081, 256 * 1024, 256,
-			      SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ | USE_CLSR)
+			      SPI_NOR_4B_OPCODES | USE_CLSR)
 	  .fixups = &s25fs_s_fixups, },
 	{ "s25sl12800", INFO(0x012018, 0x0300, 256 * 1024,  64, 0) },
 	{ "s25sl12801", INFO(0x012018, 0x0301,  64 * 1024, 256, 0) },
@@ -104,6 +270,11 @@ static const struct flash_info spansion_parts[] = {
 			     SPI_NOR_4B_OPCODES) },
 	{ "cy15x104q",  INFO6(0x042cc2, 0x7f7f7f, 512 * 1024, 1,
 			      SPI_NOR_NO_ERASE) },
+	{ "s28hs512t",   INFO(0x345b1a,      0, 256 * 1024, 256,
+			     SECT_4K | SPI_NOR_OCTAL_DTR_READ |
+			      SPI_NOR_OCTAL_DTR_PP)
+	  .fixups = &s28hs512t_fixups,
+	},
 };
 
 static void spansion_post_sfdp_fixups(struct spi_nor *nor)
diff --git a/drivers/mtd/ubi/build.c b/drivers/mtd/ubi/build.c
index 4153e0d15..445850a63 100644
--- a/drivers/mtd/ubi/build.c
+++ b/drivers/mtd/ubi/build.c
@@ -593,7 +593,7 @@ static int io_init(struct ubi_device *ubi, int max_beb_per1024)
 	dbg_gen("sizeof(struct ubi_ainf_peb) %zu", sizeof(struct ubi_ainf_peb));
 	dbg_gen("sizeof(struct ubi_wl_entry) %zu", sizeof(struct ubi_wl_entry));
 
-	if (ubi->mtd->numeraseregions != 0) {
+	if (ubi->mtd->numeraseregions > 1) {
 		/*
 		 * Some flashes have several erase regions. Different regions
 		 * may have different eraseblock size and other
diff --git a/drivers/nvmem/Kconfig b/drivers/nvmem/Kconfig
index 954d3b4a5..6436e34e4 100644
--- a/drivers/nvmem/Kconfig
+++ b/drivers/nvmem/Kconfig
@@ -270,4 +270,15 @@ config SPRD_EFUSE
 	  This driver can also be built as a module. If so, the module
 	  will be called nvmem-sprd-efuse.
 
+config NVMEM_IMX_OCOTP_FSB_S400
+	tristate "i.MX FSB/S400-API ocotp fuse box support"
+	depends on IMX_SENTNL_MU
+	default y
+	help
+	  This is a driver for the ocotp fuse box which can be accessed by
+	  FSB and S400-API.
+
+	  This driver can also be built as a module. If so, the module
+	  will be called nvmem-imx-ocotp-fsb-s400.
+
 endif
diff --git a/drivers/nvmem/Makefile b/drivers/nvmem/Makefile
index a7c377218..e97f1fb7d 100644
--- a/drivers/nvmem/Makefile
+++ b/drivers/nvmem/Makefile
@@ -55,3 +55,5 @@ obj-$(CONFIG_NVMEM_ZYNQMP)	+= nvmem_zynqmp_nvmem.o
 nvmem_zynqmp_nvmem-y		:= zynqmp_nvmem.o
 obj-$(CONFIG_SPRD_EFUSE)	+= nvmem_sprd_efuse.o
 nvmem_sprd_efuse-y		:= sprd-efuse.o
+obj-$(CONFIG_NVMEM_IMX_OCOTP_FSB_S400) += nvmem-imx-ocotp-fsb-s400.o
+nvmem-imx-ocotp-fsb-s400-y		:= imx-ocotp-fsb-s400.o
diff --git a/drivers/nvmem/imx-ocotp-fsb-s400.c b/drivers/nvmem/imx-ocotp-fsb-s400.c
new file mode 100644
index 000000000..4b5741208
--- /dev/null
+++ b/drivers/nvmem/imx-ocotp-fsb-s400.c
@@ -0,0 +1,204 @@
+// SPDX-License-Identifier: GPL-2.0+
+/*
+ * Copyright 2021 NXP
+ * Author: Alice Guo <alice.guo@nxp.com>
+ */
+
+#include <linux/dev_printk.h>
+#include <linux/errno.h>
+#include <linux/firmware/imx/sentnl_base_msg.h>
+#include <linux/io.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/mutex.h>
+#include <linux/nvmem-consumer.h>
+#include <linux/nvmem-provider.h>
+#include <linux/of_platform.h>
+#include <linux/platform_device.h>
+#include <linux/slab.h>
+
+#define LOCK_CFG	0x01
+#define ECID		0x02
+#define UNIQ_ID		0x07
+#define OTFAD_CFG	0x17
+
+struct bank_2_reg {
+	unsigned int bank;
+	unsigned int reg;
+	bool flag;
+};
+
+static const struct bank_2_reg fsb_bank_reg[] = {
+	{ 3, 0 },
+	{ 4, 8 },
+	{ 5, 64 },
+	{ 6, 72 },
+	{ 8, 80, true },
+	{ 24, 84, true },
+	{ 26, 88, true },
+	{ 27, 92, true },
+	{ 28, 96 },
+	{ 29, 104 },
+	{ 30, 112 },
+	{ 31, 120 },
+	{ 37, 128 },
+	{ 38, 136 },
+	{ 39, 144 },
+	{ 40, 152 },
+	{ 41, 160 },
+	{ 42, 168 },
+	{ 43, 176 },
+	{ 44, 184 },
+	{ 45, 192 },
+	{ 46, 200 },
+};
+
+struct imx_fsb_s400_fuse {
+	void __iomem *regs;
+	struct nvmem_config config;
+	struct mutex lock;
+};
+
+static int read_words_via_s400_api(u32 *buf, unsigned int fuse_base)
+{
+	unsigned int i;
+	int err = 0;
+
+	for (i = 0; i < 8; i++) {
+		err = read_common_fuse(fuse_base + i, buf + i);
+	}
+
+	return err;
+}
+
+static int read_words_via_fsb(void __iomem *regs, unsigned int bank, u32 *buf)
+{
+	unsigned int i;
+	unsigned int reg_id = UINT_MAX;
+	unsigned int size = ARRAY_SIZE(fsb_bank_reg);
+
+	for (i = 0; i < size; i++) {
+		if (fsb_bank_reg[i].bank == bank) {
+			reg_id = fsb_bank_reg[i].reg;
+			break;
+		}
+	}
+
+	if (reg_id != UINT_MAX) {
+		size = fsb_bank_reg[i].flag ? 4 : 8;
+
+		for (i = 0; i < size; i++) {
+			*buf = readl_relaxed(regs + (reg_id + i) * 4);
+			buf = buf + 1;
+		}
+	}
+
+	return 0;
+}
+
+static int fsb_s400_fuse_read(void *priv, unsigned int offset, void *val,
+			      size_t bytes)
+{
+	struct imx_fsb_s400_fuse *fuse = priv;
+	unsigned int num_bytes, bank;
+	u32 *buf;
+	int err;
+
+	num_bytes = round_up(2048, 4);
+	buf = kzalloc(num_bytes, GFP_KERNEL);
+	if (!buf)
+		return -ENOMEM;
+
+	err = -EINVAL;
+
+	mutex_lock(&fuse->lock);
+	for (bank = 0; bank < 63; bank++) {
+		switch (bank) {
+		case 0:
+			break;
+		case LOCK_CFG:
+			err = read_words_via_s400_api(&buf[8], 8);
+			if (err)
+				goto ret;
+			break;
+		case ECID:
+			err = read_words_via_s400_api(&buf[16], 16);
+			if (err)
+				goto ret;
+			break;
+		case UNIQ_ID:
+			err = read_common_fuse(OTP_UNIQ_ID, &buf[56]);
+			if (err)
+				goto ret;
+			break;
+		case OTFAD_CFG:
+			err = read_common_fuse(OTFAD_CONFIG, &buf[184]);
+			if (err)
+				goto ret;
+			break;
+		default:
+			err = read_words_via_fsb(fuse->regs + 0x800, bank, &buf[bank * 8]);
+			break;
+		}
+	}
+
+	memcpy(val, (u8 *)(buf + offset), bytes);
+
+ret:
+	kfree(buf);
+	mutex_unlock(&fuse->lock);
+
+	return err;
+}
+
+static int imx_fsb_s400_fuse_probe(struct platform_device *pdev)
+{
+	struct imx_fsb_s400_fuse *fuse;
+	struct nvmem_device *nvmem;
+
+	fuse = devm_kzalloc(&pdev->dev, sizeof(*fuse), GFP_KERNEL);
+	if (!fuse)
+		return -ENOMEM;
+
+	fuse->regs = devm_platform_ioremap_resource(pdev, 0);
+	if (IS_ERR(fuse->regs))
+		return PTR_ERR(fuse->regs);
+
+	fuse->config.dev = &pdev->dev;
+	fuse->config.name = "fsb_s400_fuse";
+	fuse->config.id = NVMEM_DEVID_AUTO;
+	fuse->config.owner = THIS_MODULE;
+	fuse->config.size = 2048; /* 64 Banks */
+	fuse->config.reg_read = fsb_s400_fuse_read;
+	fuse->config.priv = fuse;
+
+	nvmem = devm_nvmem_register(&pdev->dev, &fuse->config);
+	if (IS_ERR(nvmem)) {
+		dev_err(&pdev->dev, "failed to register fuse nvmem device\n");
+		return PTR_ERR(nvmem);
+	}
+
+	mutex_init(&fuse->lock);
+
+	dev_dbg(&pdev->dev, "fuse nvmem device registered successfully\n");
+
+	return 0;
+}
+
+static const struct of_device_id imx_fsb_s400_fuse_match[] = {
+	{ .compatible = "fsl,imx8ulp-ocotp", },
+	{},
+};
+
+static struct platform_driver imx_fsb_s400_fuse_driver = {
+	.driver = {
+		.name = "fsl-ocotp-fsb-s400",
+		.of_match_table = imx_fsb_s400_fuse_match,
+	},
+	.probe = imx_fsb_s400_fuse_probe,
+};
+module_platform_driver(imx_fsb_s400_fuse_driver);
+
+MODULE_AUTHOR("Alice Guo <alice.guo@nxp.com>");
+MODULE_DESCRIPTION("i.MX FSB/S400-API ocotp fuse box driver");
+MODULE_LICENSE("GPL v2");
diff --git a/drivers/nvmem/imx-ocotp.c b/drivers/nvmem/imx-ocotp.c
index 7a1ebd6fd..e9fe26561 100644
--- a/drivers/nvmem/imx-ocotp.c
+++ b/drivers/nvmem/imx-ocotp.c
@@ -4,6 +4,8 @@
  *
  * Copyright (c) 2015 Pengutronix, Philipp Zabel <p.zabel@pengutronix.de>
  *
+ * Copyright 2019 NXP
+ *
  * Based on the barebox ocotp driver,
  * Copyright (c) 2010 Baruch Siach <baruch@tkos.co.il>,
  *	Orex Computed Radiography
@@ -12,6 +14,7 @@
  * Copyright (C) 2010-2013 Freescale Semiconductor, Inc
  */
 
+#include <linux/busfreq-imx.h>
 #include <linux/clk.h>
 #include <linux/device.h>
 #include <linux/io.h>
@@ -158,22 +161,29 @@ static int imx_ocotp_read(void *context, unsigned int offset,
 {
 	struct ocotp_priv *priv = context;
 	unsigned int count;
-	u32 *buf = val;
+	u8 *buf, *p;
 	int i, ret;
-	u32 index;
+	u32 index, num_bytes;
 
 	index = offset >> 2;
-	count = bytes >> 2;
+	num_bytes = round_up((offset % 4) + bytes, 4);
+	count = num_bytes >> 2;
 
 	if (count > (priv->params->nregs - index))
 		count = priv->params->nregs - index;
 
 	mutex_lock(&ocotp_mutex);
 
+	p = kzalloc(num_bytes, GFP_KERNEL);
+	if (!p)
+		return -ENOMEM;
+	buf = p;
+
 	ret = clk_prepare_enable(priv->clk);
 	if (ret < 0) {
 		mutex_unlock(&ocotp_mutex);
 		dev_err(priv->dev, "failed to prepare/enable ocotp clk\n");
+		kfree(p);
 		return ret;
 	}
 
@@ -184,7 +194,7 @@ static int imx_ocotp_read(void *context, unsigned int offset,
 	}
 
 	for (i = index; i < (index + count); i++) {
-		*buf++ = readl(priv->base + IMX_OCOTP_OFFSET_B0W0 +
+		*(u32 *)buf = readl(priv->base + IMX_OCOTP_OFFSET_B0W0 +
 			       i * IMX_OCOTP_OFFSET_PER_WORD);
 
 		/* 47.3.1.2
@@ -193,13 +203,21 @@ static int imx_ocotp_read(void *context, unsigned int offset,
 		 * software before any new write, read or reload access can be
 		 * issued
 		 */
-		if (*(buf - 1) == IMX_OCOTP_READ_LOCKED_VAL)
+		if (*((u32*)buf) == IMX_OCOTP_READ_LOCKED_VAL)
 			imx_ocotp_clr_err_if_set(priv);
+
+		buf += 4;
 	}
 
+	index = offset % 4;
+	memcpy(val, &p[index], bytes);
+
 read_end:
 	clk_disable_unprepare(priv->clk);
 	mutex_unlock(&ocotp_mutex);
+
+	kfree(p);
+
 	return ret;
 }
 
@@ -301,6 +319,8 @@ static int imx_ocotp_write(void *context, unsigned int offset, void *val,
 		return ret;
 	}
 
+	request_bus_freq(BUS_FREQ_HIGH);
+
 	/* Setup the write timing values */
 	priv->params->set_timing(priv);
 
@@ -438,6 +458,8 @@ static int imx_ocotp_write(void *context, unsigned int offset, void *val,
 		dev_err(priv->dev, "timeout during shadow register reload\n");
 
 write_end:
+	release_bus_freq(BUS_FREQ_HIGH);
+
 	clk_disable_unprepare(priv->clk);
 	mutex_unlock(&ocotp_mutex);
 	return ret < 0 ? ret : bytes;
@@ -447,7 +469,7 @@ static struct nvmem_config imx_ocotp_nvmem_config = {
 	.name = "imx-ocotp",
 	.read_only = false,
 	.word_size = 4,
-	.stride = 4,
+	.stride = 1,
 	.reg_read = imx_ocotp_read,
 	.reg_write = imx_ocotp_write,
 };
diff --git a/drivers/of/of_net.c b/drivers/of/of_net.c
index 6e4118215..20c3ae17f 100644
--- a/drivers/of/of_net.c
+++ b/drivers/of/of_net.c
@@ -116,6 +116,10 @@ const void *of_get_mac_address(struct device_node *np)
 	if (addr)
 		return addr;
 
+	addr = of_get_mac_addr(np, "nvmem-mac-address");
+	if (addr)
+		return addr;
+
 	return of_get_mac_addr_nvmem(np);
 }
 EXPORT_SYMBOL(of_get_mac_address);
diff --git a/drivers/of/of_reserved_mem.c b/drivers/of/of_reserved_mem.c
index aed83d13f..dea8c4fc4 100644
--- a/drivers/of/of_reserved_mem.c
+++ b/drivers/of/of_reserved_mem.c
@@ -22,27 +22,16 @@
 #include <linux/slab.h>
 #include <linux/memblock.h>
 
-#if defined(CONFIG_DEBUG_FS)
-#include <linux/debugfs.h>
-#include <linux/seq_file.h>
-#endif
-
 #define MAX_RESERVED_REGIONS	64
 static struct reserved_mem reserved_mem[MAX_RESERVED_REGIONS];
 static int reserved_mem_count;
-#if defined(CONFIG_DEBUG_FS)
-#define DT_RESERVED_MEM "dt_reserved_mem"
-static int dynamic_reserved_mem_count;
-static const char *dynamic_reserved_mem_array[MAX_RESERVED_REGIONS];
-static int cma_reserved_mem_count;
-static const char *cma_reserved_mem_array[MAX_RESERVED_REGIONS];
-#endif
-
-static int __init early_init_dt_alloc_reserved_memory_arch(phys_addr_t size,
-	phys_addr_t align, phys_addr_t start, phys_addr_t end, bool nomap,
-	phys_addr_t *res_base)
+
+static int __init early_init_dt_alloc_reserved_memory_arch(unsigned long node,
+	phys_addr_t size, phys_addr_t align, phys_addr_t start,
+	phys_addr_t end, bool nomap, phys_addr_t *res_base)
 {
 	phys_addr_t base;
+	phys_addr_t highmem_start = __pa(high_memory - 1) + 1;
 
 	end = !end ? MEMBLOCK_ALLOC_ANYWHERE : end;
 	align = !align ? SMP_CACHE_BYTES : align;
@@ -50,6 +39,24 @@ static int __init early_init_dt_alloc_reserved_memory_arch(phys_addr_t size,
 	if (!base)
 		return -ENOMEM;
 
+
+	/*
+	 * Sanity check for the cma reserved region:If the reserved region
+	 * crosses the low/high memory boundary, try to fix it up and then
+	 * fall back to allocate the cma region from the low mememory space.
+	 */
+
+	if (IS_ENABLED(CONFIG_CMA)
+	    && of_flat_dt_is_compatible(node, "shared-dma-pool")
+	    && of_get_flat_dt_prop(node, "reusable", NULL) && !nomap) {
+		if (base < highmem_start && (base + size) > highmem_start) {
+			base = memblock_find_in_range(start, highmem_start,
+						      size, align);
+			if (!base)
+				return -ENOMEM;
+		}
+	}
+
 	*res_base = base;
 	if (nomap)
 		return memblock_remove(base, size);
@@ -74,13 +81,6 @@ void __init fdt_reserved_mem_save_node(unsigned long node, const char *uname,
 	rmem->name = uname;
 	rmem->base = base;
 	rmem->size = size;
-#if defined(CONFIG_DEBUG_FS)
-	if ((of_get_flat_dt_prop(node, "reusable", NULL))
-		&& (cma_reserved_mem_count < MAX_RESERVED_REGIONS)) {
-		cma_reserved_mem_array[cma_reserved_mem_count] = uname;
-		cma_reserved_mem_count++;
-	}
-#endif
 
 	reserved_mem_count++;
 	return;
@@ -150,8 +150,8 @@ static int __init __reserved_mem_alloc_size(unsigned long node,
 			end = start + dt_mem_next_cell(dt_root_size_cells,
 						       &prop);
 
-			ret = early_init_dt_alloc_reserved_memory_arch(size,
-					align, start, end, nomap, &base);
+			ret = early_init_dt_alloc_reserved_memory_arch(node,
+					size, align, start, end, nomap, &base);
 			if (ret == 0) {
 				pr_debug("allocated memory for '%s' node: base %pa, size %lu MiB\n",
 					uname, &base,
@@ -162,8 +162,8 @@ static int __init __reserved_mem_alloc_size(unsigned long node,
 		}
 
 	} else {
-		ret = early_init_dt_alloc_reserved_memory_arch(size, align,
-							0, 0, nomap, &base);
+		ret = early_init_dt_alloc_reserved_memory_arch(node,
+					size, align, 0, 0, nomap, &base);
 		if (ret == 0)
 			pr_debug("allocated memory for '%s' node: base %pa, size %lu MiB\n",
 				uname, &base, (unsigned long)(size / SZ_1M));
@@ -174,13 +174,6 @@ static int __init __reserved_mem_alloc_size(unsigned long node,
 		return -ENOMEM;
 	}
 
-#if defined(CONFIG_DEBUG_FS)
-	if (dynamic_reserved_mem_count < MAX_RESERVED_REGIONS) {
-		dynamic_reserved_mem_array[dynamic_reserved_mem_count] = uname;
-		dynamic_reserved_mem_count++;
-	}
-#endif
-
 	*res_base = base;
 	*res_size = size;
 
@@ -464,78 +457,3 @@ struct reserved_mem *of_reserved_mem_lookup(struct device_node *np)
 	return NULL;
 }
 EXPORT_SYMBOL_GPL(of_reserved_mem_lookup);
-
-#if defined(CONFIG_DEBUG_FS)
-static int dt_reserved_memory_debug_show(struct seq_file *m, void *private)
-{
-	struct reserved_mem *dt_reserved_mem = m->private;
-	struct reserved_mem *rmem = NULL;
-	int i = 0;
-	int j = 0;
-	int cma = 0;
-	int dynamic = 0;
-
-	seq_printf(m, "  num [start            ....              end]      [size]"
-		   "       [d/s]     [cma]       [name]\n");
-
-	for (i = 0; i < reserved_mem_count; i++) {
-		cma = 0;
-		dynamic = 0;
-		rmem = &(dt_reserved_mem[i]);
-
-		/* find out dynamic reserved memory node  */
-		for (j = 0; j < dynamic_reserved_mem_count; j++) {
-			if (!strcmp(rmem->name, dynamic_reserved_mem_array[j])) {
-				dynamic = 1;
-				break;
-			}
-		}
-
-		/* find out cma reserved memory node */
-		for (j = 0; j < cma_reserved_mem_count; j++) {
-			if (!strcmp(rmem->name, cma_reserved_mem_array[j])) {
-				cma = 1;
-				break;
-			}
-		}
-
-		seq_printf(m, "%4d: [0x%016llx..0x%016llx]  %8llukB   %8s %8s        %8s\n",
-				i,
-				(unsigned long long)rmem->base,
-				(unsigned long long)(rmem->base + rmem->size - 1),
-				(unsigned long long)rmem->size / SZ_1K,
-				(dynamic == 1) ? "d" : "s",
-				(cma == 1) ? "y" : "n",
-				rmem->name);
-	}
-
-	return 0;
-}
-
-static int dt_reserved_memory_debug_open(struct inode *inode, struct file *file)
-{
-	return single_open(file, dt_reserved_memory_debug_show, inode->i_private);
-}
-
-static const struct file_operations dt_reserved_memory_debug_fops = {
-	.open = dt_reserved_memory_debug_open,
-	.read = seq_read,
-	.llseek = seq_lseek,
-	.release = single_release,
-};
-
-static int __init dt_reserved_memory_init_debugfs(void)
-{
-	struct dentry *root = debugfs_create_dir(DT_RESERVED_MEM, NULL);
-	if (!root)
-		return -ENXIO;
-	debugfs_create_file("dt_reserved_memory",
-			    S_IRUGO,
-			    root,
-			    reserved_mem,
-			    &dt_reserved_memory_debug_fops);
-
-	return 0;
-}
-__initcall(dt_reserved_memory_init_debugfs);
-#endif /* CONFIG_DEBUG_FS */
diff --git a/drivers/pci/controller/dwc/pci-imx6.c b/drivers/pci/controller/dwc/pci-imx6.c
index 5cf1ef12f..d3ca0d9fe 100644
--- a/drivers/pci/controller/dwc/pci-imx6.c
+++ b/drivers/pci/controller/dwc/pci-imx6.c
@@ -8,6 +8,7 @@
  * Author: Sean Cross <xobs@kosagi.com>
  */
 
+#include <dt-bindings/soc/imx8_hsio.h>
 #include <linux/bitfield.h>
 #include <linux/clk.h>
 #include <linux/delay.h>
@@ -17,9 +18,11 @@
 #include <linux/mfd/syscon/imx6q-iomuxc-gpr.h>
 #include <linux/mfd/syscon/imx7-iomuxc-gpr.h>
 #include <linux/module.h>
+#include <linux/of_address.h>
 #include <linux/of_gpio.h>
 #include <linux/of_device.h>
 #include <linux/of_address.h>
+#include <linux/of_pci.h>
 #include <linux/pci.h>
 #include <linux/platform_device.h>
 #include <linux/regmap.h>
@@ -28,17 +31,49 @@
 #include <linux/signal.h>
 #include <linux/types.h>
 #include <linux/interrupt.h>
+#include <linux/phy/phy.h>
 #include <linux/reset.h>
 #include <linux/pm_domain.h>
 #include <linux/pm_runtime.h>
+#include <linux/busfreq-imx.h>
+#include "../../pci.h"
 
 #include "pcie-designware.h"
 
+#define IMX8MQ_PCIE_LINK_CAP_REG_OFFSET		0x7c
+#define IMX8MQ_PCIE_LINK_CAP_L1EL_64US		GENMASK(18, 17)
+#define IMX8MQ_PCIE_L1SUB_CTRL1_REG_EN_MASK	0xf
 #define IMX8MQ_GPR_PCIE_REF_USE_PAD		BIT(9)
 #define IMX8MQ_GPR_PCIE_CLK_REQ_OVERRIDE_EN	BIT(10)
 #define IMX8MQ_GPR_PCIE_CLK_REQ_OVERRIDE	BIT(11)
+#define IMX8MQ_GPR_PCIE_VREG_BYPASS		BIT(12)
 #define IMX8MQ_GPR12_PCIE2_CTRL_DEVICE_TYPE	GENMASK(11, 8)
 #define IMX8MQ_PCIE2_BASE_ADDR			0x33c00000
+#define IMX8_HSIO_PCIEB_BASE_ADDR		0x5f010000
+#define IMX8MP_GPR_REG0				0x0
+#define IMX8MP_GPR_REG0_CLK_MOD_EN		BIT(0)
+#define IMX8MP_GPR_REG0_PHY_APB_RST		BIT(4)
+#define IMX8MP_GPR_REG0_PHY_INIT_RST		BIT(5)
+#define IMX8MP_GPR_REG1				0x4
+#define IMX8MP_GPR_REG1_PM_EN_CORE_CLK		BIT(0)
+#define IMX8MP_GPR_REG1_PLL_LOCK		BIT(13)
+#define IMX8MP_GPR_REG2				0x8
+#define IMX8MP_GPR_REG2_P_PLL_MASK		GENMASK(5, 0)
+#define IMX8MP_GPR_REG2_M_PLL_MASK		GENMASK(15, 6)
+#define IMX8MP_GPR_REG2_S_PLL_MASK		GENMASK(18, 16)
+#define IMX8MP_GPR_REG2_P_PLL			(0xc << 0)
+#define IMX8MP_GPR_REG2_M_PLL			(0x320 << 6)
+#define IMX8MP_GPR_REG2_S_PLL			(0x4 << 16)
+#define IMX8MP_GPR_REG3				0xc
+#define IMX8MP_GPR_REG3_PLL_CKE			BIT(17)
+#define IMX8MP_GPR_REG3_PLL_RST			BIT(31)
+#define IMX8MP_GPR_PCIE_SSC_EN			BIT(16)
+#define IMX8MP_GPR_PCIE_PWR_OFF			BIT(17)
+#define IMX8MP_GPR_PCIE_CMN_RSTN		BIT(18)
+#define IMX8MP_GPR_PCIE_AUX_EN			BIT(19)
+#define IMX8MP_GPR_PCIE_REF_SEL_MASK		GENMASK(25, 24)
+#define IMX8MP_GPR_PCIE_REF_PLL_SYS		GENMASK(25, 24)
+#define IMX8MP_GPR_PCIE_REF_EXT_OSC		BIT(25)
 
 #define to_imx6_pcie(x)	dev_get_drvdata((x)->dev)
 
@@ -48,54 +83,100 @@ enum imx6_pcie_variants {
 	IMX6QP,
 	IMX7D,
 	IMX8MQ,
+	IMX8MM,
+	IMX8QM,
+	IMX8QXP,
+	IMX8MP,
+	IMX8QXP_EP,
+	IMX8QM_EP,
+	IMX8MQ_EP,
+	IMX8MM_EP,
+	IMX8MP_EP,
+	IMX6SX_EP,
+	IMX7D_EP,
+	IMX6Q_EP,
+	IMX6QP_EP,
 };
 
 #define IMX6_PCIE_FLAG_IMX6_PHY			BIT(0)
 #define IMX6_PCIE_FLAG_IMX6_SPEED_CHANGE	BIT(1)
 #define IMX6_PCIE_FLAG_SUPPORTS_SUSPEND		BIT(2)
+#define IMX6_PCIE_FLAG_IMX6_CPU_ADDR_FIXUP	BIT(3)
+#define IMX6_PCIE_FLAG_SUPPORTS_L1SS		BIT(4)
 
 struct imx6_pcie_drvdata {
 	enum imx6_pcie_variants variant;
+	enum dw_pcie_device_mode mode;
 	u32 flags;
 	int dbi_length;
 };
 
 struct imx6_pcie {
 	struct dw_pcie		*pci;
+	int			clkreq_gpio;
+	int			dis_gpio;
 	int			reset_gpio;
 	bool			gpio_active_high;
 	struct clk		*pcie_bus;
 	struct clk		*pcie_phy;
+	struct clk		*pcie_phy_pclk;
+	struct clk		*pcie_per;
+	struct clk		*pciex2_per;
 	struct clk		*pcie_inbound_axi;
 	struct clk		*pcie;
 	struct clk		*pcie_aux;
+	struct clk		*phy_per;
+	struct clk		*misc_per;
 	struct regmap		*iomuxc_gpr;
 	u32			controller_id;
 	struct reset_control	*pciephy_reset;
+	struct reset_control	*pciephy_perst;
 	struct reset_control	*apps_reset;
 	struct reset_control	*turnoff_reset;
+	struct reset_control	*clkreq_reset;
 	u32			tx_deemph_gen1;
 	u32			tx_deemph_gen2_3p5db;
 	u32			tx_deemph_gen2_6db;
 	u32			tx_swing_full;
 	u32			tx_swing_low;
+	u32			hsio_cfg;
+	u32			ext_osc;
+	u32			local_addr;
+	u32			l1ss_clkreq;
 	struct regulator	*vpcie;
+	struct regulator	*vph;
 	void __iomem		*phy_base;
+	void __iomem		*hsmix_base;
 
 	/* power domain for pcie */
 	struct device		*pd_pcie;
+	/* power domain for pcie csr access */
+	struct device		*pd_pcie_per;
 	/* power domain for pcie phy */
 	struct device		*pd_pcie_phy;
+	/* power domain for hsio gpio used by pcie */
+	struct device		*pd_hsio_gpio;
+	struct device_link	*pd_link;
+	struct device_link	*pd_per_link;
+	struct device_link	*pd_phy_link;
+	struct device_link	*pd_hsio_link;
+
 	const struct imx6_pcie_drvdata *drvdata;
+	struct regulator	*epdev_on;
+	struct phy		*phy;
 };
 
 /* Parameters for the waiting for PCIe PHY PLL to lock on i.MX7 */
+#define PHY_PLL_LOCK_WAIT_MAX_RETRIES	2000
+#define PHY_PLL_LOCK_WAIT_USLEEP_MIN	50
 #define PHY_PLL_LOCK_WAIT_USLEEP_MAX	200
 #define PHY_PLL_LOCK_WAIT_TIMEOUT	(2000 * PHY_PLL_LOCK_WAIT_USLEEP_MAX)
 
 /* PCIe Port Logic registers (memory-mapped) */
 #define PL_OFFSET 0x700
 
+#define PCIE_PHY_DEBUG_R1 (PL_OFFSET + 0x2c)
+
 #define PCIE_PHY_CTRL (PL_OFFSET + 0x114)
 #define PCIE_PHY_CTRL_DATA(x)		FIELD_PREP(GENMASK(15, 0), (x))
 #define PCIE_PHY_CTRL_CAP_ADR		BIT(16)
@@ -117,19 +198,11 @@ struct imx6_pcie {
 #define  PCIE_PHY_MPLL_MULTIPLIER_MASK		0x7f
 #define  PCIE_PHY_MPLL_MULTIPLIER_OVRD		BIT(9)
 
-#define PCIE_PHY_RX_ASIC_OUT 0x100D
-#define PCIE_PHY_RX_ASIC_OUT_VALID	(1 << 0)
-
 /* iMX7 PCIe PHY registers */
 #define PCIE_PHY_CMN_REG4		0x14
 /* These are probably the bits that *aren't* DCC_FB_EN */
 #define PCIE_PHY_CMN_REG4_DCC_FB_EN	0x29
 
-#define PCIE_PHY_CMN_REG15	        0x54
-#define PCIE_PHY_CMN_REG15_DLY_4	BIT(2)
-#define PCIE_PHY_CMN_REG15_PLL_PD	BIT(5)
-#define PCIE_PHY_CMN_REG15_OVRD_PLL_PD	BIT(7)
-
 #define PCIE_PHY_CMN_REG24		0x90
 #define PCIE_PHY_CMN_REG24_RX_EQ	BIT(6)
 #define PCIE_PHY_CMN_REG24_RX_EQ_SEL	BIT(3)
@@ -137,10 +210,168 @@ struct imx6_pcie {
 #define PCIE_PHY_CMN_REG26		0x98
 #define PCIE_PHY_CMN_REG26_ATT_MODE	0xBC
 
+#define PCIE_PHY_CMN_REG62			0x188
+#define PCIE_PHY_CMN_REG62_PLL_CLK_OUT		0x08
+#define PCIE_PHY_CMN_REG64			0x190
+#define PCIE_PHY_CMN_REG64_AUX_RX_TX_TERM	0x8C
+#define PCIE_PHY_CMN_REG75			0x1D4
+#define PCIE_PHY_CMN_REG75_PLL_DONE		0x3
+#define PCIE_PHY_TRSV_REG5			0x414
+#define PCIE_PHY_TRSV_REG5_GEN1_DEEMP		0x2D
+#define PCIE_PHY_TRSV_REG6			0x418
+#define PCIE_PHY_TRSV_REG6_GEN2_DEEMP		0xF
+
 #define PHY_RX_OVRD_IN_LO 0x1005
 #define PHY_RX_OVRD_IN_LO_RX_DATA_EN		BIT(5)
 #define PHY_RX_OVRD_IN_LO_RX_PLL_EN		BIT(3)
 
+/* iMX8 HSIO registers */
+#define IMX8QM_PHYX2_LPCG_OFFSET		0x00000
+#define	IMX8QM_PHYX2_LPCG_PCLK0_MASK		GENMASK(17, 16)
+#define	IMX8QM_PHYX2_LPCG_PCLK1_MASK		GENMASK(21, 20)
+#define IMX8QM_CSR_PHYX2_OFFSET			0x90000
+#define IMX8QM_CSR_PHYX1_OFFSET			0xA0000
+#define IMX8QM_CSR_PHYX_STTS0_OFFSET		0x4
+#define IMX8QM_CSR_PCIEA_OFFSET			0xB0000
+#define IMX8QM_CSR_PCIEB_OFFSET			0xC0000
+#define IMX8QM_CSR_PCIE_CTRL1_OFFSET		0x4
+#define IMX8QM_CSR_PCIE_CTRL2_OFFSET		0x8
+#define IMX8QM_CSR_PCIE_STTS0_OFFSET		0xC
+#define IMX8QM_CSR_MISC_OFFSET			0xE0000
+
+#define IMX8QM_CTRL_LTSSM_ENABLE		BIT(4)
+#define IMX8QM_CTRL_READY_ENTR_L23		BIT(5)
+#define IMX8QM_CTRL_PM_XMT_TURNOFF		BIT(9)
+#define IMX8QM_CTRL_BUTTON_RST_N		BIT(21)
+#define IMX8QM_CTRL_PERST_N			BIT(22)
+#define IMX8QM_CTRL_POWER_UP_RST_N		BIT(23)
+
+#define IMX8QM_CTRL_STTS0_PM_LINKST_IN_L2	BIT(13)
+#define IMX8QM_CTRL_STTS0_PM_REQ_CORE_RST	BIT(19)
+#define IMX8QM_STTS0_LANE0_TX_PLL_LOCK		BIT(4)
+#define IMX8QM_STTS0_LANE1_TX_PLL_LOCK		BIT(12)
+
+#define IMX8QM_PCIE_TYPE_MASK			GENMASK(27, 24)
+
+#define IMX8QM_PHYX2_CTRL0_APB_MASK		0x3
+#define IMX8QM_PHY_APB_RSTN_0			BIT(0)
+#define IMX8QM_PHY_APB_RSTN_1			BIT(1)
+
+#define IMX8QM_MISC_IOB_RXENA			BIT(0)
+#define IMX8QM_MISC_IOB_TXENA			BIT(1)
+#define IMX8QM_CSR_MISC_IOB_A_0_TXOE		BIT(2)
+#define IMX8QM_CSR_MISC_IOB_A_0_M1M0_MASK	(0x3 << 3)
+#define IMX8QM_CSR_MISC_IOB_A_0_M1M0_2		BIT(4)
+#define IMX8QM_MISC_PHYX1_EPCS_SEL		BIT(12)
+#define IMX8QM_MISC_PCIE_AB_SELECT		BIT(13)
+#define IMX8QM_MISC_CLKREQ_1			BIT(22)
+#define IMX8QM_MISC_CLKREQ_0			BIT(23)
+#define IMX8QM_MISC_CLKREQ_OVERRIDE_EN_1	BIT(24)
+#define IMX8QM_MISC_CLKREQ_OVERRIDE_EN_0	BIT(25)
+
+#define IMX8MM_GPR_PCIE_REF_CLK_SEL		(0x3 << 24)
+#define IMX8MM_GPR_PCIE_REF_CLK_PLL		(0x3 << 24)
+#define IMX8MM_GPR_PCIE_REF_CLK_EXT		(0x2 << 24)
+#define IMX8MM_GPR_PCIE_AUX_EN			BIT(19)
+#define IMX8MM_GPR_PCIE_CMN_RST			BIT(18)
+#define IMX8MM_GPR_PCIE_POWER_OFF		BIT(17)
+#define IMX8MM_GPR_PCIE_SSC_EN			BIT(16)
+
+static int imx6_pcie_cz_enabled;
+static void imx6_pcie_ltssm_disable(struct device *dev);
+
+static bool imx6_pcie_readable_reg(struct device *dev, unsigned int reg)
+{
+	enum imx6_pcie_variants variant;
+	struct imx6_pcie *imx6_pcie = dev_get_drvdata(dev);
+
+	variant = imx6_pcie->drvdata->variant;
+	if (variant == IMX8QXP || variant == IMX8QXP_EP) {
+		switch (reg) {
+		case IMX8QM_CSR_PHYX1_OFFSET:
+		case IMX8QM_CSR_PCIEB_OFFSET:
+		case IMX8QM_CSR_MISC_OFFSET:
+		case IMX8QM_CSR_PHYX1_OFFSET + IMX8QM_CSR_PHYX_STTS0_OFFSET:
+		case IMX8QM_CSR_PCIEB_OFFSET + IMX8QM_CSR_PCIE_CTRL1_OFFSET:
+		case IMX8QM_CSR_PCIEB_OFFSET + IMX8QM_CSR_PCIE_CTRL2_OFFSET:
+		case IMX8QM_CSR_PCIEB_OFFSET + IMX8QM_CSR_PCIE_STTS0_OFFSET:
+			return true;
+
+		default:
+			return false;
+		}
+	} else {
+		switch (reg) {
+		case IMX8QM_PHYX2_LPCG_OFFSET:
+		case IMX8QM_CSR_PHYX2_OFFSET:
+		case IMX8QM_CSR_PHYX1_OFFSET:
+		case IMX8QM_CSR_PCIEA_OFFSET:
+		case IMX8QM_CSR_PCIEB_OFFSET:
+		case IMX8QM_CSR_MISC_OFFSET:
+		case IMX8QM_CSR_PHYX2_OFFSET + IMX8QM_CSR_PHYX_STTS0_OFFSET:
+		case IMX8QM_CSR_PHYX1_OFFSET + IMX8QM_CSR_PHYX_STTS0_OFFSET:
+		case IMX8QM_CSR_PCIEA_OFFSET + IMX8QM_CSR_PCIE_CTRL1_OFFSET:
+		case IMX8QM_CSR_PCIEA_OFFSET + IMX8QM_CSR_PCIE_CTRL2_OFFSET:
+		case IMX8QM_CSR_PCIEA_OFFSET + IMX8QM_CSR_PCIE_STTS0_OFFSET:
+		case IMX8QM_CSR_PCIEB_OFFSET + IMX8QM_CSR_PCIE_CTRL1_OFFSET:
+		case IMX8QM_CSR_PCIEB_OFFSET + IMX8QM_CSR_PCIE_CTRL2_OFFSET:
+		case IMX8QM_CSR_PCIEB_OFFSET + IMX8QM_CSR_PCIE_STTS0_OFFSET:
+			return true;
+		default:
+			return false;
+		}
+	}
+}
+
+static bool imx6_pcie_writeable_reg(struct device *dev, unsigned int reg)
+{
+	enum imx6_pcie_variants variant;
+	struct imx6_pcie *imx6_pcie = dev_get_drvdata(dev);
+
+	variant = imx6_pcie->drvdata->variant;
+	if (variant == IMX8QXP || variant == IMX8QXP_EP) {
+		switch (reg) {
+		case IMX8QM_CSR_PHYX1_OFFSET:
+		case IMX8QM_CSR_PCIEB_OFFSET:
+		case IMX8QM_CSR_MISC_OFFSET:
+		case IMX8QM_CSR_PCIEB_OFFSET + IMX8QM_CSR_PCIE_CTRL1_OFFSET:
+		case IMX8QM_CSR_PCIEB_OFFSET + IMX8QM_CSR_PCIE_CTRL2_OFFSET:
+			return true;
+
+		default:
+			return false;
+		}
+	} else {
+		switch (reg) {
+		case IMX8QM_PHYX2_LPCG_OFFSET:
+		case IMX8QM_CSR_PHYX2_OFFSET:
+		case IMX8QM_CSR_PHYX1_OFFSET:
+		case IMX8QM_CSR_PCIEA_OFFSET:
+		case IMX8QM_CSR_PCIEB_OFFSET:
+		case IMX8QM_CSR_MISC_OFFSET:
+		case IMX8QM_CSR_PCIEA_OFFSET + IMX8QM_CSR_PCIE_CTRL1_OFFSET:
+		case IMX8QM_CSR_PCIEA_OFFSET + IMX8QM_CSR_PCIE_CTRL2_OFFSET:
+		case IMX8QM_CSR_PCIEB_OFFSET + IMX8QM_CSR_PCIE_CTRL1_OFFSET:
+		case IMX8QM_CSR_PCIEB_OFFSET + IMX8QM_CSR_PCIE_CTRL2_OFFSET:
+			return true;
+		default:
+			return false;
+		}
+	}
+}
+
+static const struct regmap_config imx6_pcie_regconfig = {
+	.max_register = IMX8QM_CSR_MISC_OFFSET,
+	.reg_bits = 32,
+	.val_bits = 32,
+	.reg_stride = 4,
+	.val_format_endian = REGMAP_ENDIAN_NATIVE,
+	.num_reg_defaults_raw =  IMX8QM_CSR_MISC_OFFSET / sizeof(uint32_t) + 1,
+	.readable_reg = imx6_pcie_readable_reg,
+	.writeable_reg = imx6_pcie_writeable_reg,
+	.cache_type = REGCACHE_NONE,
+};
+
 static int pcie_phy_poll_ack(struct imx6_pcie *imx6_pcie, bool exp_val)
 {
 	struct dw_pcie *pci = imx6_pcie->pci;
@@ -292,8 +523,15 @@ static int imx6q_pcie_abort_handler(unsigned long addr,
 		unsigned int fsr, struct pt_regs *regs)
 {
 	unsigned long pc = instruction_pointer(regs);
-	unsigned long instr = *(unsigned long *)pc;
-	int reg = (instr >> 12) & 15;
+	unsigned long instr;
+	int reg;
+
+	/* if the abort from user-space, just return and report it */
+	if (user_mode(regs))
+		return 1;
+
+	instr = *(unsigned long *)pc;
+	reg = (instr >> 12) & 15;
 
 	/*
 	 * If the instruction being executed was a read,
@@ -322,10 +560,43 @@ static int imx6q_pcie_abort_handler(unsigned long addr,
 }
 #endif
 
+static void imx6_pcie_detach_pd(struct device *dev)
+{
+	struct imx6_pcie *imx6_pcie = dev_get_drvdata(dev);
+
+	if (imx6_pcie->pd_hsio_link && !IS_ERR(imx6_pcie->pd_hsio_link))
+		device_link_del(imx6_pcie->pd_hsio_link);
+	if (imx6_pcie->pd_hsio_gpio && !IS_ERR(imx6_pcie->pd_hsio_gpio))
+		dev_pm_domain_detach(imx6_pcie->pd_hsio_gpio, true);
+	if (imx6_pcie->pd_phy_link && !IS_ERR(imx6_pcie->pd_phy_link))
+		device_link_del(imx6_pcie->pd_phy_link);
+	if (imx6_pcie->pd_pcie_phy && !IS_ERR(imx6_pcie->pd_pcie_phy))
+		dev_pm_domain_detach(imx6_pcie->pd_pcie_phy, true);
+	if (imx6_pcie->pd_per_link && !IS_ERR(imx6_pcie->pd_per_link))
+		device_link_del(imx6_pcie->pd_per_link);
+	if (imx6_pcie->pd_pcie_per && !IS_ERR(imx6_pcie->pd_pcie_per))
+		dev_pm_domain_detach(imx6_pcie->pd_pcie_per, true);
+	if (imx6_pcie->pd_link && !IS_ERR(imx6_pcie->pd_link))
+		device_link_del(imx6_pcie->pd_link);
+	if (imx6_pcie->pd_pcie && !IS_ERR(imx6_pcie->pd_pcie))
+		dev_pm_domain_detach(imx6_pcie->pd_pcie, true);
+
+	imx6_pcie->pd_hsio_gpio = NULL;
+	imx6_pcie->pd_hsio_link = NULL;
+	imx6_pcie->pd_pcie_phy = NULL;
+	imx6_pcie->pd_phy_link = NULL;
+	imx6_pcie->pd_pcie_per = NULL;
+	imx6_pcie->pd_per_link = NULL;
+	imx6_pcie->pd_pcie = NULL;
+	imx6_pcie->pd_link = NULL;
+}
+
 static int imx6_pcie_attach_pd(struct device *dev)
 {
+	int ret = 0;
 	struct imx6_pcie *imx6_pcie = dev_get_drvdata(dev);
 	struct device_link *link;
+	struct device *pd_dev;
 
 	/* Do nothing when in a single power domain */
 	if (dev->pm_domain)
@@ -344,11 +615,15 @@ static int imx6_pcie_attach_pd(struct device *dev)
 	if (!link) {
 		dev_err(dev, "Failed to add device_link to pcie pd.\n");
 		return -EINVAL;
+	} else {
+		imx6_pcie->pd_link = link;
 	}
 
 	imx6_pcie->pd_pcie_phy = dev_pm_domain_attach_by_name(dev, "pcie_phy");
-	if (IS_ERR(imx6_pcie->pd_pcie_phy))
-		return PTR_ERR(imx6_pcie->pd_pcie_phy);
+	if (IS_ERR(imx6_pcie->pd_pcie_phy)) {
+		ret = PTR_ERR(imx6_pcie->pd_pcie_phy);
+		goto err_ret;
+	}
 
 	link = device_link_add(dev, imx6_pcie->pd_pcie_phy,
 			DL_FLAG_STATELESS |
@@ -356,56 +631,77 @@ static int imx6_pcie_attach_pd(struct device *dev)
 			DL_FLAG_RPM_ACTIVE);
 	if (!link) {
 		dev_err(dev, "Failed to add device_link to pcie_phy pd.\n");
-		return -EINVAL;
+		ret = -EINVAL;
+		goto err_ret;
+	} else {
+		imx6_pcie->pd_phy_link = link;
 	}
 
-	return 0;
-}
+	switch (imx6_pcie->drvdata->variant) {
+	case IMX8QM:
+	case IMX8QM_EP:
+		/*
+		 * PCIA CSR would be touched during the initialization of the
+		 * PCIEB of 8QM.
+		 * Enable the PCIEA PD for this case here.
+		 */
+		if (imx6_pcie->controller_id) {
+			pd_dev = dev_pm_domain_attach_by_name(dev, "pcie_per");
+			if (IS_ERR(pd_dev)) {
+				ret = PTR_ERR(pd_dev);
+				goto err_ret;
+			} else {
+				imx6_pcie->pd_pcie_per = pd_dev;
+			}
+			link = device_link_add(dev, imx6_pcie->pd_pcie_per,
+					DL_FLAG_STATELESS |
+					DL_FLAG_PM_RUNTIME |
+					DL_FLAG_RPM_ACTIVE);
+			if (!link) {
+				dev_err(dev, "Failed to link pcie_per pd\n");
+				ret = -EINVAL;
+				goto err_ret;
+			} else {
+				imx6_pcie->pd_per_link = link;
+			}
+		}
+		fallthrough;
+	case IMX8QXP:
+	case IMX8QXP_EP:
+		pd_dev = dev_pm_domain_attach_by_name(dev, "hsio_gpio");
+		if (IS_ERR(pd_dev)) {
+			ret = PTR_ERR(pd_dev);
+			goto err_ret;
+		} else {
+			imx6_pcie->pd_hsio_gpio = pd_dev;
+		}
 
-static void imx6_pcie_assert_core_reset(struct imx6_pcie *imx6_pcie)
-{
-	struct device *dev = imx6_pcie->pci->dev;
+		link = device_link_add(dev, imx6_pcie->pd_hsio_gpio,
+				DL_FLAG_STATELESS |
+				DL_FLAG_PM_RUNTIME |
+				DL_FLAG_RPM_ACTIVE);
+		if (!link) {
+			dev_err(dev, "Failed to add device_link to hsio_gpio pd.\n");
+			ret = -EINVAL;
+			goto err_ret;
+		} else {
+			imx6_pcie->pd_hsio_link = link;
+		}
 
-	switch (imx6_pcie->drvdata->variant) {
-	case IMX7D:
-	case IMX8MQ:
-		reset_control_assert(imx6_pcie->pciephy_reset);
-		reset_control_assert(imx6_pcie->apps_reset);
-		break;
-	case IMX6SX:
-		regmap_update_bits(imx6_pcie->iomuxc_gpr, IOMUXC_GPR12,
-				   IMX6SX_GPR12_PCIE_TEST_POWERDOWN,
-				   IMX6SX_GPR12_PCIE_TEST_POWERDOWN);
-		/* Force PCIe PHY reset */
-		regmap_update_bits(imx6_pcie->iomuxc_gpr, IOMUXC_GPR5,
-				   IMX6SX_GPR5_PCIE_BTNRST_RESET,
-				   IMX6SX_GPR5_PCIE_BTNRST_RESET);
-		break;
-	case IMX6QP:
-		regmap_update_bits(imx6_pcie->iomuxc_gpr, IOMUXC_GPR1,
-				   IMX6Q_GPR1_PCIE_SW_RST,
-				   IMX6Q_GPR1_PCIE_SW_RST);
 		break;
-	case IMX6Q:
-		regmap_update_bits(imx6_pcie->iomuxc_gpr, IOMUXC_GPR1,
-				   IMX6Q_GPR1_PCIE_TEST_PD, 1 << 18);
-		regmap_update_bits(imx6_pcie->iomuxc_gpr, IOMUXC_GPR1,
-				   IMX6Q_GPR1_PCIE_REF_CLK_EN, 0 << 16);
+	default:
 		break;
 	}
 
-	if (imx6_pcie->vpcie && regulator_is_enabled(imx6_pcie->vpcie) > 0) {
-		int ret = regulator_disable(imx6_pcie->vpcie);
+	return 0;
 
-		if (ret)
-			dev_err(dev, "failed to disable vpcie regulator: %d\n",
-				ret);
-	}
+err_ret:
+	imx6_pcie_detach_pd(dev);
+	return ret;
 }
 
 static unsigned int imx6_pcie_grp_offset(const struct imx6_pcie *imx6_pcie)
 {
-	WARN_ON(imx6_pcie->drvdata->variant != IMX8MQ);
 	return imx6_pcie->controller_id == 1 ? IOMUXC_GPR16 : IOMUXC_GPR14;
 }
 
@@ -418,6 +714,7 @@ static int imx6_pcie_enable_ref_clk(struct imx6_pcie *imx6_pcie)
 
 	switch (imx6_pcie->drvdata->variant) {
 	case IMX6SX:
+	case IMX6SX_EP:
 		ret = clk_prepare_enable(imx6_pcie->pcie_inbound_axi);
 		if (ret) {
 			dev_err(dev, "unable to enable pcie_axi clock\n");
@@ -429,6 +726,8 @@ static int imx6_pcie_enable_ref_clk(struct imx6_pcie *imx6_pcie)
 		break;
 	case IMX6QP:
 	case IMX6Q:
+	case IMX6QP_EP:
+	case IMX6Q_EP:
 		/* power up core phy and enable ref clock */
 		regmap_update_bits(imx6_pcie->iomuxc_gpr, IOMUXC_GPR1,
 				   IMX6Q_GPR1_PCIE_TEST_PD, 0 << 18);
@@ -443,8 +742,14 @@ static int imx6_pcie_enable_ref_clk(struct imx6_pcie *imx6_pcie)
 				   IMX6Q_GPR1_PCIE_REF_CLK_EN, 1 << 16);
 		break;
 	case IMX7D:
+	case IMX7D_EP:
 		break;
 	case IMX8MQ:
+	case IMX8MM:
+	case IMX8MP:
+	case IMX8MQ_EP:
+	case IMX8MM_EP:
+	case IMX8MP_EP:
 		ret = clk_prepare_enable(imx6_pcie->pcie_aux);
 		if (ret) {
 			dev_err(dev, "unable to enable pcie_aux clock\n");
@@ -463,8 +768,65 @@ static int imx6_pcie_enable_ref_clk(struct imx6_pcie *imx6_pcie)
 				   IMX8MQ_GPR_PCIE_CLK_REQ_OVERRIDE_EN,
 				   IMX8MQ_GPR_PCIE_CLK_REQ_OVERRIDE_EN);
 		break;
+	case IMX8QXP:
+	case IMX8QXP_EP:
+	case IMX8QM:
+	case IMX8QM_EP:
+		ret = clk_prepare_enable(imx6_pcie->pcie_inbound_axi);
+		if (ret) {
+			dev_err(dev, "unable to enable pcie_axi clock\n");
+			return ret;
+		}
+		ret = clk_prepare_enable(imx6_pcie->pcie_per);
+		if (ret) {
+			dev_err(dev, "unable to enable pcie_per clock\n");
+			goto err_pcie_per;
+		}
+
+		ret = clk_prepare_enable(imx6_pcie->phy_per);
+		if (unlikely(ret)) {
+			dev_err(dev, "unable to enable phy per clock\n");
+			goto err_phy_per;
+		}
+		ret = clk_prepare_enable(imx6_pcie->misc_per);
+		if (unlikely(ret)) {
+			dev_err(dev, "unable to enable misc per clock\n");
+			goto err_misc_per;
+		}
+		/*
+		 * PCIA CSR would be touched during the initialization of the
+		 * PCIEB of 8QM.
+		 * Enable the PCIEA peripheral clock for this case here.
+		 */
+		if (imx6_pcie->drvdata->variant == IMX8QM
+				&& imx6_pcie->controller_id == 1) {
+			ret = clk_prepare_enable(imx6_pcie->pcie_phy_pclk);
+			if (unlikely(ret)) {
+				dev_err(dev, "can't enable pciephyp clock\n");
+				goto err_pcie_phy_pclk;
+			}
+			ret = clk_prepare_enable(imx6_pcie->pciex2_per);
+			if (unlikely(ret)) {
+				dev_err(dev, "can't enable pciex2 per clock\n");
+				goto err_pciex2_per;
+			}
+		}
+		break;
+	default:
+		break;
 	}
 
+	return ret;
+err_pciex2_per:
+	clk_disable_unprepare(imx6_pcie->pcie_phy_pclk);
+err_pcie_phy_pclk:
+	clk_disable_unprepare(imx6_pcie->misc_per);
+err_misc_per:
+	clk_disable_unprepare(imx6_pcie->phy_per);
+err_phy_per:
+	clk_disable_unprepare(imx6_pcie->pcie_per);
+err_pcie_per:
+	clk_disable_unprepare(imx6_pcie->pcie_inbound_axi);
 	return ret;
 }
 
@@ -480,160 +842,825 @@ static void imx7d_pcie_wait_for_phy_pll_lock(struct imx6_pcie *imx6_pcie)
 				     PHY_PLL_LOCK_WAIT_TIMEOUT))
 		dev_err(dev, "PCIe PLL lock timeout\n");
 }
-
-static void imx6_pcie_deassert_core_reset(struct imx6_pcie *imx6_pcie)
+static void imx8_pcie_wait_for_phy_pll_lock(struct imx6_pcie *imx6_pcie)
 {
+	u32 val, retries = 0, tmp = 0, orig = 0;
 	struct dw_pcie *pci = imx6_pcie->pci;
 	struct device *dev = pci->dev;
-	int ret;
 
-	if (imx6_pcie->vpcie && !regulator_is_enabled(imx6_pcie->vpcie)) {
-		ret = regulator_enable(imx6_pcie->vpcie);
-		if (ret) {
-			dev_err(dev, "failed to enable vpcie regulator: %d\n",
-				ret);
-			return;
+	switch (imx6_pcie->drvdata->variant) {
+	case IMX8MP:
+	case IMX8MP_EP:
+		if (phy_init(imx6_pcie->phy) != 0)
+			dev_err(dev, "Waiting for PHY PLL ready timeout!\n");
+		/* wait for core_clk enabled */
+		for (retries = 0; retries < PHY_PLL_LOCK_WAIT_MAX_RETRIES;
+		     retries++) {
+			tmp = readl(imx6_pcie->hsmix_base + IMX8MP_GPR_REG1);
+			if (tmp & IMX8MP_GPR_REG1_PM_EN_CORE_CLK)
+				break;
+			udelay(10);
+		}
+		break;
+	case IMX8MM:
+	case IMX8MM_EP:
+		for (retries = 0; retries < PHY_PLL_LOCK_WAIT_MAX_RETRIES;
+		     retries++) {
+			tmp = readl(imx6_pcie->phy_base + PCIE_PHY_CMN_REG75);
+			if (tmp == PCIE_PHY_CMN_REG75_PLL_DONE)
+				break;
+			udelay(10);
 		}
+		break;
+
+	case IMX8QXP:
+	case IMX8QXP_EP:
+	case IMX8QM:
+	case IMX8QM_EP:
+		for (retries = 0; retries < PHY_PLL_LOCK_WAIT_MAX_RETRIES;
+		     retries++) {
+			if (imx6_pcie->hsio_cfg == PCIEAX1PCIEBX1SATA) {
+				regmap_read(imx6_pcie->iomuxc_gpr,
+					    IMX8QM_CSR_PHYX2_OFFSET + 0x4,
+					    &tmp);
+				if (imx6_pcie->controller_id == 0) /* pciea 1 lanes */
+					orig = IMX8QM_STTS0_LANE0_TX_PLL_LOCK;
+				else /* pcieb 1 lanes */
+					orig = IMX8QM_STTS0_LANE1_TX_PLL_LOCK;
+			} else if (imx6_pcie->hsio_cfg == PCIEAX2PCIEBX1) {
+				val = IMX8QM_CSR_PHYX2_OFFSET
+					+ imx6_pcie->controller_id * SZ_64K;
+				regmap_read(imx6_pcie->iomuxc_gpr,
+					    val + IMX8QM_CSR_PHYX_STTS0_OFFSET,
+					    &tmp);
+				orig = IMX8QM_STTS0_LANE0_TX_PLL_LOCK;
+				if (imx6_pcie->controller_id == 0) /* pciea 2 lanes */
+					orig |= IMX8QM_STTS0_LANE1_TX_PLL_LOCK;
+			} else if (imx6_pcie->hsio_cfg == PCIEAX2SATA) {
+				regmap_read(imx6_pcie->iomuxc_gpr,
+					    IMX8QM_CSR_PHYX2_OFFSET + 0x4,
+					    &tmp);
+				orig = IMX8QM_STTS0_LANE0_TX_PLL_LOCK;
+				orig |= IMX8QM_STTS0_LANE1_TX_PLL_LOCK;
+			}
+			tmp &= orig;
+			if (tmp == orig)
+				break;
+			udelay(10);
+		}
+		break;
+
+	default:
+		break;
 	}
 
+	if (retries >= PHY_PLL_LOCK_WAIT_MAX_RETRIES)
+		dev_err(dev, "PCIe PLL lock timeout\n");
+	else
+		dev_info(dev, "PCIe PLL locked after %d us.\n", retries * 10);
+}
+
+static void imx6_pcie_clk_enable(struct imx6_pcie *imx6_pcie)
+{
+	int ret;
+	struct dw_pcie *pci = imx6_pcie->pci;
+	struct device *dev = pci->dev;
+
 	ret = clk_prepare_enable(imx6_pcie->pcie_phy);
-	if (ret) {
+	if (ret)
 		dev_err(dev, "unable to enable pcie_phy clock\n");
-		goto err_pcie_phy;
-	}
 
 	ret = clk_prepare_enable(imx6_pcie->pcie_bus);
-	if (ret) {
+	if (ret)
 		dev_err(dev, "unable to enable pcie_bus clock\n");
-		goto err_pcie_bus;
-	}
 
 	ret = clk_prepare_enable(imx6_pcie->pcie);
-	if (ret) {
+	if (ret)
 		dev_err(dev, "unable to enable pcie clock\n");
-		goto err_pcie;
-	}
 
 	ret = imx6_pcie_enable_ref_clk(imx6_pcie);
-	if (ret) {
+	if (ret)
 		dev_err(dev, "unable to enable pcie ref clock\n");
-		goto err_ref_clk;
-	}
 
 	/* allow the clocks to stabilize */
 	usleep_range(200, 500);
+}
 
-	/* Some boards don't have PCIe reset GPIO. */
-	if (gpio_is_valid(imx6_pcie->reset_gpio)) {
-		gpio_set_value_cansleep(imx6_pcie->reset_gpio,
-					imx6_pcie->gpio_active_high);
-		msleep(100);
-		gpio_set_value_cansleep(imx6_pcie->reset_gpio,
-					!imx6_pcie->gpio_active_high);
-	}
+static void imx6_pcie_clk_disable(struct imx6_pcie *imx6_pcie)
+{
+	clk_disable_unprepare(imx6_pcie->pcie);
+	clk_disable_unprepare(imx6_pcie->pcie_phy);
+	clk_disable_unprepare(imx6_pcie->pcie_bus);
 
 	switch (imx6_pcie->drvdata->variant) {
-	case IMX8MQ:
-		reset_control_deassert(imx6_pcie->pciephy_reset);
+	case IMX6Q:
+	case IMX6Q_EP:
+	case IMX6QP:
+	case IMX6QP_EP:
+		regmap_update_bits(imx6_pcie->iomuxc_gpr, IOMUXC_GPR1,
+				IMX6Q_GPR1_PCIE_REF_CLK_EN, 0);
+		regmap_update_bits(imx6_pcie->iomuxc_gpr, IOMUXC_GPR1,
+				IMX6Q_GPR1_PCIE_TEST_PD,
+				IMX6Q_GPR1_PCIE_TEST_PD);
+		break;
+	case IMX6SX:
+	case IMX6SX_EP:
+		clk_disable_unprepare(imx6_pcie->pcie_inbound_axi);
 		break;
 	case IMX7D:
-		reset_control_deassert(imx6_pcie->pciephy_reset);
-
-		/* Workaround for ERR010728, failure of PCI-e PLL VCO to
-		 * oscillate, especially when cold.  This turns off "Duty-cycle
-		 * Corrector" and other mysterious undocumented things.
-		 */
-		if (likely(imx6_pcie->phy_base)) {
-			/* De-assert DCC_FB_EN */
-			writel(PCIE_PHY_CMN_REG4_DCC_FB_EN,
-			       imx6_pcie->phy_base + PCIE_PHY_CMN_REG4);
-			/* Assert RX_EQS and RX_EQS_SEL */
-			writel(PCIE_PHY_CMN_REG24_RX_EQ_SEL
-				| PCIE_PHY_CMN_REG24_RX_EQ,
-			       imx6_pcie->phy_base + PCIE_PHY_CMN_REG24);
-			/* Assert ATT_MODE */
-			writel(PCIE_PHY_CMN_REG26_ATT_MODE,
-			       imx6_pcie->phy_base + PCIE_PHY_CMN_REG26);
-		} else {
-			dev_warn(dev, "Unable to apply ERR010728 workaround. DT missing fsl,imx7d-pcie-phy phandle ?\n");
-		}
-
-		imx7d_pcie_wait_for_phy_pll_lock(imx6_pcie);
+	case IMX7D_EP:
+		regmap_update_bits(imx6_pcie->iomuxc_gpr, IOMUXC_GPR12,
+				   IMX7D_GPR12_PCIE_PHY_REFCLK_SEL,
+				   IMX7D_GPR12_PCIE_PHY_REFCLK_SEL);
 		break;
-	case IMX6SX:
-		regmap_update_bits(imx6_pcie->iomuxc_gpr, IOMUXC_GPR5,
-				   IMX6SX_GPR5_PCIE_BTNRST_RESET, 0);
+	case IMX8MP:
+	case IMX8MP_EP:
+		phy_exit(imx6_pcie->phy);
+		phy_power_off(imx6_pcie->phy);
+		fallthrough;
+	case IMX8MQ:
+	case IMX8MM:
+	case IMX8MQ_EP:
+	case IMX8MM_EP:
+		clk_disable_unprepare(imx6_pcie->pcie_aux);
 		break;
-	case IMX6QP:
-		regmap_update_bits(imx6_pcie->iomuxc_gpr, IOMUXC_GPR1,
-				   IMX6Q_GPR1_PCIE_SW_RST, 0);
-
-		usleep_range(200, 500);
+	case IMX8QM:
+	case IMX8QM_EP:
+		if (imx6_pcie->controller_id == 1) {
+			clk_disable_unprepare(imx6_pcie->pciex2_per);
+			clk_disable_unprepare(imx6_pcie->pcie_phy_pclk);
+		}
+		fallthrough;
+	case IMX8QXP:
+	case IMX8QXP_EP:
+		clk_disable_unprepare(imx6_pcie->pcie_per);
+		clk_disable_unprepare(imx6_pcie->pcie_inbound_axi);
+		clk_disable_unprepare(imx6_pcie->phy_per);
+		clk_disable_unprepare(imx6_pcie->misc_per);
 		break;
-	case IMX6Q:		/* Nothing to do */
+	default:
 		break;
 	}
-
-	return;
-
-err_ref_clk:
-	clk_disable_unprepare(imx6_pcie->pcie);
-err_pcie:
-	clk_disable_unprepare(imx6_pcie->pcie_bus);
-err_pcie_bus:
-	clk_disable_unprepare(imx6_pcie->pcie_phy);
-err_pcie_phy:
-	if (imx6_pcie->vpcie && regulator_is_enabled(imx6_pcie->vpcie) > 0) {
-		ret = regulator_disable(imx6_pcie->vpcie);
-		if (ret)
-			dev_err(dev, "failed to disable vpcie regulator: %d\n",
-				ret);
-	}
 }
 
-static void imx6_pcie_configure_type(struct imx6_pcie *imx6_pcie)
+static void imx6_pcie_assert_core_reset(struct imx6_pcie *imx6_pcie)
 {
-	unsigned int mask, val;
-
-	if (imx6_pcie->drvdata->variant == IMX8MQ &&
-	    imx6_pcie->controller_id == 1) {
-		mask   = IMX8MQ_GPR12_PCIE2_CTRL_DEVICE_TYPE;
-		val    = FIELD_PREP(IMX8MQ_GPR12_PCIE2_CTRL_DEVICE_TYPE,
-				    PCI_EXP_TYPE_ROOT_PORT);
-	} else {
-		mask = IMX6Q_GPR12_DEVICE_TYPE;
-		val  = FIELD_PREP(IMX6Q_GPR12_DEVICE_TYPE,
-				  PCI_EXP_TYPE_ROOT_PORT);
-	}
-
-	regmap_update_bits(imx6_pcie->iomuxc_gpr, IOMUXC_GPR12, mask, val);
-}
+	u32 val;
+	int i;
+	struct device *dev = imx6_pcie->pci->dev;
 
-static void imx6_pcie_init_phy(struct imx6_pcie *imx6_pcie)
-{
 	switch (imx6_pcie->drvdata->variant) {
-	case IMX8MQ:
-		/*
-		 * TODO: Currently this code assumes external
-		 * oscillator is being used
-		 */
-		regmap_update_bits(imx6_pcie->iomuxc_gpr,
-				   imx6_pcie_grp_offset(imx6_pcie),
-				   IMX8MQ_GPR_PCIE_REF_USE_PAD,
-				   IMX8MQ_GPR_PCIE_REF_USE_PAD);
-		break;
 	case IMX7D:
-		regmap_update_bits(imx6_pcie->iomuxc_gpr, IOMUXC_GPR12,
-				   IMX7D_GPR12_PCIE_PHY_REFCLK_SEL, 0);
+	case IMX7D_EP:
+	case IMX8MQ:
+	case IMX8MM:
+	case IMX8MQ_EP:
+	case IMX8MM_EP:
+		reset_control_assert(imx6_pcie->pciephy_reset);
+		fallthrough;
+	case IMX8MP:
+	case IMX8MP_EP:
+		imx6_pcie_ltssm_disable(dev);
+		reset_control_assert(imx6_pcie->pciephy_reset);
+		reset_control_assert(imx6_pcie->pciephy_perst);
 		break;
 	case IMX6SX:
+	case IMX6SX_EP:
 		regmap_update_bits(imx6_pcie->iomuxc_gpr, IOMUXC_GPR12,
-				   IMX6SX_GPR12_PCIE_RX_EQ_MASK,
-				   IMX6SX_GPR12_PCIE_RX_EQ_2);
-		fallthrough;
-	default:
-		regmap_update_bits(imx6_pcie->iomuxc_gpr, IOMUXC_GPR12,
-				   IMX6Q_GPR12_PCIE_CTL_2, 0 << 10);
+				   IMX6SX_GPR12_PCIE_TEST_POWERDOWN,
+				   IMX6SX_GPR12_PCIE_TEST_POWERDOWN);
+		/* Force PCIe PHY reset */
+		regmap_update_bits(imx6_pcie->iomuxc_gpr, IOMUXC_GPR5,
+				   IMX6SX_GPR5_PCIE_BTNRST_RESET,
+				   IMX6SX_GPR5_PCIE_BTNRST_RESET);
+		break;
+	case IMX6QP:
+	case IMX6QP_EP:
+		regmap_update_bits(imx6_pcie->iomuxc_gpr, IOMUXC_GPR1,
+				   IMX6Q_GPR1_PCIE_SW_RST,
+				   IMX6Q_GPR1_PCIE_SW_RST);
+		break;
+	case IMX6Q:
+	case IMX6Q_EP:
+		regmap_update_bits(imx6_pcie->iomuxc_gpr, IOMUXC_GPR1,
+				   IMX6Q_GPR1_PCIE_TEST_PD, 1 << 18);
+		regmap_update_bits(imx6_pcie->iomuxc_gpr, IOMUXC_GPR1,
+				   IMX6Q_GPR1_PCIE_REF_CLK_EN, 0 << 16);
+		break;
+	case IMX8QXP:
+	case IMX8QXP_EP:
+		imx6_pcie_clk_enable(imx6_pcie);
+		/*
+		 * Set the over ride low and enabled
+		 * make sure that REF_CLK is turned on.
+		 */
+		regmap_update_bits(imx6_pcie->iomuxc_gpr,
+			IMX8QM_CSR_MISC_OFFSET,
+			IMX8QM_MISC_CLKREQ_1,
+			0);
+		regmap_update_bits(imx6_pcie->iomuxc_gpr,
+			IMX8QM_CSR_MISC_OFFSET,
+			IMX8QM_MISC_CLKREQ_OVERRIDE_EN_1,
+			IMX8QM_MISC_CLKREQ_OVERRIDE_EN_1);
+		val = IMX8QM_CSR_PCIEB_OFFSET;
+		regmap_update_bits(imx6_pcie->iomuxc_gpr,
+				val + IMX8QM_CSR_PCIE_CTRL2_OFFSET,
+				IMX8QM_CTRL_BUTTON_RST_N,
+				IMX8QM_CTRL_BUTTON_RST_N);
+		regmap_update_bits(imx6_pcie->iomuxc_gpr,
+				val + IMX8QM_CSR_PCIE_CTRL2_OFFSET,
+				IMX8QM_CTRL_PERST_N,
+				IMX8QM_CTRL_PERST_N);
+		regmap_update_bits(imx6_pcie->iomuxc_gpr,
+				val + IMX8QM_CSR_PCIE_CTRL2_OFFSET,
+				IMX8QM_CTRL_POWER_UP_RST_N,
+				IMX8QM_CTRL_POWER_UP_RST_N);
+		break;
+	case IMX8QM:
+	case IMX8QM_EP:
+		imx6_pcie_clk_enable(imx6_pcie);
+		/*
+		 * Set the over ride low and enabled
+		 * make sure that REF_CLK is turned on.
+		 */
+		if (imx6_pcie->controller_id) {
+			regmap_update_bits(imx6_pcie->iomuxc_gpr,
+				IMX8QM_CSR_MISC_OFFSET,
+				IMX8QM_MISC_CLKREQ_1,
+				0);
+			regmap_update_bits(imx6_pcie->iomuxc_gpr,
+				IMX8QM_CSR_MISC_OFFSET,
+				IMX8QM_MISC_CLKREQ_OVERRIDE_EN_1,
+				IMX8QM_MISC_CLKREQ_OVERRIDE_EN_1);
+		} else {
+			regmap_update_bits(imx6_pcie->iomuxc_gpr,
+				IMX8QM_CSR_MISC_OFFSET,
+				IMX8QM_MISC_CLKREQ_0,
+				0);
+			regmap_update_bits(imx6_pcie->iomuxc_gpr,
+				IMX8QM_CSR_MISC_OFFSET,
+				IMX8QM_MISC_CLKREQ_OVERRIDE_EN_0,
+				IMX8QM_MISC_CLKREQ_OVERRIDE_EN_0);
+		}
+		for (i = 0; i <= imx6_pcie->controller_id; i++) {
+			val = IMX8QM_CSR_PCIEA_OFFSET + i * SZ_64K;
+			regmap_update_bits(imx6_pcie->iomuxc_gpr,
+					val + IMX8QM_CSR_PCIE_CTRL2_OFFSET,
+					IMX8QM_CTRL_BUTTON_RST_N,
+					IMX8QM_CTRL_BUTTON_RST_N);
+			regmap_update_bits(imx6_pcie->iomuxc_gpr,
+					val + IMX8QM_CSR_PCIE_CTRL2_OFFSET,
+					IMX8QM_CTRL_PERST_N,
+					IMX8QM_CTRL_PERST_N);
+			regmap_update_bits(imx6_pcie->iomuxc_gpr,
+					val + IMX8QM_CSR_PCIE_CTRL2_OFFSET,
+					IMX8QM_CTRL_POWER_UP_RST_N,
+					IMX8QM_CTRL_POWER_UP_RST_N);
+		}
+		break;
+	}
+
+	if (imx6_pcie->vpcie && regulator_is_enabled(imx6_pcie->vpcie) > 0) {
+		int ret = regulator_disable(imx6_pcie->vpcie);
+
+		if (ret)
+			dev_err(dev, "failed to disable vpcie regulator: %d\n",
+				ret);
+	}
+}
+
+static void imx6_pcie_set_l1_latency(struct imx6_pcie *imx6_pcie)
+{
+	u32 val;
+	struct dw_pcie *pci = imx6_pcie->pci;
+
+	switch (imx6_pcie->drvdata->variant) {
+	case IMX8MQ:
+	case IMX8MM:
+	case IMX8MP:
+		/*
+		 * Configure the L1 latency of rc to less than 64us
+		 * Otherwise, the L1/L1SUB wouldn't be enable by ASPM.
+		 */
+		dw_pcie_dbi_ro_wr_en(pci);
+		val = readl(pci->dbi_base + SZ_1M +
+				IMX8MQ_PCIE_LINK_CAP_REG_OFFSET);
+		val &= ~PCI_EXP_LNKCAP_L1EL;
+		val |= IMX8MQ_PCIE_LINK_CAP_L1EL_64US;
+		writel(val, pci->dbi_base + SZ_1M +
+				IMX8MQ_PCIE_LINK_CAP_REG_OFFSET);
+		dw_pcie_dbi_ro_wr_dis(pci);
+		break;
+	default:
+		break;
+	}
+}
+
+static void imx6_pcie_deassert_core_reset(struct imx6_pcie *imx6_pcie)
+{
+	struct dw_pcie *pci = imx6_pcie->pci;
+	struct device *dev = pci->dev;
+	int ret, i;
+	u32 val, tmp;
+
+	if (imx6_pcie->vpcie && !regulator_is_enabled(imx6_pcie->vpcie)) {
+		ret = regulator_enable(imx6_pcie->vpcie);
+		if (ret) {
+			dev_err(dev, "failed to enable vpcie regulator: %d\n",
+				ret);
+			return;
+		}
+	}
+
+	switch (imx6_pcie->drvdata->variant) {
+	case IMX8QXP:
+	case IMX8QXP_EP:
+	case IMX8QM:
+	case IMX8QM_EP:
+	case IMX8MP:
+	case IMX8MP_EP:
+		/* ClKs had been enabled */
+		break;
+	default:
+		imx6_pcie_clk_enable(imx6_pcie);
+		break;
+	}
+
+	/* Some boards don't have PCIe reset GPIO. */
+	if (gpio_is_valid(imx6_pcie->reset_gpio)) {
+		gpio_set_value_cansleep(imx6_pcie->reset_gpio,
+					imx6_pcie->gpio_active_high);
+		msleep(20);
+		gpio_set_value_cansleep(imx6_pcie->reset_gpio,
+					!imx6_pcie->gpio_active_high);
+	}
+
+	switch (imx6_pcie->drvdata->variant) {
+	case IMX8QM:
+	case IMX8QM_EP:
+		if (imx6_pcie->controller_id)
+			/* Set the APB clock masks */
+			regmap_update_bits(imx6_pcie->iomuxc_gpr,
+				IMX8QM_PHYX2_LPCG_OFFSET,
+				IMX8QM_PHYX2_LPCG_PCLK0_MASK |
+				IMX8QM_PHYX2_LPCG_PCLK1_MASK,
+				IMX8QM_PHYX2_LPCG_PCLK0_MASK |
+				IMX8QM_PHYX2_LPCG_PCLK1_MASK);
+		fallthrough;
+	case IMX8QXP:
+	case IMX8QXP_EP:
+		val = IMX8QM_CSR_PCIEA_OFFSET
+			+ imx6_pcie->controller_id * SZ_64K;
+		/* bit19 PM_REQ_CORE_RST of pciex#_stts0 should be cleared. */
+		for (i = 0; i < PHY_PLL_LOCK_WAIT_MAX_RETRIES; i++) {
+			regmap_read(imx6_pcie->iomuxc_gpr,
+					val + IMX8QM_CSR_PCIE_STTS0_OFFSET,
+					&tmp);
+			if ((tmp & IMX8QM_CTRL_STTS0_PM_REQ_CORE_RST) == 0)
+				break;
+			udelay(10);
+		}
+
+		if ((tmp & IMX8QM_CTRL_STTS0_PM_REQ_CORE_RST) != 0)
+			dev_err(dev, "ERROR PM_REQ_CORE_RST is still set.\n");
+
+		/* wait for phy pll lock firstly. */
+		imx8_pcie_wait_for_phy_pll_lock(imx6_pcie);
+		break;
+	case IMX8MQ:
+	case IMX8MM:
+	case IMX8MQ_EP:
+	case IMX8MM_EP:
+		reset_control_deassert(imx6_pcie->pciephy_reset);
+
+		imx8_pcie_wait_for_phy_pll_lock(imx6_pcie);
+
+		if (imx6_pcie->drvdata->flags & IMX6_PCIE_FLAG_SUPPORTS_L1SS)
+			/*
+			 * Configure the CLK_REQ# high, let the L1SS
+			 * automatically controlled by HW later.
+			 */
+			reset_control_deassert(imx6_pcie->clkreq_reset);
+		imx6_pcie_set_l1_latency(imx6_pcie);
+		break;
+	case IMX8MP:
+	case IMX8MP_EP:
+		msleep(20);
+		reset_control_deassert(imx6_pcie->pciephy_reset);
+		reset_control_deassert(imx6_pcie->pciephy_perst);
+
+		/* release pcie_phy_apb_reset and pcie_phy_init_resetn */
+		val = readl(imx6_pcie->hsmix_base + IMX8MP_GPR_REG0);
+		val |= IMX8MP_GPR_REG0_PHY_APB_RST;
+		val |= IMX8MP_GPR_REG0_PHY_INIT_RST;
+		writel(val, imx6_pcie->hsmix_base + IMX8MP_GPR_REG0);
+
+		val = imx6_pcie_grp_offset(imx6_pcie);
+		if (imx6_pcie->ext_osc) {
+			/*TODO Configure the external OSC as REF clock */
+			regmap_update_bits(imx6_pcie->iomuxc_gpr, val,
+					   IMX8MP_GPR_PCIE_REF_SEL_MASK,
+					   IMX8MP_GPR_PCIE_REF_SEL_MASK);
+			regmap_update_bits(imx6_pcie->iomuxc_gpr, val,
+					   IMX8MP_GPR_PCIE_AUX_EN,
+					   IMX8MP_GPR_PCIE_AUX_EN);
+			regmap_update_bits(imx6_pcie->iomuxc_gpr, val,
+					   IMX8MP_GPR_PCIE_SSC_EN, 0);
+			regmap_update_bits(imx6_pcie->iomuxc_gpr, val,
+					   IMX8MP_GPR_PCIE_PWR_OFF, 0);
+			regmap_update_bits(imx6_pcie->iomuxc_gpr, val,
+					   IMX8MP_GPR_PCIE_CMN_RSTN, 0);
+			regmap_update_bits(imx6_pcie->iomuxc_gpr, val,
+					   IMX8MP_GPR_PCIE_REF_SEL_MASK,
+					   IMX8MP_GPR_PCIE_REF_EXT_OSC);
+		} else {
+			/* Configure the internal PLL as REF clock */
+			regmap_update_bits(imx6_pcie->iomuxc_gpr, val,
+					   IMX8MP_GPR_PCIE_REF_SEL_MASK,
+					   IMX8MP_GPR_PCIE_REF_PLL_SYS);
+			regmap_update_bits(imx6_pcie->iomuxc_gpr, val,
+					   IMX8MP_GPR_PCIE_AUX_EN,
+					   IMX8MP_GPR_PCIE_AUX_EN);
+			regmap_update_bits(imx6_pcie->iomuxc_gpr, val,
+					   IMX8MP_GPR_PCIE_SSC_EN, 0);
+			regmap_update_bits(imx6_pcie->iomuxc_gpr, val,
+					   IMX8MP_GPR_PCIE_PWR_OFF, 0);
+			regmap_update_bits(imx6_pcie->iomuxc_gpr, val,
+					   IMX8MP_GPR_PCIE_CMN_RSTN, 0);
+		}
+
+		phy_calibrate(imx6_pcie->phy);
+		/*
+		 * GPR_PCIE_PHY_CTRL_BUS[3:0]
+		 * 0:i_ssc_en 1:i_power_off
+		 * 2:i_cmn_rstn 3:aux_en_glue.ctrl_bus
+		 */
+		val = imx6_pcie_grp_offset(imx6_pcie);
+		regmap_update_bits(imx6_pcie->iomuxc_gpr, val,
+				   IMX8MP_GPR_PCIE_CMN_RSTN,
+				   IMX8MP_GPR_PCIE_CMN_RSTN);
+
+		imx8_pcie_wait_for_phy_pll_lock(imx6_pcie);
+
+		if (imx6_pcie->drvdata->flags & IMX6_PCIE_FLAG_SUPPORTS_L1SS)
+			/*
+			 * Configure the CLK_REQ# high, let the L1SS
+			 * automatically controlled by HW later.
+			 */
+			reset_control_deassert(imx6_pcie->clkreq_reset);
+		imx6_pcie_set_l1_latency(imx6_pcie);
+		break;
+	case IMX7D:
+	case IMX7D_EP:
+		reset_control_deassert(imx6_pcie->pciephy_reset);
+
+		/* Workaround for ERR010728, failure of PCI-e PLL VCO to
+		 * oscillate, especially when cold.  This turns off "Duty-cycle
+		 * Corrector" and other mysterious undocumented things.
+		 */
+		if (likely(imx6_pcie->phy_base)) {
+			/* De-assert DCC_FB_EN */
+			writel(PCIE_PHY_CMN_REG4_DCC_FB_EN,
+			       imx6_pcie->phy_base + PCIE_PHY_CMN_REG4);
+			/* Assert RX_EQS and RX_EQS_SEL */
+			writel(PCIE_PHY_CMN_REG24_RX_EQ_SEL
+				| PCIE_PHY_CMN_REG24_RX_EQ,
+			       imx6_pcie->phy_base + PCIE_PHY_CMN_REG24);
+			/* Assert ATT_MODE */
+			writel(PCIE_PHY_CMN_REG26_ATT_MODE,
+			       imx6_pcie->phy_base + PCIE_PHY_CMN_REG26);
+		} else {
+			dev_warn(dev, "Unable to apply ERR010728 workaround. DT missing fsl,imx7d-pcie-phy phandle ?\n");
+		}
+
+		imx7d_pcie_wait_for_phy_pll_lock(imx6_pcie);
+		break;
+	case IMX6SX:
+	case IMX6SX_EP:
+		regmap_update_bits(imx6_pcie->iomuxc_gpr, IOMUXC_GPR5,
+				   IMX6SX_GPR5_PCIE_BTNRST_RESET, 0);
+		break;
+	case IMX6QP:
+	case IMX6QP_EP:
+		regmap_update_bits(imx6_pcie->iomuxc_gpr, IOMUXC_GPR1,
+				   IMX6Q_GPR1_PCIE_SW_RST, 0);
+
+		usleep_range(200, 500);
+		break;
+	case IMX6Q:		/* Nothing to do */
+	case IMX6Q_EP:
+		break;
+	}
+
+	return;
+}
+
+static void imx6_pcie_configure_type(struct imx6_pcie *imx6_pcie)
+{
+	unsigned int addr, mask, val, mode;
+	unsigned int variant = imx6_pcie->drvdata->variant;
+	struct dw_pcie *pci = imx6_pcie->pci;
+	struct device *dev = pci->dev;
+
+	mode = imx6_pcie->drvdata->mode;
+	switch (mode) {
+	case DW_PCIE_RC_TYPE:
+		mode = PCI_EXP_TYPE_ROOT_PORT;
+		break;
+	case DW_PCIE_EP_TYPE:
+		mode = PCI_EXP_TYPE_ENDPOINT;
+		break;
+	default:
+		dev_err(dev, "INVALID device type %d\n", mode);
+	}
+
+	switch (variant) {
+	case IMX8QM:
+	case IMX8QXP:
+	case IMX8QXP_EP:
+	case IMX8QM_EP:
+		if (imx6_pcie->controller_id)
+			addr = IMX8QM_CSR_PCIEB_OFFSET;
+		else
+			addr = IMX8QM_CSR_PCIEA_OFFSET;
+		mask = IMX8QM_PCIE_TYPE_MASK;
+		val = FIELD_PREP(IMX8QM_PCIE_TYPE_MASK, mode);
+		break;
+	case IMX8MQ:
+	case IMX8MQ_EP:
+		if (imx6_pcie->controller_id == 1) {
+			addr = IOMUXC_GPR12;
+			mask = IMX8MQ_GPR12_PCIE2_CTRL_DEVICE_TYPE;
+			val = FIELD_PREP(IMX8MQ_GPR12_PCIE2_CTRL_DEVICE_TYPE, mode);
+		} else {
+			addr = IOMUXC_GPR12;
+			mask = IMX6Q_GPR12_DEVICE_TYPE;
+			val = FIELD_PREP(IMX6Q_GPR12_DEVICE_TYPE, mode);
+		}
+		break;
+	default:
+		addr = IOMUXC_GPR12;
+		mask = IMX6Q_GPR12_DEVICE_TYPE;
+		val = FIELD_PREP(IMX6Q_GPR12_DEVICE_TYPE, mode);
+		break;
+	}
+	regmap_update_bits(imx6_pcie->iomuxc_gpr, addr, mask, val);
+}
+
+static void imx6_pcie_init_phy(struct imx6_pcie *imx6_pcie)
+{
+	int i;
+	unsigned int offset, val;
+
+	switch (imx6_pcie->drvdata->variant) {
+	case IMX8QXP:
+	case IMX8QXP_EP:
+	case IMX8QM:
+	case IMX8QM_EP:
+		if (imx6_pcie->hsio_cfg == PCIEAX2SATA) {
+			/*
+			 * bit 0 rx ena 1.
+			 * bit12 PHY_X1_EPCS_SEL 1.
+			 * bit13 phy_ab_select 0.
+			 */
+			regmap_update_bits(imx6_pcie->iomuxc_gpr,
+				IMX8QM_CSR_PHYX2_OFFSET,
+				IMX8QM_PHYX2_CTRL0_APB_MASK,
+				IMX8QM_PHY_APB_RSTN_0
+				| IMX8QM_PHY_APB_RSTN_1);
+
+			regmap_update_bits(imx6_pcie->iomuxc_gpr,
+				IMX8QM_CSR_MISC_OFFSET,
+				IMX8QM_MISC_PHYX1_EPCS_SEL,
+				IMX8QM_MISC_PHYX1_EPCS_SEL);
+			regmap_update_bits(imx6_pcie->iomuxc_gpr,
+				IMX8QM_CSR_MISC_OFFSET,
+				IMX8QM_MISC_PCIE_AB_SELECT,
+				0);
+		} else if (imx6_pcie->hsio_cfg == PCIEAX1PCIEBX1SATA) {
+			regmap_update_bits(imx6_pcie->iomuxc_gpr,
+				IMX8QM_CSR_PHYX2_OFFSET,
+				IMX8QM_PHYX2_CTRL0_APB_MASK,
+				IMX8QM_PHY_APB_RSTN_0
+				| IMX8QM_PHY_APB_RSTN_1);
+
+			regmap_update_bits(imx6_pcie->iomuxc_gpr,
+				IMX8QM_CSR_MISC_OFFSET,
+				IMX8QM_MISC_PHYX1_EPCS_SEL,
+				IMX8QM_MISC_PHYX1_EPCS_SEL);
+			regmap_update_bits(imx6_pcie->iomuxc_gpr,
+				IMX8QM_CSR_MISC_OFFSET,
+				IMX8QM_MISC_PCIE_AB_SELECT,
+				IMX8QM_MISC_PCIE_AB_SELECT);
+		} else if (imx6_pcie->hsio_cfg == PCIEAX2PCIEBX1) {
+			/*
+			 * bit 0 rx ena 1.
+			 * bit12 PHY_X1_EPCS_SEL 0.
+			 * bit13 phy_ab_select 1.
+			 */
+			if (imx6_pcie->controller_id)
+				regmap_update_bits(imx6_pcie->iomuxc_gpr,
+					IMX8QM_CSR_PHYX1_OFFSET,
+					IMX8QM_PHY_APB_RSTN_0,
+					IMX8QM_PHY_APB_RSTN_0);
+			else
+				regmap_update_bits(imx6_pcie->iomuxc_gpr,
+					IMX8QM_CSR_PHYX2_OFFSET,
+					IMX8QM_PHYX2_CTRL0_APB_MASK,
+					IMX8QM_PHY_APB_RSTN_0
+					| IMX8QM_PHY_APB_RSTN_1);
+
+			regmap_update_bits(imx6_pcie->iomuxc_gpr,
+				IMX8QM_CSR_MISC_OFFSET,
+				IMX8QM_MISC_PHYX1_EPCS_SEL,
+				0);
+			regmap_update_bits(imx6_pcie->iomuxc_gpr,
+				IMX8QM_CSR_MISC_OFFSET,
+				IMX8QM_MISC_PCIE_AB_SELECT,
+				IMX8QM_MISC_PCIE_AB_SELECT);
+		}
+
+		if (imx6_pcie->ext_osc) {
+			regmap_update_bits(imx6_pcie->iomuxc_gpr,
+				IMX8QM_CSR_MISC_OFFSET,
+				IMX8QM_MISC_IOB_RXENA,
+				IMX8QM_MISC_IOB_RXENA);
+			regmap_update_bits(imx6_pcie->iomuxc_gpr,
+				IMX8QM_CSR_MISC_OFFSET,
+				IMX8QM_MISC_IOB_TXENA,
+				0);
+		} else {
+			/* Try to used the internal pll as ref clk */
+			regmap_update_bits(imx6_pcie->iomuxc_gpr,
+				IMX8QM_CSR_MISC_OFFSET,
+				IMX8QM_MISC_IOB_RXENA,
+				0);
+			regmap_update_bits(imx6_pcie->iomuxc_gpr,
+				IMX8QM_CSR_MISC_OFFSET,
+				IMX8QM_MISC_IOB_TXENA,
+				IMX8QM_MISC_IOB_TXENA);
+			regmap_update_bits(imx6_pcie->iomuxc_gpr,
+				IMX8QM_CSR_MISC_OFFSET,
+				IMX8QM_CSR_MISC_IOB_A_0_TXOE
+				| IMX8QM_CSR_MISC_IOB_A_0_M1M0_MASK,
+				IMX8QM_CSR_MISC_IOB_A_0_TXOE
+				| IMX8QM_CSR_MISC_IOB_A_0_M1M0_2);
+		}
+
+		break;
+	case IMX8MM:
+	case IMX8MM_EP:
+		offset = imx6_pcie_grp_offset(imx6_pcie);
+
+		dev_info(imx6_pcie->pci->dev, "%s REF_CLK is used!.\n",
+			 imx6_pcie->ext_osc ? "EXT" : "PLL");
+		if (imx6_pcie->ext_osc) {
+			regmap_update_bits(imx6_pcie->iomuxc_gpr, offset,
+					   IMX8MQ_GPR_PCIE_REF_USE_PAD, 0);
+			regmap_update_bits(imx6_pcie->iomuxc_gpr, offset,
+					   IMX8MM_GPR_PCIE_REF_CLK_SEL,
+					   IMX8MM_GPR_PCIE_REF_CLK_SEL);
+			regmap_update_bits(imx6_pcie->iomuxc_gpr, offset,
+					   IMX8MM_GPR_PCIE_AUX_EN,
+					   IMX8MM_GPR_PCIE_AUX_EN);
+			regmap_update_bits(imx6_pcie->iomuxc_gpr, offset,
+					   IMX8MM_GPR_PCIE_POWER_OFF, 0);
+			regmap_update_bits(imx6_pcie->iomuxc_gpr, offset,
+					   IMX8MM_GPR_PCIE_SSC_EN, 0);
+			regmap_update_bits(imx6_pcie->iomuxc_gpr, offset,
+					   IMX8MM_GPR_PCIE_REF_CLK_SEL,
+					   IMX8MM_GPR_PCIE_REF_CLK_EXT);
+			udelay(100);
+			/* Do the PHY common block reset */
+			regmap_update_bits(imx6_pcie->iomuxc_gpr, offset,
+					   IMX8MM_GPR_PCIE_CMN_RST,
+					   IMX8MM_GPR_PCIE_CMN_RST);
+			udelay(200);
+		} else {
+			/* Configure the internal PLL as REF clock */
+			regmap_update_bits(imx6_pcie->iomuxc_gpr, offset,
+					   IMX8MQ_GPR_PCIE_REF_USE_PAD, 0);
+			regmap_update_bits(imx6_pcie->iomuxc_gpr, offset,
+					   IMX8MM_GPR_PCIE_REF_CLK_SEL,
+					   IMX8MM_GPR_PCIE_REF_CLK_SEL);
+			regmap_update_bits(imx6_pcie->iomuxc_gpr, offset,
+					   IMX8MM_GPR_PCIE_AUX_EN,
+					   IMX8MM_GPR_PCIE_AUX_EN);
+			regmap_update_bits(imx6_pcie->iomuxc_gpr, offset,
+					   IMX8MM_GPR_PCIE_POWER_OFF, 0);
+			regmap_update_bits(imx6_pcie->iomuxc_gpr, offset,
+					   IMX8MM_GPR_PCIE_SSC_EN, 0);
+			regmap_update_bits(imx6_pcie->iomuxc_gpr, offset,
+					   IMX8MM_GPR_PCIE_REF_CLK_SEL,
+					   IMX8MM_GPR_PCIE_REF_CLK_PLL);
+			udelay(100);
+			/* Configure the PHY */
+			writel(PCIE_PHY_CMN_REG62_PLL_CLK_OUT,
+			       imx6_pcie->phy_base + PCIE_PHY_CMN_REG62);
+			writel(PCIE_PHY_CMN_REG64_AUX_RX_TX_TERM,
+			       imx6_pcie->phy_base + PCIE_PHY_CMN_REG64);
+			/* Do the PHY common block reset */
+			regmap_update_bits(imx6_pcie->iomuxc_gpr, offset,
+					   IMX8MM_GPR_PCIE_CMN_RST,
+					   IMX8MM_GPR_PCIE_CMN_RST);
+			udelay(200);
+		}
+
+		/*
+		 * In order to pass the compliance tests.
+		 * Configure the TRSV regiser of iMX8MM PCIe PHY.
+		 */
+		writel(PCIE_PHY_TRSV_REG5_GEN1_DEEMP,
+		       imx6_pcie->phy_base + PCIE_PHY_TRSV_REG5);
+		writel(PCIE_PHY_TRSV_REG6_GEN2_DEEMP,
+		       imx6_pcie->phy_base + PCIE_PHY_TRSV_REG6);
+
+		break;
+	case IMX8MQ:
+	case IMX8MQ_EP:
+		/*
+		 * TODO: Currently this code assumes external
+		 * oscillator is being used
+		 */
+		regmap_update_bits(imx6_pcie->iomuxc_gpr,
+				   imx6_pcie_grp_offset(imx6_pcie),
+				   IMX8MQ_GPR_PCIE_REF_USE_PAD,
+				   IMX8MQ_GPR_PCIE_REF_USE_PAD);
+		/*
+		 * Regarding to the datasheet, the PCIE_VPH is suggested
+		 * to be 1.8V. If the PCIE_VPH is supplied by 3.3V, the
+		 * VREG_BYPASS should be cleared to zero.
+		 */
+		if (imx6_pcie->vph &&
+		    regulator_get_voltage(imx6_pcie->vph) > 3000000)
+			regmap_update_bits(imx6_pcie->iomuxc_gpr,
+					   imx6_pcie_grp_offset(imx6_pcie),
+					   IMX8MQ_GPR_PCIE_VREG_BYPASS,
+					   0);
+		break;
+	case IMX8MP:
+	case IMX8MP_EP:
+		phy_power_on(imx6_pcie->phy);
+		dev_info(imx6_pcie->pci->dev, "%s REF_CLK is used!.\n",
+			 imx6_pcie->ext_osc ? "EXT" : "PLL");
+		imx6_pcie_clk_enable(imx6_pcie);
+
+		/* Set P=12,M=800,S=4 and must set ICP=2'b01. */
+		val = readl(imx6_pcie->hsmix_base + IMX8MP_GPR_REG2);
+		val &= ~IMX8MP_GPR_REG2_P_PLL_MASK;
+		val |= IMX8MP_GPR_REG2_P_PLL;
+		val &= ~IMX8MP_GPR_REG2_M_PLL_MASK;
+		val |= IMX8MP_GPR_REG2_M_PLL;
+		val &= ~IMX8MP_GPR_REG2_S_PLL_MASK;
+		val |= IMX8MP_GPR_REG2_S_PLL;
+		writel(val, imx6_pcie->hsmix_base + IMX8MP_GPR_REG2);
+		/* wait greater than 1/F_FREF =1/2MHZ=0.5us */
+		udelay(1);
+
+		val = readl(imx6_pcie->hsmix_base + IMX8MP_GPR_REG3);
+		val |= IMX8MP_GPR_REG3_PLL_RST;
+		writel(val, imx6_pcie->hsmix_base + IMX8MP_GPR_REG3);
+		udelay(10);
+
+		/* Set 1 to pll_cke of GPR_REG3 */
+		val = readl(imx6_pcie->hsmix_base + IMX8MP_GPR_REG3);
+		val |= IMX8MP_GPR_REG3_PLL_CKE;
+		writel(val, imx6_pcie->hsmix_base + IMX8MP_GPR_REG3);
+
+		/* Lock time should be greater than 300cycle=300*0.5us=150us */
+		val = readl(imx6_pcie->hsmix_base + IMX8MP_GPR_REG1);
+		for (i = 0; i < 100; i++) {
+			val = readl(imx6_pcie->hsmix_base + IMX8MP_GPR_REG1);
+			if (val & IMX8MP_GPR_REG1_PLL_LOCK)
+				break;
+			udelay(10);
+		}
+		if (i >= 100)
+			dev_err(imx6_pcie->pci->dev,
+				"PCIe PHY PLL clock is not locked.\n");
+		else
+			dev_info(imx6_pcie->pci->dev,
+				"PCIe PHY PLL clock is locked.\n");
+
+		/* pcie_clock_module_en */
+		val = readl(imx6_pcie->hsmix_base + IMX8MP_GPR_REG0);
+		val |= IMX8MP_GPR_REG0_CLK_MOD_EN;
+		writel(val, imx6_pcie->hsmix_base + IMX8MP_GPR_REG0);
+		break;
+	case IMX7D:
+	case IMX7D_EP:
+		regmap_update_bits(imx6_pcie->iomuxc_gpr, IOMUXC_GPR12,
+				   IMX7D_GPR12_PCIE_PHY_REFCLK_SEL, 0);
+		break;
+	case IMX6SX:
+	case IMX6SX_EP:
+		regmap_update_bits(imx6_pcie->iomuxc_gpr, IOMUXC_GPR12,
+				   IMX6SX_GPR12_PCIE_RX_EQ_MASK,
+				   IMX6SX_GPR12_PCIE_RX_EQ_2);
+		fallthrough;
+	default:
+		regmap_update_bits(imx6_pcie->iomuxc_gpr, IOMUXC_GPR12,
+				   IMX6Q_GPR12_PCIE_CTL_2, 0 << 10);
 
 		/* configure constant input signal to the pcie ctrl and phy */
 		regmap_update_bits(imx6_pcie->iomuxc_gpr, IOMUXC_GPR12,
@@ -728,20 +1755,42 @@ static int imx6_pcie_wait_for_speed_change(struct imx6_pcie *imx6_pcie)
 
 static void imx6_pcie_ltssm_enable(struct device *dev)
 {
+	u32 val;
 	struct imx6_pcie *imx6_pcie = dev_get_drvdata(dev);
 
 	switch (imx6_pcie->drvdata->variant) {
 	case IMX6Q:
+	case IMX6Q_EP:
 	case IMX6SX:
+	case IMX6SX_EP:
 	case IMX6QP:
+	case IMX6QP_EP:
 		regmap_update_bits(imx6_pcie->iomuxc_gpr, IOMUXC_GPR12,
 				   IMX6Q_GPR12_PCIE_CTL_2,
 				   IMX6Q_GPR12_PCIE_CTL_2);
 		break;
 	case IMX7D:
+	case IMX7D_EP:
 	case IMX8MQ:
+	case IMX8MM:
+	case IMX8MP:
+	case IMX8MQ_EP:
+	case IMX8MM_EP:
+	case IMX8MP_EP:
 		reset_control_deassert(imx6_pcie->apps_reset);
 		break;
+	case IMX8QXP:
+	case IMX8QXP_EP:
+	case IMX8QM:
+	case IMX8QM_EP:
+		/* Bit4 of the CTRL2 */
+		val = IMX8QM_CSR_PCIEA_OFFSET
+			+ imx6_pcie->controller_id * SZ_64K;
+		regmap_update_bits(imx6_pcie->iomuxc_gpr,
+				val + IMX8QM_CSR_PCIE_CTRL2_OFFSET,
+				IMX8QM_CTRL_LTSSM_ENABLE,
+				IMX8QM_CTRL_LTSSM_ENABLE);
+		break;
 	}
 }
 
@@ -753,28 +1802,40 @@ static int imx6_pcie_establish_link(struct imx6_pcie *imx6_pcie)
 	u32 tmp;
 	int ret;
 
+	dw_pcie_dbi_ro_wr_en(pci);
 	/*
 	 * Force Gen1 operation when starting the link.  In case the link is
 	 * started in Gen2 mode, there is a possibility the devices on the
 	 * bus will not be detected at all.  This happens with PCIe switches.
 	 */
-	tmp = dw_pcie_readl_dbi(pci, offset + PCI_EXP_LNKCAP);
-	tmp &= ~PCI_EXP_LNKCAP_SLS;
-	tmp |= PCI_EXP_LNKCAP_SLS_2_5GB;
-	dw_pcie_writel_dbi(pci, offset + PCI_EXP_LNKCAP, tmp);
+	if (!imx6_pcie_cz_enabled) {
+		tmp = dw_pcie_readl_dbi(pci, offset + PCI_EXP_LNKCAP);
+		tmp &= ~PCI_EXP_LNKCAP_SLS;
+		tmp |= PCI_EXP_LNKCAP_SLS_2_5GB;
+		dw_pcie_writel_dbi(pci, offset + PCI_EXP_LNKCAP, tmp);
+	}
 
 	/* Start LTSSM. */
 	imx6_pcie_ltssm_enable(dev);
-
 	ret = dw_pcie_wait_for_link(pci);
 	if (ret)
 		goto err_reset_phy;
 
-	if (pci->link_gen == 2) {
+	if (pci->link_gen >= 2) {
+		/* Fill up target link speed before speed change. */
+		tmp = dw_pcie_readl_dbi(pci, offset + PCI_EXP_LNKCTL2);
+		tmp &= ~PCI_EXP_LNKCTL2_TLS;
+		tmp |= pci->link_gen;
+		dw_pcie_writel_dbi(pci, offset + PCI_EXP_LNKCTL2, tmp);
+
+		tmp = dw_pcie_readl_dbi(pci, PCIE_LINK_WIDTH_SPEED_CONTROL);
+		tmp &= ~PORT_LOGIC_SPEED_CHANGE;
+		dw_pcie_writel_dbi(pci, PCIE_LINK_WIDTH_SPEED_CONTROL, tmp);
+
 		/* Allow Gen2 mode after the link is up. */
 		tmp = dw_pcie_readl_dbi(pci, offset + PCI_EXP_LNKCAP);
 		tmp &= ~PCI_EXP_LNKCAP_SLS;
-		tmp |= PCI_EXP_LNKCAP_SLS_5_0GB;
+		tmp |= pci->link_gen;
 		dw_pcie_writel_dbi(pci, offset + PCI_EXP_LNKCAP, tmp);
 
 		/*
@@ -812,89 +1873,366 @@ static int imx6_pcie_establish_link(struct imx6_pcie *imx6_pcie)
 	} else {
 		dev_info(dev, "Link: Gen2 disabled\n");
 	}
+	dw_pcie_dbi_ro_wr_dis(pci);
+
+	tmp = dw_pcie_readw_dbi(pci, offset + PCI_EXP_LNKSTA);
+	dev_info(dev, "Link up, Gen%i\n", tmp & PCI_EXP_LNKSTA_CLS);
+	return 0;
+
+err_reset_phy:
+	dw_pcie_dbi_ro_wr_dis(pci);
+	dev_dbg(dev, "PHY DEBUG_R0=0x%08x DEBUG_R1=0x%08x\n",
+		dw_pcie_readl_dbi(pci, PCIE_PORT_DEBUG0),
+		dw_pcie_readl_dbi(pci, PCIE_PORT_DEBUG1));
+	imx6_pcie_reset_phy(imx6_pcie);
+	if (!imx6_pcie_cz_enabled) {
+		imx6_pcie_clk_disable(imx6_pcie);
+		if (imx6_pcie->vpcie != NULL)
+			regulator_disable(imx6_pcie->vpcie);
+		if (imx6_pcie->epdev_on != NULL)
+			regulator_disable(imx6_pcie->epdev_on);
+		if (gpio_is_valid(imx6_pcie->dis_gpio))
+			gpio_set_value_cansleep(imx6_pcie->dis_gpio, 0);
+	}
+
+	return ret;
+}
+
+static void pci_imx_set_msi_en(struct pcie_port *pp)
+{
+	u8 offset;
+	u16 val;
+	struct dw_pcie *pci = to_dw_pcie_from_pp(pp);
+
+	if (pci_msi_enabled()) {
+		dw_pcie_dbi_ro_wr_en(pci);
+		offset = dw_pcie_find_capability(pci, PCI_CAP_ID_MSI);
+		val = dw_pcie_readw_dbi(pci, offset + PCI_MSI_FLAGS);
+		val |= PCI_MSI_FLAGS_ENABLE;
+		val &= ~PCI_MSI_FLAGS_64BIT;
+		dw_pcie_writew_dbi(pci, offset + PCI_MSI_FLAGS, val);
+		dw_pcie_dbi_ro_wr_dis(pci);
+	}
+}
+
+static int imx6_pcie_host_init(struct pcie_port *pp)
+{
+	struct dw_pcie *pci = to_dw_pcie_from_pp(pp);
+	struct imx6_pcie *imx6_pcie = to_imx6_pcie(pci);
+
+	dw_pcie_setup_rc(pp);
+	pci_imx_set_msi_en(pp);
+	if (imx6_pcie_establish_link(imx6_pcie))
+		return -ENODEV;
+	msleep(100);
+	dw_pcie_msi_init(pp);
+
+	return 0;
+}
+
+static const struct dw_pcie_host_ops imx6_pcie_host_ops = {
+	.host_init = imx6_pcie_host_init,
+};
+
+static int imx6_add_pcie_port(struct imx6_pcie *imx6_pcie,
+			      struct platform_device *pdev)
+{
+	struct dw_pcie *pci = imx6_pcie->pci;
+	struct pcie_port *pp = &pci->pp;
+	struct device *dev = &pdev->dev;
+	int ret;
+
+	if (IS_ENABLED(CONFIG_PCI_MSI)) {
+		pp->msi_irq = platform_get_irq_byname(pdev, "msi");
+		if (pp->msi_irq < 0)
+			return pp->msi_irq;
+	}
+
+	pp->ops = &imx6_pcie_host_ops;
+
+	ret = dw_pcie_host_init(pp);
+	if (ret) {
+		dev_err(dev, "failed to initialize host\n");
+		return ret;
+	}
+
+	return 0;
+}
+
+static int imx6_pcie_start_link(struct dw_pcie *pci)
+{
+	struct device *dev = pci->dev;
+
+	if (dw_pcie_link_up(pci)) {
+		dev_dbg(dev, "link is already up\n");
+		return 0;
+	}
+
+	/* Start LTSSM. */
+	imx6_pcie_ltssm_enable(dev);
+
+	return 0;
+}
+
+static void imx6_pcie_stop_link(struct dw_pcie *pci)
+{
+	struct device *dev = pci->dev;
+
+	/* turn off pcie ltssm */
+	imx6_pcie_ltssm_disable(dev);
+}
+
+static u64 imx6_pcie_cpu_addr_fixup(struct dw_pcie *pcie, u64 cpu_addr)
+{
+	unsigned int offset;
+	struct dw_pcie_ep *ep = &pcie->ep;
+	struct pcie_port *pp = &pcie->pp;
+	struct imx6_pcie *imx6_pcie = to_imx6_pcie(pcie);
+	struct resource_entry *entry;
+
+	if (!(imx6_pcie->drvdata->flags & IMX6_PCIE_FLAG_IMX6_CPU_ADDR_FIXUP))
+		return cpu_addr;
+
+	if (imx6_pcie->drvdata->mode == DW_PCIE_RC_TYPE) {
+		entry = resource_list_first_type(&pp->bridge->windows,
+						 IORESOURCE_MEM);
+		offset = entry->res->start;
+	} else {
+		offset = ep->phys_base;
+	}
+
+	return (cpu_addr + imx6_pcie->local_addr - offset);
+}
+
+static const struct dw_pcie_ops dw_pcie_ops = {
+	.start_link = imx6_pcie_start_link,
+	.stop_link = imx6_pcie_stop_link,
+	.cpu_addr_fixup = imx6_pcie_cpu_addr_fixup,
+};
+
+static void imx_pcie_ep_init(struct dw_pcie_ep *ep)
+{
+	enum pci_barno bar;
+	struct dw_pcie *pci = to_dw_pcie_from_ep(ep);
+
+	for (bar = BAR_0; bar <= BAR_5; bar++)
+		dw_pcie_ep_reset_bar(pci, bar);
+}
+
+static int imx_pcie_ep_raise_irq(struct dw_pcie_ep *ep, u8 func_no,
+				   enum pci_epc_irq_type type,
+				   u16 interrupt_num)
+{
+	struct dw_pcie *pci = to_dw_pcie_from_ep(ep);
+
+	switch (type) {
+	case PCI_EPC_IRQ_LEGACY:
+		return dw_pcie_ep_raise_legacy_irq(ep, func_no);
+	case PCI_EPC_IRQ_MSI:
+		return dw_pcie_ep_raise_msi_irq(ep, func_no, interrupt_num);
+	case PCI_EPC_IRQ_MSIX:
+		return dw_pcie_ep_raise_msix_irq(ep, func_no, interrupt_num);
+	default:
+		dev_err(pci->dev, "UNKNOWN IRQ type\n");
+		return -EINVAL;
+	}
 
-	tmp = dw_pcie_readw_dbi(pci, offset + PCI_EXP_LNKSTA);
-	dev_info(dev, "Link up, Gen%i\n", tmp & PCI_EXP_LNKSTA_CLS);
 	return 0;
-
-err_reset_phy:
-	dev_dbg(dev, "PHY DEBUG_R0=0x%08x DEBUG_R1=0x%08x\n",
-		dw_pcie_readl_dbi(pci, PCIE_PORT_DEBUG0),
-		dw_pcie_readl_dbi(pci, PCIE_PORT_DEBUG1));
-	imx6_pcie_reset_phy(imx6_pcie);
-	return ret;
 }
 
-static int imx6_pcie_host_init(struct pcie_port *pp)
+/*
+ * iMX8QM/iMXQXP: Bar1/3/5 are reserved.
+ */
+static const struct pci_epc_features imx8q_pcie_epc_features = {
+	.linkup_notifier = false,
+	.msi_capable = true,
+	.msix_capable = false,
+	.reserved_bar = 1 << BAR_1 | 1 << BAR_3 | 1 << BAR_5,
+};
+
+static const struct pci_epc_features imx8m_pcie_epc_features = {
+	.linkup_notifier = false,
+	.msi_capable = true,
+	.msix_capable = false,
+	.reserved_bar = 1 << BAR_1 | 1 << BAR_3,
+	.align = SZ_64K,
+};
+
+static const struct pci_epc_features imx6q_pcie_epc_features = {
+	.linkup_notifier = false,
+	.msi_capable = true,
+	.msix_capable = false,
+	.reserved_bar = 1 << BAR_0 | 1 << BAR_1 | 1 << BAR_2,
+	.align = SZ_64K,
+};
+
+static const struct pci_epc_features*
+imx_pcie_ep_get_features(struct dw_pcie_ep *ep)
 {
-	struct dw_pcie *pci = to_dw_pcie_from_pp(pp);
+	struct dw_pcie *pci = to_dw_pcie_from_ep(ep);
 	struct imx6_pcie *imx6_pcie = to_imx6_pcie(pci);
 
-	imx6_pcie_assert_core_reset(imx6_pcie);
-	imx6_pcie_init_phy(imx6_pcie);
-	imx6_pcie_deassert_core_reset(imx6_pcie);
-	imx6_setup_phy_mpll(imx6_pcie);
-	dw_pcie_setup_rc(pp);
-	imx6_pcie_establish_link(imx6_pcie);
-	dw_pcie_msi_init(pp);
-
-	return 0;
+	switch (imx6_pcie->drvdata->variant) {
+	case IMX8QM_EP:
+	case IMX8QXP_EP:
+		return &imx8q_pcie_epc_features;
+	case IMX8MQ_EP:
+	case IMX8MM_EP:
+	case IMX8MP_EP:
+	case IMX7D_EP:
+	case IMX6SX_EP:
+		return &imx8m_pcie_epc_features;
+	default:
+		return &imx6q_pcie_epc_features;
+	}
 }
 
-static const struct dw_pcie_host_ops imx6_pcie_host_ops = {
-	.host_init = imx6_pcie_host_init,
+static const struct dw_pcie_ep_ops pcie_ep_ops = {
+	.ep_init = imx_pcie_ep_init,
+	.raise_irq = imx_pcie_ep_raise_irq,
+	.get_features = imx_pcie_ep_get_features,
 };
 
-static int imx6_add_pcie_port(struct imx6_pcie *imx6_pcie,
-			      struct platform_device *pdev)
+static int imx_add_pcie_ep(struct imx6_pcie *imx6_pcie,
+					struct platform_device *pdev)
 {
-	struct dw_pcie *pci = imx6_pcie->pci;
-	struct pcie_port *pp = &pci->pp;
-	struct device *dev = &pdev->dev;
 	int ret;
+	unsigned int pcie_dbi2_offset;
+	struct dw_pcie_ep *ep;
+	struct resource *res;
+	struct dw_pcie *pci = imx6_pcie->pci;
+	struct device *dev = pci->dev;
 
-	if (IS_ENABLED(CONFIG_PCI_MSI)) {
-		pp->msi_irq = platform_get_irq_byname(pdev, "msi");
-		if (pp->msi_irq < 0)
-			return pp->msi_irq;
+	ep = &pci->ep;
+	ep->ops = &pcie_ep_ops;
+
+	switch (imx6_pcie->drvdata->variant) {
+	case IMX8MQ_EP:
+	case IMX8MM_EP:
+	case IMX8MP_EP:
+		pcie_dbi2_offset = SZ_1M;
+		break;
+	default:
+		pcie_dbi2_offset = SZ_4K;
+		break;
 	}
+	pci->dbi_base2 = pci->dbi_base + pcie_dbi2_offset;
+	res = platform_get_resource_byname(pdev, IORESOURCE_MEM, "addr_space");
+	if (!res)
+		return -EINVAL;
 
-	pp->ops = &imx6_pcie_host_ops;
+	ep->phys_base = res->start;
+	ep->addr_size = resource_size(res);
+	ep->page_size = SZ_64K;
 
-	ret = dw_pcie_host_init(pp);
+	ret = dw_pcie_ep_init(ep);
 	if (ret) {
-		dev_err(dev, "failed to initialize host\n");
+		dev_err(dev, "failed to initialize endpoint\n");
 		return ret;
 	}
+	/* Start LTSSM. */
+	imx6_pcie_ltssm_enable(dev);
 
 	return 0;
 }
 
-static const struct dw_pcie_ops dw_pcie_ops = {
-	/* No special ops needed, but pcie-designware still expects this struct */
-};
-
-#ifdef CONFIG_PM_SLEEP
 static void imx6_pcie_ltssm_disable(struct device *dev)
 {
+	u32 val;
 	struct imx6_pcie *imx6_pcie = dev_get_drvdata(dev);
 
 	switch (imx6_pcie->drvdata->variant) {
 	case IMX6SX:
+	case IMX6SX_EP:
 	case IMX6QP:
+	case IMX6QP_EP:
 		regmap_update_bits(imx6_pcie->iomuxc_gpr, IOMUXC_GPR12,
 				   IMX6Q_GPR12_PCIE_CTL_2, 0);
 		break;
 	case IMX7D:
+	case IMX7D_EP:
+	case IMX8MQ:
+	case IMX8MM:
+	case IMX8MP:
+	case IMX8MQ_EP:
+	case IMX8MM_EP:
+	case IMX8MP_EP:
 		reset_control_assert(imx6_pcie->apps_reset);
 		break;
+	case IMX8QXP:
+	case IMX8QXP_EP:
+	case IMX8QM:
+	case IMX8QM_EP:
+		/* Bit4 of the CTRL2 */
+		val = IMX8QM_CSR_PCIEA_OFFSET
+			+ imx6_pcie->controller_id * SZ_64K;
+		regmap_update_bits(imx6_pcie->iomuxc_gpr,
+				val + IMX8QM_CSR_PCIE_CTRL2_OFFSET,
+				IMX8QM_CTRL_LTSSM_ENABLE, 0);
+		regmap_update_bits(imx6_pcie->iomuxc_gpr,
+				val + IMX8QM_CSR_PCIE_CTRL2_OFFSET,
+				IMX8QM_CTRL_READY_ENTR_L23, 0);
+		break;
 	default:
 		dev_err(dev, "ltssm_disable not supported\n");
 	}
 }
 
+static ssize_t bus_freq_store(struct device *dev,
+		struct device_attribute *attr, const char *buf, size_t count)
+{
+	int ret;
+	u32 bus_freq;
+
+	ret = sscanf(buf, "%x\n", &bus_freq);
+	if (ret != 1)
+		return -EINVAL;
+	if (bus_freq) {
+		dev_info(dev, "pcie request bus freq high.\n");
+		request_bus_freq(BUS_FREQ_HIGH);
+	} else {
+		dev_info(dev, "pcie release bus freq high.\n");
+		release_bus_freq(BUS_FREQ_HIGH);
+	}
+
+	return count;
+}
+static DEVICE_ATTR_WO(bus_freq);
+
+static struct attribute *imx_pcie_rc_attrs[] = {
+	&dev_attr_bus_freq.attr,
+	NULL
+};
+
+static struct attribute_group imx_pcie_attrgroup = {
+	.attrs	= imx_pcie_rc_attrs,
+};
+
+static void imx6_pcie_clkreq_enable(struct imx6_pcie *imx6_pcie)
+{
+	/*
+	 * If the L1SS is supported, disable the over ride after link up.
+	 * Let the the CLK_REQ# controlled by HW L1SS automatically.
+	 */
+	switch (imx6_pcie->drvdata->variant) {
+	case IMX8MQ:
+	case IMX8MM:
+	case IMX8MP:
+		regmap_update_bits(imx6_pcie->iomuxc_gpr,
+			imx6_pcie_grp_offset(imx6_pcie),
+			IMX8MQ_GPR_PCIE_CLK_REQ_OVERRIDE_EN,
+			0);
+		break;
+	default:
+		break;
+	};
+}
+
+#ifdef CONFIG_PM_SLEEP
 static void imx6_pcie_pm_turnoff(struct imx6_pcie *imx6_pcie)
 {
+	int i;
+	u32 dst, val;
 	struct device *dev = imx6_pcie->pci->dev;
 
 	/* Some variants have a turnoff reset in DT */
@@ -907,12 +2245,51 @@ static void imx6_pcie_pm_turnoff(struct imx6_pcie *imx6_pcie)
 	/* Others poke directly at IOMUXC registers */
 	switch (imx6_pcie->drvdata->variant) {
 	case IMX6SX:
+	case IMX6SX_EP:
 		regmap_update_bits(imx6_pcie->iomuxc_gpr, IOMUXC_GPR12,
 				IMX6SX_GPR12_PCIE_PM_TURN_OFF,
 				IMX6SX_GPR12_PCIE_PM_TURN_OFF);
 		regmap_update_bits(imx6_pcie->iomuxc_gpr, IOMUXC_GPR12,
 				IMX6SX_GPR12_PCIE_PM_TURN_OFF, 0);
 		break;
+	case IMX6QP:
+	case IMX6QP_EP:
+		regmap_update_bits(imx6_pcie->iomuxc_gpr, IOMUXC_GPR12,
+				   IMX6SX_GPR12_PCIE_PM_TURN_OFF,
+				   IMX6SX_GPR12_PCIE_PM_TURN_OFF);
+		regmap_update_bits(imx6_pcie->iomuxc_gpr, IOMUXC_GPR12,
+				   IMX6SX_GPR12_PCIE_PM_TURN_OFF, 0);
+		break;
+	case IMX8QXP:
+	case IMX8QXP_EP:
+	case IMX8QM:
+	case IMX8QM_EP:
+		dst = IMX8QM_CSR_PCIEA_OFFSET + imx6_pcie->controller_id * SZ_64K;
+		regmap_update_bits(imx6_pcie->iomuxc_gpr,
+				dst + IMX8QM_CSR_PCIE_CTRL2_OFFSET,
+				IMX8QM_CTRL_PM_XMT_TURNOFF,
+				IMX8QM_CTRL_PM_XMT_TURNOFF);
+		regmap_update_bits(imx6_pcie->iomuxc_gpr,
+				dst + IMX8QM_CSR_PCIE_CTRL2_OFFSET,
+				IMX8QM_CTRL_PM_XMT_TURNOFF,
+				0);
+		regmap_update_bits(imx6_pcie->iomuxc_gpr,
+				dst + IMX8QM_CSR_PCIE_CTRL2_OFFSET,
+				IMX8QM_CTRL_READY_ENTR_L23,
+				IMX8QM_CTRL_READY_ENTR_L23);
+		/* check the L2 is entered or not. */
+		for (i = 0; i < 10000; i++) {
+			regmap_read(imx6_pcie->iomuxc_gpr,
+					dst + IMX8QM_CSR_PCIE_STTS0_OFFSET,
+					&val);
+			if (val & IMX8QM_CTRL_STTS0_PM_LINKST_IN_L2)
+				break;
+			udelay(10);
+		}
+		if ((val & IMX8QM_CTRL_STTS0_PM_LINKST_IN_L2) == 0)
+			dev_err(dev, "PCIE%d can't enter into L2.\n",
+					imx6_pcie->controller_id);
+		break;
 	default:
 		dev_err(dev, "PME_Turn_Off not implemented\n");
 		return;
@@ -929,39 +2306,27 @@ static void imx6_pcie_pm_turnoff(struct imx6_pcie *imx6_pcie)
 	usleep_range(1000, 10000);
 }
 
-static void imx6_pcie_clk_disable(struct imx6_pcie *imx6_pcie)
-{
-	clk_disable_unprepare(imx6_pcie->pcie);
-	clk_disable_unprepare(imx6_pcie->pcie_phy);
-	clk_disable_unprepare(imx6_pcie->pcie_bus);
-
-	switch (imx6_pcie->drvdata->variant) {
-	case IMX6SX:
-		clk_disable_unprepare(imx6_pcie->pcie_inbound_axi);
-		break;
-	case IMX7D:
-		regmap_update_bits(imx6_pcie->iomuxc_gpr, IOMUXC_GPR12,
-				   IMX7D_GPR12_PCIE_PHY_REFCLK_SEL,
-				   IMX7D_GPR12_PCIE_PHY_REFCLK_SEL);
-		break;
-	case IMX8MQ:
-		clk_disable_unprepare(imx6_pcie->pcie_aux);
-		break;
-	default:
-		break;
-	}
-}
-
 static int imx6_pcie_suspend_noirq(struct device *dev)
 {
 	struct imx6_pcie *imx6_pcie = dev_get_drvdata(dev);
 
 	if (!(imx6_pcie->drvdata->flags & IMX6_PCIE_FLAG_SUPPORTS_SUSPEND))
 		return 0;
-
-	imx6_pcie_pm_turnoff(imx6_pcie);
-	imx6_pcie_clk_disable(imx6_pcie);
-	imx6_pcie_ltssm_disable(dev);
+	if (unlikely(imx6_pcie->drvdata->variant == IMX6Q)) {
+		/*
+		 * L2 can exit by 'reset' or Inband beacon (from remote EP)
+		 * toggling phy_powerdown has same effect as 'inband beacon'
+		 * So, toggle bit18 of GPR1, used as a workaround of errata
+		 * ERR005723 "PCIe PCIe does not support L2 Power Down"
+		 */
+		regmap_update_bits(imx6_pcie->iomuxc_gpr, IOMUXC_GPR1,
+				   IMX6Q_GPR1_PCIE_TEST_PD,
+				   IMX6Q_GPR1_PCIE_TEST_PD);
+	} else {
+		imx6_pcie_pm_turnoff(imx6_pcie);
+		imx6_pcie_ltssm_disable(dev);
+		imx6_pcie_clk_disable(imx6_pcie);
+	}
 
 	return 0;
 }
@@ -974,15 +2339,29 @@ static int imx6_pcie_resume_noirq(struct device *dev)
 
 	if (!(imx6_pcie->drvdata->flags & IMX6_PCIE_FLAG_SUPPORTS_SUSPEND))
 		return 0;
-
-	imx6_pcie_assert_core_reset(imx6_pcie);
-	imx6_pcie_init_phy(imx6_pcie);
-	imx6_pcie_deassert_core_reset(imx6_pcie);
-	dw_pcie_setup_rc(pp);
-
-	ret = imx6_pcie_establish_link(imx6_pcie);
-	if (ret < 0)
-		dev_info(dev, "pcie link is down after resume.\n");
+	if (unlikely(imx6_pcie->drvdata->variant == IMX6Q)) {
+		/*
+		 * L2 can exit by 'reset' or Inband beacon (from remote EP)
+		 * toggling phy_powerdown has same effect as 'inband beacon'
+		 * So, toggle bit18 of GPR1, used as a workaround of errata
+		 * ERR005723 "PCIe PCIe does not support L2 Power Down"
+		 */
+		regmap_update_bits(imx6_pcie->iomuxc_gpr, IOMUXC_GPR1,
+				IMX6Q_GPR1_PCIE_TEST_PD, 0);
+	} else {
+		imx6_pcie_assert_core_reset(imx6_pcie);
+		imx6_pcie_init_phy(imx6_pcie);
+		imx6_pcie_deassert_core_reset(imx6_pcie);
+		dw_pcie_setup_rc(pp);
+		pci_imx_set_msi_en(pp);
+		dw_pcie_msi_init(pp);
+
+		ret = imx6_pcie_establish_link(imx6_pcie);
+		if (ret < 0)
+			dev_info(dev, "pcie link is down after resume.\n");
+		if (imx6_pcie->l1ss_clkreq)
+			imx6_pcie_clkreq_enable(imx6_pcie);
+	}
 
 	return 0;
 }
@@ -993,16 +2372,28 @@ static const struct dev_pm_ops imx6_pcie_pm_ops = {
 				      imx6_pcie_resume_noirq)
 };
 
+static int __init imx6_pcie_compliance_test_enable(char *str)
+{
+	if (!strcmp(str, "yes")) {
+		pr_info("Enable the i.MX PCIe compliance tests mode.\n");
+		imx6_pcie_cz_enabled = 1;
+	}
+	return 1;
+}
+
+__setup("pcie_cz_enabled=", imx6_pcie_compliance_test_enable);
+
 static int imx6_pcie_probe(struct platform_device *pdev)
 {
 	struct device *dev = &pdev->dev;
 	struct dw_pcie *pci;
 	struct imx6_pcie *imx6_pcie;
 	struct device_node *np;
-	struct resource *dbi_base;
+	struct resource *dbi_base, *hsio_res;
 	struct device_node *node = dev->of_node;
+	void __iomem *iomem;
+	struct regmap_config regconfig = imx6_pcie_regconfig;
 	int ret;
-	u16 val;
 
 	imx6_pcie = devm_kzalloc(dev, sizeof(*imx6_pcie), GFP_KERNEL);
 	if (!imx6_pcie)
@@ -1035,12 +2426,70 @@ static int imx6_pcie_probe(struct platform_device *pdev)
 		}
 	}
 
+	imx6_pcie->phy = devm_phy_get(dev, "pcie-phy");
+	if (IS_ERR(imx6_pcie->phy)) {
+		if (PTR_ERR(imx6_pcie->phy) == -EPROBE_DEFER)
+			return -EPROBE_DEFER;
+		/* Set NULL if there is no pcie-phy */
+		imx6_pcie->phy = NULL;
+	}
+
+	/* Find the HSIO MIX if one is defined, only imx8mp uses it */
+	np = of_parse_phandle(node, "fsl,imx8mp-hsio-mix", 0);
+	if (np) {
+		struct resource res;
+
+		ret = of_address_to_resource(np, 0, &res);
+		if (ret) {
+			dev_err(dev, "Unable to find HSIO MIX res\n");
+			return ret;
+		}
+		imx6_pcie->hsmix_base = devm_ioremap_resource(dev, &res);
+		if (IS_ERR(imx6_pcie->hsmix_base)) {
+			dev_err(dev, "Unable to map HSIO MIX res\n");
+			return PTR_ERR(imx6_pcie->hsmix_base);
+		}
+	}
+
 	dbi_base = platform_get_resource(pdev, IORESOURCE_MEM, 0);
 	pci->dbi_base = devm_ioremap_resource(dev, dbi_base);
 	if (IS_ERR(pci->dbi_base))
 		return PTR_ERR(pci->dbi_base);
 
+	if (of_property_read_u32(node, "hsio-cfg", &imx6_pcie->hsio_cfg))
+		imx6_pcie->hsio_cfg = 0;
+	if (of_property_read_u32(node, "ext_osc", &imx6_pcie->ext_osc) < 0)
+		imx6_pcie->ext_osc = 0;
+	if (of_property_read_u32(node, "local-addr", &imx6_pcie->local_addr))
+		imx6_pcie->local_addr = 0;
+	if (of_property_read_bool(node, "l1ss-disabled"))
+		imx6_pcie->l1ss_clkreq = 0;
+	else
+		imx6_pcie->l1ss_clkreq = 1;
+
 	/* Fetch GPIOs */
+	imx6_pcie->clkreq_gpio = of_get_named_gpio(node, "clkreq-gpio", 0);
+	if (gpio_is_valid(imx6_pcie->clkreq_gpio)) {
+		devm_gpio_request_one(&pdev->dev, imx6_pcie->clkreq_gpio,
+				      GPIOF_OUT_INIT_LOW, "PCIe CLKREQ");
+	} else if (imx6_pcie->clkreq_gpio == -EPROBE_DEFER) {
+		return imx6_pcie->clkreq_gpio;
+	}
+
+	imx6_pcie->dis_gpio = of_get_named_gpio(node, "disable-gpio", 0);
+	if (gpio_is_valid(imx6_pcie->dis_gpio)) {
+		ret = devm_gpio_request_one(&pdev->dev, imx6_pcie->dis_gpio,
+					    GPIOF_OUT_INIT_LOW, "PCIe DIS");
+		if (ret) {
+			dev_err(&pdev->dev, "unable to get disable gpio\n");
+			return ret;
+		}
+	} else if (imx6_pcie->dis_gpio == -EPROBE_DEFER) {
+		return imx6_pcie->dis_gpio;
+	}
+	imx6_pcie->epdev_on = devm_regulator_get(&pdev->dev, "epdev_on");
+	if (IS_ERR(imx6_pcie->epdev_on))
+		return -EPROBE_DEFER;
 	imx6_pcie->reset_gpio = of_get_named_gpio(node, "reset-gpio", 0);
 	imx6_pcie->gpio_active_high = of_property_read_bool(node,
 						"reset-gpio-active-high");
@@ -1076,19 +2525,33 @@ static int imx6_pcie_probe(struct platform_device *pdev)
 
 	switch (imx6_pcie->drvdata->variant) {
 	case IMX6SX:
+	case IMX6SX_EP:
 		imx6_pcie->pcie_inbound_axi = devm_clk_get(dev,
 							   "pcie_inbound_axi");
 		if (IS_ERR(imx6_pcie->pcie_inbound_axi))
 			return dev_err_probe(dev, PTR_ERR(imx6_pcie->pcie_inbound_axi),
 					     "pcie_inbound_axi clock missing or invalid\n");
 		break;
+	case IMX8MP:
+	case IMX8MP_EP:
+		imx6_pcie->pciephy_perst = devm_reset_control_get_exclusive(dev,
+									    "pciephy_perst");
+		if (IS_ERR(imx6_pcie->pciephy_perst)) {
+			dev_err(dev, "Failed to get PCIEPHY perst control\n");
+			return PTR_ERR(imx6_pcie->pciephy_perst);
+		}
+		fallthrough;
 	case IMX8MQ:
+	case IMX8MM:
+	case IMX8MQ_EP:
+	case IMX8MM_EP:
 		imx6_pcie->pcie_aux = devm_clk_get(dev, "pcie_aux");
 		if (IS_ERR(imx6_pcie->pcie_aux))
 			return dev_err_probe(dev, PTR_ERR(imx6_pcie->pcie_aux),
 					     "pcie_aux clock source missing or invalid\n");
 		fallthrough;
 	case IMX7D:
+	case IMX7D_EP:
 		if (dbi_base->start == IMX8MQ_PCIE2_BASE_ADDR)
 			imx6_pcie->controller_id = 1;
 
@@ -1106,6 +2569,71 @@ static int imx6_pcie_probe(struct platform_device *pdev)
 			return PTR_ERR(imx6_pcie->apps_reset);
 		}
 		break;
+	case IMX8QM:
+	case IMX8QM_EP:
+	case IMX8QXP:
+	case IMX8QXP_EP:
+		if (dbi_base->start == IMX8_HSIO_PCIEB_BASE_ADDR)
+			imx6_pcie->controller_id = 1;
+
+		imx6_pcie->pcie_per = devm_clk_get(dev, "pcie_per");
+		if (IS_ERR(imx6_pcie->pcie_per)) {
+			dev_err(dev, "pcie_per clock source missing or invalid\n");
+			return PTR_ERR(imx6_pcie->pcie_per);
+		}
+
+		imx6_pcie->pcie_inbound_axi = devm_clk_get(&pdev->dev,
+				"pcie_inbound_axi");
+		if (IS_ERR(imx6_pcie->pcie_inbound_axi)) {
+			dev_err(&pdev->dev,
+				"pcie clock source missing or invalid\n");
+			return PTR_ERR(imx6_pcie->pcie_inbound_axi);
+		}
+
+		imx6_pcie->phy_per = devm_clk_get(dev, "phy_per");
+		if (IS_ERR(imx6_pcie->phy_per)) {
+			dev_err(dev, "failed to get phy per clock.\n");
+			return PTR_ERR(imx6_pcie->phy_per);
+		}
+
+		imx6_pcie->misc_per = devm_clk_get(dev, "misc_per");
+		if (IS_ERR(imx6_pcie->misc_per)) {
+			dev_err(dev, "failed to get misc per clock.\n");
+			return PTR_ERR(imx6_pcie->misc_per);
+		}
+		if (imx6_pcie->drvdata->variant == IMX8QM
+				&& imx6_pcie->controller_id == 1) {
+			imx6_pcie->pcie_phy_pclk = devm_clk_get(dev,
+					"pcie_phy_pclk");
+			if (IS_ERR(imx6_pcie->pcie_phy_pclk)) {
+				dev_err(dev, "no pcie_phy_pclk clock\n");
+				return PTR_ERR(imx6_pcie->pcie_phy_pclk);
+			}
+
+			imx6_pcie->pciex2_per = devm_clk_get(dev, "pciex2_per");
+			if (IS_ERR(imx6_pcie->pciex2_per)) {
+				dev_err(dev, "can't get pciex2_per.\n");
+				return PTR_ERR(imx6_pcie->pciex2_per);
+			}
+		}
+
+		hsio_res = platform_get_resource_byname(pdev, IORESOURCE_MEM,
+							"hsio");
+		if (hsio_res) {
+			iomem = devm_ioremap(dev, hsio_res->start,
+					     resource_size(hsio_res));
+			if (IS_ERR(iomem))
+				return PTR_ERR(iomem);
+			imx6_pcie->iomuxc_gpr =
+				devm_regmap_init_mmio(dev, iomem, &regconfig);
+			if (IS_ERR(imx6_pcie->iomuxc_gpr)) {
+				dev_err(dev, "failed to init register map\n");
+				return PTR_ERR(imx6_pcie->iomuxc_gpr);
+			}
+		} else {
+			dev_err(dev, "missing *hsio* reg space\n");
+		}
+		break;
 	default:
 		break;
 	}
@@ -1117,12 +2645,20 @@ static int imx6_pcie_probe(struct platform_device *pdev)
 		return PTR_ERR(imx6_pcie->turnoff_reset);
 	}
 
+	imx6_pcie->clkreq_reset = devm_reset_control_get_optional_exclusive(dev, "clkreq");
+	if (IS_ERR(imx6_pcie->clkreq_reset)) {
+		dev_err(dev, "Failed to get CLKREQ reset control\n");
+		return PTR_ERR(imx6_pcie->clkreq_reset);
+	}
+
 	/* Grab GPR config register range */
-	imx6_pcie->iomuxc_gpr =
-		 syscon_regmap_lookup_by_compatible("fsl,imx6q-iomuxc-gpr");
-	if (IS_ERR(imx6_pcie->iomuxc_gpr)) {
-		dev_err(dev, "unable to find iomuxc registers\n");
-		return PTR_ERR(imx6_pcie->iomuxc_gpr);
+	if (imx6_pcie->iomuxc_gpr == NULL) {
+		imx6_pcie->iomuxc_gpr =
+			syscon_regmap_lookup_by_compatible("fsl,imx6q-iomuxc-gpr");
+		if (IS_ERR(imx6_pcie->iomuxc_gpr)) {
+			dev_err(dev, "unable to find iomuxc registers\n");
+			return PTR_ERR(imx6_pcie->iomuxc_gpr);
+		}
 	}
 
 	/* Grab PCIe PHY Tx Settings */
@@ -1157,24 +2693,69 @@ static int imx6_pcie_probe(struct platform_device *pdev)
 		imx6_pcie->vpcie = NULL;
 	}
 
+	imx6_pcie->vph = devm_regulator_get_optional(&pdev->dev, "vph");
+	if (IS_ERR(imx6_pcie->vph)) {
+		if (PTR_ERR(imx6_pcie->vph) != -ENODEV)
+			return PTR_ERR(imx6_pcie->vph);
+		imx6_pcie->vph = NULL;
+	}
+
 	platform_set_drvdata(pdev, imx6_pcie);
 
 	ret = imx6_pcie_attach_pd(dev);
 	if (ret)
 		return ret;
 
-	ret = imx6_add_pcie_port(imx6_pcie, pdev);
-	if (ret < 0)
-		return ret;
+	ret = regulator_enable(imx6_pcie->epdev_on);
+	if (ret) {
+		dev_err(dev, "failed to enable the epdev_on regulator\n");
+		goto err_ret;
+	}
+	if (gpio_is_valid(imx6_pcie->dis_gpio))
+		gpio_set_value_cansleep(imx6_pcie->dis_gpio, 1);
 
-	if (pci_msi_enabled()) {
-		u8 offset = dw_pcie_find_capability(pci, PCI_CAP_ID_MSI);
-		val = dw_pcie_readw_dbi(pci, offset + PCI_MSI_FLAGS);
-		val |= PCI_MSI_FLAGS_ENABLE;
-		dw_pcie_writew_dbi(pci, offset + PCI_MSI_FLAGS, val);
+	imx6_pcie_assert_core_reset(imx6_pcie);
+	imx6_pcie_init_phy(imx6_pcie);
+	imx6_pcie_deassert_core_reset(imx6_pcie);
+	imx6_setup_phy_mpll(imx6_pcie);
+
+	switch (imx6_pcie->drvdata->mode) {
+	case DW_PCIE_RC_TYPE:
+		/* add attributes for bus freq */
+		ret = sysfs_create_group(&pdev->dev.kobj, &imx_pcie_attrgroup);
+		if (ret)
+			goto err_ret;
+
+		ret = imx6_add_pcie_port(imx6_pcie, pdev);
+		if (ret < 0) {
+			if (imx6_pcie_cz_enabled) {
+				/* The PCIE clocks wouldn't be turned off */
+				dev_info(dev, "To do the compliance tests.\n");
+				ret = 0;
+			} else {
+				dev_err(dev, "unable to add pcie port.\n");
+			}
+			goto err_ret;
+		}
+		pci_imx_set_msi_en(&imx6_pcie->pci->pp);
+		break;
+	case DW_PCIE_EP_TYPE:
+		if (!IS_ENABLED(CONFIG_PCI_IMX_EP))
+			ret = -ENODEV;
+
+		ret = imx_add_pcie_ep(imx6_pcie, pdev);
+		if (ret < 0)
+			goto err_ret;
+		break;
+	default:
+		dev_err(dev, "INVALID device type.\n");
 	}
 
 	return 0;
+
+err_ret:
+	imx6_pcie_detach_pd(dev);
+	return ret;
 }
 
 static void imx6_pcie_shutdown(struct platform_device *pdev)
@@ -1188,27 +2769,102 @@ static void imx6_pcie_shutdown(struct platform_device *pdev)
 static const struct imx6_pcie_drvdata drvdata[] = {
 	[IMX6Q] = {
 		.variant = IMX6Q,
+		.mode = DW_PCIE_RC_TYPE,
 		.flags = IMX6_PCIE_FLAG_IMX6_PHY |
+			 IMX6_PCIE_FLAG_SUPPORTS_SUSPEND |
 			 IMX6_PCIE_FLAG_IMX6_SPEED_CHANGE,
 		.dbi_length = 0x200,
 	},
 	[IMX6SX] = {
 		.variant = IMX6SX,
+		.mode = DW_PCIE_RC_TYPE,
 		.flags = IMX6_PCIE_FLAG_IMX6_PHY |
 			 IMX6_PCIE_FLAG_IMX6_SPEED_CHANGE |
 			 IMX6_PCIE_FLAG_SUPPORTS_SUSPEND,
 	},
 	[IMX6QP] = {
 		.variant = IMX6QP,
+		.mode = DW_PCIE_RC_TYPE,
 		.flags = IMX6_PCIE_FLAG_IMX6_PHY |
-			 IMX6_PCIE_FLAG_IMX6_SPEED_CHANGE,
+			 IMX6_PCIE_FLAG_IMX6_SPEED_CHANGE |
+			 IMX6_PCIE_FLAG_SUPPORTS_SUSPEND,
+		.dbi_length = 0x200,
 	},
 	[IMX7D] = {
 		.variant = IMX7D,
+		.mode = DW_PCIE_RC_TYPE,
 		.flags = IMX6_PCIE_FLAG_SUPPORTS_SUSPEND,
 	},
 	[IMX8MQ] = {
 		.variant = IMX8MQ,
+		.mode = DW_PCIE_RC_TYPE,
+		.flags = IMX6_PCIE_FLAG_SUPPORTS_SUSPEND |
+			 IMX6_PCIE_FLAG_SUPPORTS_L1SS,
+	},
+	[IMX8MM] = {
+		.variant = IMX8MM,
+		.mode = DW_PCIE_RC_TYPE,
+		.flags = IMX6_PCIE_FLAG_SUPPORTS_SUSPEND |
+			 IMX6_PCIE_FLAG_SUPPORTS_L1SS,
+	},
+	[IMX8QM] = {
+		.variant = IMX8QM,
+		.mode = DW_PCIE_RC_TYPE,
+		.flags = IMX6_PCIE_FLAG_SUPPORTS_SUSPEND |
+			 IMX6_PCIE_FLAG_IMX6_CPU_ADDR_FIXUP,
+	},
+	[IMX8QXP] = {
+		.variant = IMX8QXP,
+		.mode = DW_PCIE_RC_TYPE,
+		.flags = IMX6_PCIE_FLAG_SUPPORTS_SUSPEND |
+			 IMX6_PCIE_FLAG_IMX6_CPU_ADDR_FIXUP,
+	},
+	[IMX8MP] = {
+		.variant = IMX8MP,
+		.mode = DW_PCIE_RC_TYPE,
+		.flags = IMX6_PCIE_FLAG_SUPPORTS_SUSPEND |
+			 IMX6_PCIE_FLAG_SUPPORTS_L1SS,
+	},
+	[IMX8QXP_EP] = {
+		.variant = IMX8QXP_EP,
+		.mode = DW_PCIE_EP_TYPE,
+		.flags = IMX6_PCIE_FLAG_IMX6_CPU_ADDR_FIXUP,
+	},
+	[IMX8QM_EP] = {
+		.variant = IMX8QM_EP,
+		.mode = DW_PCIE_EP_TYPE,
+		.flags = IMX6_PCIE_FLAG_IMX6_CPU_ADDR_FIXUP,
+	},
+	[IMX8MQ_EP] = {
+		.variant = IMX8MQ_EP,
+		.mode = DW_PCIE_EP_TYPE,
+	},
+	[IMX8MM_EP] = {
+		.variant = IMX8MM_EP,
+		.mode = DW_PCIE_EP_TYPE,
+	},
+	[IMX8MP_EP] = {
+		.variant = IMX8MP_EP,
+		.mode = DW_PCIE_EP_TYPE,
+	},
+	[IMX6SX_EP] = {
+		.variant = IMX6SX_EP,
+		.mode = DW_PCIE_EP_TYPE,
+		.flags = IMX6_PCIE_FLAG_IMX6_PHY,
+	},
+	[IMX7D_EP] = {
+		.variant = IMX7D_EP,
+		.mode = DW_PCIE_EP_TYPE,
+	},
+	[IMX6Q_EP] = {
+		.variant = IMX6Q_EP,
+		.mode = DW_PCIE_EP_TYPE,
+		.flags = IMX6_PCIE_FLAG_IMX6_PHY,
+	},
+	[IMX6QP_EP] = {
+		.variant = IMX6QP_EP,
+		.mode = DW_PCIE_EP_TYPE,
+		.flags = IMX6_PCIE_FLAG_IMX6_PHY,
 	},
 };
 
@@ -1217,7 +2873,20 @@ static const struct of_device_id imx6_pcie_of_match[] = {
 	{ .compatible = "fsl,imx6sx-pcie", .data = &drvdata[IMX6SX], },
 	{ .compatible = "fsl,imx6qp-pcie", .data = &drvdata[IMX6QP], },
 	{ .compatible = "fsl,imx7d-pcie",  .data = &drvdata[IMX7D],  },
-	{ .compatible = "fsl,imx8mq-pcie", .data = &drvdata[IMX8MQ], } ,
+	{ .compatible = "fsl,imx8mq-pcie", .data = &drvdata[IMX8MQ], },
+	{ .compatible = "fsl,imx8mm-pcie", .data = &drvdata[IMX8MM], },
+	{ .compatible = "fsl,imx8qm-pcie", .data = &drvdata[IMX8QM], },
+	{ .compatible = "fsl,imx8qxp-pcie", .data = &drvdata[IMX8QXP], },
+	{ .compatible = "fsl,imx8mp-pcie", .data = &drvdata[IMX8MP], },
+	{ .compatible = "fsl,imx8qxp-pcie-ep", .data = &drvdata[IMX8QXP_EP], },
+	{ .compatible = "fsl,imx8qm-pcie-ep", .data = &drvdata[IMX8QM_EP], },
+	{ .compatible = "fsl,imx8mq-pcie-ep", .data = &drvdata[IMX8MQ_EP], },
+	{ .compatible = "fsl,imx8mm-pcie-ep", .data = &drvdata[IMX8MM_EP], },
+	{ .compatible = "fsl,imx8mp-pcie-ep", .data = &drvdata[IMX8MP_EP], },
+	{ .compatible = "fsl,imx6sx-pcie-ep", .data = &drvdata[IMX6SX_EP], },
+	{ .compatible = "fsl,imx7d-pcie-ep", .data = &drvdata[IMX7D_EP], },
+	{ .compatible = "fsl,imx6q-pcie-ep", .data = &drvdata[IMX6Q_EP], },
+	{ .compatible = "fsl,imx6qp-pcie-ep", .data = &drvdata[IMX6QP_EP], },
 	{},
 };
 
@@ -1264,6 +2933,58 @@ static void imx6_pcie_quirk(struct pci_dev *dev)
 DECLARE_PCI_FIXUP_CLASS_HEADER(PCI_VENDOR_ID_SYNOPSYS, 0xabcd,
 			PCI_CLASS_BRIDGE_PCI, 8, imx6_pcie_quirk);
 
+static void imx6_pcie_l1ss_quirk(struct pci_dev *dev)
+{
+	u32 reg, rc_l1sub, ep_l1sub, header;
+	int ttl, ret;
+	int pos = PCI_CFG_SPACE_SIZE;
+	struct pci_bus *bus = dev->bus;
+	struct pcie_port *pp = bus->sysdata;
+	struct dw_pcie *pci = to_dw_pcie_from_pp(pp);
+	struct imx6_pcie *imx6_pcie = to_imx6_pcie(pci);
+
+	/* Return directly, if the L1SS is not supported by RC */
+	if (!(imx6_pcie->drvdata->flags & IMX6_PCIE_FLAG_SUPPORTS_L1SS))
+		return;
+
+	/* Make sure the L1SS is not force disabled. */
+	if (imx6_pcie->l1ss_clkreq == 0)
+		return;
+
+	reg = dw_pcie_find_ext_capability(pci, PCI_EXT_CAP_ID_L1SS);
+	rc_l1sub = dw_pcie_readl_dbi(pci, reg + PCI_L1SS_CAP);
+
+	/* minimum 8 bytes per capability */
+	ttl = (PCI_CFG_SPACE_EXP_SIZE - PCI_CFG_SPACE_SIZE) / 8;
+	ret = dw_pcie_read(pp->va_cfg0_base + pos, 4, &header);
+	/*
+	 * If we have no capabilities, this is indicated by cap ID,
+	 * cap version and next pointer all being 0.
+	 */
+	if (header == 0)
+		return;
+
+	while (ttl-- > 0) {
+		if (PCI_EXT_CAP_ID(header) == PCI_EXT_CAP_ID_L1SS && pos != 0)
+			break;
+
+		pos = PCI_EXT_CAP_NEXT(header);
+		if (pos < PCI_CFG_SPACE_SIZE)
+			break;
+
+		ret = dw_pcie_read(pp->va_cfg0_base + pos, 4, &header);
+	}
+	ret = dw_pcie_read(pp->va_cfg0_base + pos + PCI_L1SS_CAP, 4, &ep_l1sub);
+
+	if ((rc_l1sub && ep_l1sub) && PCI_L1SS_CAP_L1_PM_SS) {
+		imx6_pcie->l1ss_clkreq = 1;
+		imx6_pcie_clkreq_enable(imx6_pcie);
+	} else {
+		imx6_pcie->l1ss_clkreq = 0;
+	}
+}
+DECLARE_PCI_FIXUP_FINAL(PCI_VENDOR_ID_SYNOPSYS, 0xabcd, imx6_pcie_l1ss_quirk);
+
 static int __init imx6_pcie_init(void)
 {
 #ifdef CONFIG_ARM
@@ -1281,3 +3002,4 @@ static int __init imx6_pcie_init(void)
 	return platform_driver_register(&imx6_pcie_driver);
 }
 device_initcall(imx6_pcie_init);
+MODULE_LICENSE("GPL v2");
diff --git a/drivers/pci/controller/dwc/pci-layerscape.c b/drivers/pci/controller/dwc/pci-layerscape.c
index f24f79a70..ca9ea07f7 100644
--- a/drivers/pci/controller/dwc/pci-layerscape.c
+++ b/drivers/pci/controller/dwc/pci-layerscape.c
@@ -3,13 +3,16 @@
  * PCIe host controller driver for Freescale Layerscape SoCs
  *
  * Copyright (C) 2014 Freescale Semiconductor.
+ * Copyright 2020 NXP
  *
  * Author: Minghuan Lian <Minghuan.Lian@freescale.com>
  */
 
+#include <linux/delay.h>
 #include <linux/kernel.h>
 #include <linux/interrupt.h>
 #include <linux/init.h>
+#include <linux/iopoll.h>
 #include <linux/of_pci.h>
 #include <linux/of_platform.h>
 #include <linux/of_irq.h>
@@ -22,35 +25,71 @@
 
 #include "pcie-designware.h"
 
-/* PEX1/2 Misc Ports Status Register */
-#define SCFG_PEXMSCPORTSR(pex_idx)	(0x94 + (pex_idx) * 4)
-#define LTSSM_STATE_SHIFT	20
-#define LTSSM_STATE_MASK	0x3f
-#define LTSSM_PCIE_L0		0x11 /* L0 state */
-
 /* PEX Internal Configuration Registers */
 #define PCIE_STRFMR1		0x71c /* Symbol Timer & Filter Mask Register1 */
 #define PCIE_ABSERR		0x8d0 /* Bridge Slave Error Response Register */
 #define PCIE_ABSERR_SETTING	0x9401 /* Forward error of non-posted request */
 
+#define PCIE_PM_SCR		0x44
+#define PCIE_PM_SCR_PMEPS_D0	0x0
+#define PCIE_PM_SCR_PMEPS_D3	0x3
+
+#define PCIE_LNKCTL		0x80  /* PCIe link ctrl Register */
+
+/* PF Message Command Register */
+#define LS_PCIE_PF_MCR		0x2c
+#define PF_MCR_PTOMR		BIT(0)
+#define PF_MCR_EXL2S		BIT(1)
+
+/* LS1021A PEXn PM Write Control Register */
+#define SCFG_PEXPMWRCR(idx)	(0x5c + (idx) * 0x64)
+#define PMXMTTURNOFF		BIT(31)
+#define SCFG_PEXSFTRSTCR	0x190
+#define PEXSR(idx)		BIT(idx)
+
+/* LS1043A PEX PME control register */
+#define SCFG_PEXPMECR		0x144
+#define PEXPME(idx)		BIT(31 - (idx) * 4)
+
+/* LS1043A PEX LUT debug register */
+#define LS_PCIE_LDBG	0x7fc
+#define LDBG_SR		BIT(30)
+#define LDBG_WE		BIT(31)
+
 #define PCIE_IATU_NUM		6
 
+#define LS_PCIE_IS_L2(v)	\
+	(((v) & PORT_LOGIC_LTSSM_STATE_MASK) == PORT_LOGIC_LTSSM_STATE_L2)
+
+struct ls_pcie;
+
+struct ls_pcie_host_pm_ops {
+	int (*pm_init)(struct ls_pcie *pcie);
+	void (*send_turn_off_message)(struct ls_pcie *pcie);
+	void (*exit_from_l2)(struct ls_pcie *pcie);
+};
+
 struct ls_pcie_drvdata {
-	u32 lut_offset;
-	u32 ltssm_shift;
-	u32 lut_dbg;
+	const u32 pf_off;
+	const u32 lut_off;
 	const struct dw_pcie_host_ops *ops;
-	const struct dw_pcie_ops *dw_pcie_ops;
+	const struct ls_pcie_host_pm_ops *pm_ops;
 };
 
 struct ls_pcie {
 	struct dw_pcie *pci;
-	void __iomem *lut;
-	struct regmap *scfg;
 	const struct ls_pcie_drvdata *drvdata;
+	void __iomem *pf_base;
+	void __iomem *lut_base;
+	bool big_endian;
+	bool ep_presence;
+	bool pm_support;
+	struct regmap *scfg;
 	int index;
 };
 
+#define ls_pcie_lut_readl_addr(addr)	ls_pcie_lut_readl(pcie, addr)
+#define ls_pcie_pf_readl_addr(addr)	ls_pcie_pf_readl(pcie, addr)
 #define to_ls_pcie(x)	dev_get_drvdata((x)->dev)
 
 static bool ls_pcie_is_bridge(struct ls_pcie *pcie)
@@ -91,75 +130,176 @@ static void ls_pcie_disable_outbound_atus(struct ls_pcie *pcie)
 		dw_pcie_disable_atu(pcie->pci, i, DW_PCIE_REGION_OUTBOUND);
 }
 
-static int ls1021_pcie_link_up(struct dw_pcie *pci)
+/* Forward error response of outbound non-posted requests */
+static void ls_pcie_fix_error_response(struct ls_pcie *pcie)
 {
-	u32 state;
-	struct ls_pcie *pcie = to_ls_pcie(pci);
+	struct dw_pcie *pci = pcie->pci;
 
-	if (!pcie->scfg)
-		return 0;
+	iowrite32(PCIE_ABSERR_SETTING, pci->dbi_base + PCIE_ABSERR);
+}
 
-	regmap_read(pcie->scfg, SCFG_PEXMSCPORTSR(pcie->index), &state);
-	state = (state >> LTSSM_STATE_SHIFT) & LTSSM_STATE_MASK;
+static u32 ls_pcie_lut_readl(struct ls_pcie *pcie, u32 off)
+{
+	if (pcie->big_endian)
+		return ioread32be(pcie->lut_base + off);
 
-	if (state < LTSSM_PCIE_L0)
-		return 0;
+	return ioread32(pcie->lut_base + off);
+}
+
+static void ls_pcie_lut_writel(struct ls_pcie *pcie, u32 off, u32 val)
+{
+	if (pcie->big_endian)
+		return iowrite32be(val, pcie->lut_base + off);
+
+	return iowrite32(val, pcie->lut_base + off);
 
-	return 1;
 }
 
-static int ls_pcie_link_up(struct dw_pcie *pci)
+static u32 ls_pcie_pf_readl(struct ls_pcie *pcie, u32 off)
 {
-	struct ls_pcie *pcie = to_ls_pcie(pci);
-	u32 state;
+	if (pcie->big_endian)
+		return ioread32be(pcie->pf_base + off);
+
+	return ioread32(pcie->pf_base + off);
+}
 
-	state = (ioread32(pcie->lut + pcie->drvdata->lut_dbg) >>
-		 pcie->drvdata->ltssm_shift) &
-		 LTSSM_STATE_MASK;
+static void ls_pcie_pf_writel(struct ls_pcie *pcie, u32 off, u32 val)
+{
+	if (pcie->big_endian)
+		return iowrite32be(val, pcie->pf_base + off);
 
-	if (state < LTSSM_PCIE_L0)
-		return 0;
+	return iowrite32(val, pcie->pf_base + off);
 
-	return 1;
 }
 
-/* Forward error response of outbound non-posted requests */
-static void ls_pcie_fix_error_response(struct ls_pcie *pcie)
+static void ls_pcie_send_turnoff_msg(struct ls_pcie *pcie)
+{
+	u32 val;
+	int ret;
+
+	val = ls_pcie_pf_readl(pcie, LS_PCIE_PF_MCR);
+	val |= PF_MCR_PTOMR;
+	ls_pcie_pf_writel(pcie, LS_PCIE_PF_MCR, val);
+
+	ret = readx_poll_timeout(ls_pcie_pf_readl_addr, LS_PCIE_PF_MCR,
+				 val, !(val & PF_MCR_PTOMR), 100, 10000);
+	if (ret)
+		dev_info(pcie->pci->dev, "poll turn off message timeout\n");
+}
+
+static void ls1021a_pcie_send_turnoff_msg(struct ls_pcie *pcie)
+{
+	u32 val;
+
+	if (!pcie->scfg) {
+		dev_dbg(pcie->pci->dev, "SYSCFG is NULL\n");
+		return;
+	}
+
+	/* Send Turn_off message */
+	regmap_read(pcie->scfg, SCFG_PEXPMWRCR(pcie->index), &val);
+	val |= PMXMTTURNOFF;
+	regmap_write(pcie->scfg, SCFG_PEXPMWRCR(pcie->index), val);
+
+	mdelay(10);
+
+	/* Clear Turn_off message */
+	regmap_read(pcie->scfg, SCFG_PEXPMWRCR(pcie->index), &val);
+	val &= ~PMXMTTURNOFF;
+	regmap_write(pcie->scfg, SCFG_PEXPMWRCR(pcie->index), val);
+}
+
+static void ls1043a_pcie_send_turnoff_msg(struct ls_pcie *pcie)
+{
+	u32 val;
+
+	if (!pcie->scfg) {
+		dev_dbg(pcie->pci->dev, "SYSCFG is NULL\n");
+		return;
+	}
+
+	/* Send Turn_off message */
+	regmap_read(pcie->scfg, SCFG_PEXPMECR, &val);
+	val |= PEXPME(pcie->index);
+	regmap_write(pcie->scfg, SCFG_PEXPMECR, val);
+
+	mdelay(10);
+
+	/* Clear Turn_off message */
+	regmap_read(pcie->scfg, SCFG_PEXPMECR, &val);
+	val &= ~PEXPME(pcie->index);
+	regmap_write(pcie->scfg, SCFG_PEXPMECR, val);
+}
+
+static void ls_pcie_exit_from_l2(struct ls_pcie *pcie)
+{
+	u32 val;
+	int ret;
+
+	val = ls_pcie_pf_readl(pcie, LS_PCIE_PF_MCR);
+	val |= PF_MCR_EXL2S;
+	ls_pcie_pf_writel(pcie, LS_PCIE_PF_MCR, val);
+
+	ret = readx_poll_timeout(ls_pcie_pf_readl_addr, LS_PCIE_PF_MCR,
+				 val, !(val & PF_MCR_EXL2S), 100, 10000);
+	if (ret)
+		dev_info(pcie->pci->dev, "poll exit L2 state timeout\n");
+}
+
+static void ls_pcie_retrain_link(struct ls_pcie *pcie)
 {
 	struct dw_pcie *pci = pcie->pci;
+	u32 val;
 
-	iowrite32(PCIE_ABSERR_SETTING, pci->dbi_base + PCIE_ABSERR);
+	val = dw_pcie_readw_dbi(pci, PCIE_LNKCTL);
+	val |= PCI_EXP_LNKCTL_RL;
+	dw_pcie_writew_dbi(pci, PCIE_LNKCTL, val);
 }
 
-static int ls_pcie_host_init(struct pcie_port *pp)
+static void ls1021a_pcie_exit_from_l2(struct ls_pcie *pcie)
 {
-	struct dw_pcie *pci = to_dw_pcie_from_pp(pp);
-	struct ls_pcie *pcie = to_ls_pcie(pci);
+	u32 val;
 
-	/*
-	 * Disable outbound windows configured by the bootloader to avoid
-	 * one transaction hitting multiple outbound windows.
-	 * dw_pcie_setup_rc() will reconfigure the outbound windows.
-	 */
-	ls_pcie_disable_outbound_atus(pcie);
-	ls_pcie_fix_error_response(pcie);
+	regmap_read(pcie->scfg, SCFG_PEXSFTRSTCR, &val);
+	val |= PEXSR(pcie->index);
+	regmap_write(pcie->scfg, SCFG_PEXSFTRSTCR, val);
 
-	dw_pcie_dbi_ro_wr_en(pci);
-	ls_pcie_clear_multifunction(pcie);
-	dw_pcie_dbi_ro_wr_dis(pci);
+	regmap_read(pcie->scfg, SCFG_PEXSFTRSTCR, &val);
+	val &= ~PEXSR(pcie->index);
+	regmap_write(pcie->scfg, SCFG_PEXSFTRSTCR, val);
 
-	ls_pcie_drop_msg_tlp(pcie);
+	mdelay(1);
 
-	dw_pcie_setup_rc(pp);
+	ls_pcie_retrain_link(pcie);
+}
+static void ls1043a_pcie_exit_from_l2(struct ls_pcie *pcie)
+{
+	u32 val;
 
-	return 0;
+	val = ls_pcie_lut_readl(pcie, LS_PCIE_LDBG);
+	val |= LDBG_WE;
+	ls_pcie_lut_writel(pcie, LS_PCIE_LDBG, val);
+
+	val = ls_pcie_lut_readl(pcie, LS_PCIE_LDBG);
+	val |= LDBG_SR;
+	ls_pcie_lut_writel(pcie, LS_PCIE_LDBG, val);
+
+	val = ls_pcie_lut_readl(pcie, LS_PCIE_LDBG);
+	val &= ~LDBG_SR;
+	ls_pcie_lut_writel(pcie, LS_PCIE_LDBG, val);
+
+	val = ls_pcie_lut_readl(pcie, LS_PCIE_LDBG);
+	val &= ~LDBG_WE;
+	ls_pcie_lut_writel(pcie, LS_PCIE_LDBG, val);
+
+	mdelay(1);
+
+	ls_pcie_retrain_link(pcie);
 }
 
-static int ls1021_pcie_host_init(struct pcie_port *pp)
+static int ls1021a_pcie_pm_init(struct ls_pcie *pcie)
 {
-	struct dw_pcie *pci = to_dw_pcie_from_pp(pp);
-	struct ls_pcie *pcie = to_ls_pcie(pci);
-	struct device *dev = pci->dev;
+	struct device *dev = pcie->pci->dev;
 	u32 index[2];
 	int ret;
 
@@ -172,14 +312,56 @@ static int ls1021_pcie_host_init(struct pcie_port *pp)
 		return ret;
 	}
 
-	if (of_property_read_u32_array(dev->of_node,
-				       "fsl,pcie-scfg", index, 2)) {
+	ret = of_property_read_u32_array(dev->of_node, "fsl,pcie-scfg",
+					 index, 2);
+	if (ret) {
 		pcie->scfg = NULL;
-		return -EINVAL;
+		return ret;
 	}
+
 	pcie->index = index[1];
 
-	return ls_pcie_host_init(pp);
+	return 0;
+}
+
+static int ls_pcie_pm_init(struct ls_pcie *pcie)
+{
+	return 0;
+}
+
+static void ls_pcie_set_dstate(struct ls_pcie *pcie, u32 dstate)
+{
+	struct dw_pcie *pci = pcie->pci;
+	u32 val;
+
+	val = dw_pcie_readw_dbi(pci, PCIE_PM_SCR);
+	val &= ~PCI_PM_CTRL_STATE_MASK;
+	val |= dstate;
+	dw_pcie_writew_dbi(pci, PCIE_PM_SCR, val);
+}
+
+static int ls_pcie_host_init(struct pcie_port *pp)
+{
+	struct dw_pcie *pci = to_dw_pcie_from_pp(pp);
+	struct ls_pcie *pcie = to_ls_pcie(pci);
+
+	/*
+	 * Disable outbound windows configured by the bootloader to avoid
+	 * one transaction hitting multiple outbound windows.
+	 * dw_pcie_setup_rc() will reconfigure the outbound windows.
+	 */
+	ls_pcie_disable_outbound_atus(pcie);
+	ls_pcie_fix_error_response(pcie);
+
+	dw_pcie_dbi_ro_wr_en(pci);
+	ls_pcie_clear_multifunction(pcie);
+	dw_pcie_dbi_ro_wr_dis(pci);
+
+	ls_pcie_drop_msg_tlp(pcie);
+
+	dw_pcie_setup_rc(pp);
+
+	return 0;
 }
 
 static int ls_pcie_msi_host_init(struct pcie_port *pp)
@@ -205,71 +387,57 @@ static int ls_pcie_msi_host_init(struct pcie_port *pp)
 	return 0;
 }
 
-static const struct dw_pcie_host_ops ls1021_pcie_host_ops = {
-	.host_init = ls1021_pcie_host_init,
-	.msi_host_init = ls_pcie_msi_host_init,
-};
-
-static const struct dw_pcie_host_ops ls_pcie_host_ops = {
-	.host_init = ls_pcie_host_init,
-	.msi_host_init = ls_pcie_msi_host_init,
-};
-
-static const struct dw_pcie_ops dw_ls1021_pcie_ops = {
-	.link_up = ls1021_pcie_link_up,
+static struct ls_pcie_host_pm_ops ls1021a_pcie_host_pm_ops = {
+	.pm_init = &ls1021a_pcie_pm_init,
+	.send_turn_off_message = &ls1021a_pcie_send_turnoff_msg,
+	.exit_from_l2 = &ls1021a_pcie_exit_from_l2,
 };
 
-static const struct dw_pcie_ops dw_ls_pcie_ops = {
-	.link_up = ls_pcie_link_up,
+static struct ls_pcie_host_pm_ops ls1043a_pcie_host_pm_ops = {
+	.pm_init = &ls1021a_pcie_pm_init,
+	.send_turn_off_message = &ls1043a_pcie_send_turnoff_msg,
+	.exit_from_l2 = &ls1043a_pcie_exit_from_l2,
 };
 
-static const struct ls_pcie_drvdata ls1021_drvdata = {
-	.ops = &ls1021_pcie_host_ops,
-	.dw_pcie_ops = &dw_ls1021_pcie_ops,
+static struct ls_pcie_host_pm_ops ls_pcie_host_pm_ops = {
+	.pm_init = &ls_pcie_pm_init,
+	.send_turn_off_message = &ls_pcie_send_turnoff_msg,
+	.exit_from_l2 = &ls_pcie_exit_from_l2,
 };
 
-static const struct ls_pcie_drvdata ls1043_drvdata = {
-	.lut_offset = 0x10000,
-	.ltssm_shift = 24,
-	.lut_dbg = 0x7fc,
-	.ops = &ls_pcie_host_ops,
-	.dw_pcie_ops = &dw_ls_pcie_ops,
+static const struct dw_pcie_host_ops ls_pcie_host_ops = {
+	.host_init = ls_pcie_host_init,
+	.msi_host_init = ls_pcie_msi_host_init,
 };
 
-static const struct ls_pcie_drvdata ls1046_drvdata = {
-	.lut_offset = 0x80000,
-	.ltssm_shift = 24,
-	.lut_dbg = 0x407fc,
+static const struct ls_pcie_drvdata ls1021a_drvdata = {
 	.ops = &ls_pcie_host_ops,
-	.dw_pcie_ops = &dw_ls_pcie_ops,
+	.pm_ops = &ls1021a_pcie_host_pm_ops,
 };
 
-static const struct ls_pcie_drvdata ls2080_drvdata = {
-	.lut_offset = 0x80000,
-	.ltssm_shift = 0,
-	.lut_dbg = 0x7fc,
+static const struct ls_pcie_drvdata ls1043a_drvdata = {
 	.ops = &ls_pcie_host_ops,
-	.dw_pcie_ops = &dw_ls_pcie_ops,
+	.lut_off = 0x10000,
+	.pm_ops = &ls1043a_pcie_host_pm_ops,
 };
 
-static const struct ls_pcie_drvdata ls2088_drvdata = {
-	.lut_offset = 0x80000,
-	.ltssm_shift = 0,
-	.lut_dbg = 0x407fc,
+static const struct ls_pcie_drvdata layerscape_drvdata = {
 	.ops = &ls_pcie_host_ops,
-	.dw_pcie_ops = &dw_ls_pcie_ops,
+	.lut_off = 0x80000,
+	.pf_off = 0xc0000,
+	.pm_ops = &ls_pcie_host_pm_ops,
 };
 
 static const struct of_device_id ls_pcie_of_match[] = {
-	{ .compatible = "fsl,ls1012a-pcie", .data = &ls1046_drvdata },
-	{ .compatible = "fsl,ls1021a-pcie", .data = &ls1021_drvdata },
-	{ .compatible = "fsl,ls1028a-pcie", .data = &ls2088_drvdata },
-	{ .compatible = "fsl,ls1043a-pcie", .data = &ls1043_drvdata },
-	{ .compatible = "fsl,ls1046a-pcie", .data = &ls1046_drvdata },
-	{ .compatible = "fsl,ls2080a-pcie", .data = &ls2080_drvdata },
-	{ .compatible = "fsl,ls2085a-pcie", .data = &ls2080_drvdata },
-	{ .compatible = "fsl,ls2088a-pcie", .data = &ls2088_drvdata },
-	{ .compatible = "fsl,ls1088a-pcie", .data = &ls2088_drvdata },
+	{ .compatible = "fsl,ls1012a-pcie", .data = &layerscape_drvdata },
+	{ .compatible = "fsl,ls1021a-pcie", .data = &ls1021a_drvdata },
+	{ .compatible = "fsl,ls1028a-pcie", .data = &layerscape_drvdata },
+	{ .compatible = "fsl,ls1043a-pcie", .data = &ls1043a_drvdata },
+	{ .compatible = "fsl,ls1046a-pcie", .data = &layerscape_drvdata },
+	{ .compatible = "fsl,ls2080a-pcie", .data = &layerscape_drvdata },
+	{ .compatible = "fsl,ls2085a-pcie", .data = &layerscape_drvdata },
+	{ .compatible = "fsl,ls2088a-pcie", .data = &layerscape_drvdata },
+	{ .compatible = "fsl,ls1088a-pcie", .data = &layerscape_drvdata },
 	{ },
 };
 
@@ -288,6 +456,15 @@ static int __init ls_add_pcie_port(struct ls_pcie *pcie)
 		return ret;
 	}
 
+	if (dw_pcie_link_up(pci)) {
+		dev_dbg(pci->dev, "Endpoint is present\n");
+		pcie->ep_presence = true;
+	}
+
+	if (pcie->drvdata->pm_ops && pcie->drvdata->pm_ops->pm_init &&
+	    !pcie->drvdata->pm_ops->pm_init(pcie))
+		pcie->pm_support = true;
+
 	return 0;
 }
 
@@ -310,7 +487,6 @@ static int __init ls_pcie_probe(struct platform_device *pdev)
 	pcie->drvdata = of_device_get_match_data(dev);
 
 	pci->dev = dev;
-	pci->ops = pcie->drvdata->dw_pcie_ops;
 
 	pcie->pci = pci;
 
@@ -319,7 +495,13 @@ static int __init ls_pcie_probe(struct platform_device *pdev)
 	if (IS_ERR(pci->dbi_base))
 		return PTR_ERR(pci->dbi_base);
 
-	pcie->lut = pci->dbi_base + pcie->drvdata->lut_offset;
+	pcie->big_endian = of_property_read_bool(dev->of_node, "big-endian");
+
+	if (pcie->drvdata->lut_off)
+		pcie->lut_base = pci->dbi_base + pcie->drvdata->lut_off;
+
+	if (pcie->drvdata->pf_off)
+		pcie->pf_base = pci->dbi_base + pcie->drvdata->pf_off;
 
 	if (!ls_pcie_is_bridge(pcie))
 		return -ENODEV;
@@ -333,11 +515,88 @@ static int __init ls_pcie_probe(struct platform_device *pdev)
 	return 0;
 }
 
+static bool ls_pcie_pm_check(struct ls_pcie *pcie)
+{
+	if (!pcie->ep_presence) {
+		dev_dbg(pcie->pci->dev, "Endpoint isn't present\n");
+		return false;
+	}
+
+	if (!pcie->pm_support)
+		return false;
+
+	return true;
+}
+
+#ifdef CONFIG_PM_SLEEP
+static int ls_pcie_suspend_noirq(struct device *dev)
+{
+	struct ls_pcie *pcie = dev_get_drvdata(dev);
+	struct dw_pcie *pci = pcie->pci;
+	u32 val;
+	int ret;
+
+	if (!ls_pcie_pm_check(pcie))
+		return 0;
+
+	pcie->drvdata->pm_ops->send_turn_off_message(pcie);
+
+	/* 10ms timeout to check L2 ready */
+	ret = readl_poll_timeout(pci->dbi_base + PCIE_PORT_DEBUG0,
+				 val, LS_PCIE_IS_L2(val), 100, 10000);
+	if (ret) {
+		dev_err(dev, "PCIe link enter L2 timeout! ltssm = 0x%x\n", val);
+		return ret;
+	}
+
+	ls_pcie_set_dstate(pcie, PCIE_PM_SCR_PMEPS_D3);
+
+	return 0;
+}
+
+static int ls_pcie_resume_noirq(struct device *dev)
+{
+	struct ls_pcie *pcie = dev_get_drvdata(dev);
+	struct dw_pcie *pci = pcie->pci;
+	int ret;
+
+	if (!ls_pcie_pm_check(pcie))
+		return 0;
+
+	ls_pcie_set_dstate(pcie, PCIE_PM_SCR_PMEPS_D0);
+
+	pcie->drvdata->pm_ops->exit_from_l2(pcie);
+
+	/* delay 10ms to access EP */
+	mdelay(10);
+
+	ret = ls_pcie_host_init(&pci->pp);
+	if (ret) {
+		dev_err(dev, "ls_pcie_host_init failed! ret = 0x%x\n", ret);
+		return ret;
+	}
+
+	ret = dw_pcie_wait_for_link(pci);
+	if (ret) {
+		dev_err(dev, "wait link up timeout! ret = 0x%x\n", ret);
+		return ret;
+	}
+
+	return 0;
+}
+#endif /* CONFIG_PM_SLEEP */
+
+static const struct dev_pm_ops ls_pcie_pm_ops = {
+	SET_NOIRQ_SYSTEM_SLEEP_PM_OPS(ls_pcie_suspend_noirq,
+				      ls_pcie_resume_noirq)
+};
+
 static struct platform_driver ls_pcie_driver = {
 	.driver = {
 		.name = "layerscape-pcie",
 		.of_match_table = ls_pcie_of_match,
 		.suppress_bind_attrs = true,
+		.pm = &ls_pcie_pm_ops,
 	},
 };
 builtin_platform_driver_probe(ls_pcie_driver, ls_pcie_probe);
diff --git a/drivers/pci/controller/dwc/pcie-designware.c b/drivers/pci/controller/dwc/pcie-designware.c
index c2dea8fc9..df74d596b 100644
--- a/drivers/pci/controller/dwc/pcie-designware.c
+++ b/drivers/pci/controller/dwc/pcie-designware.c
@@ -141,7 +141,7 @@ u32 dw_pcie_read_dbi(struct dw_pcie *pci, u32 reg, size_t size)
 	int ret;
 	u32 val;
 
-	if (pci->ops->read_dbi)
+	if (pci->ops && pci->ops->read_dbi)
 		return pci->ops->read_dbi(pci, pci->dbi_base, reg, size);
 
 	ret = dw_pcie_read(pci->dbi_base + reg, size, &val);
@@ -156,7 +156,7 @@ void dw_pcie_write_dbi(struct dw_pcie *pci, u32 reg, size_t size, u32 val)
 {
 	int ret;
 
-	if (pci->ops->write_dbi) {
+	if (pci->ops && pci->ops->write_dbi) {
 		pci->ops->write_dbi(pci, pci->dbi_base, reg, size, val);
 		return;
 	}
@@ -171,7 +171,7 @@ void dw_pcie_write_dbi2(struct dw_pcie *pci, u32 reg, size_t size, u32 val)
 {
 	int ret;
 
-	if (pci->ops->write_dbi2) {
+	if (pci->ops && pci->ops->write_dbi2) {
 		pci->ops->write_dbi2(pci, pci->dbi_base2, reg, size, val);
 		return;
 	}
@@ -186,7 +186,7 @@ static u32 dw_pcie_readl_atu(struct dw_pcie *pci, u32 reg)
 	int ret;
 	u32 val;
 
-	if (pci->ops->read_dbi)
+	if (pci->ops && pci->ops->read_dbi)
 		return pci->ops->read_dbi(pci, pci->atu_base, reg, 4);
 
 	ret = dw_pcie_read(pci->atu_base + reg, 4, &val);
@@ -200,7 +200,7 @@ static void dw_pcie_writel_atu(struct dw_pcie *pci, u32 reg, u32 val)
 {
 	int ret;
 
-	if (pci->ops->write_dbi) {
+	if (pci->ops && pci->ops->write_dbi) {
 		pci->ops->write_dbi(pci, pci->atu_base, reg, 4, val);
 		return;
 	}
@@ -271,7 +271,7 @@ static void __dw_pcie_prog_outbound_atu(struct dw_pcie *pci, u8 func_no,
 {
 	u32 retries, val;
 
-	if (pci->ops->cpu_addr_fixup)
+	if (pci->ops && pci->ops->cpu_addr_fixup)
 		cpu_addr = pci->ops->cpu_addr_fixup(pci, cpu_addr);
 
 	if (pci->iatu_unroll_enabled) {
@@ -479,13 +479,14 @@ int dw_pcie_link_up(struct dw_pcie *pci)
 {
 	u32 val;
 
-	if (pci->ops->link_up)
+	if (pci->ops && pci->ops->link_up)
 		return pci->ops->link_up(pci);
 
 	val = readl(pci->dbi_base + PCIE_PORT_DEBUG1);
 	return ((val & PCIE_PORT_DEBUG1_LINK_UP) &&
 		(!(val & PCIE_PORT_DEBUG1_LINK_IN_TRAINING)));
 }
+EXPORT_SYMBOL_GPL(dw_pcie_link_up);
 
 void dw_pcie_upconfig_setup(struct dw_pcie *pci)
 {
diff --git a/drivers/pci/controller/dwc/pcie-designware.h b/drivers/pci/controller/dwc/pcie-designware.h
index 9d2f511f1..0d863f525 100644
--- a/drivers/pci/controller/dwc/pcie-designware.h
+++ b/drivers/pci/controller/dwc/pcie-designware.h
@@ -54,6 +54,7 @@
 #define PCIE_PORT_DEBUG0		0x728
 #define PORT_LOGIC_LTSSM_STATE_MASK	0x1f
 #define PORT_LOGIC_LTSSM_STATE_L0	0x11
+#define PORT_LOGIC_LTSSM_STATE_L2	0x15
 #define PCIE_PORT_DEBUG1		0x72C
 #define PCIE_PORT_DEBUG1_LINK_UP		BIT(4)
 #define PCIE_PORT_DEBUG1_LINK_IN_TRAINING	BIT(29)
diff --git a/drivers/pci/controller/mobiveil/pcie-layerscape-gen4.c b/drivers/pci/controller/mobiveil/pcie-layerscape-gen4.c
index ee0156921..98a1f438f 100644
--- a/drivers/pci/controller/mobiveil/pcie-layerscape-gen4.c
+++ b/drivers/pci/controller/mobiveil/pcie-layerscape-gen4.c
@@ -22,8 +22,12 @@
 
 #include "pcie-mobiveil.h"
 
+#define REV_1_0				0x10
+
 /* LUT and PF control registers */
 #define PCIE_LUT_OFF			0x80000
+#define PCIE_LUT_GCR			0x28
+#define PCIE_LUT_GCR_RRE		BIT(0)
 #define PCIE_PF_OFF			0xc0000
 #define PCIE_PF_INT_STAT		0x18
 #define PF_INT_STAT_PABRST		BIT(31)
@@ -40,6 +44,7 @@ struct ls_pcie_g4 {
 	struct mobiveil_pcie pci;
 	struct delayed_work dwork;
 	int irq;
+	u8 rev;
 };
 
 static inline u32 ls_pcie_g4_lut_readl(struct ls_pcie_g4 *pcie, u32 off)
@@ -64,6 +69,30 @@ static inline void ls_pcie_g4_pf_writel(struct ls_pcie_g4 *pcie,
 	iowrite32(val, pcie->pci.csr_axi_slave_base + PCIE_PF_OFF + off);
 }
 
+static void workaround_A011451(struct ls_pcie_g4 *pcie)
+{
+	struct mobiveil_pcie *mv_pci = &pcie->pci;
+	u32 val;
+
+	/* Set ACK latency timeout */
+	val = mobiveil_csr_readl(mv_pci, GPEX_ACK_REPLAY_TO);
+	val &= ~(ACK_LAT_TO_VAL_MASK << ACK_LAT_TO_VAL_SHIFT);
+	val |= (4 << ACK_LAT_TO_VAL_SHIFT);
+	mobiveil_csr_writel(mv_pci, val, GPEX_ACK_REPLAY_TO);
+}
+
+static int ls_pcie_g4_host_init(struct mobiveil_pcie *pci)
+{
+	struct ls_pcie_g4 *pcie = to_ls_pcie_g4(pci);
+
+	pcie->rev = mobiveil_csr_readb(pci, PCI_REVISION_ID);
+
+	if (pcie->rev == REV_1_0)
+		workaround_A011451(pcie);
+
+	return 0;
+}
+
 static int ls_pcie_g4_link_up(struct mobiveil_pcie *pci)
 {
 	struct ls_pcie_g4 *pcie = to_ls_pcie_g4(pci);
@@ -201,12 +230,39 @@ static void ls_pcie_g4_reset(struct work_struct *work)
 	ls_pcie_g4_enable_interrupt(pcie);
 }
 
+static int ls_pcie_g4_read_other_conf(struct pci_bus *bus, unsigned int devfn,
+				   int where, int size, u32 *val)
+{
+	struct mobiveil_pcie *pci = bus->sysdata;
+	struct ls_pcie_g4 *pcie = to_ls_pcie_g4(pci);
+	u32 reg;
+	int ret;
+
+	if (pcie->rev == REV_1_0 && where == PCI_VENDOR_ID) {
+		reg = ls_pcie_g4_lut_readl(pcie, PCIE_LUT_GCR);
+		reg &= ~PCIE_LUT_GCR_RRE;
+		ls_pcie_g4_lut_writel(pcie, PCIE_LUT_GCR, reg);
+	}
+
+	ret = pci_generic_config_read(bus, devfn, where, size, val);
+
+	if (pcie->rev == REV_1_0 && where == PCI_VENDOR_ID) {
+		reg = ls_pcie_g4_lut_readl(pcie, PCIE_LUT_GCR);
+		reg |= PCIE_LUT_GCR_RRE;
+		ls_pcie_g4_lut_writel(pcie, PCIE_LUT_GCR, reg);
+	}
+
+	return ret;
+}
+
 static struct mobiveil_rp_ops ls_pcie_g4_rp_ops = {
 	.interrupt_init = ls_pcie_g4_interrupt_init,
+	.read_other_conf = ls_pcie_g4_read_other_conf,
 };
 
 static const struct mobiveil_pab_ops ls_pcie_g4_pab_ops = {
 	.link_up = ls_pcie_g4_link_up,
+	.host_init = ls_pcie_g4_host_init,
 };
 
 static int __init ls_pcie_g4_probe(struct platform_device *pdev)
diff --git a/drivers/pci/controller/mobiveil/pcie-mobiveil-host.c b/drivers/pci/controller/mobiveil/pcie-mobiveil-host.c
index a2632d02c..368c5f34a 100644
--- a/drivers/pci/controller/mobiveil/pcie-mobiveil-host.c
+++ b/drivers/pci/controller/mobiveil/pcie-mobiveil-host.c
@@ -29,6 +29,12 @@
 
 static bool mobiveil_pcie_valid_device(struct pci_bus *bus, unsigned int devfn)
 {
+	struct mobiveil_pcie *pcie = bus->sysdata;
+
+	/* If there is no link, then there is no device */
+	if (!pci_is_root_bus(bus) && !mobiveil_pcie_link_up(pcie))
+		return false;
+
 	/* Only one device down on each root port */
 	if (pci_is_root_bus(bus) && (devfn > 0))
 		return false;
@@ -61,6 +67,12 @@ static void __iomem *mobiveil_pcie_map_bus(struct pci_bus *bus,
 	if (pci_is_root_bus(bus))
 		return pcie->csr_axi_slave_base + where;
 
+	/* Make sure the Master Enable bit not cleared */
+	value = mobiveil_csr_readl(pcie, PCI_COMMAND);
+	if (!(value & PCI_COMMAND_MASTER))
+		mobiveil_csr_writel(pcie, value | PCI_COMMAND_MASTER,
+				    PCI_COMMAND);
+
 	/*
 	 * EP config access (in Config/APIO space)
 	 * Program PEX Address base (31..16 bits) with appropriate value
@@ -76,9 +88,20 @@ static void __iomem *mobiveil_pcie_map_bus(struct pci_bus *bus,
 	return rp->config_axi_slave_base + where;
 }
 
+static int mobiveil_pcie_config_read(struct pci_bus *bus, unsigned int devfn,
+				     int where, int size, u32 *val)
+{
+	struct mobiveil_pcie *pcie = bus->sysdata;
+	struct mobiveil_root_port *rp = &pcie->rp;
+
+	if (!pci_is_root_bus(bus) && rp->ops->read_other_conf)
+		return rp->ops->read_other_conf(bus, devfn, where, size, val);
+
+	return pci_generic_config_read(bus, devfn, where, size, val);
+}
 static struct pci_ops mobiveil_pcie_ops = {
 	.map_bus = mobiveil_pcie_map_bus,
-	.read = pci_generic_config_read,
+	.read = mobiveil_pcie_config_read,
 	.write = pci_generic_config_write,
 };
 
@@ -301,6 +324,10 @@ int mobiveil_host_init(struct mobiveil_pcie *pcie, bool reinit)
 	value |= (PCI_CLASS_BRIDGE_PCI << 16);
 	mobiveil_csr_writel(pcie, value, PAB_INTP_AXI_PIO_CLASS);
 
+	/* Platform specific host init */
+	if (pcie->ops->host_init)
+		return pcie->ops->host_init(pcie);
+
 	return 0;
 }
 
@@ -591,10 +618,8 @@ int mobiveil_pcie_host_probe(struct mobiveil_pcie *pcie)
 	bridge->ops = &mobiveil_pcie_ops;
 
 	ret = mobiveil_bringup_link(pcie);
-	if (ret) {
+	if (ret)
 		dev_info(dev, "link bring-up failed\n");
-		return ret;
-	}
 
 	return pci_host_probe(bridge);
 }
diff --git a/drivers/pci/controller/mobiveil/pcie-mobiveil.c b/drivers/pci/controller/mobiveil/pcie-mobiveil.c
index 62ecbaeb0..157046436 100644
--- a/drivers/pci/controller/mobiveil/pcie-mobiveil.c
+++ b/drivers/pci/controller/mobiveil/pcie-mobiveil.c
@@ -170,18 +170,12 @@ void program_ib_windows(struct mobiveil_pcie *pcie, int win_num,
 /*
  * routine to program the outbound windows
  */
-void program_ob_windows(struct mobiveil_pcie *pcie, int win_num,
-			u64 cpu_addr, u64 pci_addr, u32 type, u64 size)
+void __program_ob_windows(struct mobiveil_pcie *pcie, u8 func_no, int win_num,
+			  u64 cpu_addr, u64 pci_addr, u32 type, u64 size)
 {
 	u32 value;
 	u64 size64 = ~(size - 1);
 
-	if (win_num >= pcie->apio_wins) {
-		dev_err(&pcie->pdev->dev,
-			"ERROR: max outbound windows reached !\n");
-		return;
-	}
-
 	/*
 	 * program Enable Bit to 1, Type Bit to (00) base 2, AXI Window Size Bit
 	 * to 4 KB in PAB_AXI_AMAP_CTRL register
@@ -195,6 +189,7 @@ void program_ob_windows(struct mobiveil_pcie *pcie, int win_num,
 	mobiveil_csr_writel(pcie, upper_32_bits(size64),
 			    PAB_EXT_AXI_AMAP_SIZE(win_num));
 
+	mobiveil_csr_writel(pcie, func_no, PAB_AXI_AMAP_PCI_HDR_PARAM(win_num));
 	/*
 	 * program AXI window base with appropriate value in
 	 * PAB_AXI_AMAP_AXI_WIN0 register
@@ -209,10 +204,98 @@ void program_ob_windows(struct mobiveil_pcie *pcie, int win_num,
 			    PAB_AXI_AMAP_PEX_WIN_L(win_num));
 	mobiveil_csr_writel(pcie, upper_32_bits(pci_addr),
 			    PAB_AXI_AMAP_PEX_WIN_H(win_num));
+}
+
+void program_ob_windows(struct mobiveil_pcie *pcie, int win_num, u64 cpu_addr,
+			u64 pci_addr, u32 type, u64 size)
+{
+	if (win_num >= pcie->apio_wins) {
+		dev_err(&pcie->pdev->dev,
+			"ERROR: max outbound windows reached !\n");
+		return;
+	}
+
+	__program_ob_windows(pcie, 0, win_num, cpu_addr,
+			     pci_addr, type, size);
 
 	pcie->ob_wins_configured++;
 }
 
+void program_ob_windows_ep(struct mobiveil_pcie *pcie, u8 func_no, int win_num,
+			   u64 cpu_addr, u64 pci_addr, u32 type, u64 size)
+{
+	if (size & (size - 1))
+		size = 1 << (1 + ilog2(size));
+
+	__program_ob_windows(pcie, func_no, win_num, cpu_addr,
+			     pci_addr, type, size);
+}
+
+void program_ib_windows_ep(struct mobiveil_pcie *pcie, u8 func_no,
+			   int bar, u64 phys)
+{
+	mobiveil_csr_writel(pcie, upper_32_bits(phys),
+			    PAB_EXT_PEX_BAR_AMAP(func_no, bar));
+	mobiveil_csr_writel(pcie, lower_32_bits(phys) | PEX_BAR_AMAP_EN,
+			    PAB_PEX_BAR_AMAP(func_no, bar));
+}
+
+void mobiveil_pcie_disable_ib_win_ep(struct mobiveil_pcie *pcie,
+				     u8 func_no, u8 bar)
+{
+	u32 val;
+
+	val = mobiveil_csr_readl(pcie, PAB_PEX_BAR_AMAP(func_no, bar));
+	val &= ~(1 << 0);
+	mobiveil_csr_writel(pcie, val, PAB_PEX_BAR_AMAP(func_no, bar));
+}
+
+void mobiveil_pcie_disable_ob_win(struct mobiveil_pcie *pcie, int win_num)
+{
+	u32 val;
+
+	val = mobiveil_csr_readl(pcie, PAB_AXI_AMAP_CTRL(win_num));
+	val &= ~(1 << WIN_ENABLE_SHIFT);
+	mobiveil_csr_writel(pcie, val, PAB_AXI_AMAP_CTRL(win_num));
+}
+
+void mobiveil_pcie_enable_bridge_pio(struct mobiveil_pcie *pcie)
+{
+	u32 val;
+
+	val = mobiveil_csr_readl(pcie, PAB_CTRL);
+	val |= 1 << AMBA_PIO_ENABLE_SHIFT;
+	val |= 1 << PEX_PIO_ENABLE_SHIFT;
+	mobiveil_csr_writel(pcie, val, PAB_CTRL);
+}
+
+void mobiveil_pcie_enable_engine_apio(struct mobiveil_pcie *pcie)
+{
+	u32 val;
+
+	val = mobiveil_csr_readl(pcie, PAB_AXI_PIO_CTRL);
+	val |= APIO_EN_MASK;
+	mobiveil_csr_writel(pcie, val, PAB_AXI_PIO_CTRL);
+}
+
+void mobiveil_pcie_enable_engine_ppio(struct mobiveil_pcie *pcie)
+{
+	u32 val;
+
+	val = mobiveil_csr_readl(pcie, PAB_PEX_PIO_CTRL);
+	val |= 1 << PIO_ENABLE_SHIFT;
+	mobiveil_csr_writel(pcie, val, PAB_PEX_PIO_CTRL);
+}
+
+void mobiveil_pcie_enable_msi_ep(struct mobiveil_pcie *pcie)
+{
+	u32 val;
+
+	val =  mobiveil_csr_readl(pcie, PAB_INTP_AMBA_MISC_ENB);
+	val |= PAB_INTP_PAMR;
+	mobiveil_csr_writel(pcie, val, PAB_INTP_AMBA_MISC_ENB);
+}
+
 int mobiveil_bringup_link(struct mobiveil_pcie *pcie)
 {
 	int retries;
@@ -225,7 +308,7 @@ int mobiveil_bringup_link(struct mobiveil_pcie *pcie)
 		usleep_range(LINK_WAIT_MIN, LINK_WAIT_MAX);
 	}
 
-	dev_err(&pcie->pdev->dev, "link never came up\n");
+	dev_info(&pcie->pdev->dev, "link never came up\n");
 
 	return -ETIMEDOUT;
 }
diff --git a/drivers/pci/controller/mobiveil/pcie-mobiveil.h b/drivers/pci/controller/mobiveil/pcie-mobiveil.h
index 6082b8afb..7b0cf21fb 100644
--- a/drivers/pci/controller/mobiveil/pcie-mobiveil.h
+++ b/drivers/pci/controller/mobiveil/pcie-mobiveil.h
@@ -15,8 +15,12 @@
 #include <linux/pci.h>
 #include <linux/irq.h>
 #include <linux/msi.h>
+#include <linux/pci-epc.h>
+#include <linux/pci-epf.h>
+
 #include "../../pci.h"
 
+#define MAX_IATU_OUT			256
 /* register offsets and bit positions */
 
 /*
@@ -42,6 +46,9 @@
 #define  PAGE_SEL_MASK			0x3f
 #define  PAGE_LO_MASK			0x3ff
 #define  PAGE_SEL_OFFSET_SHIFT		10
+#define  FUNC_SEL_SHIFT			19
+#define  FUNC_SEL_MASK			0x1ff
+#define  MSI_SW_CTRL_EN			BIT(29)
 
 #define PAB_ACTIVITY_STAT		0x81c
 
@@ -52,6 +59,7 @@
 #define  PIO_ENABLE_SHIFT		0
 
 #define PAB_INTP_AMBA_MISC_ENB		0x0b0c
+#define  PAB_INTP_PAMR			BIT(0)
 #define PAB_INTP_AMBA_MISC_STAT		0x0b1c
 #define  PAB_INTP_RESET			BIT(1)
 #define  PAB_INTP_MSI			BIT(3)
@@ -72,6 +80,8 @@
 #define  WIN_TYPE_MASK			0x3
 #define  WIN_SIZE_MASK			0xfffffc00
 
+#define PAB_AXI_AMAP_PCI_HDR_PARAM(win)	PAB_EXT_REG_ADDR(0x5ba0, win)
+
 #define PAB_EXT_AXI_AMAP_SIZE(win)	PAB_EXT_REG_ADDR(0xbaf0, win)
 
 #define PAB_EXT_AXI_AMAP_AXI_WIN(win)	PAB_EXT_REG_ADDR(0x80a0, win)
@@ -86,6 +96,10 @@
 #define PAB_AXI_AMAP_PEX_WIN_H(win)	PAB_REG_ADDR(0x0bac, win)
 #define PAB_INTP_AXI_PIO_CLASS		0x474
 
+#define GPEX_ACK_REPLAY_TO		0x438
+#define  ACK_LAT_TO_VAL_MASK		0x1fff
+#define  ACK_LAT_TO_VAL_SHIFT		0
+
 #define PAB_PEX_AMAP_CTRL(win)		PAB_REG_ADDR(0x4ba0, win)
 #define  AMAP_CTRL_EN_SHIFT		0
 #define  AMAP_CTRL_TYPE_SHIFT		1
@@ -97,6 +111,22 @@
 #define PAB_PEX_AMAP_PEX_WIN_L(win)	PAB_REG_ADDR(0x4ba8, win)
 #define PAB_PEX_AMAP_PEX_WIN_H(win)	PAB_REG_ADDR(0x4bac, win)
 
+/* PPIO WINs EP mode */
+#define PAB_PEX_BAR_AMAP(func, bar)	(0x1ba0 + 0x20 * func + 4 * bar)
+#define PAB_EXT_PEX_BAR_AMAP(func, bar)	(0x84a0 + 0x20 * func + 4 * bar)
+#define PEX_BAR_AMAP_EN			BIT(0)
+
+#define PAB_MSIX_TABLE_PBA_ACCESS	0xD000
+
+#define GPEX_BAR_ENABLE			0x4D4
+#define GPEX_BAR_SIZE_LDW		0x4D8
+#define GPEX_BAR_SIZE_UDW		0x4DC
+#define GPEX_BAR_SELECT			0x4E0
+
+#define CFG_UNCORRECTABLE_ERROR_SEVERITY	0x10c
+#define UNSUPPORTED_REQUEST_ERROR_SHIFT		20
+#define CFG_UNCORRECTABLE_ERROR_MASK		0x108
+
 /* starting offset of INTX bits in status register */
 #define PAB_INTX_START			5
 
@@ -143,9 +173,12 @@ struct mobiveil_msi {			/* MSI information */
 };
 
 struct mobiveil_pcie;
+struct mobiveil_pcie_ep;
 
 struct mobiveil_rp_ops {
 	int (*interrupt_init)(struct mobiveil_pcie *pcie);
+	int (*read_other_conf)(struct pci_bus *bus, unsigned int devfn,
+			       int where, int size, u32 *val);
 };
 
 struct mobiveil_root_port {
@@ -161,6 +194,29 @@ struct mobiveil_root_port {
 
 struct mobiveil_pab_ops {
 	int (*link_up)(struct mobiveil_pcie *pcie);
+	int (*host_init)(struct mobiveil_pcie *pcie);
+};
+
+struct mobiveil_pcie_ep_ops {
+	void (*ep_init)(struct mobiveil_pcie_ep *ep);
+	int (*raise_irq)(struct mobiveil_pcie_ep *ep, u8 func_no,
+			 enum pci_epc_irq_type type, u16 interrupt_num);
+	const struct pci_epc_features* (*get_features)
+				       (struct mobiveil_pcie_ep *ep);
+};
+
+struct mobiveil_pcie_ep {
+	struct pci_epc *epc;
+	const struct mobiveil_pcie_ep_ops *ops;
+	phys_addr_t phys_base;
+	size_t addr_size;
+	size_t page_size;
+	phys_addr_t *apio_addr;
+	unsigned long *apio_wins_map;
+	u32 apio_wins;
+	void __iomem *msi_mem;
+	phys_addr_t msi_mem_phys;
+	u8 bar_num;
 };
 
 struct mobiveil_pcie {
@@ -174,8 +230,12 @@ struct mobiveil_pcie {
 	int ib_wins_configured;		/* configured inbound windows */
 	const struct mobiveil_pab_ops *ops;
 	struct mobiveil_root_port rp;
+	struct mobiveil_pcie_ep ep;
 };
 
+#define to_mobiveil_pcie_from_ep(endpoint)   \
+			    container_of((endpoint), struct mobiveil_pcie, ep)
+
 int mobiveil_pcie_host_probe(struct mobiveil_pcie *pcie);
 int mobiveil_host_init(struct mobiveil_pcie *pcie, bool reinit);
 bool mobiveil_pcie_link_up(struct mobiveil_pcie *pcie);
@@ -222,4 +282,23 @@ static inline void mobiveil_csr_writeb(struct mobiveil_pcie *pcie, u8 val,
 	mobiveil_csr_write(pcie, val, off, 0x1);
 }
 
+void program_ib_windows_ep(struct mobiveil_pcie *pcie, u8 func_no,
+			   int bar, u64 phys);
+void program_ob_windows_ep(struct mobiveil_pcie *pcie, u8 func_num, int win_num,
+			   u64 cpu_addr, u64 pci_addr, u32 type, u64 size);
+void mobiveil_pcie_disable_ib_win_ep(struct mobiveil_pcie *pci,
+				     u8 func_no, u8 bar);
+void mobiveil_pcie_disable_ob_win(struct mobiveil_pcie *pcie, int win_num);
+int mobiveil_pcie_ep_init(struct mobiveil_pcie_ep *ep);
+int mobiveil_pcie_ep_raise_legacy_irq(struct mobiveil_pcie_ep *ep, u8 func_no);
+int mobiveil_pcie_ep_raise_msi_irq(struct mobiveil_pcie_ep *ep, u8 func_no,
+				   u8 interrupt_num);
+int mobiveil_pcie_ep_raise_msix_irq(struct mobiveil_pcie_ep *ep, u8 func_no,
+				    u16 interrupt_num);
+void mobiveil_pcie_ep_reset_bar(struct mobiveil_pcie *pci, u8 bar);
+u8 mobiveil_pcie_ep_get_bar_num(struct mobiveil_pcie_ep *ep, u8 func_no);
+void mobiveil_pcie_enable_bridge_pio(struct mobiveil_pcie *pci);
+void mobiveil_pcie_enable_engine_apio(struct mobiveil_pcie *pci);
+void mobiveil_pcie_enable_engine_ppio(struct mobiveil_pcie *pci);
+void mobiveil_pcie_enable_msi_ep(struct mobiveil_pcie *pci);
 #endif /* _PCIE_MOBIVEIL_H */
diff --git a/drivers/pci/pcie/err.c b/drivers/pci/pcie/err.c
index c543f419d..4a2735b70 100644
--- a/drivers/pci/pcie/err.c
+++ b/drivers/pci/pcie/err.c
@@ -165,8 +165,29 @@ pci_ers_result_t pcie_do_recovery(struct pci_dev *dev,
 	pci_dbg(dev, "broadcast error_detected message\n");
 	if (state == pci_channel_io_frozen) {
 		pci_walk_bus(bus, report_frozen_detected, &status);
+		/*
+		 * After resetting the link using reset_link() call, the
+		 * possible value of error status is either
+		 * PCI_ERS_RESULT_DISCONNECT (failure case) or
+		 * PCI_ERS_RESULT_NEED_RESET (success case).
+		 * So ignore the return value of report_error_detected()
+		 * call for fatal errors.
+		 *
+		 * In EDR mode, since AER and DPC Capabilities are owned by
+		 * firmware, reported_error_detected() will return error
+		 * status PCI_ERS_RESULT_NO_AER_DRIVER. Continuing
+		 * pcie_do_recovery() with error status as
+		 * PCI_ERS_RESULT_NO_AER_DRIVER will report recovery failure
+		 * irrespective of recovery status. But successful reset_link()
+		 * call usually recovers all fatal errors. So ignoring the
+		 * status result of report_error_detected() also helps EDR based
+		 * error recovery.
+		 */
 		status = reset_link(dev);
-		if (status != PCI_ERS_RESULT_RECOVERED) {
+		if (status == PCI_ERS_RESULT_RECOVERED) {
+			status = PCI_ERS_RESULT_NEED_RESET;
+		} else {
+			status = PCI_ERS_RESULT_DISCONNECT;
 			pci_warn(dev, "link reset failed\n");
 			goto failed;
 		}
@@ -182,10 +203,22 @@ pci_ers_result_t pcie_do_recovery(struct pci_dev *dev,
 
 	if (status == PCI_ERS_RESULT_NEED_RESET) {
 		/*
-		 * TODO: Should call platform-specific
-		 * functions to reset slot before calling
-		 * drivers' slot_reset callbacks?
+		 * TODO: Optimize the call to pci_reset_bus()
+		 *
+		 * There are two components to pci_reset_bus().
+		 *
+		 * 1. Do platform specific slot/bus reset.
+		 * 2. Save/Restore all devices in the bus.
+		 *
+		 * For hotplug capable devices and fatal errors,
+		 * device is already in reset state due to link
+		 * reset. So repeating platform specific slot/bus
+		 * reset via pci_reset_bus() call is redundant. So
+		 * can optimize this logic and conditionally call
+		 * pci_reset_bus().
 		 */
+		pci_reset_bus(dev);
+
 		status = PCI_ERS_RESULT_RECOVERED;
 		pci_dbg(dev, "broadcast slot_reset message\n");
 		pci_walk_bus(bus, report_slot_reset, &status);
diff --git a/drivers/pci/pcie/portdrv_core.c b/drivers/pci/pcie/portdrv_core.c
index 3779b264d..de31ed449 100644
--- a/drivers/pci/pcie/portdrv_core.c
+++ b/drivers/pci/pcie/portdrv_core.c
@@ -37,6 +37,20 @@ static void release_pcie_device(struct device *dev)
 	kfree(to_pcie_device(dev));
 }
 
+/**
+ * pcibios_check_service_irqs - check irqs in the device tree
+ * @dev: PCI Express port to handle
+ * @irqs: Array of irqs to populate
+ * @mask: Bitmask of port capabilities returned by get_port_device_capability()
+ *
+ * Return value: 0 means no service irqs in the device tree
+ *
+ */
+int __weak pcibios_check_service_irqs(struct pci_dev *dev, int *irqs, int mask)
+{
+	return 0;
+}
+
 /*
  * Fill in *pme, *aer, *dpc with the relevant Interrupt Message Numbers if
  * services are enabled in "mask".  Return the number of MSI/MSI-X vectors
@@ -165,10 +179,25 @@ static int pcie_port_enable_irq_vec(struct pci_dev *dev, int *irqs, int mask)
 static int pcie_init_service_irqs(struct pci_dev *dev, int *irqs, int mask)
 {
 	int ret, i;
+	int irq = -1;
 
 	for (i = 0; i < PCIE_PORT_DEVICE_MAXSERVICES; i++)
 		irqs[i] = -1;
 
+	/* Check if some platforms owns independent irq pins for AER/PME etc.
+	 * Some platforms may own independent AER/PME interrupts and set
+	 * them in the device tree file.
+	 */
+	ret = pcibios_check_service_irqs(dev, irqs, mask);
+	if (ret) {
+		if (dev->irq)
+			irq = dev->irq;
+		for (i = 0; i < PCIE_PORT_DEVICE_MAXSERVICES; i++)
+			if (irqs[i] == -1)
+				irqs[i] = irq;
+		return 0;
+	}
+
 	/*
 	 * If we support PME but can't use MSI/MSI-X for it, we have to
 	 * fall back to INTx or other interrupts, e.g., a system shared
diff --git a/drivers/pci/quirks.c b/drivers/pci/quirks.c
index bb863ddb5..cb0768fb5 100644
--- a/drivers/pci/quirks.c
+++ b/drivers/pci/quirks.c
@@ -2524,6 +2524,9 @@ DECLARE_PCI_FIXUP_FINAL(PCI_VENDOR_ID_VIA, PCI_DEVICE_ID_VIA_VT3351, quirk_disab
 DECLARE_PCI_FIXUP_FINAL(PCI_VENDOR_ID_VIA, PCI_DEVICE_ID_VIA_VT3364, quirk_disable_all_msi);
 DECLARE_PCI_FIXUP_FINAL(PCI_VENDOR_ID_VIA, PCI_DEVICE_ID_VIA_8380_0, quirk_disable_all_msi);
 DECLARE_PCI_FIXUP_FINAL(PCI_VENDOR_ID_SI, 0x0761, quirk_disable_all_msi);
+DECLARE_PCI_FIXUP_EARLY(PCI_VENDOR_ID_MARVELL_EXT, 0x2b42, quirk_disable_all_msi);
+DECLARE_PCI_FIXUP_EARLY(PCI_VENDOR_ID_MARVELL_EXT, 0x2b43, quirk_disable_all_msi);
+DECLARE_PCI_FIXUP_EARLY(PCI_VENDOR_ID_MARVELL_EXT, 0x2b44, quirk_disable_all_msi);
 
 /* Disable MSI on chipsets that are known to not support it */
 static void quirk_disable_msi(struct pci_dev *dev)
